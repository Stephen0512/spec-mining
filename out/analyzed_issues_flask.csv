ISSUE_LINK,AI_VERDICT,REASON,LIBRARY_NAME,API_NAME,ISSUE_DESCRIPTION,NORMAL_CONDITIONS,TRIGGER_CONDITIONS,REASON_FOR_DIFFICULTY_IN_DETECTION,ISSUE_TITLE,ISSUE_BODY,ANSWER_1,ANSWER_2,ANSWER_3,HUMAN_CLASSIFICATION,HUMAN_REASON,ISSUE_SCORE,ISSUE_VIEWS
https://stackoverflow.com/questions/16544238,false,The issue does not meet the criteria for deeper analysis as it does not involve unexpected behavior or failures of a specific API.,,,,,,,How does Flask knows which decorated function to call?,"So I'm going through the basic Flask tutorial, and looking at their code there's this snippet:

 @app.teardown_appcontext
 def close_db_connection(exception):
    """"""Closes the database again at the end of the request.""""""
    top = _app_ctx_stack.top
    if hasattr(top, 'sqlite_db'):
        top.sqlite_db.close()


Now, for what I've read in their manual, the function ""app.teardown_appcontext"" is called whenever one of the callbacks has an unexpected behavior. Decorating a function with it allows you to add functionality to the original function. Or at least that's what I understand from decorators. But, if I do this:

@app.teardown_appcontext
def stack_overflow_rocks(exception):
    """"""Closes the database again at the end of the request.""""""
    top = _app_ctx_stack.top
    if hasattr(top, 'sqlite_db'):
        top.sqlite_db.close()


It still works. How does Flask manages this? 

My guess is that when I run the ""flaskr.py"" file with all the main code, it associates whatever decorated function with their code to call it when necessary. I tried reading a lot of sources about decorator to see if my interpretation is wrong, but could not find any mistake.
","As you can see in the code, the decorator adds the function you decorate with it to a list of functions (self.teardown_appcontext_funcs) on a Flask object instance (app in your case).  This list is then iterated over in reverse order when the appcontext is torn down, with each function being passed the exception triggering the teardown, or a placeholder exception if none was raised.  This happens in Flask.do_teardown_appcontext().
",,,false,,,
https://stackoverflow.com/questions/37017218,false,"The issue does not meet the criteria for deeper analysis as it is related to the behavior of logical operators in pandas, rather than an API-related problem.",,,,,,,How to design Flask URL path with &#39;/&#39;,"In my first Flask application, I am experimenting with URLs that end with a slash vs. those that don't and am seeing some unexpected browser behavior.


My view function is just like this:

@app.route('/hello')
def hello_world():
    return 'Hello World!'


Then I can go to 127.0.0.1:5000/hello and see ""Hello World"".
I change the URL to:

@app.route('/hello/')
def hello_world():
    return 'Hello World!'


Then I can go to 127.0.0.1:5000/hello but the browser redirects to 127.0.0.1:5000/hello/.
I change the URL back to /hello:

@app.route('/hello')
def hello_world():
    return 'Hello World!'



Then I can not access either /hello or /hello/. When I visit 127.0.0.1:5000/hello, the browser still redirects to 127.0.0.1:5000/hello/ and the response is a 404. I cannot see anything unless I rollback to step 2.

What is going on?
","Quoting from a (slightly modified) section of the docs:


  Unique URLs / Redirection Behavior
  
  Though [your rules] look rather similar, they differ in their use of the trailing slash in the URL definition. In [your step #2], the canonical URL for the [hello_world] endpoint has a trailing slash. In that sense, it is similar to a folder on a file system. Accessing it without a trailing slash will cause Flask to redirect to the canonical URL with the trailing slash.


What this means is that Flask in step #2 will redirect the /hello URL using a 301 Moved redirect.  This is a permanent redirect and most browsers will cache it.  This is why, even when you change your code (in step #3) the browser will still request /hello/ even though you asked for /hello (since when it did so for step #2 Flask told it that /hello has moved to /hello/.)

The simplest solution in such cases is to clear your browser's cache - that removes the ""memory"" of the redirect and things will work again.

Personally, I use /directory/ style URLs for resources which would be expected to contain other resources and /leaf for resources which have no further sub-resources.
",,,false,,,
https://stackoverflow.com/questions/59493009,true,The issue involves Flask ignoring the Cache-Control header. Further analysis is required to identify the specific API or framework responsible for this behavior.,,,,,,,Why is Flask ignoring Cache-Control?,"I am running a Flask application that includes an hourly process which updates a json variable in memory, and includes that variable in its response template. I've encountered the following unexpected behavior:


Initial visits to the web page show the data that was instantiated when the server was initiated only. The most recent hourly update of the data is ignored.
Rapidly hitting reload 5-10 times will bring the browser up-to-date and show the most recent json data (reloading just once or twice has no effect).
After the browser shows the most recent data, hitting reload again will revert back to the initial update as though it were cached.


Server Code:

data = None 
def updatejson():

    global data
    data = redditapi()

updatejson()

scheduler = BackgroundScheduler()
scheduler.add_job(func=updatejson, trigger=""interval"", minutes=60)
scheduler.start()
atexit.register(lambda: scheduler.shutdown())

app = Flask(__name__)
app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 0

@app.route(""/"")
def hello():
    global data
    return render_template('index.html', data=data)

@app.after_request
def add_header(r):
    r.headers[""Cache-Control""]  = ""no-store""
    return r

if __name__ == ""__main__"":
    app.run(host='0.0.0.0')


I have also tried setting the headers below, but same behavior:

    r.headers[""Cache-Control""] = ""no-cache, no-store, must-revalidate, public, max-age=0'""
    r.headers[""Pragma""] = ""no-cache""
    r.headers[""Expires""] = ""0""


The index.html template also has this meta:

&lt;meta http-equiv=""Cache-Control"" content=""no-cache, no-store, must-revalidate"" /&gt;
&lt;meta http-equiv=""Pragma"" content=""no-cache"" /&gt;
&lt;meta http-equiv=""Expires"" content=""0"" /&gt;


Confirmed response headers are correct on client side:

Cache-Control:no-store
Connection:keep-alive
Content-Encoding:gzip
Content-Type:text/html; charset=utf-8
Date:Thu, 26 Dec 2019 19:49:15 GMT
Server:nginx/1.14.0 (Ubuntu)
Transfer-Encoding:chunked


Edit:
curl -I reports the following:

HTTP/1.1 301 Moved Permanently
Server: nginx/1.14.0 (Ubuntu)
Date: Thu, 26 Dec 2019 22:24:29 GMT
Content-Type: text/html
Content-Length: 194
Connection: keep-alive
Location: https://pcsalesapp.com/


Tried adding expires -1 and Cache Control to Nginx but behavior persists:

location / {
    expires -1;
    add_header Cache-Control ""no-store"";
    include uwsgi_params;
    uwsgi_pass unix:/home/jv/pcsalesapp/pcsalesapp.sock;
}


Do I need to address this in uwsgi as well?
","This right way to set cache-control for your case is:
@app.after_request
def add_header(r):
    r.headers[""Cache-Control""]  = ""no-store max-age=0""
    return r

no-store will only prevent new resource from being cached, but it will not prevent the cache from responding with a resource from an earlier request. Setting max-age=0 will force the cache to revalidate.
Also, setting cache-control the following way is a bad way to achieve this, and that's why it didn't work:
r.headers[""Cache-Control""] = ""no-cache, no-store, must-revalidate, public, max-age=0'""
",,,false,,,
https://stackoverflow.com/questions/59776874,false,"The issue does not meet the criteria for deeper analysis as it is related to logging duplication caused by Plotly dashboards, rather than an API-related problem.",,,,,,,Flask log entries duplicated when using Plotly dashboards,"I'm seeing unexpected behavior when introducing Plotly dashboards into my Flask application. Each Plotly dashboard causes Flask log entries to be duplicated. 

For example, if I attach two Plotly dashboards to my Flask application, log entries (e.g. current_app.logger.info('hi')) will appear three times in my logs. If I remove the Plotly dashboards, the log entry appears once, which is the expected behavior.

I've tried removing existing handlers in my logging config code via app.logger.handlers.clear() and by setting dictConfig's disable_existing_loggers to True, both of which result in nothing being logged. I've also tried using the singleton approach to configuring the logger (again, using dictConfig) and I still see the log entries repeated multiple times.

How can I prevent Plotly dashboards from causing duplicate log entries?

UPDATE:

Here's a simplified version of how Dash apps are being initialized:

def register_dashapp(app):
    from dashboards.dash_files.my_dash import (
        define_layout,
        define_callbacks,
    )
    my_dashapp = dash.Dash(__name__,
                         server=app,
                         url_base_pathname='/my_dash/',
                         assets_folder=""../dashboards/foo/bar/assets"",
                         )
    with app.app_context():
        my_dashapp.title = ""Test""
        define_layout(my_dashapp)
        define_callbacks(my_dashapp)

def create_app():
    app = Flask(__name__, instance_relative_config=False)
    app.config.from_object('config.Config')

    with app.app_context():
        register_extensions(app)
        app.register_blueprint(main)
        register_dash_app(app)
        return app

","I was having a log duplication issue and solved it using the same HasHandlers logic, however I call logs in a slight different way. This requires the python arrow library, which I find superior to datetime in most use cases.
I define the site_logger in my main app.py or _init_.py file.
# define logger
def site_logger(log_name):
    now = arrow.now('US/Eastern').format('YYYY_MM_DD')
    handler = logging.FileHandler('logs/' + log_name + '_' + now + '.log')
    formatter = logging.Formatter('%(asctime)s %(levelname)s %(name)s: %(message)s')
    handler.setFormatter(formatter)
    logger = logging.getLogger(log_name)
    logger.setLevel(""DEBUG"")
    if logger.hasHandlers():
        logger.handlers.clear()
    logger.addHandler(handler)
    logger.propagate = False
    return logger

I then call the logger in the following way in any views.py file or function, you can also pass the logger into a function you call in a views.py, keeping logs results of a function in the correct page file it was called from.
from app import site_logger
logger = site_logger('page_name')

I can then log events in the usual way. Two examples are below, and using f strings in logger is a great way to easily pass vars into log data.
logger.info(f'{user} logged in successfully')
logger.warning(f'{user} password failure!')

This will provide uniformly named log handlers and log files you can more easily trace back to the page or function call made. The date formatted files should auto rotate when the arrow.now('timezome') value rotates to the next day.
","I was able to work around this by removing the logging handler added by the Dash library.

my_dash = dash.Dash(__name__,
    server=app,
    url_base_pathname='/my_dash/',
    assets_folder=""../dashboards/foo/bar/assets""
)

if (my_dash.logger.hasHandlers()):
    my_dash.logger.handlers.clear()


There doesn't appear to be any downside to doing this, but it is possible I'm overlooking something and I'd be interested to see if anyone else has a better approach. I'll hold off on accepting my own answer for a few more days.

On a related note, I'd think this would be configurable via the Dash constructor. I'd also be curious to know if anyone has thoughts about that. I may open a ticket with the project to see what they think about the possibility.
","if not DashboardDAO.validate_create_title(dashboard_title, unique()):
      exceptions.append(DashboardTitleExistsValidationError())
   

",false,,,
https://stackoverflow.com/questions/71386613,false,"The issue does not meet the criteria for deeper analysis as it is related to the usage of lru_cache in Flask, rather than an API-related problem.",,,,,,,lru caching not working between application runs for same argument on Flask App,"*Edit: just realized I made a mistake in my function design where I re-instantiated the AppDAO in my Class1 function and that is what was causing the unexpected behavior. I figured it out by printing the self argument in cache_call.
I have a Flask App with the following design:
 from flask import Flask, request
 from Class1 import Class1
 from AppDAO import AppDAO
 
 app = Flask(__name__)

 def main():
   app.config['appDAO'] = AppDAO()
   app.run()

 @app.route('/app_route1',methods=['POST'])
 def app_route1():
     print(""Running app route 1..."")
     print(app.config['appDAO'].cache_call.cache_info())
     
     cache_param = request.json.get('cached_parameter')
     print(""The cached parameter is: %s."" % cache_param)

     class1 = Class1(app.config['appDAO'])

     for item in ['item1', 'item2']:
           class1.do_processing(item,cache_param)

Class1.py:
class Class1(object):
   def __init__(self, app_dao):
     self.app_dao = app_dao

   def do_processing(self, item, cache_param):
        print(""Processing for item: %s..."" % item)

        resp_cache = self.app_dao.cache_call(cache_param)
        print(self.app_dao.cache_call.cache_info())
        
        return resp_cache

AppDAO.py:
from functools import lru_cache
import mysql.connector 

class AppDAO(object):
  
  def __init__():
      self.conn = mysql.connector.connect('user1','password1','server1','database')
  
  @lru_cache(maxsize=4)
  def cache_call(self, cache_param):
     print(""Running cache call with parameter: %s..."" % cache_param)

     cursor = self.conn.cursor()
     cursor.execute(""SELECT * FROM Table1 WHERE Column1 = `%s`;"" % cache_param)
     rs = cursor.fetchall()

     return rs
       

If I run the app making a post, the AppDAO.cache_call functions correctly with the following output print output:
 Running app route 1...
 CacheInfo(hits=0, misses=0, maxsize=4, currsize=0)
 Processing items: item1...
 Running cache call with parameter: foo1...
 CacheInfo(hits=0, misses=1, maxsize=4, currsize=1)
 Processing items: item2...
 CacheInfo(hits=1, misses=1, maxsize=4, currsize=1)

But I make another post to the branch using the same parameter for the cache_call, I get the following print output:
 Running app route 1...
 CacheInfo(hits=1, misses=1, maxsize=4, currsize=1)
 Processing items: item1...
 Running cache call with parameter: foo1...
 CacheInfo(hits=1, misses=2, maxsize=4, currsize=2)
 Processing items: item2...
 CacheInfo(hits=2, misses=2, maxsize=4, currsize=2)
  

I run the app using the Anaconda QT Console, but I experience the following caching issue if I used an Anaconda Command Prompt as well. Can anyone speculate why the lru_cache is not working when a new post is made to the app despite the cached call still clearing being stored?
","Note that
@lru_cache(maxsize=4)
def cache_call(self, cache_param):

is wrapping a method, not a function. In your example, self, which will be used as as part of the cache key, is an instance of Class1 and is created once per route handler invocation. The result is that you aren't getting the caching you expect.
Updated: I misread the code. Assuming that
for item in [item1, item2]:

was a typo, and should be
for item in ['item1', 'item2']:

and that you're do_processing is intentionally not passing item (which varies) to cache_call, then what you're seeing is consistent with how lru_cache behaves.
On first request, it's going to add one thing (request.json.get('cached_parameter')) to the cache, scoring it as a miss the for 'item1' and a hit for 'item2'.
On second request, request.json.get('cached_parameter') is a different object. It gets scored as a miss for 'item1', added (increasing 'currsize' to 2). For 'item2', it gets scored as a hit.
What behavior did you expect?
Unrelated but worth mentioning: The way you're constructing that query leaves you open to SQL Injection attacks. Consider using a bind parameter instead.
",,,false,,,
https://stackoverflow.com/questions/70429054,false,"The issue does not meet the criteria for deeper analysis as it is related to the connection between a React Native frontend and a Flask backend, rather than an API-related problem.",,,,,,,Not receiving on React-Native frontend from Flask backend,"I'm new to React Native and trying to build an app. I'm confused on how exactly to ""connect"" the backend and frontend. I have added a proxy in package.json as most tutorials state:
{
  ""name"": ""frontend"",
  ""version"": ""1.0.0"",
  ""main"": ""node_modules/expo/AppEntry.js"",
  ""proxy"": ""http://127.0.0.1:5000"",
  ""scripts"": {
    ""start"": ""expo start"",
    ""android"": ""expo start --android"",
    ""ios"": ""expo start --ios"",
    ""web"": ""expo start --web"",
    ""eject"": ""expo eject""
  },
  ""dependencies"": {
    ""expo"": ""~44.0.0"",
    ""expo-status-bar"": ""~1.2.0"",
    ""react"": ""17.0.1"",
    ""react-dom"": ""^17.0.1"",
    ""react-native"": ""0.64.3"",
    ""react-native-web"": ""^0.17.1""
  },
  ""devDependencies"": {
    ""@babel/core"": ""^7.12.9""
  },
  ""private"": true
}

I also have these two functions:
import React, {useEffect, useState} from 'react';
import test from './components/Home';

function App() {
  test();
  return (
    &lt;div&gt; &lt;/div&gt;
  )
}

export default App;

import React, {useEffect, useState} from 'react';

function test() {
    useEffect(() =&gt; {
        fetch(""/"")
        .then(response =&gt; response.json()
        .then(data =&gt; {
            console.log(data)
        })
    )}, []);
}

export default test;

Right now, I'm just trying to print out the data in the console to see if the data is actually be received correctly (it's not) as I am getting an Uncaught (in promise) SyntaxError: JSON.parse: unexpected character at line 1 column 1 of the JSON data error in the console.
however, the data I am trying to get printed out comes from my backend which currently looks like this:
from flask import Flask

app = Flask(__name__)

# API Routes
@app.route(""/"", methods=[""GET""])
def home():
    return {""TEST"": [""1"", ""2"", ""3""]}

if __name__ == ""__main__"":
    app.run(debug=True)

Going back to my test function in the JS file, if I change response.json() to response.text(), the error goes away but the console logs this:
&lt;!DOCTYPE html&gt;
&lt;html lang=""en""&gt;
  &lt;head&gt;
    &lt;meta charset=""utf-8"" /&gt;
    &lt;meta httpEquiv=""X-UA-Compatible"" content=""IE=edge"" /&gt;
    &lt;!-- 
      This viewport works for phones with notches.
      It's optimized for gestures by disabling global zoom.
     --&gt;
    &lt;meta
      name=""viewport""
      content=""width=device-width, initial-scale=1, minimum-scale=1, maximum-scale=1.00001, viewport-fit=cover""
    /&gt;
    &lt;title&gt;portfolio&lt;/title&gt;
    &lt;style&gt;
      /**
       * Extend the react-native-web reset:
       * https://github.com/necolas/react-native-web/blob/master/packages/react-native-web/src/exports/StyleSheet/initialRules.js
       */
      html,
      body,
      #root {
        width: 100%;
        /* To smooth any scrolling behavior */
  ... and much more HTML

So it seems like I'm not receiving data from my backend. Is there something obvious I am missing? Thanks
","You must configure Cross-origin to allow flask to receive the request from react.
from flask import Flask
from flask_cors import CORS

app = Flask(__name__)
# enable CORS
CORS(app, resources={r'/*': {'origins': '*'}})

# API Routes
@app.route(""/"", methods=[""GET""])
def home():
    return {""TEST"": [""1"", ""2"", ""3""]}

if __name__ == ""__main__"":
    app.run(debug=True)

For more details on the subject : flask-cors
",,,false,,,
https://stackoverflow.com/questions/16528679,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Unit test a Flask session - cannot reproduce failure with session_transaction,"I am testing a Flask application (Flask 0.9), and in particular I have a session fixture that I would like to run in the documented-way, being something like this (as I understand it):

from flask import Flask, session
app = Flask(__name__)

@app.route('/', methods=['POST'])
def m():
    logging.error(session) # expect {'x': 1}
    return """"

with app.test_request_context() as trc:
  with app.test_client() as c:
    with c.session_transaction() as sess:
      sess['x'] = 1
    c.post()


This works as expected, with the output being something like this:

ERROR:root:&lt;SecureCookieSession {'x': 1}&gt;


Unfortunately I am encountering an unexpected result where the session data is not set in the endpoint function, i.e. the output is something like this:

ERROR:root:&lt;SecureCookieSession {}&gt;


This issue exhibits only when run from my unit testing framework. As it stands, I am unable to reproduce this problem with a degenerate case, though I have made a fairly substantial effort with a gist of some of this effort here. The salient points being that I have included itsdangerous and Google App Engine testbed, expecting maybe one of them to have been the cause.

On my own system I have gone further than the gist, and almost completely replicated my unit test framework trying to isolate this. Likewise, I have removed ever-increasing amounts of relevant code from my testing framework. To the point, I am unable to think of differences between the degenerate case and my stripped-down framework that could influence the outcome. I have traversed the c.post() call in pdb to try eek out the cause of this malignity, but have yet to glean any useful insight.

Which is all to say, I would be grateful for a little direction or suggestion as to where the issue may lie. What could possibly be influencing the Werkzeug context in such a way that the session_transaction is not being honoured?
","I hate to resurrect an old question, but I believe that I figured out the solution to this issue. For testing, try setting your server name to localhost:

app.config['SERVER_NAME'] = 'localhost'


I was originally using Brian's hack, but this solved the problem for me.
",,,false,,,
https://stackoverflow.com/questions/73731239,false,The issue does not meet the criteria for deeper analysis as it is related to test setup and configuration rather than an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,How to prevent &#39;Microsoft.VisualStudio.TestPlatform.ObjectModel.TestPlatformException: Could not find testhost&#39; exception,"I have a .NET 6.0 solution I use for automated UI testing of a web application. This solution consists of a number of projects, one of which contains all the tests, another being the logging implementation for the tests, and the others for other miscellaneous dependencies the framework has.
The project containing the tests uses NUnit as the test framework - it has the NuGet packages NUnit (3.13.3) and NUnit3TestAdapter (4.2.1). The logging project also includes the NUnit package because it uses the NUnit.Framework.TestContext to write out logs to the context of each test running.
I am using VS 2022 for the development of this solution. When I perform a build of the solution it will tell me the build succeeded (briefly flashing up in the bottom right) before immediately saying ""Unexpected error detected. Check the Tests Output Pane for details."". If I check that I can see:
Test project MyNamespace.Logging does not reference any .NET NuGet adapter. Test discovery or execution might not work for this project.
It's recommended to reference NuGet test adapters in each test project in the solution.
========== Starting test discovery ==========
Microsoft.VisualStudio.TestPlatform.ObjectModel.TestPlatformException: Could not find testhost
   at Microsoft.VisualStudio.TestPlatform.CrossPlatEngine.Hosting.DotnetTestHostManager.GetTestHostProcessStartInfo(IEnumerable`1 sources, IDictionary`2 environmentVariables, TestRunnerConnectionInfo connectionInfo)
   at Microsoft.VisualStudio.TestPlatform.CrossPlatEngine.Client.ProxyOperationManager.SetupChannel(IEnumerable`1 sources, String runSettings)
   at Microsoft.VisualStudio.TestPlatform.CrossPlatEngine.Client.ProxyDiscoveryManager.DiscoverTests(DiscoveryCriteria discoveryCriteria, ITestDiscoveryEventsHandler2 eventHandler)
NUnit Adapter 4.2.0.0: Test discovery starting
NUnit Adapter 4.2.0.0: Test discovery complete
========== Test discovery aborted: 60 Tests found in 1 sec ==========

So it's complaining that there is no test adaptor for my logging project. Of course I do not want or need an adaptor for this project as it legitimately contains no tests. Just to try and make some progress I installed the same NUnit adaptor as my test project uses. The error in the Test Output Pane then reduces to:
========== Starting test discovery ==========
Microsoft.VisualStudio.TestPlatform.ObjectModel.TestPlatformException: Could not find testhost
   at Microsoft.VisualStudio.TestPlatform.CrossPlatEngine.Hosting.DotnetTestHostManager.GetTestHostProcessStartInfo(IEnumerable`1 sources, IDictionary`2 environmentVariables, TestRunnerConnectionInfo connectionInfo)
   at Microsoft.VisualStudio.TestPlatform.CrossPlatEngine.Client.ProxyOperationManager.SetupChannel(IEnumerable`1 sources, String runSettings)
   at Microsoft.VisualStudio.TestPlatform.CrossPlatEngine.Client.ProxyDiscoveryManager.DiscoverTests(DiscoveryCriteria discoveryCriteria, ITestDiscoveryEventsHandler2 eventHandler)
NUnit Adapter 4.2.0.0: Test discovery starting
NUnit Adapter 4.2.0.0: Test discovery complete
========== Test discovery aborted: 60 Tests found in 1.1 sec ==========

So installing the package clears the first part of it (but of course I don't really want to install it). I then had a read of the NUnit docs and found the NonTestAssembly attribute which seemed like it might be what I needed. I created an AssemblyInfo.cs file and added it in to the root of my logging project and then added the line [assembly: NUnit.Framework.NonTestAssembly] within it. Rebuilt the solution but the error remains as above. Does anyone know what I can do to get VS to be happy with this? Its frustrating as it shows the conical flask icon over my logging project which isn't ideal and then also makes it harder to see the 'Build succeeded' message as it's quickly overridden with the error.
Am I wrong to use the NUnit package as I am doing?
","I had this same problem, but it went away when I added the Microsoft.NET.Test.Sdk package.
","This error can also occur if you have got a filter applied to your tests. Removing the filter (CTRL+D, CTRL+F) fixes the issue.

",,false,,,
https://stackoverflow.com/questions/60740315,true,The issue involves an unexpected behavior in the marshmallow library's _deserialize function when a keyword argument 'partial' is provided. This API-related issue can lead to a TypeError and requires further analysis.,,,,,,,TypeError: _deserialize() got an unexpected keyword argument &#39;partial&#39; in marshmallow,"I'm trying image upload API i'm getting the following error

127.0.0.1  ""POST //upload/image HTTP/1.1"" 500 -
Traceback (most recent call last):
  File ""D:\c_code\projects\python_api\.venv\lib\site-packages\flask\app.py"", line 2463, in __call__
    return self.wsgi_app(environ, start_response)
  File ""D:\c_code\projects\python_api\.venv\lib\site-packages\flask\app.py"", line 2449, in wsgi_app
    response = self.handle_exception(e)
  File ""D:\c_code\projects\python_api\.venv\lib\site-packages\flask_cors\extension.py"", line 161, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File ""D:\c_code\projects\python_api\.venv\lib\site-packages\flask_restful\__init__.py"", line 272, in error_router
    return original_handler(e)
  File ""D:\c_code\projects\python_api\.venv\lib\site-packages\flask\app.py"", line 1866, in handle_exception
    reraise(exc_type, exc_value, tb)
  File ""D:\c_code\projects\python_api\.venv\lib\site-packages\flask\_compat.py"", line 38, in reraise
    raise value.with_traceback(tb)
  File ""D:\c_code\projects\python_api\.venv\lib\site-packages\flask\app.py"", line 2446, in wsgi_app
    response = self.full_dispatch_request()
  File ""D:\c_code\projects\python_api\.venv\lib\site-packages\flask\app.py"", line 1951, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File ""D:\c_code\projects\python_api\.venv\lib\site-packages\flask_cors\extension.py"", line 161, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File ""D:\c_code\projects\python_api\.venv\lib\site-packages\flask_restful\__init__.py"", line 272, in error_router
    return original_handler(e)
  File ""D:\c_code\projects\python_api\.venv\lib\site-packages\flask\app.py"", line 1820, in handle_user_exception
    reraise(exc_type, exc_value, tb)
  File ""D:\c_code\projects\python_api\.venv\lib\site-packages\flask\_compat.py"", line 38, in reraise
    raise value.with_traceback(tb)
  File ""D:\c_code\projects\python_api\.venv\lib\site-packages\flask\app.py"", line 1949, in full_dispatch_request
    rv = self.dispatch_request()
  File ""D:\c_code\projects\python_api\.venv\lib\site-packages\flask\app.py"", line 1935, in dispatch_request
    return self.view_functions[rule.endpoint](**req.view_args)
  File ""D:\c_code\projects\python_api\.venv\lib\site-packages\flask_restful\__init__.py"", line 468, in wrapper
    resp = resource(*args, **kwargs)
  File ""D:\c_code\projects\python_api\.venv\lib\site-packages\flask\views.py"", line 89, in view
    return self.dispatch_request(*args, **kwargs)
  File ""D:\c_code\projects\python_api\.venv\lib\site-packages\flask_restful\__init__.py"", line 583, in dispatch_request
    resp = meth(*args, **kwargs)
  File ""D:\c_code\projects\python_api\.venv\lib\site-packages\flask_jwt_extended\view_decorators.py"", line 108, in wrapper
    return fn(*args, **kwargs)
  File ""D:\c_code\projects\python_api\resources\image.py"", line 24, in post
    data = image_schema.load(request.files)
  File ""D:\c_code\projects\python_api\.venv\lib\site-packages\marshmallow\schema.py"", line 723, in load
    data, many=many,  unknown=unknown, postprocess=True
  File ""D:\c_code\projects\python_api\.venv\lib\site-packages\marshmallow\schema.py"", line 861, in _do_load
    unknown=unknown,
  File ""D:\c_code\projects\python_api\.venv\lib\site-packages\marshmallow\schema.py"", line 669, in _deserialize
    index=index,
  File ""D:\c_code\projects\python_api\.venv\lib\site-packages\marshmallow\schema.py"", line 493, in _call_and_store
    value = getter_func(data)
  File ""D:\c_code\projects\python_api\.venv\lib\site-packages\marshmallow\schema.py"", line 662, in &lt;lambda&gt;
    val, field_name, data, **d_kwargs
  File ""D:\c_code\projects\python_api\.venv\lib\site-packages\marshmallow\fields.py"", line 342, in deserialize
    output = self._deserialize(value, attr, data, **kwargs)
TypeError: _deserialize() got an unexpected keyword argument 'partial'



The code of File ""D:\c_code\projects\python_api\resources\image.py"", line 24, in post is the following

from marshmallow import Schema, fields
from werkzeug.datastructures import FileStorage

from marshmallow import Schema, fields
from werkzeug.datastructures import FileStorage


class FileStorageField(fields.Field):
    default_error_messages = {
        ""invalid"": ""Not a valid image.""
    }

    def _deserialize(self, value, attr, data) -&gt; FileStorage:
        if value is None:
            return None

        if not isinstance(value, FileStorage):
            self.fail(""invalid"")

        return value


class ImageSchema(Schema):
    image = FileStorageField(required=True)


The code is working fine when call the API image upload it is raising error.
I'm using flask marshmallow, Flask uploads, packages.
","Since marshmallow 3, _deserialize may receive partial kwarg.

Every custom field should copy Field._deserialize signature and accept unknown kwargs.

    def _deserialize(
        self,
        value: typing.Any,
        attr: typing.Optional[str],
        data: typing.Optional[typing.Mapping[str, typing.Any]],
        **kwargs
    ):


Change your code like this to accept kwargs silently:

    def _deserialize(self, value, attr, data, **kwargs) -&gt; FileStorage:
        if value is None:
            return None

",,,false,,,
https://stackoverflow.com/questions/58118481,true,"The issue involves an unexpected behavior in the Flask-Migrate extension where the 'migrate' attribute is None, leading to an AttributeError. This API-related issue requires further analysis.",,,,,,,Flask migration fails,"I'm making migrations in Flask using unsurprisingly Flask-Migrate.
once I execute python manage.py db init it creates directory migrations with initial migrations file. Then
I execute python manage.py db migrate and I get this:

...
...
target_metadata = current_app.extensions['migrate'].db.metadata
AttributeError: 'NoneType' object has no attribute 'metadata'


I understand from this output that 'migrate' is None hence I'm getting an attribute error.

models.py:

from sqlalchemy.sql import func
from project import db, bcrypt


class User(db.Model):
    __tablename__ = 'users'
    id = db.Column(db.Integer, primary_key=True, autoincrement=True)
    username = db.Column(db.String(128), nullable=False, unique=True)
    email = db.Column(db.String(128), nullable=False, unique=True)
    password = db.Column(db.String(255), nullable=False)
    active = db.Column(db.Boolean(), default=True, nullable=False)
    created_date = db.Column(db.DateTime, default=func.now(), nullable=False)

    def __init__(self, username, email, password):
        self.username = username
        self.email = email
        self.password = bcrypt.generate_password_hash(password).decode()

    def to_json(self):
        return {
            'id': self.id,
            'username': self.username,
            'email': self.email,
            'active': self.active,
        }


The question is why nothing is being passed to it ? I'm following a tutorial and I'm not supposed to have this error.

I've got this from similar topic:


  NoneType means that instead of an instance of whatever Class or Object
  you think you're working with, you've actually got None. That usually
  means that an assignment or function call up above failed or returned
  an unexpected result.


this is what I've found in env.py file in the migrations directory:

from flask import current_app
config.set_main_option('sqlalchemy.url',
                       current_app.config.get('SQLALCHEMY_DATABASE_URI'))
target_metadata = current_app.extensions['migrate'].db.metadata


current_app is being imported from Flask but doesn't contain the extension migrate from which I need to use the metadata.

There's no reason for it to be throwing None though because the extension is correctly initilised in __init__.py file:

...
...
from flask_migrate import Migrate

db = SQLAlchemy()
toolbar = DebugToolbarExtension()
cors = CORS()
migrate = Migrate()
bcrypt = Bcrypt()

def create_app(script_info=None):
    app = Flask(__name__)
    app_settings = os.getenv('APP_SETTINGS')
    app.config.from_object(app_settings)
    app.config.from_object('project.config.DevelopmentConfig')
    toolbar.init_app(app)
    cors.init_app(app)
    db.init_app(app)
    migrate.init_app(app)     #  &lt;--
    bcrypt.init_app(app)

    from project.api.users import users_blueprint
    app.register_blueprint(users_blueprint)

    @app.shell_context_processor
    def ctx():
        return {'app': app, 'db': db}

    return app

","I had a missing argument in the initialization of the migrate extension. Migrate takes in the app instance and the instance of db.

def create_app(script_info=None):
    app = Flask(__name__)
    app_settings = os.getenv('APP_SETTINGS')
    app.config.from_object(app_settings)
    app.config.from_object('project.config.DevelopmentConfig')
    toolbar.init_app(app)
    cors.init_app(app)
    db.init_app(app)
    migrate.init_app(app, db)     #  &lt;--
    bcrypt.init_app(app)

    from project.api.users import users_blueprint
    app.register_blueprint(users_blueprint)

    @app.shell_context_processor
    def ctx():
        return {'app': app, 'db': db}

    return app

",,,false,,,
https://stackoverflow.com/questions/76091836,false,The issue does not meet the criteria for deeper analysis as it is related to frontend JavaScript code and does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Displaying python list as dropdown on a flask web application,"I am trying to display a dropdown menu in a flask web application. I pass a python list as an input for the dropdown menu and I want to recieve the selected item back as the output on click of a submit button.
Here's my simple python backend:
from flask import Flask, render_template, json
app = Flask(__name__)

@app.route('/')
def index():    
    name = json.dumps(['Red', 'Blue', 'Orange', 'Yellow', 'Green'])
    return render_template('index2.html', name=name)

if __name__ == ""__main__"":
    app.run(debug=True, use_reloader=False)


And here's the frontend (index2.html):
&lt;!DOCTYPE html&gt;
&lt;html lang=""en""&gt;
&lt;head&gt;
    &lt;meta charset=""UTF-8""&gt;
    &lt;title&gt;Report Generation&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;  
    &lt;select id=""selectvalue""&gt;
    &lt;/select&gt;  
    &lt;script&gt;
        var selectvalue = document.getElementById(""selectvalue"");
        // const test = {{ name | tojson | safe }}
        const test = JSON.parse(""{{name}}"");
        for (var i=0;i&lt;test.length;i++)
        {
            var selection = document.createElement('OPTION');
            var txt = document.createTextNode(test[i]);
            selection.appendChild(txt);
            selection.setAttribute(""value"", test[i]);
            selectvalue.insertBefore(selection, selectvalue.lastChild);
        }
    &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;

I tried two methods, the second line (when uncommented) within  tag is giving me this error:
Uncaught SyntaxError: Unexpected token '{'
and trying the third line gives me this error:
Uncaught SyntaxError: Expected property name or '}' in JSON at position 1
at JSON.parse ()
Here's the output I want:
dropdown
Also, how do I recieve the selected item back to flask backend on click of a button?
Thanks in advance!
","Since you're using flask, take advantage of the jinja template to fill the dropdwon / select.
first send a list to the template rather than a json string.
loop over the items and write the template.
here is your modified code.
from flask import Flask, render_template, json
app = Flask(__name__)

@app.route('/')
def index():    
    name = ['Red', 'Blue', 'Orange', 'Yellow', 'Green']
    return render_template('index2.html', name=name)

if __name__ == ""__main__"":
    app.run(debug=True, use_reloader=False)

And here is the template
&lt;!DOCTYPE html&gt;
&lt;html lang=""en""&gt;
&lt;head&gt;
    &lt;meta charset=""UTF-8""&gt;
    &lt;title&gt;Report Generation&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt; 

    &lt;select id=""selectvalue""&gt;
        {% for n in name %}
            &lt;option value=""{{n}}""&gt;{{ n }}&lt;/option&gt;
        {% endfor %}

    &lt;/select&gt;  

&lt;/body&gt;
&lt;/html&gt;

if you want to send the value back, you have to use a form and call a post route with the selected value. This also can be done using the jinja2 template and a flask route.
",,,false,,,
https://stackoverflow.com/questions/62213923,true,"The issue involves the Flask-RestX library and the MarshallingError. The API documentation generation using flask-restx is not handling the MarshallingError as expected, resulting in incorrect formatting of the error message.",Flask-RestX,MarshallingError,"When generating API documentation using flask-restx, the MarshallingError is not being handled correctly, leading to incorrect formatting of the error message.",The MarshallingError is typically raised when there is an issue with marshalling the response data.,The issue is triggered when flask-restx encounters a MarshallingError during the generation of API documentation.,This issue might be challenging to detect during development and testing as it specifically relates to the behavior of flask-restx when generating API documentation.,Flask restx MarshallingError incorrect formatting,"Problem context

I'm experiencing some unexpected behaviour with MarshallingError, when generating api documentation using flask-restx. I have a custom flask-restx field definition, like below.

class EnumField(StringMixin, Raw):

    def __init__(self, enum_type, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.enum_type = enum_type

    def format(self, value):
        try:
            return self.enum_type(value)
        except ValueError as e:
            raise MarshallingError(e)

    def output(self, key, obj, **kwargs):
        return self.format(obj[key]).value


where enum_type is something simple like

class DemoEnum(Enum):
    a = 'a'
    b = 'b'
    c = 'c'


This is then packaged inside a restx api.model, which looks like the following.

model = api.model('Demo', {""name"": EnumField(enum_type=DemoEnum, required=True)})


Issue

When I enter an integer into name, as expected, I'm getting a nice error like below.

{
  ""errors"": {
    ""name"": ""1 is not of type 'string'""
  },
  ""message"": ""Input payload validation failed""
}


However, when I then enter a value that is not in my enum (""d"" for instance), the error seems to be caught in my format definition, however, MarshallingError isn't hiding all of the internal errors as expected. Here's a short snippet of what is being output.

&lt;!DOCTYPE HTML PUBLIC ""-//W3C//DTD HTML 4.01 Transitional//EN""
  ""http://www.w3.org/TR/html4/loose.dtd""&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;MarshallingError: 'string' is not a valid DemoEnum // Werkzeug Debugger&lt;/title&gt;
...


Quesions


Is this expected behaviour?
Is it possible to return a cleaner error, like the one shown above? My understanding was that my definition of format should achieve this?


Full application for testing

from flask_restx import Api, Resource
from flask_restx.fields import Raw, StringMixin, MarshallingError

from flask import Flask
from werkzeug.middleware.proxy_fix import ProxyFix

from enum import Enum

# =============================================================================
# Custom EnumField and Enum
# =============================================================================

class EnumField(StringMixin, Raw):

    def __init__(self, enum_type, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.enum_type = enum_type

    def format(self, value):
        try:
            return self.enum_type(value)
        except ValueError as e:
            raise MarshallingError(e)

    def output(self, key, obj, **kwargs):
        return self.format(obj[key]).value

class DemoEnum(Enum):
    a = 'a'
    b = 'b'
    c = 'c'

# =============================================================================
# Demo restx model
# =============================================================================

app = Flask(__name__)
app.wsgi_app = ProxyFix(app.wsgi_app)
api = Api(app, version='1.0', title='Test API', validate=True)

ns = api.namespace('demo')

model = api.model('Demo', {
    ""name"": EnumField(enum_type=DemoEnum, required=True)
})

# =============================================================================
# Api endpoint
# =============================================================================

@ns.route('/')
class Demo(Resource):
    @ns.doc('create_demo')
    @ns.expect(model, validate=True)  # validate checks the input is provided
    @ns.marshal_with(model, code=201)
    def post(self):
        '''Create demo'''
        return api.payload

if __name__ == '__main__':
    app.run(debug=True)

","
Is this expected behaviour?

Yes, because you're function is not aborting correctly or returning anything.

Is it possible to return a cleaner error, like the one shown above? My understanding was that my definition of format should achieve this?

Yes, you can rescue the error like you were doing, then return your own message and make sure it aborts properly using Flask's abort
Try this:
from flask import Flask, abort


def output(self, key, obj, **kwargs):
    try:
        return self.format(obj[key])
    except (ValueError, MarshallingError) as e:
        return abort(400,  f'Unable to marshal field. errors: [{key}: {str(e)}]')

The output for this example would be a 400 error formatted:
{
  ""message"": ""Unable to marshal field. errors: [name: 'd' is not a valid DemoEnum]""
}

This will not effect the error messaging from the expect decorator, ie. if you enter 1 for the name field you will receive the same message as before.
",,,false,,,
https://stackoverflow.com/questions/50409865,true,"The issue involves the Flask server being used in production, which is not designed to handle real-life production edge cases. The built-in server crashes when faced with certain scenarios, leading to unexpected behavior.",Flask,Built-in server,"The Flask built-in server is not suitable for production use and can crash when faced with certain scenarios. It is recommended to use a production-quality WSGI server, such as Apache with mod_wsgi, Gunicorn, or uWSGI.",The Flask built-in server is designed for development and testing purposes.,The issue is triggered when the Flask built-in server is used in a production environment.,This issue might be challenging to detect during development and testing as it specifically relates to the behavior of the Flask built-in server in a production environment.,Flask shutdown after working 10-15 sec,"I am developing a python messenger Bot using a wrapper from pymessenger. It works locally but in production it breaks.Like in every sec there are 15-20 req. I am using Pm2 to restart the process when shutdown/close. When i start the app it run for 10-20 sec, works as expected but suddenly show that error and restart. i would really appreciate if anybody can help me.

Here is the code:

# encoding=utf8
import sys
reload(sys)
sys.setdefaultencoding('utf8')

import os
import emoji
from flask import Flask, request
from pymessenger.bot import Bot    
app = Flask(__name__)

bot = Bot(ACCESS_TOKEN)


@app.route(""/webhook"", methods=['GET', 'POST'])
def hello():
    if request.method == 'GET':
        if request.args.get(""hub.verify_token"") == VERIFY_TOKEN:
            return request.args.get(""hub.challenge"")
        else:
            return 'Invalid verification token'
    try:
        if request.method == 'POST':
            output = request.get_json()
            for event in output['entry']:
                if event.get(""messaging""):
                    messaging = event['messaging']
                    for x in messaging:
                        if x.get('message'):
                            recipient_id = x['sender']['id']
                            if x['message'].get('text'):
                                message = emoji.demojize(x['message']['text'])


#-----------------------some other code ------------------
#-------------------------------------------------------
                                bot.send_text_message(
                                    recipient_id, ""replay"")
                            if x['message'].get('attachments'):
                                bot.send_text_message(
                                    recipient_id, ""No result!!"")
                        else:
                            pass
                return ""Success""
        return ""Success""
    except IOError as (errno, strerror):
        print ""I/O error({0}): {1}"".format(errno, strerror)
    except ValueError:
        print ""Could not convert data to an integer.""
    except:
        print ""Unexpected error:"", sys.exc_info()[0]
        raise

    if __name__ == ""__main__"":
       app.run(port=5000, debug=False)


I am not a python developer,just using it for a library i can't find in other platform for messenger Bot. 

Here is Error log:

  File ""/usr/lib/python2.7/SocketServer.py"", line 290, in _handle_request_noblock
    self.process_request(request, client_address)
  File ""/usr/lib/python2.7/SocketServer.py"", line 318, in process_request
   self.finish_request(request, client_address)
  File ""/usr/lib/python2.7/SocketServer.py"", line 331, in finish_request
    self.RequestHandlerClass(request, client_address, self)
   File ""/usr/lib/python2.7/SocketServer.py"", line 654, in __init__
     self.finish()
   File ""/usr/lib/python2.7/SocketServer.py"", line 713, in finish
     self.wfile.close()
   File ""/usr/lib/python2.7/socket.py"", line 283, in close
     self.flush()
  File ""/usr/lib/python2.7/socket.py"", line 307, in flush
    self._sock.sendall(view[write_offset:write_offset+buffer_size])
 socket.error: [Errno 32] Broken pipe

","You are using the built-in server that comes with Flask, in production. Don't do that, it was only ever designed as a convenience to make developing easy. It can't handle real-life production edgecases.

What's happening is that the remote client the server was sending a response to, has closed the connection early. This happens from time to time, is not quite how it is supposed to work, but that's the internet for you. This is not something you need to care about when developing your app, so the built-in server doesn't handle this edgecase.

Instead, you need to deploy Flask on a production-quality WSGI server. That can be Apache with mod_wsgi, or Gunicorn, or uWSGI, or any other such server. See the Deploying chapter of the Flask documentation.
","Use Gunicorn with Flask to manage the WSGI requests. Here are the small scripts which can help you start and stop Flask Server running with Gunicorn. Flask's built-in server is not made to be used in production. It crashes with time. Therefore look into the Gunicorn:

Start Script:

#!/bin/bash
stat=0
COUNTER=0
swait()
{
        echo -ne ""Waiting for service to start""
                until [[ $stat -ge 1 ]]
                do
        stat=$(netstat -lnt | awk '$4 ~ /:5001$/' |wc -l)
                        COUNTER=$((COUNTER+1))
                        if [ $COUNTER == 5 ] ; then
                                echo -e '\nError-Service start failed'
                                exit;
                         fi
                        echo -ne "".""
                        sleep 2 
                    done
}
service_start()
{
        echo ""Starting Service""

        /&lt;project_path&gt;/venv/bin/gunicorn --reload -b 0.0.0.0:5001 api:app --access-logfile=/var/log/&lt;project_name&gt;.log --error-logfile=/var/log/&lt;project_name&gt;_error.log -D -w 2 --access-logformat='%(h)s %(l)s %(u)s %(t)s ""%(r)s"" %(s)s %(b)s ""%(f)s"" ""%(a)s"" %(L)s' --log-level=info

}
service_start
swait

echo -e ""\nService started Successfully""


Stop Script

#!/bin/bash
echo ""Stopping Service""
stat=1
COUNTER=0

swait()
{
        echo -ne ""Waiting for service to stop""
                until [[ $stat -eq 0 ]]
                do
        stat=$(netstat -lnt | awk '$4 ~ /:5001$/' |wc -l)
                        COUNTER=$((COUNTER+1))
                        if [ $COUNTER == 8 ] ; then
                                echo -e '\nService stop failed'
                                exit;
                         fi
                        echo -ne "".""
                        sleep 2 
                    done
}

service_stop()
{
        for pid in `ps augx | grep gunicorn | grep -E ':5001' | grep -v grep | awk '{print $2}'`;
        do
                echo ""Killing PID"" $pid
                kill $pid
        done
}

service_stop
swait


echo -e ""\nService Stopped Successfully""

","You can used Waitress with Flask, Flash is basic WSGI service for testing only


  https://github.com/Pylons/waitress

",false,,,
https://stackoverflow.com/questions/49803518,false,"The issue does not involve an API exhibiting unexpected failures or unpredictable behaviors. It is related to handling nested dictionaries in Python requests, but there is no indication of API-related problems.",,,,,,,Handling nested dictionaries with python requests,"I recently got my first Flask webapp hosted, and built a relatively simple API around it. It's driven by a very large database full of open meteorological surface observations (more info on the /about page), and right now I'm able to query the API with the following sample code (a separate script written for testing):

import requests
import json

r = requests.get('http://www.asosquery.com/api/v1/stations?state=PA&amp;lat={""gt"": 39, ""lt"": 50}')
content = json.loads(r)


This returns JSON-encoded information regarding all ASOS stations with a latitude greater than 39.00 N and less than 50.00 N. A SQLAlchemy query of the MySQL database is dynamically generated based on the arguments in the GET request.

However, I would like to be able to do something like this, following an example on the requests package documentation:

import requests # standard python requests package
import json

payload = {
    'state': 'PA',
    'lat': {
        'gt': 39,
        'lt': 50
    }
}

r = requests.get('http://www.asosquery.com/api/v1/stations', params=payload)
content = json.loads(r)


This exercise fails each time. In the Flask route /api/v1/stations, I've tried printing the request made to the server like this:

from flask import request

@app.route('/api/v1/stations', methods=['GET'])
def get_stations():
    print(request)
    print(request.args)
    # -- do the query stuff here -- #
    return jsonify(query_results)


But, the output (prior to a raised error) is not as I expected it to be:

# print(request) prints:
&lt;Request 'http://localhost:5000/api/v1/stations?lat=lt&amp;lat=gt&amp;state=PA' [GET]&gt;
# print(request.args) prints:
ImmutableMultiDict([('lat', 'lt'), ('lat', 'gt'), ('state', 'PA')])


I've tried encoding the payload as JSON with the following:

r = requests.get('http://www.asosquery.com/api/v1/stations', params=json.dumps(payload), headers={'Content-Type': 'application/json'})


but execution of that code prints the following in from the flask route:

# print(request) prints:
&lt;Request 'http://localhost:5000/api/v1/stations?{""state"": ""PA"", ""lat"": {""gt"": 39, ""lt"": 50}}' [GET]&gt;
# print(request.args) prints:
ImmutableMultiDict([('{""state"": ""PA"", ""lat"": {""gt"": 39, ""lt"": 50}}', '')])


At the moment, the query fails to execute due to the unexpected nature of the argument formatting.

Anybody know a good workaround? Am I handling the greater-than, less-than functionality in the best way possible? 

Thank you in advance to all who offer some insight.
","Workaround would be not to nest the dictionary:

payload = {
    'state': 'PA',
    'lat': ""{'gt': 39,'lt': 50}""
}


It does work, but it's quite ugly.
",,,false,,,
https://stackoverflow.com/questions/45669015,false,"The issue does not involve an API exhibiting unexpected failures or unpredictable behaviors. It is related to handling file access and mutual exclusion in a Flask web server, but there is no indication of API-related problems.",,,,,,,Python flask how to avoid multi file access at the same time (mutual exclusion on files)？,"I am currently developing a data processing web server(linux) using python flask.

The general work flow is:


Get an input file from the user (handled by python flask)
Flask passes this input file to a java program 
Java program processes this input file, saves the outputs (multiple files) on the server.
Flask calls another python script which will process these outputs to get the final result and return the result back to the client.


The problem is: between step 3 and step 4, there exist some intermediate files, this would not have been a problem at all if this is a local program. but as a server program, When more than one clients access this program, they could get unexpected result generated by input that is provided by another user who is using the web program at the same time. 

From the point I see it, this is kind of a mutual exclusion problem on file access. I have had problems with mutual exclusion problems on threads before, I solved some of them using thread locks such as like synchronization in java and lock in pythons, but I am not sure what to do when it comes to files instead of threads. 

It occurred to me that maybe I canspawn different copies of files based on different clients. But as I understand, the HTTP is stateless so you can't really know who is accessing the server. I don't want to add a login system and a user database to achieve this purpose as I sense there is a much simpler and better way to resolve this problem. 

I have been looking for a good solution these days but haven't found an ideal one so I am looking for some advice here. Any suggestions will be highly appreciated. If you can suggest a viable solution, please feel free to provide me with your name so I can add you to the thank list of digital and paper publications about this tool when it's published.
","As a system kind of person I suggest you something like this

https://docs.python.org/3/library/fcntl.html#fcntl.lockf

This is how I would solve it there is so many way to solve this problem and it is up to debate of course it is come hard with the best solution 

Assume the output file is where the conflict happen 

so you lock the file and you keep polling until the resource is release (the user need to wait) so you force one user to access the file at a time (polling here time.sleep) for like 2-3 seconds (add a try except) here thread lock on the output file only when the resource is release the next user process will pass through normally. 

Another easy way is to dump the data in a rds like mysql or postgres it will handle all the file access nightmare occurred from concurrent request (put the output file in a db).
",,,false,,,
https://stackoverflow.com/questions/42565513,false,"The issue is related to the usage of Pug and Flask, but it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.",,,,,,,Conditionals of dynamic content with PUG and FLASK,"This is the flask file.

from flask import render_template
from app import app

@app.route('/')
@app.route('/index')
def index():
    user = {'nickname': 'Miguel'}  # fake user
    return render_template('index.html',title='Home',user=user)


This is pug file:

doctype html
html(lang=""en"")
    head
        title pageTitle

        if title
            title {{ title }} - microblog
        else if !title
            title Welcome to microblog1
        else
            title Welcome to microblog2

    body
    h1 Hello,  {{ user.nickname }}!
    if {{ user.nickname }} == ""Miguel""
        h1 Miguel


This is what the index.html looks like once converted with Prepros:

&lt;!DOCTYPE html&gt;
&lt;html lang=""en""&gt;
    &lt;head&gt;
        &lt;title&gt;pageTitle&lt;/title&gt;
        &lt;title&gt;Welcome to microblog1&lt;/title&gt;
    &lt;/head&gt;
    &lt;body&gt;
        &lt;h1&gt;Hello,  {{ user.nickname }}!&lt;/h1&gt;
        &lt;h1&gt;{{ user.nickname }}&lt;/h1&gt;
        &lt;h1&gt;# user.nickname&lt;/h1&gt;
    &lt;/body&gt;
&lt;/html&gt;


I can get dynamic content from FLASK with my PUG file.
So the following in the script works:

h1 Hello,  {{ user.nickname }}!


The output is ""Hello, Miguel!""

but this part doesn't work.

if {{ user.nickname }} == ""Miguel""
        h1 Miguel


I get a syntax error: Unexpected token. So I can get the name from Flask, but I can't use it in an if statement?
I'm not sure if I'm doings something wrong or if it's just not supported. 
Btw, I'm using Prepros(which is giving the error) to convert my PUG file to HTML.

Something that might be related is that when I do convert my file via Prepros, I don't really get the result I would expect.

This is from the PUG file:

title pageTitle
if title
    h1 {{ title }}
else if !title
    title Welcome to microblog1


In the html I would expect:

&lt;title&gt;pageTitle&lt;/title&gt;
{% if title %}
    &lt;title&gt;{{ title }}&lt;/title&gt;
{% else if !title %}
    &lt;title&gt; Welcome to microblog1


but I end up with:

&lt;title&gt;pageTitle&lt;/title&gt;
&lt;title&gt;Welcome to microblog1&lt;/title&gt;


It's as if Prepros answers the IF statement before converting to HTML. Which means the code is not dynamic. I'm new to both PUG and FLASK, so I'm not sure where to try find the solution.
","Thanks guys. Found the solution. 

| {% if user.nickname == 'Miguels'%}
|   h1 Miguel
| {% endif %}


This then comes out in the HTML as:

{% if user.nickname == 'Miguels'%}
    h1 Miguel
{% endif %}


This also solves the issue of answering the IF statement in the conversion.

@cs01
Thanks, that article was where I found the solution. The ""-"" didn't work.

@Shea Belsky
Thanks. I knew it existed since it ""printed"" it with:

h1 user.nickname

","I think you're looking for the - character. 

if {{ user.nickname }} == ""Miguel""
        h1 Miguel


would be 

- if user.nickname == 'Miguel'
    h1 Miguel


Source: https://github.com/matannoam/pypugjs#using-templatetags-and-any-feature-of-the-compiled-to-language

Using templatetags (and any feature of the compiled-to language)

Using Django and crispy-forms as an illustrative example but the information can be generalized.

If you need to use templatetags, you can use PugJS's syntax for rendering code:

- load crispy_forms_tags
- crispy form
This will compile into

{% load crispy_forms_tags %}
{% crispy form %}
If you have any trouble with this feature, or there's some feature of your template language that is being misinterpreted when using this syntax, you can also do something like this:

| {% load crispy_forms_tags %}
| {% crispy form %}
This will compile into the same Django template snippet.

","Double curly braces {{ }} is not valid Pug syntax. (I think it's part of another HTML preprocessor, I don't remember what off the top of my head). In Pug, the two curly braces prefixed by a pound symbol #{} indicate code that you can run to return something. Your source pug file would look like this, then:

doctype html
html(lang=""en"")
    head
        title pageTitle

        if title
            title #{ title } - microblog
        else if !title
            title Welcome to microblog1
        else
            title Welcome to microblog2

    body
    h1 Hello,  #{ user.nickname }!
    if #{ user.nickname } == ""Miguel""
        h1 Miguel


You do not need to use that syntax when indicating a variable inside of a loop or conditional. You can do just if variable === ""something"", and that should work just fine.

In your example, you would change your if statement to not have any curly braces.

if user.nickname == ""Miguel""
    h1 Miguel


If you're always going to be having an h1 for the user's nickname, you can just embed it directly using those curly braces.

h1 #{user.nickname}


Lastly, you have two title elements in your code, which is why it's coming up twice. You can take out the topmost one (title pageTitle) in order for only one to appear, where the content is dependent on there being a valid title variable passed to the processor.
",false,,,
https://stackoverflow.com/questions/32833381,false,"The issue is related to the configuration of Webpack and Babel, but it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.",,,,,,,Webpack i18n plugin not working with babel es6,"I am trying to use the i18n-webpack-plugin alongside babel-loader.

My webpack config:

var path        = require(""path""),
    I18nPlugin  = require(""i18n-webpack-plugin""),
    webpack     = require(""webpack""),
    languages   = {
        ""en"": null,
        ""es"": require(""./src/locale/es.po.json"")
    };

module.exports = Object.keys(languages).map(function(language) {
    return {
        name: language,
        entry: {
            home: ""./src/static/scripts/script.js"",
            alt: ""./src/static/scripts/alt.js""
        },
        output: {
            path: path.join(__dirname, ""dist/static/scripts""),
            filename: language + "".[name].output.js""
        },
        modules: {
            loaders: [
                {
                    test: /\.js$/,
                    exclude: /node_modules/,
                    loader: [""babel-loader""]
                },
            ]
        },
        plugins: [
            new I18nPlugin(
                languages[language]
            ),
            new webpack.optimize.UglifyJsPlugin({minimize: true})
        ]
    };
});


The error I receive: 

ERROR in ./src/static/scripts/script.js
    Module parse failed: /Users/anthonydandrea/react/gulp-react-flask/src/static/scripts/script.js Line 1: Unexpected token
    You may need an appropriate loader to handle this file type.
    | import React from 'react';


Unsure as to what is causing the problem. Seems as though babel is never used and won't let me do the ES6 import on the first line. Note: everything works fine when I comment out the ES6 code.
","Use 'loaders' for array and 'loader' for string.

loader: 'babel?someparam!ts'


vs.

loaders: ['babel?someparam', 'ts']

",,,false,,,
https://stackoverflow.com/questions/26030001,false,"The issue is related to the usage of Celery in a Python application, but it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.",,,,,,,takes exactly 2 arguments (1 given) celery simple process,"Trying to run a simple command in a celery task but getting 'takes exactly 2 arguments (1 given)' every time I try to execute.

I am able to perform the 'add' celery task without issue and I see in the celery log that it tells me the result (i'm on debug)...   but when I try to run the bash_run task it has a exception

[2014-09-24 22:17:08,240: DEBUG/MainProcess] TaskPool: Apply &lt;function _fast_trace_task at 0x10dba12a8&gt; (args:('tasks.bash_run', 'c75860c4-71b2-4ce6-881d-3ed208038891', ('/bin/sleep 50',), {}, {'utc': True, u'is_eager': False, 'chord': None, u'group': None, 'args': ('/bin/sleep 50',), 'retries': 0, u'delivery_info': {u'priority': 0, u'redelivered': None, u'routing_key': u'celery', u'exchange': u'celery'}, 'expires': None, u'hostname': 'celery@MKT2AHF1G3', 'task': 'tasks.bash_run', 'callbacks': None, u'correlation_id': u'c75860c4-71b2-4ce6-881d-3ed208038891', 'errbacks': None, 'timelimit': (None, None), 'taskset': None, 'kwargs': {}, 'eta': None, u'reply_to': u'98d88cb9-6883-3f1d-a1ef-422df9175c88', 'id': 'c75860c4-71b2-4ce6-881d-3ed208038891', u'headers': {}}) kwargs:{})
[2014-09-24 22:17:08,243: DEBUG/MainProcess] Task accepted: tasks.bash_run[c75860c4-71b2-4ce6-881d-3ed208038891] pid:21290
[2014-09-24 22:17:08,246: ERROR/MainProcess] Task tasks.bash_run[c75860c4-71b2-4ce6-881d-3ed208038891] raised unexpected: TypeError('bash_run() takes exactly 2 arguments (1 given)',)
Traceback (most recent call last):
  File ""/Users/andy.terhune/coregrapherenv/lib/python2.7/site-packages/celery/app/trace.py"", line 240, in trace_task
    R = retval = fun(*args, **kwargs)
  File ""/Users/andy.terhune/coregrapherenv/lib/python2.7/site-packages/celery/app/trace.py"", line 437, in __protected_call__
    return self.run(*args, **kwargs)
TypeError: bash_run() takes exactly 2 arguments (1 given)


My code:

SECRET_KEY = 'not_a_secret'
CELERY_BROKER_URL='redis://localhost:6379/0'
CELERY_RESULT_BACKEND='redis://localhost:6379/0'
CELERY_ACCEPT_CONTENT = ['pickle', 'json', 'msgpack', 'yaml']
CELERY_ANNOTATIONS = {'tasks.bash_run': {'rate_limit': '2/s'}}

from celery import Celery
import settings
import flask
import os

def make_celery(app):
    celery = Celery(app.import_name, broker=app.config['CELERY_BROKER_URL'])
    celery.conf.update(app.config)
    TaskBase = celery.Task
    class ContextTask(TaskBase):
        abstract = True
        def __call__(self, *args, **kwargs):
            with app.app_context():
                return TaskBase.__call__(self, *args, **kwargs)
    celery.Task = ContextTask
    return celery

app = flask.Flask(__name__)
app.config.from_object(settings)
app.wsgi_app = ProxyFix(app.wsgi_app)
celery = make_celery(app)

@celery.task(name=""tasks.bash_run"")
def bash_run(command):
    f = os.popen(command)
    output = f.read()
    return output

@celery.task(name=""tasks.add"")
def add(x, y):
    return x + y

@app.route('/', methods=['GET'])
def get_stuff():
    #working...
    #res=add.delay(23,43)
    #print res.task_id
    #print res.get()

    #not working...
    string = '/bin/sleep 50'
    res = bash_run.delay(string)
    print res.task_id

","It's weird, I run into the same problem just now, trying to run this task:

@app.task(bind=True)
def task_signup_email(user_id):
    # fetch user
    user = User.objects.get(id=user_id)
    # send verification email
    send_verification_email(user)


turns out since it was in a tasks.py file and celery was configured to auto discover tasks in Django apps' tasks.py files, the bind=True was redundant. everything returned to normal as soon as I removed the bind=True argument, meaning it didn't require two arguments anymore :-\
",,,false,,,
https://stackoverflow.com/questions/25677629,false,"The issue is related to the CGI implementation in Python and how browsers interpret the response, but it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.",,,,,,,Python CGI returns correct text to curl but browsers display trailing zero,"I wrote this simple CGI app in Python 3:

#! /usr/bin/env python3.4

print(""Content-type: text/html\n"")

print(""AAAA"")



If I go to the URL with any browser, I get a page showing this: ""AAAA 0"". It displays exactly this in Firefox, Chrome, and Safari on a Mac and Safari on an iPhone. Changing the ""AAAA"" to anything else changes the output accordingly in all browsers, but the trailing ""0"" always remains in every browser.
The browser's ""view source"" always shows the expected string+newline (which the browser treats as a space, of course) followed by an unexpected 0:

AAAA
0

directly executing it from the server's command line (./foo.py | hex) and viewing the output with a hex editor produced the expected output: both header and content lines, with the content line as 41 41 41 0A (""AAAA\n"")
using curl from both my Mac laptop and from the Linux server's command line likewise produces exactly the hex output I expect: 41 41 41 41 0A
curl on any (tested) platform shows no trailing zero. All browsers on all platforms DO show a trailing zero.
If I remove the second ""print"" statement, leaving only the one ""print"" statement for the header, the trailing ""0"" disappears in all browsers, leaving only a blank page, but if I put any print statement after the header print, a trailing zero will appear in all browsers but not in any curl. Even an empty ""print()"" produces an empty first line (the newline, I'm sure) followed by a ""0"" on the second line of the ""view source"". If I ADD more print lines, inserting the proper doctype &amp; html, the trailing zero shows up after the end-html tag in the source. If I print anything other than the header, a trailing zero shows up in the browser source.
Changing to Python3.2 made no difference
So, trying to make curl spoof a browser, I added the ""user-agent"" from a couple of browsers. No difference. Curl still always shows what I expect it to show and all the browsers still display a trailing zero.
Retyping the simple code (not copying and pasting) to make sure there are no invisible characters produces the same results (and hex view of the Python source, of the output from running it on the server, and the output obtained by curl all show no extra characters).
This is shared hosting using Apache+CGI, and I haven't changed any Apache files or created any .htaccess files.
I could use mod_wsgi, which works fine, if this were for production, but it's for learning. I'm trying to teach kids how to use low-level CGI, having them manually extract GET data from ENV vars, etc., so they can see what's going on underneath before moving up to more pre-built functionality (cgi module, then WSGI, then Flask, etc.) The point is to understand what's going on, but I don't.


So, can anybody tell me what's going on here in this most basic of web apps? Where is that ""0"" coming from (successful status code?), and why does it show up in browser source but not in curl? And, most importantly, how do I get rid of it?

UPDATE:
This problem only occurs when my browser is on a phone using ATT's ""LTE"" for data, or any browser accessing the Web via tethering to ATT's ""LTE"". If I walk my phone into the house, it switches over to Comcast/Wifi, refresh the browser page and ""AAAA 0"" turns into ""AAAA"". Walk out of the house (out of wifi range), refresh using LTE, and ""AAAA"" turns back into ""AAAA 0"". Same happens with browser on laptop.

So, here's the telnet output when the laptop is tethered and showing ""AAAA 0"" in all browsers (no problem I can see, just as in curl):

&gt; telnet my.domain.com 80
Trying 100.99.98.97...
Connected to my.domain.com.
Escape character is '^]'.
GET /temp.py HTTP/1.0
Host: my.domain.com

HTTP/1.1 200 OK
Server: nginx
Date: Fri, 05 Sep 2014 23:28:10 GMT
Content-Type: text/html
Connection: close
Vary: Accept-Encoding

AAAA
Connection closed by foreign host.

",,,,false,,,
https://stackoverflow.com/questions/71298698,true,The issue involves the usage of a Jinja2 filter and the behavior observed is unexpected. Further analysis is required to identify the specific API and conditions under which it fails.,,,,,,,Calling a jinja2 filter with only the context as an argument,"I'm trying to render a jinja2 template in my service (not using flask, just pure jinja2 and constructing a jinja2 Environment.
Let's say I have the following filter defined
import jinja2

@jinja2.contextfilter
def my_function(context):
    if context.get('my_var'):
        return ""hello""
    else:
        return ""world""

Super simplified example, but the point of it is that I have some logic that conditionally returns a value based on some variable passed into the context.
Also, I'm using jinja2 2.11 or something like that, which is why I'm using @contextfilter instead of @pass_context.
I've added this filter to my environment using env.filters['my_function'] = my_function
In rendering the template, I'm calling
template = env.get_template('my_template.html')
template.render({'my_var': 'some_value'})

where the template might look something like
... some html here
{{ my_function }}
... some more html

This doesn't actually return ""hello"", and instead just is empty/blank.
I managed to get it by passing in a dummy variable
@jinja2.contextfilter
def my_function(context, value):
    .... code is the same

And then in the template, I call it with {{ 'hi' | my_function }}. But obviously this is just a hack and not very desirable.
So my question is, how can I call a jinja2 filter function that only takes the context in as an argument? I've tried {{ my_function() }} which returns the error UndefinedError: 'my_function' is undefined, and {{ | my_function }}, which returns the error TemplateSyntaxError: unexpected '|'`
Or is there some other jinja2 construct I should be using?
Edit: my suspicion is that jinja2 uses the | to identify a filter vs a variable, and since I don't have |, then it tries to just render the variable my_function from the context, and since it doesn't exist in the context, it just outputs an empty string.
","Jinja2 calls these kind of functions global functions (like range()), not filters. Just change filters to globals in this line:
env.globals['my_function'] = my_function

And then you can call your function in the templates: {{ my_function() }}.
",,,false,,,
https://stackoverflow.com/questions/55355324,false,The issue does not meet the criteria for deeper analysis as it does not involve unexpected behavior or failures of an API.,,,,,,,Logs in Flask unittests print out dot after newline,"I have a dead simple Flask application :

from flask import Flask

app = Flask(__name__)

@app.route(""/"")
def hello():
    return(""Hello World!"")

if __name__ == '__main__':
    app.run()


along with __main__.py file:

from .core import app

import src.core

app.run()


and i added a test:

from unittest import TestCase
import logging as log

import src.core

class runTests(TestCase):

    def setUp(self):
        src.core.app.testing = True
        self.client = src.core.app.test_client()

    def test_hello_world(self):
        response = self.client.get(""/"")
        log.warning(f""resp: {response.data}"")
        self.assertEqual(b""Hello World!"",response.data)


overall tree structure looked like:

➜  apptest tree -L 2
.
├── src
│   ├── core.py
│   ├── __main__.py
│   └── __pycache__
└── tests
    ├── __pycache__
    └── test.py

4 directories, 3 files
➜  apptest


When i run the tests, i got unexpected output:

➜  apptest python -m unittest tests.test
WARNING:root:resp: b'Hello World!'
.
----------------------------------------------------------------------
Ran 1 test in 0.011s

OK
➜  apptest


There is this random dot after newline of the log. I tried out modifying test.py to check it out:

from unittest import TestCase
import logging as log

import src.core

class runTests(TestCase):

    def setUp(self):
        src.core.app.testing = True
        self.client = src.core.app.test_client()

    def test_hello_world(self):
        response = self.client.get(""/"")
        log.warning(f""resp: {response.data}"")
        log.warning(""2nd log"")
        self.assertEqual(b""Hello World!"",response.data)

    def test_hello_world_2(self):
        log.warning(""3rd log"")
        log.warning(""4th log"")
        self.assertEqual(""Hello World!"",self.teststring)


And the output:

➜  apptest python -m unittest tests.test
WARNING:root:resp: b'Hello World!'
WARNING:root:2nd log
.WARNING:root:3rd log
WARNING:root:4th log
.
----------------------------------------------------------------------
Ran 2 tests in 0.011s

OK
➜  apptest


And it appears that last log of every function is printing \n. instead of just \n , if my thinking is right.

What is causing this, and how to get rid of it?
","I got the same problem so I did a little test.
If my test hasn't any output, the unittest output will prints out few dots according to the number of unittest functions.
When I have three functions the output format looks like:
...
----------------------------------------------------------------------
Ran 3 tests in 0.002s
OK
It seems like unittest prints out one dot a time in ONE LINE after certain test has been done.
",,,false,,,
https://stackoverflow.com/questions/52034690,false,"The issue does not meet the criteria for deeper analysis as it is related to a misunderstanding of logical operators in pandas, rather than an API-related problem.",,,,,,,"Flask-WTF, unexpected output using macro use of {{ field |safe}} (HTML escaping)","
When the input is  


When then output is  


But when I change the input to  


My output changes to  




Please some body explain me why this is happening?
What's the role of {{ field |safe}}?

My App.py code -

class ContactForm(FlaskForm):
   name = StringField(""Name Of Student"",validators = [InputRequired(message 
       = 'Name is missing'),Length(min=5,max=10,message=""wrong"")])
   email = StringField(""email"",[validators.Email(""Please enter your email 
       address."")])

@app.route('/form', methods = ['GET','POST'])
def index():
    form = ContactForm()

    if form.validate_on_submit():
        return render_template('macro_output.html',form=form)

    return render_template('main_form.html',form=form)


macro_form.html

{% macro render_output(field) %}
&lt;p&gt;
{{ field.label}}
{{ field |safe}}
&lt;/p&gt;
{% endmacro %}


macro_output.html

{% from ""macro_form.html"" import render_field, 
render_ErrorMessage,render_output %}
&lt;html&gt;
&lt;body&gt;
    {{ render_output(form.name)}}
    {{ render_output(form.name.data)}}
    {{ render_output(form.email)}}
    {{ render_output(form.email.data)}}

&lt;/body&gt;
&lt;/html&gt;

","The jijna2 filter safe treats strings as, well, safe and does not do any pre-formatting by automatically escaping any characters that would otherwise be interpreted as code (in this case HTML code).

So if a variable, say, form.name.data = &lt;html&gt; then invoking {{ form.name.data | safe }} will embed an html tag (&lt;html&gt;) into your HTML, and I expect that the HTML browser parser simply ignores it as an error (you can check the rendered page source). But invoking {{ form.name.data }} jinja2 will escape the '&lt;&gt;' characters only 'html' will go into the HTML and therefore be rendered as text.

I would strongly advise against the use of the safe filter for user input, since an arbitrary user could inject code into your page, e.g. &lt;script&gt; ... &lt;/script&gt;
",,,false,,,
https://stackoverflow.com/questions/38102078,true,"The issue involves the Salesforce API and the failure to generate a request token. The grant_type parameter is not supported, and removing the request_token_url resolves the issue.",,,,,,,OAuthException: Failed to generate request token with Salesforce,"I'm facing an issue I can't seems to fix, despite having tried everything I could.

I'm using Flask + Flask_oauthlib to connect to SalesForce. Here's my code :

from flask import Flask, url_for
from flask_oauthlib.client import OAuth

app = Flask(__name__)
oauth = OAuth(app)


salesforce = oauth.remote_app('salesforce',
    consumer_key='my_consumer_key',
    # grant_type='authorization_code',
    consumer_secret='my_consumer_secret',
    request_token_url='https://login.salesforce.com/services/oauth2/token',
    access_token_url='https://login.salesforce.com/services/oauth2/token',
    authorize_url='https://login.salesforce.com/services/oauth2/authorize')

@app.route('/')
def home():
    url = url_for('oauth', _external=True)
    salesforce.authorize(callback=url)
    return 'ok'


@app.route('/oauth')
def oauth():
    resp = salesforce.authorized_response()
    print resp

    return 'ok'


if __name__ == '__main__':
    app.run(host='0.0.0.0', debug=True)


When I run this and goes to /, I get the following exception :


  OAuthException: Failed to generate request token


I added an output from the line in question where the exception is thrown (""/usr/lib64/python2.7/site-packages/flask_oauthlib/client.py"", line 580), and this is the response from Salesforce :

{u'error_description': u'grant type not supported', u'error': u'unsupported_grant_type'}


So apparently I need to set the grant_type to something allowed.

I tried to add the grant_type as you can see in the commented section, but when I restart the code, it stops with the following error :


  TypeError: init() got an unexpected keyword argument 'grant_type'


Yay ...

I took a look, and applied the answers from the following questions, without any luck :


https://salesforce.stackexchange.com/questions/34928/oauth2-token-request-using-json-fails-grant-type-not-supported
Salesforce returning ""unsupported_grant_type""
Salesforce Authentication Failing


Does anyone has an idea about why I have this issue ?
","Ok I've found the solution, it's really vicious !

salesforce = oauth.remote_app('salesforce',
    consumer_key='my_consumer_key',
    consumer_secret='my_consumer_secret',
    access_token_url='https://login.salesforce.com/services/oauth2/token',
    authorize_url='https://login.salesforce.com/services/oauth2/authorize')


Don't see the difference ? I had to remove the request_token_url, that's all !

Now it works!
",,,false,,,
https://stackoverflow.com/questions/58224221,false,The issue does not meet the criteria for deeper analysis as it is related to the handling of JSON strings in Jinja templates and does not involve unexpected behavior or failures of an API.,,,,,,,Send json string from python app to javascript in jinja template,"I'm trying to send a list from python using Flask on a web server to a client with jinja and javascript. This should be simple using json. This is my python code:

@app.route(""/demo"")
def demo():
    basket = [{""fruit"": ""apple"", ""amount"": 3}, {""fruit"": ""pear"", ""amount"": 1}, {""fruit"": ""kiwi"", ""amount"": 2}]
    return render_template(""demo.html"", basket=json.dumps(basket))


This is a simplified code, in the final program the list will be the result of a database query. The jinja template is as follows:



{% extends ""layout.html"" %}

{% block title %}
    Demo
{% endblock %}

{% block main %}
    &lt;script&gt;
        console.log('{{ basket }}');
        object = JSON.parse('{{ basket }}')
    &lt;/script&gt;

{% endblock %}




However, javascript returns a parsing error:


  [{""fruit"": ""apple"", ""amount"": 3}, {""fruit"": ""pear"", ""amount"": 1}, {""fruit"": ""kiwi"", ""amount"": 2}]
  demo:1 Uncaught SyntaxError: Unexpected token &amp; in JSON at position 2
      at JSON.parse ()
      at demo:54


It seems that the double quote "" is somehow translated to the HTML code &amp;#34 for the "" character. Subsequently JSON.parse cannot handle that. Tried breaking up the list in two arrays 'fruit' and 'amount', same error. I'm guessing that the client doesn't know that I'm sending json and that I should set content-type to application/json. Is that right, and if it is, how and where should I do this?

UPDATE after Makozaki's answer:
Passing 'basket' as a python object (instead of a json object) combined with a jinja for loop works, but only if you rebuild arrays of single elements:

&lt;script&gt;
    fruit = [];
    {% for item in basket %}
        fruit.push('{{ item[""fruit""] }}')
    {% endfor %}
    console.log(fruit)
&lt;/script&gt;


Trying to push items consisting of 'fruit' and 'amount' will again contain all the escaped characters. And it seems silly that you would have to rebuild an array that is passed in its entirety as an object.

Turning off autoescape works as well, but in an unexpected way:

&lt;script&gt;
    {% autoescape false %}
        object = {{ basket }};
    {% endautoescape %}
&lt;/script&gt;


This returns exactly the object that is passed. But the funny thing is: you have to omit the single quotes before and after the double curly braces! (as opposed to the previous example)

Thanks for the inspiration!
","In short object|tojson|safe is the way to do it, example from JSON Support.

&lt;script type=text/javascript&gt;
    doSomethingWith({{ user.username|tojson|safe }});
&lt;/script&gt;

",,,false,,,
https://stackoverflow.com/questions/47320455,false,The issue does not meet the criteria for deeper analysis as it is related to SSL configuration and does not involve unexpected behavior or failures of an API.,,,,,,,Flask SSL receiving garbage requests,"I've got a basic Flask server setup with some endpoints. I'm trying to test this out using curl (I've tried both from localhost and remotely, the result is the same).

If I curl the path over http, it works great.  If I do it over https, the request looks like garbage (see below) and curl returns ""curl: (35) gnutls_handshake() failed: An unexpected TLS packet was received.""

Requests received over https typically looks similar to:

136.152.142.32 - - [16/Nov/2017 01:32:56] code 400, message Bad request syntax ('\x16\x03\x01\x00\xe3\x01\x00\x00\xdf\x03\x03Z\x0c\xea\xcf\rG\x12,\xea}\xc4\x17n\xb7\x0c\x0b\xea\xdbM\x87n\xf3\x95\xa7(\x15+\xb5lyzY\x00\x00n\x00\xff\xc0,\xc0+\xc0$\xc0#\xc0')
136.152.142.32 - - [16/Nov/2017 01:32:56] ""??Z
G,?}?n?           

                        ??


I added SSL functionality by simply adding an ssl_context to my flask app.

if __name__ == '__main__':
    context = ('fullcert.pem', 'privkey.pem')
    app.run(debug=False, ssl_context=context)


The keys are signed by a CA and worked fine in a comparable node application (I'm trying to convert that node application over to python/flask).

I've tried basically reinstalling from the ground up with no success.

This is being hosted on DigitalOcean in case anyone knows of some weird default configuration that they do that could be causing this.  I've specifically opened the port that the application is running on.

Does anyone have any other suggestions of what could be causing the problem?
",,,,false,,,
https://stackoverflow.com/questions/29795766,false,The issue does not have enough information to determine if it involves an API exhibiting unexpected failures or behaviors.,,,,,,,"flask apns - SysCallError: (-1, &#39;Unexpected EOF&#39;)",,,,,false,,,
https://stackoverflow.com/questions/29621527,false,The issue does not have enough information to determine if it involves an API exhibiting unexpected failures or behaviors.,,,,,,,Can&#39;t connect to MongoDB after upgrading?,"I'm building a website using Flask in which I use MongoDB with the MongoEngine ORM. To go for a fresh start again I now upgraded all apt and pip packages on my ubuntu 14.04 development machine. Unfortunately this broke my connection to MongoDB:

Traceback (most recent call last):
  File ""./run.py"", line 4, in &lt;module&gt;
    from app import app, socketio
  File ""/home/kr65/beta/app/__init__.py"", line 21, in &lt;module&gt;
    mongoDb = MongoEngine(app)
  File ""/usr/local/lib/python2.7/dist-packages/flask_mongoengine/__init__.py"", line 33, in __init__
    self.init_app(app)
  File ""/usr/local/lib/python2.7/dist-packages/flask_mongoengine/__init__.py"", line 66, in init_app
    self.connection = mongoengine.connect(**conn_settings)
  File ""/usr/local/lib/python2.7/dist-packages/mongoengine/connection.py"", line 164, in connect
    return get_connection(alias)
  File ""/usr/local/lib/python2.7/dist-packages/mongoengine/connection.py"", line 126, in get_connection
    raise ConnectionError(""Cannot connect to database %s :\n%s"" % (alias, e))
mongoengine.connection.ConnectionError: Cannot connect to database default :
False is not a read preference.


I checked if MongoDB is up:

$ sudo service mongodb status
mongodb start/running, process 781


and if I could get into the interactive command line:

$ mongo
MongoDB shell version: 2.4.9
connecting to: test
Welcome to the MongoDB shell.
For interactive help, type ""help"".
For more comprehensive documentation, see
    http://docs.mongodb.org/
Questions? Try the support group
    http://groups.google.com/group/mongodb-user
Server has startup warnings:
Tue Apr 14 09:14:10.267 [initandlisten]
Tue Apr 14 09:14:10.267 [initandlisten] ** WARNING: You are running in OpenVZ. This is known to be broken!!!
Tue Apr 14 09:14:10.267 [initandlisten]
&gt;


I didn't change anything to the code or passwords or anything like that. I did a reboot and restarted mongoDB, but nothing works. My settings are like this:

MONGODB_SETTINGS = {
    'db': 'mydatabasename'
}


and I instantiate the connection like this (which worked before):

app = Flask(__name__)
app.config.from_object('config')
mongoDb = MongoEngine(app)


Since I didn't really change anything, I'm kind of unsure where to search for a solution. Does anybody have any tips how I could solve this?

[EDIT]
With the tip of @lapinkoira my MongoDB now starts up correctly, but I now get the error below while querying. Any ideas how to solve this one?

File ""/home/kr65/beta/app/views/webviews.py"", line 476, in getDoc
    userDoc = UserDocument.objects(id=docId).first()
  File ""/usr/local/lib/python2.7/dist-packages/mongoengine/queryset/base.py"", line 309, in first
    result = queryset[0]
  File ""/usr/local/lib/python2.7/dist-packages/mongoengine/queryset/base.py"", line 160, in __getitem__
    return queryset._document._from_son(queryset._cursor[key],
  File ""/usr/local/lib/python2.7/dist-packages/mongoengine/queryset/base.py"", line 1410, in _cursor
    **self._cursor_args)
  File ""/usr/local/lib/python2.7/dist-packages/pymongo/collection.py"", line 924, in find
    return Cursor(self, *args, **kwargs)
TypeError: __init__() got an unexpected keyword argument 'snapshot'

",,,,false,,,
https://stackoverflow.com/questions/75505141,false,The issue does not meet the criteria for deeper analysis as it is related to a Flask routing error and does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,&quot;TypeError: got an unexpected keyword argument&quot; when trying to use Flask.route() in python,"I'm running the following this code for a codding exercise:
from flask import Flask
from random import randint

rand_n = randint(0, 9)
app = Flask(__name__)


def decorator_header(function):
    def wrapper():
        return f""&lt;h1&gt;{function()}&lt;/h1&gt;""
    return wrapper


def check_decorator(function):
    def wrapper_function(*args):
        result = function(args[0])
        if result == ""You found me!"":
            return f""&lt;b style='color:green;'&gt;{result}&lt;/b&gt;""
        if result == ""Too low, try again!"":
            return f""&lt;b style='color:red;'&gt;{result}&lt;/b&gt;""
        return f""&lt;b style='color:purple;'&gt;{result}&lt;/b&gt;""
    return wrapper_function


@app.route('/')
@decorator_header
def guess_number():
    return 'Guess a number between 0 and 9'


@app.route('/&lt;number&gt;', endpoint='check_number')
@check_decorator
def check_number(number):
    if int(number) &lt; rand_n:
        return ""Too low, try again!""
    if int(number) &gt; rand_n:
        return ""Too high, try again!""
    return ""You found me!""


if __name__ == ""__main__"":
    app.run()

If I run the code like this, at first it works: I can load the page that says ""Guess a number between 0 and 9"" on my browser. Now, when I try to add the number in the url, like URL/1 for example, I get the following error:
[2023-02-19 21:16:23,710] ERROR in app: Exception on /1 [GET]
Traceback (most recent call last):
  File ""C:\Users\pauLo\venv\lib\site-packages\flask\app.py"", line 2528, in wsgi_app
    response = self.full_dispatch_request()
  File ""C:\Users\pauLo\venv\lib\site-packages\flask\app.py"", line 1825, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File ""C:\Users\pauLo\venv\lib\site-packages\flask\app.py"", line 1823, in full_dispatch_request
    rv = self.dispatch_request()
  File ""C:\Users\pauLo\venv\lib\site-packages\flask\app.py"", line 1799, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
TypeError: wrapper_function() got an unexpected keyword argument 'number'
127.0.0.1 - - [19/Feb/2023 21:16:23] ""GET /1 HTTP/1.1"" 500 -

If I just change the argument of the wrapper function, like so:
    def wrapper_function(number):
        result = function(number)

then it works fine. In fact, if I use anything else other than ""number"", it gives the error above.
Also, if I run the code without using Flask, with the decorator functions like the original and the rest like so:
@decorator_header
def guess_number():
    return 'Guess a number between 0 and 9'


@check_decorator
def check_number(number):
    if int(number) &lt; rand_n:
        return ""Too low, try again!""
    if int(number) &gt; rand_n:
        return ""Too high, try again!""
    return ""You found me!""


guess = input(guess_number())
print(check_number(guess))

It also works just fine. So why do I have to keep the same variable name inside the decoration function? Is Flask.route() returning number=number or something like that? I tried to look into the code for this function, but couldn't figure thigns out.
","The problem is that Flask calls your functions with keyword arguments (like check_number(number=""1"")), whereas your check_decorator wrapper expects only positional arguments (def wrapper_function(*args)).
You could rewrite it like this and it would work:
def check_decorator(function):
    def wrapper_function(*args, **kwargs):
        result = function(kwargs['number'])
        if result == ""You found me!"":
            return f""&lt;b style='color:green;'&gt;{result}&lt;/b&gt;""
        if result == ""Too low, try again!"":
            return f""&lt;b style='color:red;'&gt;{result}&lt;/b&gt;""
        return f""&lt;b style='color:purple;'&gt;{result}&lt;/b&gt;""
    return wrapper_function

But for what you're doing it doesn't make any sense to implement this logic in a decorator -- it should just be part of your check_number method.
","The way flask calls the decorated function is like this:
kwargs={'number': input()}
view_function(**kwargs)

It's important to remember decorators are just syntactic sugar:
@my_decorator
def my_func():
    return

# is the same as
def my_func():
    return
my_func = my_decorator(my_func)

So the function returned by the decorator (a wrapper in your case) is assigned to the symbol. In your example, this means that your check_decorator's returned function (wrapper_function here) is called by flask in the way described above. Your wrapper is modifying the call signature of the original function so you're basically doing this:
def check_number(number):
    if int(number) &lt; rand_n:
        return ""Too low, try again!""
    if int(number) &gt; rand_n:
        return ""Too high, try again!""
    return ""You found me!""

@app.route('/&lt;number&gt;', endpoint='check_number')
def wrapper_function(*args):
    result = check_number(args[0])
    if result == ""You found me!"":
        return f""&lt;b style='color:green;'&gt;{result}&lt;/b&gt;""
    if result == ""Too low, try again!"":
        return f""&lt;b style='color:red;'&gt;{result}&lt;/b&gt;""
    return f""&lt;b style='color:purple;'&gt;{result}&lt;/b&gt;""

And taking the number parameter as a positional argument isn't supported.

Your function then receives the &lt;variable_name&gt; as a keyword argument.
(source: https://flask.palletsprojects.com/en/2.2.x/quickstart/#variable-rules)

",,false,,,
https://stackoverflow.com/questions/68600333,true,The issue involves converting a Python object to a valid JSON object and is relevant for deeper analysis.,,,,,,,Pass Python object as json to JavaScript,"I'm using Python/Flask and I've troubles converting my python object in a valid json object.
@app.route('/')
@app.route('/index')
@login_required
def index():
    sites = Site.query.filter(Site.id==2).all()

    site_list = []
    for site in sites:
        site_element = {}
        site_element['long'] = site.longitude
        site_element['lat'] = site.latitude
        site_element['id'] = site.id
        site_element['name'] = 'test'
        site_list.append(site_element)

    site_json = json.dumps(site_list, separators=(',', ':'))
    return render_template('index.html', title='Home', site_json=site_json)

I'm consuming the json in the js like this:
var markers = JSON.parse('{{ site_json | tojson | safe }}');

It results in following error:
Uncaught SyntaxError: JSON.parse: unexpected non-whitespace character after JSON data at line 1 column 5 of the JSON data
What seems strange to me: If I construct the json manually, it just works fine!
@app.route('/')
@app.route('/index')
@login_required
def index():
    sites = Site.query.filter(Site.id==2).all()

    # site_list = []
    # for site in sites:
    #     site_element = {}
    #     site_element['long'] = site.longitude
    #     site_element['lat'] = site.latitude
    #     site_element['id'] = site.id
    #     site_element['name'] = 'test'
    #     site_list.append(site_element)
    # site_json = json.dumps(site_list, separators=(',', ':'))

    site_json = [{'long':36.02, 'lat':37.04, 'id':2, 'name':'test'}]

    return render_template('index.html', title='Home', site_json=site_json)

","You should pass the object rather than string. With json.dumps you are dumping the json as string.
@app.route('/')
@app.route('/index')
@login_required
def index():
    sites = Site.query.filter(Site.id==2).all()

    site_list = []
    for site in sites:
        site_element = {}
        site_element['long'] = site.longitude
        site_element['lat'] = site.latitude
        site_element['id'] = site.id
        site_element['name'] = 'test'
        site_list.append(site_element)
    
    # site_json = json.dumps(site_list, separators=(',', ':')) &lt;-- this is causing problem

    return render_template('index.html', title='Home', site_json=site_list)

",,,false,,,
https://stackoverflow.com/questions/61707996,false,The issue does not meet the criteria for deeper analysis as it is related to a MongoDB connection error and does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Getting TypeError: __init__() got an unexpected keyword argument &#39;safe&#39; while connection to mongodb,"I wrote the following program to connect to my mongo database 

from flask import Flask
from flask_mongoalchemy import MongoAlchemy
app = Flask(__name__)

app.config['MONGOALCHEMY_DATABASE']='MyDatabase'
app.config['MONGOALCHEMY_CONNECTION_STRING']='mongodb://&lt;username&gt;:&lt;password&gt;@mycluster-shard-00-00-cfkbg.mongodb.net:27017,mycluster-shard-00-01-cfkbg.mongodb.net:27017,mycluster-shard-00-02-cfkbg.mongodb.net:27017/test?ssl=true&amp;replicaSet=MyCluster-shard-0&amp;authSource=admin&amp;retryWrites=true&amp;w=majority'

db=MongoAlchemy(app)

class Example(db.Document):
    name=db.StringField()

if __name__=='__main__':
    obj=Example(name='Aman')
    obj.save()


Error:

Traceback (most recent call last):
  File ""app.py"", line 15, in &lt;module&gt;
    obj.save()
  File ""/usr/local/lib/python3.6/dist-packages/flask_mongoalchemy/__init__.py"", line 271, in save
    self._session.insert(self, safe=safe)
  File ""/usr/local/lib/python3.6/dist-packages/mongoalchemy/session.py"", line 172, in insert
    self.add(item, safe=safe)
  File ""/usr/local/lib/python3.6/dist-packages/mongoalchemy/session.py"", line 188, in add
    return self.flush()
  File ""/usr/local/lib/python3.6/dist-packages/mongoalchemy/session.py"", line 414, in flush
    result = op.execute()
  File ""/usr/local/lib/python3.6/dist-packages/mongoalchemy/ops.py"", line 97, in execute
    return self.collection.save(self.data, safe=self.safe)
  File ""/usr/local/lib/python3.6/dist-packages/pymongo/collection.py"", line 1881, in save
    write_concern = WriteConcern(**kwargs)
TypeError: __init__() got an unexpected keyword argument 'safe'


","Try to install an older version of pymongo (preferably 2.9.0).
According to https://github.com/MongoEngine/mongoengine/issues/1154:


  last version of mongoengine is not compatible with pymongo 3+:

",,,false,,,
https://stackoverflow.com/questions/53525106,false,The issue does not meet the criteria for deeper analysis as it is related to a Flask routing error and does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Flask - get() got an unexpected keyword argument,"I have these methods:

def hardCoded(rng):
    numbers_to_add = list(range(rng))
    try:
        req = request.Request('http://127.0.0.1:5000/total'
            , data=bytes(json.dumps(numbers_to_add), 'utf_8')
            , headers={'Content-Type': 'application/json'}
            , method='POST')
        result = json.loads(request.urlopen(req).read(), encoding='utf_8')
        print(json.dumps(result, indent=4))
    except Exception as ex:
        print(ex)

class rangeNumbers(Resource):
    def get(self, rng):
        rng_num = rangeNumbers()
        rng_num.get(10000001)
        return {'data': directSum.hardCoded(rng).get(10000001)}

api.add_resource(rangeNumbers, '/range/&lt;range&gt;')


On visiting url /range/&lt;range&gt; , it should give me the result of that range 10000001

However when I try http://localhost:5000/range/range it throws me this:

Traceback (most recent call last):
File ""/home/user/.virtualenvs/test_sum/lib/python3.6/site-packages/flask/app.py"", line 1612, in full_dispatch_request
rv = self.dispatch_request()
File ""/home/user/.virtualenvs/test_sum/lib/python3.6/site-packages/flask/app.py"", line 1598, in dispatch_request
return self.view_functions[rule.endpoint](**req.view_args)
File ""/home/user/.virtualenvs/test_sum/lib/python3.6/site-packages/flask_restful/__init__.py"", line 480, in wrapper
resp = resource(*args, **kwargs)
File ""/home/user/.virtualenvs/test_sum/lib/python3.6/site-packages/flask/views.py"", line 84, in view
return self.dispatch_request(*args, **kwargs)
File ""/home/user/.virtualenvs/test_sum/lib/python3.6/site-packages/flask_restful/__init__.py"", line 595, in dispatch_request
resp = meth(*args, **kwargs)
TypeError: get() got an unexpected keyword argument 'range'


Maybe I should use /range/&lt;10000001&gt; as a url query for this?

It should show something like this as a result: 

`{
    ""total"": 50000005000000
}


`
Thanks
","the parameter rng of get(self, rng) function should be the ""range"". I met the problem as you, then change the function parameter name to the value between Angle brackets （&lt;&gt;）. You can try. 
",,,false,,,
https://stackoverflow.com/questions/53368579,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,TypeError: cursor() got an unexpected keyword argument &#39;dictionary&#39; using flaskext.mysql,"I'm using flask framework and MySQL database connector. 

I did the below:

from flaskext.mysql import MySQL
mysql = MySQL()
## app.config database configuration code
mysql.init_app(app)
conn = mysql.connect()
cursor = conn.cursor();
cursor.execute(
        'SELECT * FROM customer WHERE email = (%s)', (username,)
    )
user = cursor.fetchone()


I can access the user columns using index like user[8] (which I need to execute the query once and check the column number), but when I try to specify 

conn = mysql.connect(dictionary=True)


I get the error 


  'TypeError: cursor() got an unexpected keyword argument 'dictionary''


Is there a way to get the results of the query in dictionary format when using flask-MySQL?
","You can follow this answer: https://stackoverflow.com/a/41388992/3129414 

Existing code modification:


use DictCursor in MySQL initialization
remove dictionary=True from cursor
use json package to convert dictionary items to json format


app.py:

import json
from flask import Flask
from flaskext.mysql import MySQL
from pymysql.cursors import DictCursor

app = Flask(__name__)
app.config['MYSQL_DATABASE_USER'] = 'root'
app.config['MYSQL_DATABASE_PASSWORD'] = '123'
app.config['MYSQL_DATABASE_DB'] = 'practice_db'
app.config['MYSQL_DATABASE_HOST'] = 'localhost'
mysql = MySQL(cursorclass=DictCursor)
mysql.init_app(app)
conn = mysql.connect()

@app.route(""/"", methods=['GET'])
def home():
    email_address = 'dummy@example.com'
    cursor = conn.cursor();
    cursor.execute(
            'SELECT * FROM user_table WHERE email = (%s)', (email_address,)
        )
    users = cursor.fetchall()
    return json.dumps(users)

app.run(debug=True)


Screenshot:


",,,false,,,
https://stackoverflow.com/questions/36717816,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,TypeError: flow_from_clientsecrets() got an unexpected keyword argument &#39;include_granted_scopes&#39;,,,,,false,,,
https://stackoverflow.com/questions/35771592,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,SelectMultipleField default value is not being selected on HTML,,,,,false,,,
https://stackoverflow.com/questions/69680256,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Unexpected end of JSON input - Plain JS,"This is a test program as I'm learning to work with JSON and tokens.  The end point is Python Flask.  It seems to work fine, even what it displays in my page is fine, only I see the error in the console.
Code:
function encodeUser(user, password) {
   var token = user + "":"" + password;
   var hash = btoa(token);
   return ""Basic "" + hash;
}

function login(resultElement) {
    result = document.getElementById(resultElement)
    u = document.getElementById(""email"").value;
    p = document.getElementById(""password"").value;
    let xhr = new XMLHttpRequest();
    let url = config_baseurl + ""/login""
    xhr.open(""POST"",url,true);
    xhr.setRequestHeader(""Content-Type"",""application/json"");
    xhr.setRequestHeader(""Authorization"", encodeUser(u, p)); 
    xhr.onreadystatechange = function() {
       txt = this.responseText;
       respJson = JSON.parse(txt);
       result.innerHTML = 'response: ' + txt + '&lt;br&gt;&lt;br&gt;token: ' + respJson.token;
    };
     xhr.send();
}

The results display as expected in my page:
response: { ""token"": ""eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJwdWJsaWNfaWQiOiI3ODIxMDVjNi00ZWRhLTQyMjMtYmQ2Yy1hMDhmMzgzNWExZmUiLCJleHAiOjE2MzQ5MjA4NDR9.iHJQf3qGOJlWcSuw-itTk-IirUGUAnmtNKyUXBDnI0Y"" }
token: eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJwdWJsaWNfaWQiOiI3ODIxMDVjNi00ZWRhLTQyMjMtYmQ2Yy1hMDhmMzgzNWExZmUiLCJleHAiOjE2MzQ5MjA4NDR9.iHJQf3qGOJlWcSuw-itTk-IirUGUAnmtNKyUXBDnI0Y
The console shows this error
Uncaught SyntaxError: Unexpected end of JSON input
at JSON.parse ()
at XMLHttpRequest.xhr.onreadystatechange (example.js:36)
","Can you try with fetch / promises? Timing stuff with XMLHttpRequest is difficult. I suspect that responseText doesn't actually have a value at the time you are decoding the JSON
Something like this
function encodeUser(user, password) {
    const token = user + "":"" + password;
    const encoded = btoa(token); // NOTE: Base64 is not hashing!
    return ""Basic "" + encoded;
}

function login(resultElement) {
    const result = document.getElementById(resultElement);
    const u = document.getElementById(""email"").value;
    const p = document.getElementById(""password"").value;

    const url = config_baseurl + ""/login"";
    const init = {
        method: ""POST"",
        headers: {
        ""Content-Type"": ""application/json"",
        Authorization: encodeUser(u, p),
        },
    };

    fetch(url, init)
        .then(res =&gt; res.json())
        .then(data =&gt; {
            console.log({ data });
            result.innerText = data.token;
        })
        .catch(console.error);
}

",,,false,,,
https://stackoverflow.com/questions/67861658,false,The issue is not relevant for deeper analysis as it does not meet the criteria of exhibiting unexpected behavior under specific runtime conditions.,,,,,,,"flask to javascript, sending json, running into invalid syntax error","I ran into this error while trying to send a pandas to_json object to front end using flask. the codes and errors look like this:
df_higg_msi_scored_manual = pd.read_csv(r'static/CSVFiles/higg_msi_scored_manual.csv')    
materials = df_higg_msi_scored_manual.iloc[:33, 3]
material = materials.to_json(orient=""values"")
return render_template('/impacttool.html', material = material)

var user = JSON.parse('{{brand | tojson | safe}}');

and this is the error that pops up no matter how valid the resulting json file is:

depending on which json i send to the front end, i get either unexpected number or unexpected token, with unexpected token always matching the first alphabet of the first string in json. Could someone please help me figure this out? I've even tried print(material) on flask, then copied the exact json that was printed to the console, assigned that to a variable and sent it to the front end and it worked fine! but for some reason when i do to_json and assign it directly to a variable it throws this error. If someone knows how to fix it  I would love to know. Thank you.
","I found a solution thanks to RaphSinai, it was because the {{ brands | tojson }} was formatted with extra double quotes as ""[whatever...]"" instead of just the [], so I changed the code from material = materials.to_json(orient=""values"") to json.loads(material = materials.to_json(orient=""values"")) and it worked fine.
","In your Javascript try to see what
console.log('{{brand | tojson | safe}}')
gets you because maybe you're trying to turn JSON data into JSON data so maybe also consider removing the | to json part of the variable call
Edit: calling variables doesn't work in files other than HTML files so try parsing the variable directly in the HTML file like so:
&lt;script&gt;
var user = JSON.parse('{{brand | tojson | safe}}')
&lt;/script&gt;

or you could add it to a variable in the HTML file then parse it in the javascript file like so:
filename.html:
&lt;script&gt;
var jsondata = '{{brand | tojson | safe}}'
&lt;/script&gt;

filename.js
var user = JSON.parse(jsondata)

",,false,,,
https://stackoverflow.com/questions/63831384,false,The issue is not relevant for deeper analysis as it does not meet the criteria of exhibiting unexpected behavior under specific runtime conditions.,,,,,,,Testing Flask methods which return a render_template,"I have looked into a bunch of different options, but since Python is really as dynamic as we want it to be, I wanted to ask here.
When doing unit tests, it allows me to mock data and test functionality for expected and unexpected results.  I noticed that there are a large number of functions in the app i am working on which are Flask Routes, which return render_templated data.  Not bad, I am used to that.  The issue here is that I wanted to mock data and test those endpoints.  I saw there are some options though.  When looking on github, i noticed a no-longer-maintained tool flask-testing is no longer maintained it seems. Test Flask render_template() context
I was thinking this would be useful to touch the context to see the resulting data, which is more important than the rendered template to me.  That way, I could control inputs and test the resulting dataset.
Is there something that is in unittest or other that is up to date? If this doesn't work, I guess I could just parse the HTML if i know where the data is for it, but it seems a bit bulky to me to just ensure the data passed into render_template is right or wrong.
What is the way people do this normally?   parse resulting html for the data you need, or is there a way to mock and obtain the context of the result in order to verify.  I have been looking through base docs for unittest and have yet to find anything.
","I just parse the HTML. This makes sure both the data is there (and correct) and the page gets rendered correctly.
If you have a complex function, I'd just extract it out of the view function and unit test it directly.
I am not convinced that mocking would be a great idea here, so I do not mention that you could mock ""render_template"" itself :-)
",,,false,,,
https://stackoverflow.com/questions/63215903,false,The issue is not relevant for deeper analysis as it does not meet the criteria of exhibiting unexpected behavior under specific runtime conditions.,,,,,,,Cannot GET data from Flask from React when deployed on Heroku but works locally,"I am trying to host a web application built with React and it's REST api built with Python + Flask on Heroku. If I serve it locally with npm start, then I can successfully read and use JSON data from Flask. However, if I try to do the same on Heroku - even with a proxy in place - I find the JSON cannot be read.
I've tried changing the JSON to be read as text, as well as adding application/json headers, but to no avail. Despite it working locally, the application continues to be unable to read data from its backend counterpart. Instead, it raises the following error:
(index):1 Uncaught (in promise) SyntaxError: Unexpected token &lt; in JSON at position 0. If I try to print out the response as text with fetch('/api/multiply/10').then(res =&gt; res.text()).then(data =&gt; { console.log(data) }), I get a bunch of HTML that does not match the simple text returned on the local server.
On the locally running server I get the expected { ""result"": 100 } while with Heroku and the same command I get the default HTML:
&lt;!doctype html&gt;&lt;html lang=""en""&gt;&lt;head&gt;&lt;meta charset=""utf-8""/&gt;&lt;link rel=""icon"" href=""/favicon.ico""/&gt;&lt;meta name=""viewport"" content=""width=device-width,initial-scale=1""/&gt;&lt;meta name=""theme-color"" content=""#000000""/&gt;&lt;meta name=""description"" content=""Web site created using create-react-app""/&gt;&lt;link rel=""apple-touch-icon"" href=""/logo192.png""/&gt;&lt;link rel=""manifest"" href=""/manifest.json""/&gt;&lt;title&gt;React App&lt;/title&gt;&lt;link href=""/static/css/2.3c095960.chunk.css"" rel=""stylesheet""&gt;&lt;link href=""/static/css/main.f2d4b2b8.chunk.css"" rel=""stylesheet""&gt;&lt;/head&gt;&lt;body&gt;&lt;noscript&gt;You need to enable JavaScript to run this app.&lt;/noscript&gt;&lt;div id=""root""&gt;&lt;/div&gt;&lt;script&gt;!function(e){function r(r){for(var n,p,i=r[0],l=r[1],a=r[2],f=0,s=[];f&lt;i.length;f++)p=i[f],Object.prototype.hasOwnProperty.call(o,p)&amp;&amp;o[p]&amp;&amp;s.push(o[p][0]),o[p]=0;for(n in l)Object.prototype.hasOwnProperty.call(l,n)&amp;&amp;(e[n]=l[n]);for(c&amp;&amp;c(r);s.length;)s.shift()();return u.push.apply(u,a||[]),t()}function t(){for(var e,r=0;r&lt;u.length;r++){for(var t=u[r],n=!0,i=1;i&lt;t.length;i++){var l=t[i];0!==o[l]&amp;&amp;(n=!1)}n&amp;&amp;(u.splice(r--,1),e=p(p.s=t[0]))}return e}var n={},o={1:0},u=[];function p(r){if(n[r])return n[r].exports;var t=n[r]={i:r,l:!1,exports:{}};return e[r].call(t.exports,t,t.exports,p),t.l=!0,t.exports}p.m=e,p.c=n,p.d=function(e,r,t){p.o(e,r)||Object.defineProperty(e,r,{enumerable:!0,get:t})},p.r=function(e){""undefined""!=typeof Symbol&amp;&amp;Symbol.toStringTag&amp;&amp;Object.defineProperty(e,Symbol.toStringTag,{value:""Module""}),Object.defineProperty(e,""__esModule"",{value:!0})},p.t=function(e,r){if(1&amp;r&amp;&amp;(e=p(e)),8&amp;r)return e;if(4&amp;r&amp;&amp;""object""==typeof e&amp;&amp;e&amp;&amp;e.__esModule)return e;var t=Object.create(null);if(p.r(t),Object.defineProperty(t,""default"",{enumerable:!0,value:e}),2&amp;r&amp;&amp;""string""!=typeof e)for(var n in e)p.d(t,n,function(r){return e[r]}.bind(null,n));return t},p.n=function(e){var r=e&amp;&amp;e.__esModule?function(){return e.default}:function(){return e};return p.d(r,""a"",r),r},p.o=function(e,r){return Object.prototype.hasOwnProperty.call(e,r)},p.p=""/"";var i=this[""webpackJsonpchinese-resource-app""]=this[""webpackJsonpchinese-resource-app""]||[],l=i.push.bind(i);i.push=r,i=i.slice();for(var a=0;a&lt;i.length;a++)r(i[a]);var c=l;t()}([])&lt;/script&gt;&lt;script src=""/static/js/2.e64d4889.chunk.js""&gt;&lt;/script&gt;&lt;script src=""/static/js/main.7180a907.chunk.js""&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;

Relevant content from App.tsx:
import React, { useState, useEffect } from 'react';
...
...
function App() {
  const [result, setResult] = useState(0);
  useEffect(() =&gt; {
    fetch(""/api/multiply/10"", {
      headers : {
      'Content-Type': 'application/json',
      'Accept': 'application/json'
      }
    }).then(res =&gt; res.json()).then(data =&gt; {
      // setResult(data)
      console.log(data)
      console.log(data) // should show {result: 100}
    })
  }, []);

Backend:
from flask import Flask, request
from flask_restful import Resource, Api

app = Flask(__name__)
api = Api(app)

class ComplexExample(Resource):
    """"""
    Demonstrates a GET request with parameters.
    """"""

    def get(self, num):
        return {""result"": num * 10}


api.add_resource(
    ComplexExample, ""/api/multiply/&lt;int:num&gt;""
)

Relevant lines from package.json:
  ""scripts"": {
    ""start"": ""npm-run-all --parallel scriptstart api"",
    ""scriptstart"": ""react-scripts start"",
    ""api"": ""cd api &amp;&amp; flask run"",
    ""build"": ""react-scripts build"",
    ""test"": ""react-scripts test"",
    ""eject"": ""react-scripts eject""
  },
  ...
  ""proxy"": ""http://localhost:5000""
}

Am I missing something or is there any way to successfully have a Flask REST api and a React frontend hosted on Heroku? The website is currently being hosted here: https://test-mandarin-web-app.herokuapp.com.
You can view the repository and the rest of the code here: https://github.com/Destaq/chinese-resource-app/tree/268a747bf6f803e328d96caeb9b81719154b4ec0
","You're getting a 502 when accessing the API. You have either the reverse proxy (nginx) or backend misconfigured or both. Can't say much more without knowing how you're deploying.
",,,false,,,
https://stackoverflow.com/questions/59104813,true,"The issue involves an unexpected behavior when trying to load JSON data from a Flask URL in React. The issue is related to the incorrect format of the returned data from the Flask route, which causes a JSON parsing error in JavaScript. The issue is relevant for deeper analysis.",,,,,,,how to load data from a flask url and console log the data n react?,"I want to load a json file that I get from a url generated in flask. 
     After d3.json(url, function) I'm trying to console log the json, but nothing happens and I dont know what's wrong. So maybe someone can help

This is basically my code:

Component where I want to display a graph (Display.js):

import React, { Component } from 'react';
import ""./Display.css"";
import * as d3 from ""d3"";

export default class Display extends Component {

 componentWillReceiveProps() {

    const url = ""http://localhost:5000/company?company_name="" + this.props.inputDataFromParent        //the url depends on the input the user made. InputDataFromParent is the passed value (from the parent) that the user typed in

    d3.json(url, function (data) {

      console.log(data)
    })
  }


when I type in an input (company name) that doesnt exist in the database I get an error: ""Uncaught (in promise) SyntaxError: Unexpected token N in JSON at position 0""at (index):1

when I type in an input that does exist nothing happens in the console.

Here's my main.py:

import flask
from pandas import DataFrame
from models import company_search
from flask import request
from models import subsidiaries

app=flask.Flask(""__main__"")

@app.route(""/company"")
def result():
    if request.method == 'GET':
        company_name = request.args.get('company_name', None)
        if company_name:
            return subsidiaries(company_name)
        return ""No place information is given""


app.run(debug=True)


and this is models.py (neo4j is used as the database):

def subsidiaries(eingabe):
     if regex_eingabe_kontrolle(eingabe):
        namelistdf = graph.run(""MATCH (c:Company)-[rel:Relation]-&gt;(d:Company) WHERE rel.relation_group='OWNERSHIP' AND rel.percent_share &gt;= 50 AND c.company_name= $eingabe RETURN c, rel, d"",eingabe=eingabe).to_data_frame()
        if namelistdf.empty:
            return ""No company with this name exists""
        namelistjson = namelistdf.to_json(orient=""records"",date_unit=""s"",default_handler=str)
        return namelistjson
     else:
         return ""Please enter a valid company name""


I get the data from a neo4j database.
It's not about to console log the data because I want to generate a graph from the data. The console log is only for testing if the data is right. But now it seems that the data isn't passed to d3.json(url, function (data) correctly
","Your problem occurs in your main file when you return No place information is given. Since this is not in JSON format, JavaScript fails to parse it causing the error to be thrown. To fix this, you can change it to:

import json

@app.route(""/company"")
def result():
    if request.method == 'GET':
        company_name = request.args.get('company_name', None)
        if company_name:
            return subsidiaries(company_name)
        return json.dumps(""No place information is given"")


If you do the same for No company with this name exists and Please enter a valid company name, you won't get anymore JSON deserialization errors. However, D3 may still throw errors because it does not know what to do with a string.

You may want to return HTTP status codes along with your error messages so you can control the error. To do this in Flask, you can return the text along with the status code. For example: return json.dumps(""Error message""), 400 will return the JSON string Error message with the status code 400. Since d3.json makes an underlying call to the JavaScript fetch function, you should be able to access the status code  by using data.status.
",,,false,,,
https://stackoverflow.com/questions/57173316,true,The issue involves unexpected results when using a CSRF token in Python Flask. The issue is related to the incorrect implementation of the CSRF token in the JavaScript code. The issue is relevant for deeper analysis.,,,,,,,Python Flask CSRF token is giving unexpected results,"I am trying to implement csrf but I am confused as how this works.
My python file.

from flask_wtf.csrf import CSRFProtect, CSRFError
csrf = CSRFProtect()
app = Flask(__name__)
app.config['SECRET_KEY'] = 'FlaskAppKey'
csrf.init_app(app)


My js file.

       var csrftoken = ""{{ csrf_token () }}"";
       $.ajax(
       {
    url: '/calendar_data/',
    dataType:'json',
    type: 'GET',
    contentType: 'application/json',
    data:dataString,
    beforeSend:function(xhr,settings)
    {
      xhr.setRequestHeader(""X-CSRFToken"", csrftoken);
        },


The request.header dump shows.

X-Csrftoken: IjQ5NjYxOWRiYzgwOWU1N2Q0OWY0MmUxMDRjOGU1ZDcwNGUwNTJkM


If I remove the token the site doesn't error.

I have an error route.  So I am unsure if I am implementing everything correctly.  Once I removed the token from the code I was expecting an error.

      @app.errorhandler(CSRFError)
      def handle_csrf_error(e):
  print(e)
  return ''


If the token isn't sent shouldn't the request error?

routes page

@app.route(""/calendar_data/"")
def calendar_data():
    stuff
return jsonify(data=data[1])

","You might want to test with a POST request instead.
This might not answer your question directly, but rather guide you towards the WTF-Forms behavior. Have you tried sending a POST request instead of a GET request? The reason why I ask is because usually the protection will be against insertion of data, and specifically in POST requests (A lot more information on this thread.
Also, according to the docs you can set up your beforeSend ajax method to the following:
 var csrf_token = ""{{ csrf_token() }}"";

    $.ajaxSetup({
        beforeSend: function(xhr, settings) {
            if (!/^(GET|HEAD|OPTIONS|TRACE)$/i.test(settings.type) &amp;&amp; !this.crossDomain) {
                xhr.setRequestHeader(""X-CSRFToken"", csrf_token);
            }
        }
    });

## this should also technically exclude the CSRF token from the header

If you do try with POST requests, just make sure to accept it on your route:
@app.route(""/calendar_data/"", methods=('GET', 'POST'))
def calendar_data():
    if request.method == 'POST':
        print ('posted')
    stuff
return jsonify(data=data[1])

From my understanding that case will not work if you do not pass the CSRF-token to the POST request, or if it is somehow malformed.
Some more on CSRF in GET Requests
According to this cheatsheet on CSRF security tokens:


The ideal solution is to only include the CSRF token in POST requests and modify server-side actions that have state changing affect to only respond to POST requests. This is in fact what the RFC 2616 requires for GET requests. If sensitive server-side actions are guaranteed to only ever respond to POST requests, then there is no need to include the token in GET requests.


Also, according to rfc7231:


Request methods are considered ""safe"" if their defined semantics are
essentially read-only




Of the request methods defined by this specification, the GET, HEAD,
OPTIONS, and TRACE methods are defined to be safe.


",,,false,,,
https://stackoverflow.com/questions/50856734,true,The issue involves an error when accessing URL arguments through the request.args in Flask. The issue is related to the incorrect usage of the route and the request.args.get function. The issue is relevant for deeper analysis.,,,,,,,Accessing url arguments through request args in flask,"I had been trying to deploy a machine learning model through flask. I need to pass some text through url so that it could be retrieved for classification. I am using request.args.get function but its throwing the error:  

TypeError: index() got an unexpected keyword argument 'text'


The url is: 

http://127.0.0.1:8000/index/text=Windows%20is%20a%20operating%20system


Its showing the error too:

Internal Server Error

The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.


service.py:

from flask import Flask, request, jsonify
import pickle

app = Flask(__name__)

file = open(""models/GridSearchCV_nb.pickle"",""rb"")
nb_clf = pickle.load(file)

file = open(""models/GridSearchCV_svm.pickle"",""rb"")
svc_clf = pickle.load(file)

file = open(""models/ctargets.pickle"",""rb"")
targets = pickle.load(file)

def nbclassifyit(text):
  idx_nb = nb_clf.predict([text])[0]
  return targets[idx_nb]

def svclassifyit(text):
  idx_svc = svc_clf.predict([text])[0]
  return targets[idx_svc]


@app.route('/index/&lt;text&gt;')
def index():
 text = request.args.get('text')
 result = {""prediction"" : nbclassifyit(text)}
 return jsonify(result)


What am I doing wrong??
","The request.args.get function looks for arguments after a ? at the end of the route. You don't need to use &lt;text&gt; in your route.

So you can try changing your index route and function like this:

@app.route('/index/')
def index():
 text = request.args.get('text')
 result = {""prediction"" : nbclassifyit(text)}
 return jsonify(result)


And giving the text argument in your url like this:

http://127.0.0.1:8000/index/?text=Windows%20is%20a%20operating%20system

",,,false,,,
https://stackoverflow.com/questions/43644425,true,The issue involves the Flask framework and the error message indicates a problem with accessing the request context. This suggests that the issue may be related to an API in Flask that requires an active HTTP request context.,Flask,request context,"The error message ""Working outside of request context"" indicates that the code is trying to access functionality that requires an active HTTP request context. This typically happens when using Flask APIs that rely on the request context, such as accessing the request object.",The Flask APIs that rely on the request context work as expected when they are called within the context of an active HTTP request.,"The issue is triggered when the code attempts to access Flask APIs that require the request context outside of an active HTTP request, such as when using Celery tasks.","This issue might be challenging to detect during development and testing because it only occurs when the code is executed outside of an active HTTP request context, which may not be easily replicated in a development or testing environment.",Flask throwing &#39;Working outside of request context.&#39;,"I am trying to use celery for my app which is made in flask but I get the following error ""Working outside of request context"". It sounds like I am  trying to access a request object before the front end makes a request, but I cannot figure out what is wrong. I appreciate if you can let me know what is the problem.

[2017-04-26 13:33:04,940: INFO/MainProcess] Received task: app.result[139a2679-e9df-49b9-ab42-1f53a09c01fd]  
[2017-04-26 13:33:06,168: ERROR/PoolWorker-2] Task app.result[139a2679-e9df-49b9-ab42-1f53a09c01fd] raised unexpected: RuntimeError('Working outside of request context.\n\nThis typically means that you attempted to use functionality that needed\nan active HTTP request.  Consult the documentation on testing for\ninformation about how to avoid this problem.',)
Traceback (most recent call last):
  File ""/Library/Python/2.7/site-packages/celery/app/trace.py"", line 367, in trace_task
    R = retval = fun(*args, **kwargs)
  File ""/Users/Pooneh/projects/applications/ray_tracer_app_flask/flask_celery.py"", line 14, in __call__
    return TaskBase.__call__(self, *args, **kwargs)
  File ""/Library/Python/2.7/site-packages/celery/app/trace.py"", line 622, in __protected_call__
    return self.run(*args, **kwargs)
  File ""/Users/Pooneh/projects/applications/ray_tracer_app_flask/app.py"", line 33, in final_result
    light_position = request.args.get(""light_position"", ""(0, 0, 0)"", type=str)
  File ""/Library/Python/2.7/site-packages/werkzeug/local.py"", line 343, in __getattr__
    return getattr(self._get_current_object(), name)
  File ""/Library/Python/2.7/site-packages/werkzeug/local.py"", line 302, in _get_current_object
    return self.__local()
  File ""/Library/Python/2.7/site-packages/flask/globals.py"", line 37, in _lookup_req_object
    raise RuntimeError(_request_ctx_err_msg)
RuntimeError: Working outside of request context.

This typically means that you attempted to use functionality that needed
an active HTTP request.  Consult the documentation on testing for
information about how to avoid this problem.


app.py

app = Flask(__name__)
app.config.update(CELERY_BROKER_URL = 'amqp://localhost//',
CELERY_RESULT_BACKEND='amqp://localhost//')

celery = make_celery(app)


@app.route('/')
def my_form():
    return render_template(""form.html"")

@app.route('/result')
def result():
    final_result.delay()
    return ""celery!""

@celery.task(name='app.result')
def final_result():
    light_position = request.args.get(""light_position"", ""(0, 0, 0)"", type=str)
    light_position_coor = re.findall(""[-+]?\d*\.\d+|[-+]?\d+"", light_position)
    x = float(light_position_coor[0])
    y = float(light_position_coor[1])
    z = float(light_position_coor[2])

    encoded = base64.b64encode(open(""/Users/payande/projects/applications/app_flask/static/pic.png"", ""rb"").read())
    return jsonify(data=encoded)

",,,,false,,,
https://stackoverflow.com/questions/40718953,false,The issue is related to searching data in a Flask application and does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Flask - Search db model by column,"I am using built in admin website of flask for searching data from db. So I created db model, and model view in which I specified column_searchable_list. When I enter search text, it will match this search text with each column in column_searchable_list (1), and return list of matched rows.

This is cool, but sometimes it causes some unexpected result because some part of data from this column may match with part of data from other columns. Therefore, I wonder is there any way to implement search by specific column in flask. Or I have to create my own search tab. I am quite new to flask, so hope some of you guys know some tricks for this.
",,,,false,,,
https://stackoverflow.com/questions/30081097,false,The issue does not provide enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Querying broken with pymongo 3.0 and Flask-MongoEngine,,,,,false,,,
https://stackoverflow.com/questions/70068050,false,The issue does not provide enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,SyntaxError: Unexpected token &lt; in JSON at position 0 while doing api post request in reactjs,,,,,false,,,
https://stackoverflow.com/questions/52553470,false,The issue does not provide enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,jinja2.exceptions.TemplateSyntaxError,,,,,false,,,
https://stackoverflow.com/questions/46024840,false,The issue is a general question about the use of a web server in Flask deployments and does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,What is the use of a web server in flask deployments?,"Note: the question was closed as a duplicate but it is not (of neither the questions).
I specifically described an app in web mode, then in WSGI mode - I have no doubts on which to use when (both linked questions address this point). I also explained that I know well what a web server is for. 
The accepted answer makes a good summary of that, and answers the question of whether a web server is a requirement to run a prod flask app (it is not). 

I have a flask application. The development version, with all its limitations,  is 

import flask

app = flask.Flask(__name__)

@app.route(""/"")
def hello():
    return ""Hello World!""

app.run()


When I want to move it to production, I use gevent, per the deployment documentation:

import gevent.monkey
gevent.monkey.patch_all()
import flask
import gevent.wsgi

app = flask.Flask(__name__)

@app.route(""/"")
def hello():
    return ""Hello World!""

gevent.wsgi.WSGIServer(('127.0.0.1', 5000), app).serve_forever()


Both cases work, with the first one occasionally having issues (which is not unexpected, due to its nature).

Then, a lot of information I read here and there mention that the third component for production deployments of a flask application is a web server (Apache, nginx). What is its actual use for WSGI-enabled flask applications?

Specifically, I would like to understand whether it has a practical impact on the performance / stability of the flask application. 

I know what the various usages of a webserver are (authentication, reverse proxy, whitelisting, rewrites, load management, and many others). My question is specifically about what a webserver provides for a flask WSGI application (if anything). 
","With Flask, you build your web application. WSGI is the interface the application follows to be hosted by WSGI servers. gevent is a WSGI server that can host your application.

Usually, you would then put a full fledged web server (e.g. nginx or apache) as a reverse proxy in front of it to get the full features modern web servers usually offer, without the intermediate WSGI server having to offer those features themselves. That makes everything simpler and easier to reason about, since every component can focus on what it does best (the WSGI server’s job being to only host your application).

The dev server that comes with Flask is a very simple server that runs in a single process. It uses werkzeug for this, which also explictly mentions that it should not be used for production:


  The development server is not intended to be used on production systems. It was designed especially for development purposes and performs poorly under high load. For deployment setups have a look at the Application Deployment pages.


So instead, you use a “real” WSGI server to host your application; it will then do whatever necessary to run your application properly. A WSGI server is still rather simple though; you put another web server as a reverse proxy in front to get access to the features that make webservers really powerful (e.g. load balancing, caching, SSL termination, …).
",,,false,,,
https://stackoverflow.com/questions/69870017,true,The issue involves a conflict between Jinja syntax and JavaScript code when using Plotly graphs in a Flask web app.,Jinja,Jinja syntax,"The issue arises when using Jinja syntax inside JavaScript code to pass a JSON file to a JavaScript variable. The Jinja syntax conflicts with the JavaScript syntax, resulting in an unexpected identifier error.",Jinja syntax works as expected when used within HTML templates or Flask routes.,"The issue is triggered when Jinja syntax is used within JavaScript code, particularly when passing variables from Flask to JavaScript.",This issue might be challenging to detect during development and testing because it involves a specific combination of Jinja and JavaScript code that may not be immediately obvious.,Plotly Graphs - Conflict between Javascript and Jinja,"I've tried plotting graphs in my Flask web app using Plotly which didn't work for some reason so I started to simplify the issue to find the error.
It seems like there is an issue with the Jinja Syntax {{ myJSONfile | safe }} in javascript.
Aslong as I pass an empty string """" to the variable the graph renders but obviously without datapoints.
(Inspect Element Console gives an Unexpected token '{' Error referring to the first opening bracket of my Jinja variable)
According to this post I should have written the the syntax inside the javascript block correctly in order to pass a JSON-File to the javascript variable and I am out of ideas right now.
I'd appreciate if somebody has further ideas and can help me out here :)
Code example:
   {% extends ""layout.html"" %} {% block content %}

&lt;div class="" row p-4 ""&gt;
    &lt;div class=""card m-auto "" style=""width: 90%; "" data-aos=""fade-left ""&gt;
        &lt;div class=""card-body ""&gt;
            &lt;div id=""chart1 ""&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;


&lt;script src=""https://cdn.plot.ly/plotly-latest.min.js ""&gt;&lt;/script&gt;
&lt;script&gt;
    var graphs1 = {
        {
            graph1JSON | safe
        }
    };
    Plotly.plot(""chart1 "", graphs1, {});
&lt;/script&gt;

I've since tested out another test code from a tutorial github repository to eliminate the possibility that it may have been some typing errors in my code I wasn't able to identify.
But those copy paste examples gave me the same issue.
I've tried different things suggested in some posts I've found here on Stackoverflow

checked again if my data was saved to the JSON variable in app.py correctly (which it does)
using quotes like: var graph1 = '{{ graph1JSON | safe }}'
using block code syntax: var graph1 = {%block code %} {{ graph1JSON | safe }} {%endblock code %}
Several combinations of above syntax

During debug I clearly see that the JSON file is created successfully and holds the desired data, Flask/Jinja just doesnt want to communicate with Javascript
Here's an additional Screenshot of how the syntax highlighting looks in my VS Code. (Other than in this particular case my Flask app is running fine, being able to render pages dynamically etc.)

(Syntax not recognized in the javascript part)
","The problem here lies with VSCode, especially with Syntax Highlighting and Formatting Extensions.
There is some conflict between some of your enabled extensions which - on save - format the javascript code in above way.

Disable all enabled formatting extensions in VSCode
I only activated the following:


Python
Python Extension Pack by Jayamanne
Better Jinja by Samuel Colvin

This way on save the syntax doesn't get shredded anymore making the JavaScript recognize your JSON-File correctly.
","Please do not pull apart the jinja instruction. Jinja looks for double curly brackets in the template, which follow one another directly with no whitespace in between.
var graphs1 = {{ graph1JSON | safe }};
Plotly.plot('chart1', graphs1, {});

",,false,,,
https://stackoverflow.com/questions/67001768,false,The issue does not provide enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Chart.js not rendering,"I have been using and learning Flask with python recently, and was looking to use some charts to visualize some data. I straight up followed a youtube guide and used almost the exact same code to visualize my data, but it didnt work. So, i tried using his exact code and still, it did not render the chart. What might be the issue?
from flask import flask, render template

app = flask(__name__)

data = [
    (""01-01-2020"", 1597),
    (""02-01-2020"", 1456),
    (""03-01-2020"", 1908),
    (""04-01-2020"", 896),
    (""05-01-2020"", 755),
    (""06-01-2020"", 453),
    (""07-01-2020"", 1100),
    (""08-01-2020"", 1235),
    (""09-01-2020"", 1478),
]
labels = [row[0] for row in data]
values = [row[1] for row in data]

return render_template(""graph.html"", labels=labels, values=values)

the above is a part of my python app, below is the HTML that goes with it:
&lt;!DOCTYPE html&gt;
&lt;html lang=""en""&gt;
&lt;head&gt;
  &lt;meta charset=""utf-8"" /&gt;
    &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1.0""&gt;
  &lt;title&gt; Sample chart &lt;/title&gt;
  &lt;script src=""https://cdn.jsdelivr.net/npm/chart.js@2.9.4/dist/Chart.min.js""&gt;&lt;/script&gt;
&lt;/head&gt;


&lt;body&gt;
    &lt;canvas id=""lineChart"" width=""900"" height=""400""&gt;&lt;/canvas&gt;
    &lt;script&gt;
        var ctx = document.getElementById(""lineChart"").getContext(""2d"");
        var lineChart = new Chart(ctx, {
            type: ""line"",
            data: {
                labels: {{ labels | safe }}
                datasets: [
                    {
                        label: ""Data points"",
                        data: {{ values | safe }}
                        fill: true,
                        borderColor: ""rgb(75, 192, 192)"",
                        lineTension: 0.1
                    }
                ]
            },
            options: {
                responsive: false
            }
        });
    &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt; 

When i load my localhost, the page is empty. just nothing. If i put in this above, it renders just fine:
&lt;p&gt; {{ labels }} &lt;/p&gt;

When i inspect the web page, i can see all the html code, however, in the console when i inspect, there is an error:
Uncaught SyntaxError: Unexpected indetifier
example:17
Tried to google it a bit but didnt really get anything i understood to use. So, any ideas on what might be the issue?
(Also, i would link the youtube video but im a bit unsure about the rules and if i can even copy his code in here?)
","you have to use or import chart js library by or else go through documentation first
like this if you are using CDN
&lt;script src=""https://cdnjs.cloudflare.com/ajax/libs/Chart.js/3.0.2/chart.min.js"" &gt;&lt;/script&gt;

",,,false,,,
https://stackoverflow.com/questions/41638552,true,The issue involves the Flask-SocketIO extension and the error message indicates a problem with the WebSocket handshake. This suggests that the issue may be related to an API in Flask-SocketIO that handles the WebSocket handshake process.,Flask-SocketIO,WebSocket handshake,"The error message ""WebSocket connection failed: Error during WebSocket handshake: Unexpected response code: 200"" indicates a problem with the WebSocket handshake process. This typically happens when the server-side API responsible for handling the WebSocket handshake does not respond with the expected status code (101 Switching Protocols).",The WebSocket handshake process in Flask-SocketIO works as expected when the server-side API responds with the status code 101 Switching Protocols.,"The issue is triggered when the server-side API responsible for the WebSocket handshake in Flask-SocketIO does not respond with the expected status code, such as when running the Flask development server on a different port (e.g., port 80).",This issue might be challenging to detect during development and testing because it may only occur when running the Flask development server on a different port or in certain network environments.,Websocket returns status 200 instead of 101 (flask socket.io),"I've done quite a bit of reading around to try and solve this issue but I'm still stuck. My problem is with trying to get the websocket handshake to complete using socket.io client side and flask_socket.io server side. 

I can run the flask development server on my local machine using: 



app = Flask(__name__)
app.secret_key = 'A0Zr98j/3yX R~XHH!jmN]LWX/,?RT'
socketio = SocketIO(app)
socketio.run(app)
...




and if I point chrome to localhost:5000 and press the button which I have linked to opening a websocket it works fine and chrome network tab shows status 101.

However on uploading the code to a remote machine and again using flask's development server but changing the port to 80, 



socketio.run(app,host='0.0.0.0',port=80)




the websocket handshake stops working and gives status 200 instead.

WebSocket connection to 'ws://example.com/socket.io/?EIO=3&amp;transport=websocket&amp;sid=cfb1949b243b42578fe422782a0db359' failed: Error during WebSocket handshake: Unexpected response code: 200

All websocket messages are now sent over xhr polling instead of inside the websocket frame. 

I've followed all of the guides I can find on google relating to this but with no success. I was previously using nginx and gunicorn and followed the advice to change the nginx conf to allow upgrade to websockets but that didn't solve the problem. So I simplified to using the flask development server but I still haven't been able to get a successful handshake.
","I found a solution after finding a similar problem posted here https://nolanlawson.com/2013/05/31/web-sockets-with-socket-io-node-js-and-nginx-port-80-considered-harmful/#comment-85425.

It turns out many public wifi networks block websockets when they are running on port 80. However often ports 443 and 8080 are not blocked. You can find out which ports are blocked from this website: http://websocketstest.com/. I just moved the address of my websocket from example.com to example.com:8080.
","I ran into a similar problem but due to a different reason. When using flask-socketio you have to install gevent-websocket or else it's going to use long-polling and you'll see a lot of 200 responses. Thus, my solution to that problem was just.

pip install gevent-websocket

",,false,,,
https://stackoverflow.com/questions/30042652,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Extra characters appearing in Flask JavaScript files,"Something very random has happened during my development and I can't for the life of me figure out what has gone wrong or why.

Im building an application in Flask as well as using Docker. Everything has been running fine up until now.

If I have a JavaScript file that if I modify Flask loads it in with some random characters in it at the end of the file. Or to be more specific, 

If I have a file with 

alert('random text');


And I load the page, the JS will do what you would expect. But then if I add any extra characters to the file,

alert('randomer text');


I get 2 random characters at the end of the file. Both look like

�


If I was to delete characters from the original file, say

alert('random');


I would get a file with 5 characters missing from the end, so it would look like

alert('random te


As you can see very bizarre.

When running Flask locally everything works fine its only when I load everything into Docker that this starts to happen, so I have to assume its something with Docker &amp; Flask/Python.

The Flask app is started with Gunicorn using default settings, again this has not been an issue in the past.

My Docker environment is run with 

docker run -t -i -d --name pv -v $PWD:/app/code -p 5000:5000 -p 5555:5555 --link redis_db:redis_db my_image


Again this hasn't changed in the last month.

This project is 2+ months old and has been using Docker right from the start with no issues at all.

The only thing that has happened that I can recall since this error has started is that I had to do a Hard GIT Reset to move back one commit.

Things I have already tried.


Using a different IDE to see if it was doing something strange with encoding.
Declaring the JavaScript file as utf-8 when loading it in.
Loading in different browsers. Chrome throws ""Uncaught SyntaxError: Unexpected 
token ILLEGAL"". And other browsers do similar.
Using an older Docker file.
Loading the script from a different view template.


Honestly I'm at a loss. Any help would be appreciated.

Edit

To add to this I only now seem to get the error when running the application using Gunicorn.
","You gave the actual byte values as: (239, 191, 189)

This is U+FFFD, the unicode replacement character:

http://www.fileformat.info/info/unicode/char/0fffd/index.htm

My guess is you've written a bad character to the file that your editor is incapable of displaying or editing (as you explained by the weird behavior when adding/removing characters at the end of the file). 

I would forget about docker, javascript, IDEs, browsers, etc. and just simply look at the raw bytes of the file and replace them if necessary. You can use python to do this:

&gt;&gt;&gt; data = open('something.js').read()

# view the last 8 bytes of the file
&gt;&gt;&gt; data[-8:]
...

# if you see the last 3 bytes of the file are the bad 239, 191, 189 sequence,
# (displayed as ""\xef\xbf\xbd"" in python), then chop them off:
&gt;&gt;&gt; open('something.js', 'w').write(data[:-3])

# or if they occur somewhere else,
# use some other string processing to replace them..
&gt;&gt;&gt; open('something.js', 'w').write(data.replace(""\xef\xbf\xbd"", """"))

",,,false,,,
https://stackoverflow.com/questions/71797317,true,"The issue involves Jinja variable parsing in JavaScript code within a static JS file. This API-related problem occurs because Jinja variable parsing only works in the HTML template, and when the JavaScript code is in a static JS file, the Flask/Jinja variables cannot be accessed. The suggested solution is to use the tojson Jinja filter to safely embed only the JSON data into the document and then load it in JavaScript.",,,,,,,Fix @ Jinja variable parsing at Javascript code in a static JS file …?,"I am running into this “old problem”: Jinja variable parsing only works on the html template (passed in to render_template), so if your Javascript code is in a static JS file the Flask/Jinja variables can't be accessed”.
Jinja Flask issue: Uncaught SyntaxError: Unexpected token { in JSON at position 1 at JSON.parse
Does anyone know if there is already a solution for this. It's ugly to embed the JS code in the HTML file
","You can use the tojson Jinja filter to safely embed only the JSON data into the document, then load it in JS.
{% set data = [1, 2, 3, 4] %}
&lt;script id=""data"" type=""application/json""&gt;{{ data|tojson }}&lt;/script&gt;

And in the external JS file:
const value = JSON.parse(document.getElementById('data').textContent);

",,,false,,,
https://stackoverflow.com/questions/55291944,true,"The issue involves Jinja variable parsing in JavaScript code within a static JS file. Similar to the previous issue, Jinja variable parsing only works in the HTML template, and when the JavaScript code is in a static JS file, the Flask/Jinja variables cannot be accessed. The suggested solution is to use the tojson Jinja filter to safely embed only the JSON data into the document and then load it in JavaScript.",,,,,,,Jinja Flask issue: Uncaught SyntaxError: Unexpected token { in JSON at position 1 at JSON.parse,"Hi I've got an issue passing a simple variable from Flask app to javascript. My python looks as follows:

@app.route('/')
def loadInitialData():

    data={""grade"":""0""}

    return render_template('index.html', data= json.dumps(data))


My javascript looks like this:

var data = JSON.parse('{{ data }}');
console.log(data);


And I keep getting this error:

VM24:1 Uncaught SyntaxError: Unexpected token { in JSON at position 1
    at JSON.parse ()
","Jinja variable parsing only works on the html template (passed in to render_template), so if your Javascript code is in a static JS file the Flask/Jinja variables can't be accessed.
",,,false,,,
https://stackoverflow.com/questions/34672071,true,"The issue involves an unexpected behavior in the re.sub function in Python 2.7. The issue is not related to an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions, but rather a problem with the Python 2 re.sub function itself. The suggested solution is to explicitly convert the text to Unicode and handle the encoding and decoding properly.",,,,,,,Python 2 re.sub issue,"I got this a function that replaces sub-string matches with the match surrounded with HTML tags. This function will consume string in English and Greek mostly.

The function:

def highlight_text(st, kwlist, start_tag=None, end_tag=None):
    if start_tag is None:
        start_tag = '&lt;span class=""nom""&gt;'

    if end_tag is None:
        end_tag = '&lt;/span&gt;'

    for kw in kwlist:
        st = re.sub(r'\b' + kw + r'\b', '{}{}{}'.format(start_tag, kw, end_tag), st)
    return st


The testing string is in Greek except the first sub-string [Korais]: st=""Korais Ο Αδαμάντιος Κοραής (Σμύρνη, 27 Απριλίου 1748 – Παρίσι, 6 Απριλίου 1833), ήταν Έλληνας φιλόλογος με βαθιά γνώση του ελληνικού πολιτισμού. Ο Κοραής είναι ένας από τους σημαντικότερους εκπροσώπους του νεοελληνικού διαφωτισμού και μνημονεύεται, ανάμεσα σε άλλα, ως πρωτοπόρος στην έκδοση έργων αρχαίας ελληνικής γραμματείας, αλλά και για τις γλωσσικές του απόψεις στην υποστήριξη της καθαρεύουσας, σε μια μετριοπαθή όμως μορφή της με σκοπό την εκκαθάριση των πλείστων ξένων λέξεων που υπήρχαν στη γλώσσα του λαού.""

The test code:

kwlist = ['ελληνικού', 'Σμύρνη', 'Αδαμάντιος', 'Korais']
d = highlight_text(st, kwlist, start_tag=None, end_tag=None)
print(d)


When I'm running the code [st is the above string] only sub-strings in English get tagged. Greek substr are ignored. Notice that I run the above block on Python 2.7. When I use Python 3.4 all sub-string get replaced.
Another issue is that when I'm running the above function withing Flask application, it throws me an error: unexpected end of regular expression.

How should I tackle the above issue without using external library if possible?
I'm pulling my hairs off my head two days now.
","In Python 2.7, you need to explicitly convert text to Unicode. See the fixed snippet below:

# -*- coding: utf-8 -*-
import re
def highlight_text(st, kwlist, start_tag=None, end_tag=None):
    if start_tag is None:
        start_tag = '&lt;span class=""nom""&gt;'

    if end_tag is None:
        end_tag = '&lt;/span&gt;'

    for kw in kwlist:
        st = re.sub(ur'\b' + kw.decode('utf8') + ur'\b', 
           u'{}{}{}'.format(start_tag.decode('utf8'), kw.decode('utf8'), end_tag.decode('utf8')),
           st.decode('utf8'), 0, re.U).encode(""utf8"")
    return st

st=""Korais Ο Αδαμάντιος Κοραής (Σμύρνη, 27 Απριλίου 1748 – Παρίσι, 6 Απριλίου 1833), ήταν Έλληνας φιλόλογος με βαθιά γνώση του ελληνικού πολιτισμού. Ο Κοραής είναι ένας από τους σημαντικότερους εκπροσώπους του νεοελληνικού διαφωτισμού και μνημονεύεται, ανάμεσα σε άλλα, ως πρωτοπόρος στην έκδοση έργων αρχαίας ελληνικής γραμματείας, αλλά και για τις γλωσσικές του απόψεις στην υποστήριξη της καθαρεύουσας, σε μια μετριοπαθή όμως μορφή της με σκοπό την εκκαθάριση των πλείστων ξένων λέξεων που υπήρχαν στη γλώσσα του λαού.""
kwlist = ['ελληνικού', 'Σμύρνη', 'Αδαμάντιος', 'Korais']
d = highlight_text(st, kwlist, start_tag=None, end_tag=None)
print(d)


See demo

Note that all literals are declared with u prefix and all variables are decodeed and the re.sub result is encoded back to UTF8.
","
  English get tagged. Greek substr are ignored.


Where does your st come from? Please notice that in Python 2.x 'μορφή' != u'μορφή' Maybe you are comparing str with unicode.

Suggestions: Use unicode everywhere when you can, e.g.:

kwlist = [u'ελληνικού', u'Σμύρνη', u'Αδαμάντιος', u'Korais']

",,false,,,
https://stackoverflow.com/questions/73912016,true,"The issue involves connecting Apache Superset to Dremio using SQLAlchemy. While the issue is not directly related to an API exhibiting unexpected failures or unpredictable behaviors, it involves the integration of two APIs (Superset and Dremio) and the need to install the latest version of sqlalchemy_dremio. The suggested solution is to ensure the latest version is installed and refer to the provided GitHub issue for more details.",,,,,,,Can&#39;t connect superset to dremio,"I am running apache-superset using docker-compose by following the instructions here (https://superset.apache.org/docs/installation/installing-superset-using-docker-compose/) using docker-compose-non-dev.yml.
I have also added sqlalchemy-dremio to superset/docker/requirements-local.txt, in order to add dremio support as mentioned here (https://superset.apache.org/docs/databases/docker-add-drivers)
For dremio, I have a seperate container running on dremio/dremio-oss image using
docker run -p 9047:9047 -p 31010:31010 -p 45678:45678 -p 32010:32010 dremio/dremio-oss

and then made an account in dremio using the web interface at localhost:9047
But when I try to add dremio as a database in superset I get the following errors
on pressing test connection I get the following error

The connection string I'm using is
dremio+flight://dremio:dremio123@host.docker.internal:32010/dremio;SSL=0

At first I thought it might be a network error or an error in dremio, but I can connect to dremio using the python script here https://github.com/dremio-hub/arrow-flight-client-examples/blob/main/python/example.py
python example.py -host host.docker.internal -query 'SELECT 1'

This script runs successfully from both outside the container from host_os using localhost and from inside the superset_app container using host.docker.internal as host. Therefore I don't think its a network configuration problem, also this confirms that the sqlalchemy-dremio package was installed properly inside the superset containers.
Here is the docker logs for this error from superset_app container
2022-09-30 16:34:09,635:WARNING:superset.views.base:SupersetErrorsException
Traceback (most recent call last):
  File ""/app/superset/databases/commands/test_connection.py"", line 123, in run
    raise DBAPIError(None, None, None)
sqlalchemy.exc.DBAPIError: (builtins.NoneType) None
(Background on this error at: https://sqlalche.me/e/14/dbapi)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1516, in full_dispatch_request
    rv = self.dispatch_request()
  File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1502, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)
  File ""/usr/local/lib/python3.8/site-packages/flask_appbuilder/security/decorators.py"", line 89, in wraps
    return f(self, *args, **kwargs)
  File ""/app/superset/views/base_api.py"", line 114, in wraps
    raise ex
  File ""/app/superset/views/base_api.py"", line 111, in wraps
    duration, response = time_function(f, self, *args, **kwargs)
  File ""/app/superset/utils/core.py"", line 1572, in time_function
    response = func(*args, **kwargs)
  File ""/app/superset/utils/log.py"", line 244, in wrapper
    value = f(*args, **kwargs)
  File ""/app/superset/views/base_api.py"", line 84, in wraps
    return f(self, *args, **kwargs)
  File ""/app/superset/databases/api.py"", line 708, in test_connection
    TestConnectionDatabaseCommand(item).run()
  File ""/app/superset/databases/commands/test_connection.py"", line 148, in run
    raise DatabaseTestConnectionFailedError(errors) from ex
superset.databases.commands.exceptions.DatabaseTestConnectionFailedError: [SupersetError(message='(builtins.NoneType) None\n(Background on this error at: https://sqlalche.me/e/14/dbapi)', error_type=&lt;SupersetErrorType.GENERIC_DB_ENGINE_ERROR: 'GENERIC_DB_ENGINE_ERROR'&gt;, level=&lt;ErrorLevel.ERROR: 'error'&gt;, extra={'engine_name': 'Dremio', 'issue_codes': [{'code': 1002, 'message': 'Issue 1002 - The database returned an unexpected error.'}]})]
***************
['UID=dremio', 'PWD=dremio123', 'HOST=host.docker.internal', 'PORT=32010', 'Schema=dremio', 'SSL=0']
***************

","Ensure you are installing the latest version of sqlalchemy_dremio. You may need to install from source as setup.py wasn't updated accordingly (around time of writing). You will also need to add some SQLAlchemy base functions to sqlalchemy_dremio. Have a look at the following issue: https://github.com/narendrans/sqlalchemy_dremio/issues/20
",,,false,,,
https://stackoverflow.com/questions/63025581,true,The issue involves a syntax error in parsing JSON data received from a Flask API in a React JS component. The error occurs because the fetch request does not include the Content-Type and Accept headers. The suggested solution is to add these headers to the fetch request to indicate that the expected response is in JSON format.,,,,,,,Uncaught (in promise) SyntaxError: Unexpected end of JSON input Promise.then (async) - React,"I am trying to display the values from my get request to the client-side using fetch. However, I am getting this syntax error:
Uncaught (in promise) SyntaxError: Unexpected token &lt; in JSON at position 0
I know the issue is due to it not returning JSON object however I have created a JSON object for it to be received from my flask route. So I am not too sure what is causing this error.
App.py
from flask import Flask, request, jsonify
from flask_cors import CORS, cross_origin


app = Flask(__name__)
CORS(app)


@app.route('/api', methods=['GET','POST'])
def api():
    if request.method == 'POST':
        username = request.form['username']
        email = request.form['email']
        occupation = request.form['occupation']
        print('Username: ' + username + ' Email: ' + email + ' occupation: ' + occupation) 
        print('Json ', (jsonify(username)))
        return {""username"" : username} 
    else:
        return {""username"" : username}

App.js
import React, {useState, useEffect} from 'react';
import Form from './components/Form'
import './App.css';


function App() {
  const [initialData, setInitialData] = useState ([{}])

  useEffect(()=&gt; {

    fetch('/api').then(
      response =&gt; response.json()
    ).then(data =&gt; console.log(data))
  });





  return (
    &lt;div className=""App""&gt;
      &lt;Form/&gt;
    &lt;/div&gt;
  );
}

export default App;

","Add Content-Type and Accept headers to your fetch, example as below.
fetch('/api', {
      headers : { 
        'Content-Type': 'application/json',
        'Accept': 'application/json'
       }).then(
      response =&gt; response.json()
    ).then(data =&gt; console.log(data))

",,,false,,,
https://stackoverflow.com/questions/59105909,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Getting ERROR in React JS: SyntaxError: JSON.parse: unexpected character at line 1 column 1 of the JSON data?,"We are working on Firebase and we want to fetch the firebase data in our react js UI. We have created API for fetching the data in Flask. The flask code is given below

firebase = pyrebase.initialize_app(config) db = firebase.database()

# Receive data from Firebase RealTime Database @app.route(""/"") def home():
    db_events = db.child().get().val()
    return jsonify(db_events)


Now, the API is called in React JS component, the code is given below:-

      import React, { Component } from 'react';
import Temperature from './components/temperature';

class App extends Component {
  state = {
    contacts: [],
    temperatures: [],
  };

  componentDidMount(){
    fetch('192.168.1.2:5000')
      .then( res =&gt; res.json() )
      .then( (data) =&gt; {
        this.setState({ contacts: data })
        console.log(data)
      })
      .catch(console.log)
  }

  render() {
    return (
      &lt;div&gt;&lt;/div&gt;
    );
  }

}

export default App;


But, when we start the server, we got error in console. The error is given below:


  SyntaxError: ""JSON.parse: unexpected character at line 1 column 1 of
  the JSON data""


The JSON we are getting from the APIs is given below:

{
    ""DHT11"": {
        ""Humidity"": {
            ""-LuWFvEpzI9QAu_8eMEr"": ""49.00%"",
            ""-LuWHg8WL90DOdkSKd5J"": ""48.00%"",
            ""-LuWHmHpZ2veEKk1qqx2"": ""49.00%"",
            ""-LuWHpUA9l-W6_ZBUV9W"": ""49.00%""
        },
        ""LED_STATUS"": ""OFF"",
        ""Temperature"": {
            ""-LuWFvMVeyUhfKEpCxqe"": ""23.00°C"",
            ""-LuWHgGX-tepMSXLRZiJ"": ""23.00°C"",
            ""-LuWHmPdHdgBaQxkSbh4"": ""23.00°C"",
            ""-LuWHpb-d4UbkomxayjN"": ""23.00°C"",
            ""-LuWHsnQqIeUm1QGtixw"": ""23.00°C""
       }
    }
}


Why we are getting this error, all the other dummy APIs are working here. When we checked the format of JSON, it is valid. What we are getting from the error is the keys in our JSON format are not supporting.

Please help us to solve the issue. Thank you in advance. 
","Your Temperature object is missing an ending brace...
Also JSON.parse fails for trailing commas...
See the corrected JSON below...

{
    ""DHT11"": {
        ""Humidity"": {
            ""-LuWFvEpzI9QAu_8eMEr"": ""49.00%"",
            ""-LuWHg8WL90DOdkSKd5J"": ""48.00%"",
            ""-LuWHmHpZ2veEKk1qqx2"": ""49.00%"",
            ""-LuWHpUA9l-W6_ZBUV9W"": ""49.00%""
        },
        ""LED_STATUS"": ""OFF"",
        ""Temperature"": {
            ""-LuWFvMVeyUhfKEpCxqe"": ""23.00°C"",
            ""-LuWHgGX-tepMSXLRZiJ"": ""23.00°C"",
            ""-LuWHmPdHdgBaQxkSbh4"": ""23.00°C"",
            ""-LuWHpb-d4UbkomxayjN"": ""23.00°C"",
            ""-LuWHsnQqIeUm1QGtixw"": ""23.00°C""
        }
    }
}

",,,false,,,
https://stackoverflow.com/questions/57186122,false,The issue is related to the layout and styling of the HTML page rather than an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Unexpected whitespace element inserted in HTML,"I have a page with a bunch of images, each with auto-generated hyperlinks to their own personal image page; when you click an image, it takes you to a page to view the image on its own. The issue I have is that, when generating the image-viewing page, my uppermost body element doesn't touch the top of the screen because there is unexpected white space, which is detectable in the inspect-element screen.



I have reformatted the page multiple times but the white space still remains. I am unsure whether this is an issue with the fact that I am rendering the pages using python/flask and passing in the variables as such.



    &lt;!DOCTYPE html&gt;
    &lt;html&gt;
    &lt;head&gt;
    ​
        &lt;title&gt;Image {{imageNumber}}&lt;/title&gt;
        &lt;link rel=""stylesheet"" type=""text/css"" href=""{{ url_for('static',filename='styles/styleSheet.css') }}""&gt;
    ​
    &lt;/head&gt;
    
    &lt;body&gt;
        &lt;h1 class=""titleText""&gt;Thermal Imaging&lt;/h1&gt;
        &lt;a href=""/static/images/{{imageNumber}}.jpg"" download&gt;
            &lt;img class=""bigImg"" src=""/static/images/{{imageNumber}}.jpg""&gt;
        &lt;/a&gt;
    &lt;/body&gt;
    &lt;/html&gt;




I expect the white space that appears to not be there. No error messages appear, but in the inspector I can see (and temporarily delete) the white space causing the issue: it is labelled as  &amp;#8203
","Browsers have built-in stylesheets that apply a default margin and/or padding to the body. Additionally, an h1 element has built-in margins as well. You adjust/remove these with CSS rules.

Here's an example that removes the top margin from the body and the first h1 element, allowing the first item in the body to be placed at the extreme top of the page:



body, .noTopMargin { margin-top:0; }
&lt;h1 class=""noTopMargin""&gt;I have no top margin&lt;/h1&gt;
&lt;h1&gt;I have a top margin&lt;/h1&gt;



","Ok, the solution was, for me, as follows: I fiddled around with the HTML, reformatting it and deleting blank spaces. I must have, at some point, deleted the zero-width-space character and now it works as intended. I recommend, if you have a similar issue, trying to delete, copy, paste, reformat etc your html until it works.
",,false,,,
https://stackoverflow.com/questions/55638934,false,"The issue is related to passing an unexpected keyword argument to the Flask-Login library, rather than an API exhibiting unexpected failures or unpredictable behaviors.",,,,,,,TypeError when adding duration parameter to Flask_login,"When I pass the duration parameter through Flask_login I get a TypeError. Am I doing something wrong here?

I'm using the login_user() class exposed through the Flask_login package. I'm on python 2.7 and Flask-Login version 0.2.11. As The initial setup works great and I'm able to past user and the remember parameter through the login_user() class with no issue. However, the default remember cookie is set to 365 days and I want to reduce this. According to the documentation (found here: https://flask-login.readthedocs.io/en/latest/#flask_login.login_user) I should also be able to pass a duration parameter to set the length of the remember me cookie. However, when I pass the duration parameter I get a TypeError saying 'duration' is an unexpected keyword argument. Below is the snippet of code I using:

first I set a variable for the cooking length at the top of my views.py file:

REMEMBER_COOKIE_DURATION = datetime.timedelta(minutes=5)


Then I go ahead and call the login_user() class and try to pass the duration parameter along with the user and remember parameters:

if u.active and login_user(u, remember=remember, duration=REMEMBER_COOKIE_DURATION):
                    u.update_activity_tracking(request.remote_addr)


When this class is called I get the following error message:

TypeError: login_user() got an unexpected keyword argument 'duration'


I'm not sure why this is not working and getting the TypeError. Am I doing something wrong? As noted, when removing duration the class works fine.
","It seems like my version of Flask_login is not accepting the duration parameter. An update to my version solved the issue.
",,,false,,,
https://stackoverflow.com/questions/15984982,false,"The issue is related to integrating Fine Uploader into a Flask application, rather than an API exhibiting unexpected failures or unpredictable behaviors.",,,,,,,js: attempting to hook fine-uploader into a flask application,"Am attempting to hook fine uploader into a Flask endpoint.

Endpoint looks like:

@app.route('/', methods=['GET', 'POST'])
def a_function():
    if request.method == 'POST':
         file = request.files['file']
         {{ do stuff }}
         return render_template('index.html', {{ variables }} )
    return render_template('index.html' )


Am attempting to replace a standard form:

&lt;form action="""" method=post enctype=multipart/form-data&gt;
    &lt;input type=file name=file&gt;
    &lt;input type=submit value=Upload&gt;
&lt;/form&gt;


with fine-uploader:

&lt;div class=""centered_div""&gt;
   &lt;div id=""manual-fine-uploader""&gt; &lt;/div&gt;
   &lt;div id=""triggerUpload"" class=""btn btn-primary"" style=""margin-top: 10px;""&gt;
       &lt;i class=""icon-upload icon-white""&gt;&lt;/i&gt; Upload now&gt;
   &lt;/div&gt;
&lt;/div&gt;

...

$(document).ready(function() {
    var manualuploader = $('#manual-fine-uploader').fineUploader({
        request: {
            endpoint: '/'
        },
        autoUpload: false,
        text: {
            uploadButton: '&lt;i class=""icon-plus icon-white""&gt;&lt;/i&gt; Select Files'
        },
        failedUploadTextDisplay: {
            mode: 'custom',
            maxChars: 40,
            responseProperty: 'error',
            enableTooltip: true
        }
    });


    $('#triggerUpload').click(function() {
        manualuploader.fineUploader('uploadStoredFiles');
    });
});


but I'm getting some js errors in the console and the endpoint doesn't seem to be managing the request correctly:


  POST http://{{ localhost }}:5000/ 400 (BAD REQUEST)
  jquery.fineuploader-3.4.1.js:3903 [FineUploader] Error when attempting
  to parse xhr response text (SyntaxError: Unexpected token &lt;)
  jquery.fineuploader-3.4.1.js:155 [FineUploader] 'error' is not a valid
  property on the server response.


and the application errors out with Upload failed.

I'm guessing that the issue occurs when I hand the request off in the endpoint: '/' line, and am really hoping that I don't have to totally rewrite the {{ do stuff }} part of my endpoint. 
",,,,false,,,
https://stackoverflow.com/questions/52854022,false,The issue does not provide sufficient information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Python SQLite Data inserted into table disappearing?,,,,,false,,,
https://stackoverflow.com/questions/66243955,false,The issue does not provide sufficient information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,url_for not working for Javascript file in HTML,,,,,false,,,
https://stackoverflow.com/questions/28241989,false,"The issue is related to the Flask app restarting behavior and CPU usage, rather than an API exhibiting unexpected failures or unpredictable behaviors.",,,,,,,Flask app &quot;Restarting with stat&quot;,"I've built a few Flask apps, but on my latest project I noticed something a little strange in development mode.  The second line of the usual message in the terminal which always reads:

 * Running on http://127.0.0.1:5000/
 * Restarting with reloader


has been replaced by:

 * Restarting with stat


I don't think I've done anything different, in fact, I started by cloning a starter-kit project that I have used many times, which itself, does not display this behavior.  I also notice that this project consumes about 15% CPU steadily, whereas my other project are barely a blip.

Any ideas why this is happening?
","my filename was __main__.py and I exported it as such: export FLASK_APP=__main__.py
Upon changing the name to app.py and reexporting it, it worked.
",,,false,,,
https://stackoverflow.com/questions/34581255,true,"The issue involves sending messages from a thread to clients using Flask-SocketIO, which can exhibit unexpected behavior depending on the computational intensity of the thread.",,,,,,,Python - Flask-SocketIO send message from thread: not always working,"I am in the situation where I receive a message from the client. Within the function that handles that request (@socketio.on) I want to call a function where some heavy work is done. This should not result in blocking the main thread and the client is thought to be informed once the work is done. Thus I start a new thread.

Now I encounter a really strange behavior:
The message never reaches the client. However, the code reaches that particular spot where the message is sent.
Even more surprising is the fact that if there is nothing happening in the thread except for the message being sent to the client then the answer actually finds its way to the client.

To sum it up:
If something computationally intensive happens before the message is sent it is not being delivered, otherwise it is.

Like it is said here and here, sending messages from a thread to the clients is not a problem at all:


  In all the examples shown until this point the server responds to an event sent by the client. But for some applications, the server needs to be the originator of a message. This can be useful to send notifications to clients of events that originated in the server, for example in a background thread.


Here is a sample code. When removing the commenting sharps (#) the message ('foo from thread') does not find its way to the client, otherwise it does.

from flask import Flask
from flask.ext.socketio import SocketIO, emit
app = Flask(__name__)
socketio = SocketIO(app)

from threading import Thread
import time 

@socketio.on('client command')
def response(data):
    thread = Thread(target = testThreadFunction)
    thread.daemon = True
    thread.start()

    emit('client response', ['foo'])

def testThreadFunction():
#   time.sleep(1)

    socketio.emit('client response', ['foo from thread'])

socketio.run(app)


I am using Python 3.4.3, Flask 0.10.1, flask-socketio1.2, eventlet 0.17.4.

This sample can be copied and pasted in a .py file and the behavior can be instantly reproduced.

Can somebody explain this strange behavior?

Update

It seems to be a bug of eventlet. If I do:

socketio = SocketIO(app, async_mode='threading')


It forces the application not to use eventlet although it is installed.

However, this is not an applicable solution for me as using 'threading' as async_mode refuses to accept binary data. Every time I send some binary data from the client to the server it says:

WebSocket transport not available. Install eventlet or gevent and gevent-websocket for improved performance.

The third option, using gevent as the async_mode does not work for me as well as gevent does not have support for python 3 yet.

So any other suggestions?
","I have the same problem.
But I think I found out what's matter.
When starting SocketIO with the following code and create the threading like yours, the client CAN NOT receive the message which emitted by server.
socketio.run()

I find out that the flask_socketio offer a function named start_background_task from document.
Here are the description of it.

start_background_task(target, *args, **kwargs)


Start a background task using the appropriate async model. This is a utility function that applications can use to start a background task using the method that is compatible with the selected async mode.


Parameters:


target – the target function to execute. args – arguments to pass to the function.
kwargs – keyword arguments to pass to the function. This function returns an object compatible with the Thread class in the Python standard library.


The start() method on this object is already called by this function.

So I replace my code thread=threading(target=xxx) with socketio.start_background_task(target=xxx) then socketio.run() . The server get stuck in the thread when run into it ,which means that the function start_background_task only returned after the thread finished.
Then I try to use gunicorn to run my server with gunicorn --worker-class eventlet -w 1 web:app -b 127.0.0.1:5000
Then everything works well!
So let start_background_task choose a proper way to start a thread.
","The problem that you are running into is caused by the fact that eventlet and gevent (two threading modes of socket.io) don't support multiprocessing. So this is not a bug, but the way that is implemented. In order to make it work you can use async_mode=threading, or you can monkey-patch evenlet to enable the usage of a background thread.
socketio = SocketIO(app, async_mode='eventlet')
import eventlet
eventlet.monkey_patch()

",,false,,,
https://stackoverflow.com/questions/28809168,false,The issue does not provide sufficient information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Why does PyMongo throw AutoReconnect?,,,,,false,,,
https://stackoverflow.com/questions/23580395,false,The issue does not provide sufficient information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Flask sse-stream not terminated after firefox disconnects,,,,,false,,,
https://stackoverflow.com/questions/24877025,false,"The issue is related to working outside of the Flask application context during unit testing, rather than an API exhibiting unexpected failures or unpredictable behaviors.",,,,,,,&quot;RuntimeError: working outside of application context&quot; when unit testing with py.test,"I'm trying to migrate to py.test for the ease of use and auto-discovery of tests.  When I run my tests with unittest, the test works fine.  When I run the test under py.test, I get RuntimeError: working outside of application context.

Here's the test code (test_app.py):

import unittest

from app import app

class TestAPILocally(unittest.TestCase):
    def setUp(self):
        self.client = app.test_client()

    def testRoot(self):
        retval = self.client.get('/').data
        self.assertTrue('v1' in retval)

if __name__ == '__main__':
    unittest.main()


And here's the stripped down file I'm testing (app.py):

from flask import Flask
from flask.ext.restful import Api, Resource

class APIListAPI(Resource):
    def get(self):
        return ['v1']

app = Flask(__name__)
api = Api(app)
api.add_resource(APIListAPI, '/')


As you can see, this is very similar to the docs on the flask site: the testing skeleton, and indeed, when I run it with unittest, it succeeds:

$ python tmp1/test_app.py 
.
----------------------------------------------------------------------
Ran 1 test in 0.115s

OK
$ 


But, when I test with py.test, it fails:

$ ./py.test tmp1/test_app.py
=================== test session starts =========================
platform sunos5 -- Python 2.7.5 -- py-1.4.22 -- pytest-2.6.0
collected 1 items

tmp1/test_app.py F

========================= FAILURES ==============================
_________________ TestAPILocally.testRoot _______________________

self = &lt;tmp1.test_app.TestAPILocally testMethod=testRoot&gt;

    def testRoot(self):
&gt;       retval = self.client.get('/').data

tmp1/test_app.py:10:
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
werkzeug/test.py:762: in get
    return self.open(*args, **kw)
flask/testing.py:108: in open
    follow_redirects=follow_redirects)
werkzeug/test.py:736: in open
    response = self.run_wsgi_app(environ, buffered=buffered)
werkzeug/test.py:659: in run_wsgi_app
    rv = run_wsgi_app(self.application, environ, buffered=buffered)
werkzeug/test.py:855: in run_wsgi_app
    app_iter = app(environ, start_response)
tmp1/flask/app.py:1836: in __call__
    return self.wsgi_app(environ, start_response)
tmp1/flask/app.py:1820: in wsgi_app
    response = self.make_response(self.handle_exception(e))
flask_restful/__init__.py:256: in error_router
    if self._has_fr_route():
flask_restful/__init__.py:237: in _has_fr_route
    if self._should_use_fr_error_handler():
flask_restful/__init__.py:218: in _should_use_fr_error_handler
    adapter = current_app.create_url_adapter(request)
werkzeug/local.py:338: in __getattr__ 
    return getattr(self._get_current_object(), name)
werkzeug/local.py:297: in _get_current_object
    return self.__local()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    def _find_app():
        top = _app_ctx_stack.top
        if top is None:
&gt;           raise RuntimeError('working outside of application context')
E           RuntimeError: working outside of application context

flask/globals.py:34: RuntimeError
================ 1 failed in 1.02 seconds ======================


Now, it turns out, I can make this test pass just by doing this:

$ rm tmp1/__init__.py


And make it fail again by doing this:

$ touch tmp1/__init__.py


So, is there some difference between the way that unittest and py.test handles files in modules?  It seems very strange that it breaks enough to make Flask complain, as I clearly am in an app context calling app.test_client().get().  Is this expected behavior, or should I file a bug against py.test?

In case it's relevant, the reason I'm executing the tests from the parent directory is because I don't have the ability to add modules to site-packages, so I'm initiating all my code from the parent directory, where I've installed Flask, py.test, etc.

Edit: Solved.  It was an installation problem.  Adding pythonpath tag, since that was the solution.
",,,,false,,,
https://stackoverflow.com/questions/31387427,false,The issue does not provide sufficient information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Flask session cookie not set in Safari,"I experienced a strange behavior with my session cookie: Running the flask app on my mac, everything works fine and on any browser the cookie is set.

However, if I run it on a windows server, the session cookie is not set on Safari (and iOS) - but still works on any other browsers. How can this happen? Here is an example of a simple app:

import os
import uuid
from flask import Flask, render_template, session

app = Flask(__name__)

SESSION_LIFETIME = 3600

@app.before_request
def before_request():

    # create session
    if not session.get('uid'):
        session.permanent = True
        session['uid'] = uuid.uuid4()

@app.route('/', methods=['GET'])
def test():

    return render_template('test.html')

if __name__ == ""__main__"":
    app.secret_key = os.urandom(24)
    app.permanent_session_lifetime = SESSION_LIFETIME
    app.debug = True
    app.run(threaded=True,
            host=""0.0.0.0"",
            port=int(""5000"")
            )


with an example test.html:

&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head lang=""en""&gt;
    &lt;meta charset=""UTF-8""&gt;
    &lt;title&gt;Wubwub&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
Jojo
&lt;/body&gt;
&lt;/html&gt;


Why does it work on any browser but not on the (important) Safari? And why does the same code work when run on my mac (accessed from both outside and local), but not on windows? All other browsers work with windows (even from outside).
","i had the same issue what i did was using python device detector to detect safari browser and set my session to {}. here a simple code for it.
from device_detector import DeviceDetector

browser = DeviceDetector(user_agent).parse()        
if ""Safari"" in str(browser.client_name()):
    session = {}
       
        

",,,false,,,
https://stackoverflow.com/questions/47890232,false,The issue does not meet the criteria for deeper analysis. It does not indicate any specific API-related problems or unexpected behavior under certain runtime conditions.,,,,,,,Why are the parallel tasks always slow at the first time?,"I have some classifiers which I want to evaluate on the one sample. This task can be ran in parallel since they are independent of each other. This means that I want to parallelize it. 

I tried it with python and also as a bash script. The problem is that when I run it the program for the first time, it takes like 30s-40s to finish. When I run the program multiple times consecutively, it takes just 1s-3s to finish. Even If I fed classifiers with different input I got different result so it seems that there is no caching. When I run some other program and afterwards rerun the program then it again takes 40s to finish.

I also observed in htop that CPUs are not that much utilized when the program is run for the first time but then when I rerun it again and again the CPUs are fully utilized. 

Can someone please explain me this strange behaviour? How can I avoid  it so that even the first run of the program will be fast?

Here is the python code:

import time
import os
from fastText import load_model
from joblib import delayed, Parallel, cpu_count
import json

os.system(""taskset -p 0xff %d"" % os.getpid())

def format_duration(start_time, end_time):
    m, s = divmod(end_time - start_time, 60)
    h, m = divmod(m, 60)
    return ""%d:%02d:%02d"" % (h, m, s)

def classify(x, classifier_name, path):
    f = load_model(path + os.path.sep + classifier_name)    
    labels, probabilities = f.predict(x, 2)
    if labels[0] == '__label__True':
        return classifier_name
    else:
        return None

if __name__ == '__main__':
    with open('classifier_names.json') as json_data:
        classifiers = json.load(json_data)
    x = ""input_text""

    Parallel(n_jobs=cpu_count(), verbose=100, backend='multiprocessing', pre_dispatch='all') \
        (delayed(perform_binary_classification)
         (x, classifier, 'clfs/') for
         classifier in classifiers)

    end_time = time.time()
    print(format_duration(start_time, end_time))


Here is the bash code:

#!/usr/bin/env bash
N=4
START_TIME=$SECONDS
open_sem(){
    mkfifo pipe-$$
    exec 3&lt;&gt;pipe-$$
    rm pipe-$$
    local i=$1
    for((;i&gt;0;i--)); do
        printf %s 000 &gt;&amp;3
    done
}
run_with_lock(){
    local x
    read -u 3 -n 3 x &amp;&amp; ((0==x)) || exit $x
    (
    ""$@"" 
    printf '%.3d' $? &gt;&amp;3
    )&amp;
}
open_sem $N
for d in classifiers/* ; do
    run_with_lock ~/fastText/fasttext predict ""$d"" test.txt 
done

ELAPSED_TIME=$(($SECONDS - $START_TIME))
echo time taken $ELAPSED_TIME seconds


EDITED

The bigger picture is that I am running flask app with 2 API methods. Each of them calls the function that parallelize the classification. When I am doing requests, it behaves the same way like this program below. First request to method A takes a lot and then subsequent requests take like 1s. When I switch to method B it is the same behavior as with method A. If I switch between method A and method B several times like A,B,A,B then each request takes like 40s to finish.
","One approach is to modify your python code to use an event loop, stay running all the time, and execute new jobs in parallel whenever new jobs are detected. One way to do this is is to have a job directory, and place a file in that directory whenever there is a new job todo. The python script should also move completed jobs out of that directory to prevent running them more than once. How to run an function when anything changes in a dir with Python Watchdog?
Another option is to use a fifo file which is piped to the python script, and add new lines to that file for new jobs. https://www.linuxjournal.com/content/using-named-pipes-fifos-bash
I personally dislike parallelizing in python, and prefer to parallelize in bash using GNU parallel. To do it this way, I would

implement the event loop and jobs directory or the fifo file job queue using bash and GNU parallel
modify the python script to remove all the parallel code
read each jobspec from stdin
process each one serially in a loop
pipe jobs to parallel, which pipes them to ncpu python processes, which each runs forever waiting for the next job from stdin

e.g., something like:
run_jobs.sh:
mkfifo jobs
cat jobs | parallel --pipe --round-robin -n1 ~/fastText/fasttext

queue_jobs.sh:
echo jobspec &gt;&gt; jobs

.py:
for jobspec in sys.stdin:
    ...

This has the disadvantage that all ncpu python processes may have the slow startup problem, but they can stay running indefinitely, so the problem becomes insignificant, and the code is much simpler and easier to debug and maintain.
Using a jobs directory and a file for each jobspec instead of a fifo jobs queue requires slightly more code, but it also makes it more straightforward to see which jobs are queued and which jobs are done.
",,,false,,,
https://stackoverflow.com/questions/12883341,false,The issue does not provide enough information or code snippets to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Static folder with blueprints in flask,,,,,false,,,
https://stackoverflow.com/questions/45525030,false,"The issue does not meet the criteria for deeper analysis. It discusses video streaming with Flask and multiprocessing, but does not indicate any specific API-related problems or unexpected behavior under certain runtime conditions.",,,,,,,"video streaming with flask, multiprocessing, CPU usage capped to single core level","I'm trying to use flask to do video streaming, following the instructions of https://blog.miguelgrinberg.com/post/video-streaming-with-flask. It's working, but I noticed a few things, and some strange behaviors with respect to multiprocessing.

Below is the code. A background process gets from the camera feed and saves the frames in a shared array frame. The foreground loop encodes the frame array into .jpg bytes. A web server runs in a background daemon thread, and route /video_feed sends a long-connecting multipart response.

from multiprocessing import Process, Lock, Value, Array
from threading import Thread
import sys
import ctypes
import numpy as np
import cv2
from flask import Flask, render_template, Response, request
from flask_socketio import SocketIO, send, emit

SCREEN_WIDTH = 1280
SCREEN_HEIGHT = 720

frame = np.ctypeslib.as_array(Array(ctypes.c_uint8, SCREEN_HEIGHT * SCREEN_WIDTH * 3).get_obj()).reshape(SCREEN_HEIGHT, SCREEN_WIDTH, 3)
stopped = Value(ctypes.c_bool, False)

def get_from_stream():
    stream = cv2.VideoCapture(0)
    stream.set(cv2.CAP_PROP_FPS, 30)

    while True:
        if stopped.value:
            stream.release()
            return

        _, frame_raw = stream.read()
        frame[:] = frame_raw

Process(target=get_from_stream).start()

# web server
app = Flask(__name__)
# socketio = SocketIO(app, async_mode=None)

@app.route('/')
def index():
    return render_template('index.html')

def gen():
    while True:
        yield (b'--frame\r\n'
               # b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n\r\n')
               b'Content-Type: image/jpeg\r\n\r\n' + cv2.imencode('.jpg', frame_marked)[1].tobytes() + b'\r\n\r\n')

@app.route('/video_feed')
def video_feed():
    return Response(gen(),
                    mimetype='multipart/x-mixed-replace; boundary=frame')

# @socketio.on('quit')
# def quit():
#     stopped.value = True

thread_flask = Thread(target=app.run, kwargs=dict(debug=False, threaded=True))  # threaded Werkzeug server
# thread_flask = Thread(target=socketio.run, args=(app,), kwargs=dict(debug=False, log_output=True))  # eventlet server
thread_flask.daemon = True
thread_flask.start()

while True:
    if stopped.value:
        sys.exit(0)
    frame_bytes = cv2.imencode('.jpg', frame)[1].tobytes()
    frame_marked = frame


The commented-out code sections show my experiments. I noticed that if the generator gen() gets the already encoded (by the main loop) frame_bytes, 

b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n\r\n')


instead of encoding it right inside of the generator,

b'Content-Type: image/jpeg\r\n\r\n' + cv2.imencode('.jpg', frame_marked)[1].tobytes() + b'\r\n\r\n')


the total CPU usage gets consistently below 100% on a dual-core Macbook Pro, if /video_feed is being visited. If no one is visiting /video_feed, or someone is visiting but the generator encodes the frames itself, the main process takes 90+% CPU and the background get_from_stream takes 20%, in total bigger than one core usage level.

I can be sure this is not due to imprecision of CPU usage estimates (htop), and if there is some other background processes consuming a lot of CPU, the same capping happens to those processes as well so the total CPU usage is below 100%, again, if /video_feed is being visited and the generator gets the already encoded frame_bytes.

The same appears to the flask-socketio server with eventlet installed and automatically switched on. In addition, when I comment out those lines and run the eventlet server, when encoding frames in the generator, only one feed request can be processed, all other page visits and socketio messages are essentially blocked. When I restart the program, those blocked socketio messages get processed, as I haven't refreshed the page and they must have been queued somewhere on the frontend. This is unique to the eventlet server, because when I used the threaded Werkzeug server above, multiple page/feed requests can happen at the same time, although each feed encodes frames on its own, resulting in very big CPU consumption (total close to dual-core level). But, with the eventlet server, when the above CPU capping is taking place (generator getting frame_bytes), multiple requests (multiple page/feed requests at the same time), and socketio messages are processed asyncly without problem.

The deal with flask-socketio is just something related that occurred during my trial-and-error. The main problem is there with the plain Werkzeug server. I wouldn't want to let each /video_feed request encode frames on its own, would I? It seems trivial to have that view function directly get the encoded bytes, but it's just strange that total CPU capping is taking place affecting other processes.
",,,,false,,,
https://stackoverflow.com/questions/57013906,false,The issue does not provide enough information or code snippets to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Why is Google Chrome appending a forward slash to my flask url when there is none?,"While testing my Flask-based web app on various browsers, I found out that Chrome browser appends a ""/"" after one of of my routes and only one. This behavior results in a page not found error since my routes is like this: 

/dictionary


But Chrome renders is like this:

/dictionary/


Which according to flask is not the same thing.

Here is my /dictionary route and method:

@app.route(""/dictionary"", methods=[""GET"", ""POST""])
def dictionary():
    results = []
    if request.method == 'POST':
        word = request.form.get(""word"")
        # do stuff here
        return render_template(""results"", results=results)
    return render_template(""dictionary.html"")


My html url:

&lt;a href=""{{url_for(dictionary)}}""&gt; &lt;/a&gt;


It generates the following expected url:

&lt;a href=""/dictionary""&gt;&lt;/a&gt;


Please notice that this strange behavior is only noticed on Chrome browser. It works fine on Opera, Firefox, and EI. And more strangely it's only on this one route. Other routes with similar methods and url building act normal.
N.B: I could change my route to ""/dictionary/"" so it works, but I wish to preserve ""/url_example"" like routes. Thank you in advance. 
",,,,false,,,
https://stackoverflow.com/questions/59607953,true,The issue involves the behavior of the os.mkdir function in a Flask application and the use of multiprocessing. The code snippet provided demonstrates a race condition where multiple threads attempt to create the same directory simultaneously. The suggested solution of using a try-except block to handle the FileExistsError and ensure the directory is created before continuing is a valid approach.,,,,,,,os.makedir race condition in single thread? How to ensure directory created before continue,"I have very strange behavior of os.makedir in flask application.

I have an API endpoint for images upload. Each image should be grouped into directories based on conditions. If directory not exists, the directory should be created.

Initially, I had this code in my app: 

    # create needed dir if doesn't exist
    if not os.path.isdir(os.path.dirname(abs_path)):
        os.mkdir(os.path.dirname(abs_path))

    # create a file and save it into a needed place
    with open(abs_path, 'wb') as f:
        shutil.copyfileobj(fp, f)
        f.flush()


And in 90% of cases, it works great. But when there was two files in the request, that should be placed in same directory, and the directory was not yet created I got this:

flask_1  |   File ""/app/storage.py"", line 101, in save_file
flask_1  |     os.mkdir(os.path.dirname(abs_path))
flask_1  | FileExistsError: [Errno 17] File exists: '/static/df273d04909e71beb8b63b4d1b1c0a969ee6fc15'


It can be reproduced locally with 100% success in flask debug mode with 1 thread. Seems it is some kind of Linux/docker or some cache race condition.

Then I changed code simply to this one:

if not os.path.isdir(os.path.dirname(abs_path)):
    try:
        os.mkdir(os.path.dirname(abs_path))
    except FileExistsError:
        # Another thread was already created the directory when
        # several simultaneous requests has come
        if os.path.isdir(os.path.dirname(abs_path)):
            pass
        else:
            raise

    # create a file and save it into a needed place
    with open(abs_path, 'wb') as f:
        shutil.copyfileobj(fp, f)
        f.flush()


And problem is gone. 

But I have concerns about using this code in production, as it is very strange that the same check does different results.

How to ensure that the directory really created before continue first request processing?

P.S. Files are in place, with second code snippet both files in place. With the first one only first file in directory and error on second.

I.E. With first code snippet Flask thinks that everything ok and continue 
","os.makedirs accepts a parameter exist_ok that when is True it will not raise an error if the dir exists

os.makedirs(os.path.dirname(abs_path), exist_ok=True)

",,,false,,,
https://stackoverflow.com/questions/61696901,false,"The issue does not meet the criteria for deeper analysis. It discusses random logouts with Flask-Login on IIS with FastCGI, but does not indicate any specific API-related problems or unexpected behavior under certain runtime conditions.",,,,,,,Random logouts with flask-login on IIS with FastCGI,"I'm running a Dash/Flask app on Windows Server 2019 with IIS. I installed IIS with CGI, installed wfastcgi in the app's virtual environment, ran wfastcgi-enable as an administrator and specified the FastCGI application as a route handler in web.config using the virtual environment's python executable and wfastcgi.py file, etc.

That all went smoothly and the app is up and running. The app redirects to '/' to login if the user is logged out. This all works perfectly when I run the app on Flask's built-in server, but only works periodically (i.e. sometimes the user is no longer logged in, after the redirect, or refreshing the page logs out the user by chance) in this IIS/fastcgi setup. I use flask-login to login and authenticate users, following closely the example given here: https://github.com/RafaelMiquelino/dash-flask-login.

I also tried to configure flask-login's remember me functionality to persist the login after browser close, but this didn't change the mentioned issues. 

Has anyone else experienced this? I'm open to any ideas on why I'm experiencing this strange (session?) behavior with IIS and FastCGI.
Thanks!

EDIT:

Moreover, I did some more tests and found that it is not only random logouts, but also some kind of ""random logins"": 
1. User logs in at login page and is redirected to the ""real"" content located under /success: Message: User could not be authenticated. 
2. Reloading the webpage ""/success"" without any further action: User is authenticated and can see the content. After repeated reloading the same user is randomly authenticated or not.
","Try to increase the iis application pool recycling and ideal time out value. 



increase fast cgi ideal time out:



Make sure you set app.secret_key to some secret key. yo could get key by following below code:

import os
os.urandom(24)


Use the following command to quickly generate a value for Flask.secret_key (or SECRET_KEY):

$ python -c 'import os; print(os.urandom(16))'
b'_5#y2L""F4Q8z\n\xec]/'


Refer this link for more detail:

flask-login invalidates session randomly after authentication

https://flask-login.readthedocs.io/en/latest/
",,,false,,,
https://stackoverflow.com/questions/63997051,true,The issue involves the API file.getDownloadUrl() in Google Add-on Apps Script.,Google Add-on Apps Script,file.getDownloadUrl(),"The file.getDownloadUrl() method returns null when called on Google's filetypes (e.g., application/vnd.google-apps.document or application/vnd.google-apps.spreadsheet). Additionally, when a URL is returned, access to the URL is restricted unless the user is signed into the file owner's G Suite account.",The file.getDownloadUrl() method is expected to return a URL that can be used to download a file.,The issue is triggered when file.getDownloadUrl() is called on Google's filetypes or when access to the URL is restricted.,This issue might be challenging to detect during development and testing because the behavior of file.getDownloadUrl() depends on the file type and the user's access permissions.,file.getDownloadUrl() not working for Google Add-on Apps Script,"I am creating a google add-on for Google Drive. I am using the DriveApp  class to access and handle files. I would like to be able to generate a link for downloading a file. Eventually, I want to send this download link to a server for further file processing.
DriveApp's file class appears to have a perfect method for this purpose, file.getDownloadUrl(), which ""Gets the URL that can be used to download the file.""
Unfortunately, I am seeing some strange behavior and I am not sure if I am using the method correctly.
First, the method returns null when called on Google's filetypes, e.g. application/vnd.google-apps.documentor application/vnd.google-apps.spreadsheet. It makes sense that we may need to set some kind of parameter for what filetype we'd like to export to, but that does not appear to be an option for getDownloadUrl().
Second, when getDownloadUrl() does return a url, access to the url is severely restricted. Unless I am on Chrome and signed into the file owner's G Suite account, I cannot access the file. Signing into the owner account, but browsing on Firefox also returns a 403 error.
I have a flask server running on a set of Drive API credentials. Is there a way to authorize those credentials to access this download link?
Any help would be greatly appreciated!
","Files that have the Google MIME type cannot be downloaded directly, and file.getDownloadUrl() returns null.
For example, a Spreadsheet.
Before downloading manually, you can see that the file is converted to .xlsx. So to download it, you need to convert the file into something.

    // --- Apps Script ---
    let new_file = Drive.Files.insert({ //DriveApi
        title: file.getName(), //name
        parents: [{
          id: file.getParents().next().getId() //folder
        }],
        mimeType: ""application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"" //new mimeType
      },
      file.getBlob()
    );

    console.log(new_file.getDownloadUrl())


However, to download a file from this link, you need to be logged in to Google and have access to the file in Drive.
Otherwise, you can get a blob of a file and convert it to a file in another place, for example, on your server.

    // --- Apps Script ---
    let blob = file.getBlob()
    let blob_type = blob.getContentType() // for some reason, this is a application/pdf, so it will download as .pdf
    let blob_string = blob.getDataAsString() // data of this blob as a String with UTF-8 encoding



    // --- JS ---
    // convert to js blob
    let js_blob = new Blob([blob_string], {
      type: blob_type
    });
    // and download
    let a = document.createElement(""a"")
    document.body.appendChild(a)
    a.style = ""display: none""
    let url = window.URL.createObjectURL(js_blob)
    a.href = url
    a.download = ""fileName.pdf"" //file name and extension
    a.click()
    a.remove()
    window.URL.revokeObjectURL(url)


",,,false,,,
https://stackoverflow.com/questions/21824534,false,The issue does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is related to a misunderstanding of logical operators and conditions in pandas.,,,,,,,Unable to kill Flask server launched by Popen on Ubuntu,"Here is the reduced requirement of what I am trying to achieve.

# run.py
import requests
import time

from subprocess import Popen, PIPE

server = Popen(""./app.py"", stdout=PIPE, stderr=PIPE, shell=True)
time.sleep(1)
res = requests.get(""http://localhost:1234/"")
assert res.status_code == 200
server.kill()
server.terminate()
res = requests.get(""http://localhost:1234/"")
print res


And the actual server script.

#!/usr/bin/env python
from flask import Flask, make_response, request

app = Flask(__name__)
@app.route('/')
def view():
    return make_response("""")

if __name__ == ""__main__"":
    app.run(host=""localhost"", port=1234)


On the command line I run python run.py. From shell:

(t)yeukhon@fubini:/tmp$ ps aux|grep app
yeukhon  21452  0.6  0.4  16416  9992 pts/2    S    03:50   0:00 python ./app.py
yeukhon  21471  0.0  0.0   4384   804 pts/2    S+   03:51   0:00 grep --color=auto app


So app.py is still hanging there. I have to kill it from the command line. In fact, the last line of run.py tells us the server was still alive (200 was returned).

I tried to kill with os.kill(server.pid, signal.SIGTERM) and os.kill(server.pid, signal.SIGKILL) but none works.

Normally kill will work, but I am really not sure why it can't receive the signal. I am sure somehow Flask is refusing to stop. 

What options do I have?

strangely, my script above works perfectly fine on Mac OSX (I am on 10.8.5, Mountain Lion). So far I have tested on two Ubuntu 12.04 machines and they have the same behavior. I am running Python 2.7.3 on both Ubuntu machines and Python 2.7.2 on my Mac OSX.

correction:
The only option I have is to use http://flask.pocoo.org/snippets/67/. But I prefer not to. And yes, I have to launch one using Popen.
","Problem quite old but I met similar when I was running flask server with subprocess.Popen in conftest.py with pytest in docker container on Mac OS.
This piece of code is not working for me (in conftest.py)
flask_server_proc = subprocess.Popen([
  'python', 'code/flask_server/main.py',
  '--local'
])

flask_server_proc.kill()

Parent process was killed but server still was running and answering requests.
So I did this:
import psutil
import subprocess

server = subprocess.Popen([
    'python', 'code/flask_server/main.py',
    '--mysql-user', 'root',
    '--mysql-password', 'pass',
    '--mysql-host', 'mysql',
    '--local-artifact-store'
])

# Here I check if server is up. For example with some health check
# url. Sleep mimics it.
import time
time.sleep(10)
print(server.pid)

# Somewhere here you will call 'yield server'. This is just snippet
# with potential solution of problem so no yielding it.
# The next part should be run after 'yield server'.

# This should kill server.
# server.kill()

# Actually it should be one such process like flask.
flask_to_kill: List[psutil.Process] = []
for process in psutil.process_iter():
    if 'code/flask_server/main.py' in process.cmdline():
        flask_to_kill.append(process)

def on_terminate(proc: psutil.Process):
    print(""process {} terminated with exit code {}"".format(proc, proc.returncode))

for f in flask_to_kill:
    f.terminate()

gone, alive = psutil.wait_procs(flask_to_kill, timeout=3, callback=on_terminate)

for to_stab in alive:
    to_stab.kill()


so looks like remedy is to use psutil package to kill server after tests.
Happy hacking!
",,,false,,,
https://stackoverflow.com/questions/28785603,false,The issue does not provide enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Flask LoginManager not calling correct Login_View,,,,,false,,,
https://stackoverflow.com/questions/46222462,false,The issue does not provide enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Rest Template unable to parse json rest api response properly,"I am trying to extract Named Entities from text using Spacy's NER for German text. I have exposed the service as a REST POST request which takes source text as input and returns a dictionary(Map) of list of named entities (person, location, organization). These services are exposed using Flask Restplus hosted on a linux server. 

Consider for a sample text, I get following response using POST request at REST API exposed via Swagger UI:

{
  ""ner_locations"": [
    ""Deutschland"",
    ""Niederlanden""
  ],
  ""ner_organizations"": [
    ""Miele &amp; Cie. KG"",
    ""Bayer CropScience AG""
  ],
  ""ner_persons"": [
    ""Sebastian Krause"",
    ""Alex Schröder""
  ]
}


When I use Spring's RestTemplate to POST request at the API hosted at Linux server from Spring boot application (on Windows OS in Eclipse). The json parsing is done correctly. I have added following line for using UTF-8 encoding.

restTemplate.getMessageConverters().add(0, new StringHttpMessageConverter(Charset.forName(""UTF-8"")));


But When I deploy this spring boot application on linux machine and POST request to API for NER tagging, the ner_persons are not parsed correctly. While remotely debugging, I get following response

{
  ""ner_locations"": [
    ""Deutschland"",
    ""Niederlanden""
  ],
  ""ner_organizations"": [
    ""Miele &amp; Cie. KG"",
    ""Bayer CropScience AG""
  ],
  ""ner_persons"": [
    ""Sebastian "",
    ""Krause"",
    ""Alex "",
    ""Schröder""
  ]
}


I am not able to understand why this strange behavior occurs in case of persons but not organizations.
",,,,false,,,
https://stackoverflow.com/questions/17061691,false,The issue does not provide enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,"using ajax: hide div, replacewith, reattach behavior then show",,,,,false,,,
https://stackoverflow.com/questions/23457827,false,The issue does not provide enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,flask-security encrypt_password(&#39;mypassword&#39;) varies every time when i reload the page,,,,,false,,,
https://stackoverflow.com/questions/43956321,false,The issue does not provide enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Send request as content type of x-www-form-urlencoded with wreq,"I'm learning to use wreq this weekend and I've run into some strange behavior.

I have a module AuthRequest

{-# LANGUAGE OverloadedStrings #-}
{-# LANGUAGE DeriveGeneric #-}
module AuthRequest where

import Data.Aeson
import GHC.Generics
import Data.Monoid

data AuthRequest = AuthRequest {
    client_id :: String
  , client_secret :: String
  , grant_type :: String
} deriving (Generic,  Show)

instance ToJSON AuthRequest where
    toJSON (AuthRequest id_ secret grant) =
      object [ ""client_id"" .= id_
             , ""client_secret"" .= secret
             , ""grant_type"" .= grant
             ]
    toEncoding(AuthRequest id_ secret grant) =
      pairs (""client_id"" .= id_ &lt;&gt; ""client_secret"" .= secret &lt;&gt; ""grant_type"" .= grant)


and a module HttpDemo

{-# LANGUAGE OverloadedStrings #-}
{-# LANGUAGE DeriveGeneric #-}
module HttpDemo where

import Control.Lens
import Network.Wreq
import AuthRequest
import Data.Aeson

clientId = ""some_id""
clientSecret = ""some_secret""
url = ""http://localhost:5000""

opts :: Options
opts = defaults
  &amp; header ""Content-Type"" .~ [""application/x-www-form-urlencoded""]

req :: AuthRequest
req = AuthRequest clientId clientSecret ""credentials""

postIt = postWith opts url (toJSON req)


On the other end, I have a simple python flask server that listens to this request with a breakpoint so I can see the value that comes through.

When I look at the request.form on the server side, I see this: ImmutableMultiDict([('{""client_secret"":""some_secret"",""client_id"":""some_id"",""grant_type"":""whatever""}', '')])

The key is what should be my post body!

But if I make a similar request using the requests python library

requests.post('http://localhost:5000', data={'client_id': clientId, 'client_secret': clientSecret, 'grant_type': grant_type}, headers={'content-type': 'application/x-www-form-urlencoded'})


I see what I expect: ImmutableMultiDict([('grant_type', 'whatever'), ('client_id', 'some_id'), ('client_secret', 'some_secret')])

What I think I want is to send this request as x-www-form-urlencoded. I see there are some docs here around this, but not clear on how to proceed. Maybe I need a FormValue instance? An example would be helpful.
",,,,false,,,
https://stackoverflow.com/questions/45890097,false,The issue does not provide enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Flask Redirection with Gunicorn &amp; nginx,"My flask is showing a strange redirection behavior. I don't know what I am doing wrong. All of my html files work fine if I load them as the '/' route, but redirection doesn't work right and I get the following error message:

ERR_NAME_NOT_RESOLVED
DNS address could not be found


The error can also be reproduced with the following 4 routes:

@app.route('/')
def index():
    return 'The index page'

@app.route('/projects/')
def projects():
    return 'The project page'

@app.route('/about')
def about():
    return 'The about page'

@app.route('/main')
def main():
    return 'The main page'


No 1 will work, when typing just the server ip into the browser.

No 2 will work like this: ip/projects/ but not liek this ip/projects

No 3 works like this: ip/about but not like this ip/about/

No 4 doesn't work at all! Why?

I am runnung gunicorn with nginx as proxy. Many thanks in advance!
",,,,false,,,
https://stackoverflow.com/questions/55128421,false,The issue does not provide enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,strange behavior with flask on windows,"I'm maintaining a web application built with Flask with python 2.7 coupled with Jinja and angularjs .In a Linux environment, everything is working fine.

On windows when I run the application on cmd or git bash (python app.py), I only see that the server is running and in which port (and everything else is working fine in the browser), but the problem is that the logs in console aren't shown like in a Linux terminal. 
For example, I can't see the requests like: POST  /login..or an exceptional mission or even a simple print ""test"" Dosen""to show (still everything is working in a browser).

Even worst, when I terminate the server with ""ctr+c"" all the previous messages and logs are printed in the terminal, all together in one single dump!

--- Update ---
when i use the command python -u app.py 
it's even worst , the application dose'nt run in the browser anymore , no log in console and when i termiante it shows this :
screenshot of terminal
",,,,false,,,
https://stackoverflow.com/questions/55411291,false,The issue does not provide enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Logging failure with multiprocessing,"I am trying to implement logging with multiprocessing for our application(flask). We use python2.7, I am using the concept of queues to keep log requests from all the forks and logging records present in the queue. I followed this approach. Only change from that link is I am using TimedRotatatingFileHandler instead of RotatingFileHandler. This is my dictconfig

I am initializing the logger before initializing the forks and in code in the following way

    from flask import Flask
    from tornado.wsgi import WSGIContainer 
    from tornado.httpserver import HTTPServer
    from tornado.ioloop import IOLoop


    path = 'share/log_test/logging.yaml'
    if os.path.exists(path):
        with open(path, 'rt') as f:
            config = yaml.load(f.read())
        logging.config.dictConfig(config)

    logger = logging.getLogger('debuglog') # problem starts if i keep this statement

    app = Flask(__name__)
    init_routes(app) # initialize our routes
    server_conf = config_manager.load_config(key='server')
    logger.info(""Logging is set up."") # only this line gets logged and other log statement to be logged by forks in code with same logger are not writing to the file.

    http_server = HTTPServer(WSGIContainer(app))

    http_server.bind(server_conf.get(""PORT"")) # port to listen
    http_server.start(server_conf.get(""FORKS"")) # number of forks
    IOLoop.current().start()



The problem I am facing is if i use getLogger in the code before initializing the forks, the forks are not writing logs to the logfile, only log statements before initializing forks are being logged. If I remove the logging.getLogger('debuglog') , forks are logging correctly. 

I paused the execution flow and verified if the handler is assigned to logger or not but that seems to be fine

Why this strange behavior is observed?

Update: when I use another logger with the same file to write and everything is working fine. But when i use same logger it's not working. Anything related to RLock?
",,,,false,,,
https://stackoverflow.com/questions/56874014,false,The issue does not provide enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Flux.subscribe finishes before the last element in processed,"Strange behavior of Spring + Flux. I have Python server code (using Flask, but that's not important, treat it as pseudo-code) which is streaming response:

def generate():
    for row in range(0,10):
        time.sleep(1)
        yield json.dumps({""count"": row}) + '\n'
return Response(generate(), mimetype='application/json')


With that, I simulate processing some tasks from the list and sending me results as soon as they are ready, instead of waiting for everything to be done, mostly to avoid keeping that everything in memory first of the server and then of the client. Now I want to consume that with Spring WebClient:

Flux&lt;Count&gt; alerts = webClient
        .post()
        .uri(""/testStream"")
        .accept(MediaType.APPLICATION_JSON)
        .retrieve()
        .bodyToFlux( Count.class )
        .log();
alerts.subscribe(a -&gt; log.debug(""Received count: "" + a.count));
Mono&lt;Void&gt; mono = Mono.when(alerts);
mono.block();
log.debug(""All done in method"");


Here is what I'm getting in log:

2019-07-03 18:45:08.330 DEBUG 16256 --- [ctor-http-nio-4] c.k.c.restapi.rest.Controller     : Received count: 8

2019-07-03 18:45:09.323  INFO 16256 --- [ctor-http-nio-2] reactor.Flux.MonoFlatMapMany.4           : onNext(com.ksftech.chainfacts.restapi.rest.Controller$Count@55d09f83)

2019-07-03 18:45:09.324  INFO 16256 --- [ctor-http-nio-2] reactor.Flux.MonoFlatMapMany.4           : onComplete()

2019-07-03 18:45:09.325 DEBUG 16256 --- [io-28088-exec-4] c.k.c.restapi.rest.Controller     : All done in method

2019-07-03 18:45:09.331  INFO 16256 --- [ctor-http-nio-4] reactor.Flux.MonoFlatMapMany.4           : onNext(com.ksftech.chainfacts.restapi.rest.Controller$Count@da447dd)

2019-07-03 18:45:09.332 DEBUG 16256 --- [ctor-http-nio-4] c.k.c.restapi.rest.Controller     : Received count: 9
2019-07-03 18:45:09.333  INFO 16256 --- [ctor-http-nio-4] reactor.Flux.MonoFlatMapMany.4           : onComplete()


Notice how last object is processed by subscribe after mono.block returns. I understand that Reactor is asynchronous, and once it sees no more objects, it releases Mono and calls my code in subscribe in parallel. Then it is a mercy of scheduler to see what runs first.

I came up with quite ugly kludge of having subscribe with completeConsumer, and using good old wait/notify. Then it works fine. But is there more elegant way of making sure my method waits until all elements of Flux are processed?
",,,,false,,,
https://stackoverflow.com/questions/57436903,true,The issue involves a memory leak in a Flask application running in a Docker container. The problem is not directly related to an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Memory leak from a docker container with a Flask application,"I am having a strange problem, when I start multiple docker containers with Flask applications. The containers with the apps are used for simulation purposes and are not deployed for production, I simply needed a way to allow the docker containers to communicate between each other and GET/POST API calls seemed to be a good solution. However, this is where my problem occurred, when I start the containers and the Flask application starts, the memory usage (which I am observing with htop) starts to increase. Just by starting the Flask server, the container size increases by 200 MB. I can honestly live with that, however, the problem is, that after every API call, the memory usage keeps increasing. Here is a small snippet of one of the functions:

@app.route('/execute/step=&lt;int:step&gt;', methods=['GET'])
def execute(step):
    url = f'http://my_url:5000/some/api/call/step={step}'
    response = requests.get(url)
    data = eval(response.text)

    if data:
        # unimportant calculations

        if demand &lt;= supply:
            for b in people_b:
                buyer_id = b['id']
                post_data = {some_data}
                url = f'http://my_url:5000/set_data/id={buyer_id}'
                requests.post(url, data=post_data)

            for s in people_s[:-1]:

                seller_id = s['id']
                post_data = {some_data
                             }
                url = f'http://my_url:5000/set_data/id={seller_id}'
                requests.post(url, data=post_data)

            # unimportant steps

            seller_id = local_ids[-1]['id']
            post_data = {some_data}
            url = f'http://my_url:5000/set_data/id={seller_id}'
            requests.post(url, data=post_data)

            return 'Success\n'
        else:
            for s in people_s:
                seller_id = s['id']
                post_data = {some_data}
                url = f'http://my_url:5000/set_data/id={seller_id}'
                requests.post(url, data=post_data)

            for b in people_b[:-1]:
                #unimportant steps

                buyer_id = b['id']
                post_data = {some_data}
                url = f'http://my_url:5000/set_data/id={buyer_id}'
                requests.post(url, data=post_data)

            #unimportant steps

            buyer_id = people_b[-1]['id']
            post_data = {some_data}
            url = f'http://my_url:5000/set_data/id={buyer_id}'
            requests.post(url, data=post_data)

            return 'Success\n'
    else:
        return 'No success\n'


Above is one of the methods, I have deleted some unimportant computation steps, but what I wanted to show is, that there are nested API calls as well. I tried calling gc.collect() before every return in the functions, however, this resulted no success.

Is this behavior expected when performing so many API calls or is there a problem with the implementation or docker/Flask usage?
","The problem with the memory leak was entirely due to using eval and response.text. After switching to using json output, the memory leaks were gone.
",,,false,,,
https://stackoverflow.com/questions/58750960,true,The issue involves unexpected behavior with Twilio WhatsApp API callbacks. The problem is not directly related to an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,"Twilio WhatsApp HTTP retrieval failure, but can&#39;t reproduce error locally","Working with the WhatsApp API I have a very simple Flask app running on 2 servers, the app just accepts a post request at the root address and prints what it received. On one host it is behind Traefik and on the other I run it directly so Flask's built-in development server is exposed directly. The first host is referenced as http://sub.domain.com/incoming/ and for the second I use an IP http://12.34.56.78.

On the latter everything works as expected: I receive Twilio's callbacks, and I can call the API myself as well and get a clean response (HTTP 200, &lt;Response&gt;&lt;/Response&gt; as body). On the former, if I call the API myself it works fine and I get the same output. But when Twilio sends its callbacks I consistently get a 11200 HTTP retrieval failure on Twilio's debugger.

I find this difference in behavior a little bit strange, but there is one more detail that I really find a bit bizarre - the Twilio debugger has an option to ""Replay Request"" in which case its callback gets re-sent. On the host where I get the retrieval failures, if I replay the failing requests they consistently succeed!

On the server where everything is working, I have stored a raw Twilio request (HTTP with headers etc), and I've tried sending this request to the failing server manually using netcat (after updating the Host header field). When I do this the server responds without any issues so the structure of the request does not seem to be the problem.

I am really at a loss, I've run out of ideas regarding where I can look for the cause of this issue. Any suggestions what could be going on?
","Heyooo. Twilio Developer Evangelist here. 👋

For completeness: Twilio doesn’t accept underscores in the domain or subdomain for the webhook URL “when a message comes in” for SMS sent to your Twilio number. If you try to save the phone number configuration page with an underscore in the domain or subdomain of the URL, you’ll see an error in console “URL is not valid”.

However, the configuration for the webhook for Twilio Whatsapp has a bug and doesn’t reject the URL, even though it’s invalid for Twilio! So although the URL is accepted, the requests will fail.

We created a ticket for it and the engineering team is now aware of this issue.

Thank you for raising this issue. :) 
","After some back and forth with Twilio's developer support it seems this was a problem on their end. The issue was that the subdomain part of my URL contained an underscore. For some reason Twilio's webhook system does not accept this, even though their ""Replay Request"" functionality has no issues with it (seems like those go through different subsystems). I've fixed the issue by replacing the underscore by a dash, everything works as expected now.
",,false,,,
https://stackoverflow.com/questions/61561295,false,The issue is related to enabling port 8000 on Ubuntu 18 firewall and does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,port 8000 not enable even after enable it on firewall Ubuntu 18,"I'm stuck with a strange behavior with ubuntu 18 into digital ocean, I just created a droplet and didn't use DO firewall but try to enable port 8000 into server, like this:

sudo ufw allow 8000/tcp

When I check my port rules its ok, I mean its really what I need, there's even more (cause I also added udp) 

sudo ufw status
Status: active

To                         Action      From
--                         ------      ----
22/tcp                     ALLOW       Anywhere
80/tcp                     ALLOW       Anywhere
443/tcp                    ALLOW       Anywhere
80/udp                     ALLOW       Anywhere
443/udp                    ALLOW       Anywhere
8000/tcp                   ALLOW       Anywhere
8000/udp                   ALLOW       Anywhere
22/tcp (v6)                ALLOW       Anywhere (v6)
80/tcp (v6)                ALLOW       Anywhere (v6)
443/tcp (v6)               ALLOW       Anywhere (v6)
80/udp (v6)                ALLOW       Anywhere (v6)
443/udp (v6)               ALLOW       Anywhere (v6)
8000/tcp (v6)              ALLOW       Anywhere (v6)
8000/udp (v6)              ALLOW       Anywhere (v6)


When I run a flask service using port 8000 into server, something like this:

FLASK_APP=app.py flask run --host=127.0.0.1 --port=8000

I can get a response inside server, eg:

curl 127.0.0.1:8000

But when I try to do the same thing out site, I got refused connection, eg:

curl IPSERVER:8000

response:

curl: (7) Failed to connect to IPSERVER port 8000: Connection refused

I also check the port status using this service: https://www.yougetsignal.com/tools/open-ports/

And it says that port 8000 is closed, but I enabled it and there's no firewall on DO (I have one but I removed to test and it still not working) 

Does anyone know what could be? Ubuntu 18 has a another place to enable it? Should I restart the server before made these changes? 
","You need to call your script with;

--host=&lt;your public ip&gt; if you want to bind to just the address specified.

--host=0.0.0.0 to bind to all available addresses.

--host=127.0.0.1 will only bind to the loop-back address.

The Quick Start docs states;


  Externally Visible Server
  
  If you run the server you will notice that the server is only
  accessible from your own computer, not from any other in the network.
  This is the default because in debugging mode a user of the
  application can execute arbitrary Python code on your computer.
  
  If you have the debugger disabled or trust the users on your network,
  you can make the server publicly available simply by adding
  --host=0.0.0.0 to the command line:
  
  $ flask run --host=0.0.0.0
  
  This tells your operating system to listen on all public IPs.

",,,false,,,
https://stackoverflow.com/questions/64153077,false,The issue does not provide sufficient information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Strange additional button added to Flask app with bootstrap,,,,,false,,,
https://stackoverflow.com/questions/49188151,true,The issue involves an ImportError related to the 'moves' module in the 'six' library. The problem is not directly related to an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,ImportError: No module named moves,"Versions  


Python : 2.7.14  
six : 1.9.0 &amp; 1.11.0(tried on both)  
OS : mac(10.13.3) &amp; ubuntu(16.04) [tried on both]


Error 


  from six.moves import http_client
  ImportError: No module named moves


Description  

In flask application which is running on google app engine while running it on local system using dev_appserver.py getting above error while importing from six.moves import http_client

What I have tried  

After importing six have tried dir(six) which shows that moves is there in list but it's not able to import it which is very strange.

Output of six.__version__: 1.11.0

Output if dir(six)


  ['/opt/tribes-backend', '/opt/tribes-backend/lib1', '/usr/lib/google-cloud-sdk/platform/google_appengine', '/usr/lib/google-cloud-sdk/platform/google_appengine', '/usr/lib/python2.7', '/usr/lib/python2.7/lib-dynload', '/usr/lib/google-cloud-sdk/platform/google_appengine/lib/ssl-2.7.11', '/usr/lib/google-cloud-sdk/platform/google_appengine/lib/grpcio-1.0.0', '/usr/lib/google-cloud-sdk/platform/google_appengine/lib/six-1.9.0', '/usr/lib/google-cloud-sdk/platform/google_appengine/lib/protobuf-3.0.0', '/usr/lib/google-cloud-sdk/platform/google_appengine/lib/enum-0.9.23', '/usr/lib/google-cloud-sdk/platform/google_appengine/lib/futures-3.0.5', '/usr/lib/google-cloud-sdk/platform/google_appengine/lib/setuptools-36.6.0', '/usr/lib/google-cloud-sdk/platform/google_appengine/lib/protorpc-1.0', '/usr/lib/google-cloud-sdk/platform/google_appengine/lib/pytz-2017.2', '/usr/lib/google-cloud-sdk/platform/google_appengine/lib/webapp2-2.3', '/usr/lib/google-cloud-sdk/platform/google_appengine/lib/webob-1.1.1', '/usr/lib/google-cloud-sdk/platform/google_appengine/lib/werkzeug-0.11.10', '/usr/lib/google-cloud-sdk/platform/google_appengine/lib/yaml-3.10', '/usr/local/lib/python2.7/dist-packages/enum', '/usr/lib/google-cloud-sdk/platform/google_appengine/lib/concurrent/concurrent', '/usr/local/lib/python2.7/dist-packages/concurrent', '/usr/local/lib/python2.7/dist-packages/google', '/usr/lib/google-cloud-sdk/platform/google_appengine/google']
  ['BytesIO', 'Iterator', 'MAXSIZE', 'Module_six_moves_urllib', 'Module_six_moves_urllib_error', 'Module_six_moves_urllib_parse', 'Module_six_moves_urllib_request', 'Module_six_moves_urllib_response', 'Module_six_moves_urllib_robotparser', 'MovedAttribute', 'MovedModule', 'PY2', 'PY3', 'StringIO', '_LazyDescr', '_LazyModule', '_MovedItems', '_SixMetaPathImporter', 'author', 'builtins', 'doc', 'file', 'name', 'package', 'path', 'version', '_add_doc', '_assertCountEqual', '_assertRaisesRegex', '_assertRegex', '_func_closure', '_func_code', '_func_defaults', '_func_globals', '_import_module', '_importer', '_meth_func', '_meth_self', '_moved_attributes', '_print', '_urllib_error_moved_attributes', '_urllib_parse_moved_attributes', '_urllib_request_moved_attributes', '_urllib_response_moved_attributes', '_urllib_robotparser_moved_attributes', 'absolute_import', 'add_metaclass', 'add_move', 'advance_iterator', 'assertCountEqual', 'assertRaisesRegex', 'assertRegex', 'b', 'binary_type', 'byte2int', 'callable', 'class_types', 'create_bound_method', 'exec_', 'functools', 'get_function_closure', 'get_function_code', 'get_function_defaults', 'get_function_globals', 'get_method_function', 'get_method_self', 'get_unbound_function', 'indexbytes', 'int2byte', 'integer_types', 'iterbytes', 'iteritems', 'iterkeys', 'iterlists', 'itertools', 'itervalues', 'moves', 'next', 'operator', 'print_', 'python_2_unicode_compatible', 'raise_from', 'remove_move', 'reraise', 'string_types', 'sys', 'text_type', 'types', 'u', 'unichr', 'viewitems', 'viewkeys', 'viewvalues', 'with_metaclass', 'wraps'].


As it can be seen from above output moves inside six still giving error while importing it.

Spent a lot of time on this and no solution till now any help would be greatly appreciated here. :( 

UPDATE1

Error stacktrace :- 

 from google.cloud.datastore import helpers
 File ""/opt/tribes-backend/denv/local/lib/python2.7/site-packages/google/cloud/datastore/helpers.py"", line 27, in &lt;module&gt;
 from google.cloud._helpers import _datetime_to_pb_timestamp
 File ""/opt/tribes-backend/denv/local/lib/python2.7/site-packages/google/cloud/_helpers.py"", line 30, in &lt;module&gt;
 from six.moves import http_client
 ImportError: No module named moves

","For me the issue was resolved by following it on https://github.com/googleapis/python-ndb/issues/249

andrewsg commented 11 days ago:


  I think we've identified an issue with devappserver related to the six library specifically. Could you please try a workaround? Add the line: import six; reload(six) to the top of your app, before NDB is loaded and let me know if that works.

","Based on follow up with google support team have figured out that communicating with datastore using google-cloud-datastore is deprecated 
instead using ndb for communicating datastore is the way to go.

Updated documentation stating deprecation using client datastore library is documented here

Documentation to getting started with ndb client library in python is documented here 
",,false,,,
https://stackoverflow.com/questions/60125805,true,The issue involves unexpected behavior with styling individual cells in a Dash DataTable. The problem is not directly related to an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Dash DataTable individual highlight using style_data_conditionals works unusual,"I'm working on a Project using Python3, Flask and Dash.
I'm visualizing a CSV Table using the DataTable() from dash_table and want to highlight some specific cells.
Accordistrong textng the documentation of table styling, this can be done by using the style_data_conditional attribute inside of the DataTable definition (reference).
My CSV table looks like this:
testclient, 0.40, 0.48, False, False, False, 0.14, True, True, 0.0, 2
raspberrypi, 0.20, 0.21, False, True, False, 0.18, True, False, 0.0, 3

When trying to access the first column, all style changes are working.
[...]
style_data_conditional=[
    {
        'if': {
            'column_id': 'hostname',
            'filter_query': '{hostname} eq ""testclient""'
        },
        'color': 'green',
    }
],
[...]

But when trying to access any other row column like ""ftp"" or ""http"", it won't work and even if I use the debug=True parameter at the app.run(...) function call, I get no error output.
[...]
style_data_conditional=[
    {
        'if': {
            'column_id': 'ftp',
            'filter_query': '{ftp} eq ""True""'
        },
        'color': 'green',
    }
],
[...]

There's an order of ""style"" attributes inside of the DataTable ...


style_data_conditional
style_data
style_filter_conditional
style_filter
style_header_conditional
style_header
style_cell_conditional
style_cell


... but as you can see, the given style attribute is the first mentioned in the listing.
The table is defined like this:
content = dash_table.DataTable(
    id='table',
    columns=[{""name"": i, ""id"": i} for i in df.columns],
    [...]

Do you have any clue, why the DataTable is behaving that strange just by changing the column_id?
","Since you don't provide column headers with your csv example, I can only assume that ftp and http refer to boolean columns?

The support for boolean-type columns in Dash DataTables seems to be anywhere between limited and non-existent. filter_query expressions don't seem to work with boolean values. The documentation doesn't even mention a boolean data type for columns:


  columns (dict; optional): 
  
  
  type (a value equal to: 'any', 'numeric', 'text', 'datetime'; optional): The data-type of the column's data.
  


I worked around this by setting the data type for all boolean columns to str in my dataframe:

for col, dtype in df.dtypes.items():
    if dtype == 'bool':
        df[col] = df[col].astype('str')


Then, conditional styling works as expected:

DataTable(
    [...],
    style_data_conditional=[
        {
            'if': {
                'column_id': 'hostname',
                'filter_query': '{hostname} eq ""testclient""'
            },
            'backgroundColor': 'green',
        },
        {
            'if': {
                'column_id': 'ftp',
                'filter_query': '{ftp} eq ""True""'
            },
            'backgroundColor': 'green',
        }
    ]
)



",,,false,,,
https://stackoverflow.com/questions/38508982,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,"Why do trim_blocks and lstrip_blocks under Flask/OpenShift produce different results when tested online, compared when to tested locally?","I'm writing a simple web app using Flask, which is hosted on OpenShift. I want to control whitespace in my template files, with the Jinja command lines essentially removed as in:

&lt;div&gt;
{% if True %}
    yay
{% endif %}
&lt;/div&gt;


...producing:

&lt;div&gt;
    yay
&lt;/div&gt;


The Jinja docs at http://jinja2.readthedocs.io/en/latest/templates.html#whitespace-control (and other sources) imply I should do 

flask_app_obj.jinja_env.lstrip_blocks = True
flask_app_obj.jinja_env.trim_blocks = True


...which I have done, in my init.py file for my app package. However, this yields inconsistent behaviour when I test locally and then on OpenShift; locally, I get the expected result (i.e. the Jinja commands essentially removed, as if they were never there), and on OpenShift I get:

&lt;div&gt;
        YAY
    &lt;/div&gt;


Consulting the docs and researching similar whitespace issues, it seemed there could be two causes of the inconsistency. Either there is something strange going on with newlines, with my local machine using a different scheme compared to the hosted OpenShift environment (along the lines of https://superuser.com/questions/374028/how-are-n-and-r-handled-differently-on-linux-and-windows) and this produces different whitespace-culling behaviour when the template is generated at the OpenShift end, or, I am changing the Jinja2 environment object when it is shared or after a template has been loaded, which violates the docs which quote:


  Instances of this class may be modified if they are not shared and if no template was loaded so far. Modifications on environments after the first  template was loaded will lead to surprising effects and undefined behaviour.


... along the lines of Stripping whitespace in jinja2 &amp; flask...why do I still need the minus sign? and Trimming blocks using whitespace control from jinja2 template. 

Plausible causes, but I am in doubt they are the reason for the strange OpenShift-side template behaviour. If I had operated on the Jinja environment too early, surely I would see incorrect template output locally as well (which I don't, I get the expected result locally). Indeed, it's in my init.py file that I set lstrip_blocks and trim_blocks to True. I doubt it's a newline issue too since I am developing on OS X, and the OpenShift environment is *nix, so both environments should be using the same newline scheme.

Given the above, I have no more theories as to why I could be getting the inconsistent results between OpenShift testing and local testing. So my questions are these: Have I set the Jinja options in the wrong place and they should be somewhere other than init.py? Am I modifying the Jinja2 Environment inappropriately? Is my method of setting Jinja2 options just plain wrong? Perhaps I should be using some other avenue to set such options other than 

flask_app_obj.jinja_env.lstrip_blocks = True
flask_app_obj.jinja_env.trim_blocks = True


Thanks for answering.
","Check your version of Jinja2 on OpenShift, it needs to be Version 2.2 or higher.
",,,false,,,
https://stackoverflow.com/questions/22591174/pandas-multiple-conditions-while-indexing-data-frame-unexpected-behavior,false,The issue does not meet the criteria for deeper analysis as it stems from a misunderstanding of logical operators and conditions in pandas rather than a problem with an API.,,,,,,,,,,,,false,,,
https://stackoverflow.com/questions/75161819,false,The issue does not meet the criteria for deeper analysis as it is related to logging and debugging configuration in GCP Cloud Run rather than an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,GCP cloud-run - Python code does not leave stack-trace when it crashes,"I have a strange situation when I deploy a python flask based service on GCP cloud-run.
I have some bug in my code that results in a crash as a part of processing some web API. But GCP cloud-run logs don't show anything except just a 500 error message. The same code, when I deploy locally on my machine throws a proper exception with the line number and other details. How do I get GCP cloud-run logs to show all that? All other logs from my code (other print statements, logger output, etc.) shows reliably. It is just these python exceptions that dont show up - making it impossible to troubleshoot issues that happen in production.
I am attaching an image that shows GCP logger output. You see the 500 error there but nothing about where i my code the exception happened and such.

","In my Dockerfile, I had to replace the first line with the 2nd line for it to work. I still have not found an explanation for it. But I am happy to have made the change - debugging is much easier - especially for long-lived application where one does not always have the luxury to instrument code reproduce problems that happen unexpectedly.
CMD exec gunicorn --bind :$PORT --workers 1 --threads 8 --timeout 0 my_main:app

CMD [ ""python"", ""-u"", ""my_main.py""]

","Posting this as a community wiki as @sachinsdesai mentioned that the issue occurred when using gunicorn when building and deploying the Cloud Run instance.
",,false,,,
https://stackoverflow.com/questions/64319236,false,The issue does not meet the criteria for deeper analysis as it is related to a specific configuration issue with PM2 and does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,weird issue with PM2 start,"I have a python3 application that I want to run continually on an Ubuntu server. I'm managing it using pm2, but running into a very strange error.
I am starting the pm2 process using:
pm2 start --name python_app --watch --interpreter /usr/bin/python3.8 python_app.py

When I first run this, it doesn't start properly: pm2 continually stops and restarts the process multiple times per second, and will keep doing this unless stopped. The output of the pm2 error logs makes very little sense: it's a lot of very long tracebacks through python libraries (almost always Flask), but without any actual errors attached to them, other than KeyboardInterrupts, which I am not making.
After manually stopping and starting the app (using the commands below), everything runs as expected (and then continues to work fine for subsequent restarts).
pm2 stop python_app
pm2 start python_app

I have repeated this process (deleting and remaking the pm2 process to see the error, and then stopping and restarting to make it work) multiple times, with the same results every time. I wonder whether this is the result of something else that's not right? Or, whether there's an equivalent command in pm2 to 'setup' a new process without launching it, then starting it separately.
I tried increasing the startup memory that pm2 could use, but it just uses 100% of whatever I give it, and still experiences the same restarting issue (just much faster, haha).
","ah, I think I know what the issue was: I noticed that watching appeared as 'disabled' when I listed processes, even though I had run with the --watch command.
When I removed --watch from the start command, it worked fine: perhaps it's not meant to be used with Python?
Would love to hear from anyone who knows more, but problem solved.
",,,false,,,
https://stackoverflow.com/questions/60260963,false,The issue does not meet the criteria for deeper analysis as it is related to file upload and processing in AWS Lambda and does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,AWS Lambda Flask file upload issue,"Im looking at a super strange issue when uploading files, using boto3 and Flask.
If I upload a standard txt file, all is fine and dandy, but if any other file type, like zip, exe or pdf, the files is changed. IE. the file size, type and hash is different the the original file. 

Here as an example I've uploaded Putty.exe.
Output :

{
""file"": ""putty.exe"",
""message"": ""success"",
""path"": ""/tmp/putty.exe"",
""s3"": """",
""sha1"": ""9b36616702410e029857bc2dd3b7f2f0d7db187a"",
""sha256"": ""5e3dfdce6cefb28f3cafe506a657a5ff44e199c3c821cbd587906f5aea435d10"",
""size"": ""1.7 MB"",
""type"": ""MS-DOS executable""
}


The correct SHA-1 of putty is 73016558c8353509b15cd757063816369e9abfa7

And when testing by flask app locally the file size and info is correct.

output from local test.

{
""file"": ""putty.exe"",
""message"": ""success"",
""path"": ""/tmp/putty.exe"",
""s3"": """",
""sha1"": ""73016558c8353509b15cd757063816369e9abfa7"",
""sha256"": ""736330aaa3a4683d3cc866153510763351a60062a236d22b12f4fe0f10853582"",
""size"": ""1.0 MB"",
""type"": ""PE32 executable (GUI) Intel 80386, for MS Windows""
}


Here is my current testing code.

import os
import boto3
import yara
import tempfile
import hashlib
import pefile
import uuid
import magic
from flask import Flask, request, redirect, send_file, url_for, jsonify
from werkzeug.utils import secure_filename

app = Flask(__name__)
bucket_name = ""&lt;Bucket name&gt;""

# File size
def convert_bytes(num):
    """"""
    this function will convert bytes to MB.... GB... etc
    """"""
    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:
        if num &lt; 1024.0:
            return ""%3.1f %s"" % (num, x)
        num /= 1024.0

def file_size(file_path):
    """"""
    this function will return the file size
    """"""
    if os.path.isfile(file_path):
        file_info = os.stat(file_path)
        return convert_bytes(file_info.st_size)

def get_hash(filename):
    fh = open(filename, 'rb')
    m = hashlib.md5()
    s = hashlib.sha1()
    s256 = hashlib.sha256()
    s512 = hashlib.sha512()
    while True:
        data = fh.read(8192)
        if not data:
                break

        m.update(data)
        s.update(data)
        s256.update(data)
        s512.update(data)

    md5  = m.hexdigest()
    sha1 = s.hexdigest()
    sha256 = s256.hexdigest()
    sha512 = s512.hexdigest()

    return md5,sha1,sha256,sha512



def process_file(file):
    s3_resource = boto3.resource('s3')
    file_path = os.path.join(tempfile.gettempdir(),file)
    s3_resource.Bucket(bucket_name).download_file(file,file_path)
    return True

@app.route(""/"")
def main():
    return  '{""messasge"" : ""Hello world""}'

@app.route(""/realtimescan"", methods=['POST'])
def realtimescan():
    filetype = """"
    tempdirectory = tempfile.gettempdir()
    file = request.files['file']
    content_type = request.mimetype
    if file:
        filename = secure_filename(file.filename)
        s3_resource = boto3.resource('s3')
        my_bucket = s3_resource.Bucket(bucket_name)
        my_bucket.Object(filename).put(Body=file.file)
        #boto3.client('s3').put_object(Bucket=bucket_name, Key=filename, Body=file)
        tmp_path = os.path.join(tempdirectory, filename)

        if process_file(filename):
            md5, sha1, sha256, sha512 = get_hash(tmp_path)
            try:
                filetype = str(magic.from_file(tmp_path, mime=False))
            except:
                filetype = ""na""

            ret = ({""message"" : ""success"",
                ""file"" : filename,
                ""path"" : tmp_path,
                ""size"" : file_size(tmp_path),
                ""type"" : filetype,
                ""sha256"" : sha256,
                ""sha1"" : sha1,
                ""s3"" : """"
            })
        else:
            ret = ({""message"" : ""error""})
        return ret

if __name__ == ""__main__"":
    app.run()


I have zero clue what the issue is.
Also, if there are a better way to process the file in memory rather then saving to /tmp, tips &amp; tricks are more than welcome.

Thanks 
","Ok turned out that one needs to set Binary Media Types under API Gateway settings to */* to accept binary file types.
",,,false,,,
https://stackoverflow.com/questions/41109643,false,The issue does not meet the criteria for deeper analysis as it is related to running a Flask app with WSGI and does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,"flask app fails when loaded with wsgi, but works fine with dev server","I have my flask app working just great with the dev server when I run it like this:

python manage.py runserver


But when I try to run it with wsgi I get all kinds of ""module not installed"" errors, and even syntax errors.  Strangely, it shows a different error each time I hit an app route.

on some of the errors, from the output in the apache error log, I can see that it's trying to run 2.7 versions of packages, when I am using 3.4.

File ""/usr/lib/python2.7/dist-packages/requests/__init__.py"", line 55, in &lt;module&gt;


I don't know why this is, python 3 is the default on the server and 

$ python --version
Python 3.4.2


is the output for every user on the system.  I am using virtualenv, but I did follow these instructions for setting up mod_wsgi with virtualenv: http://flask.pocoo.org/docs/0.11/deploying/mod_wsgi/

my wsgi file looks like this:

import sys

activate_this = '/home/flask-dev/es_app/venv/bin/activate_this.py'
with open(activate_this) as file_:
    exec(file_.read(), dict(__file__=activate_this))

print(sys.path)

from searchapp import app as application


and that print(sys.path) outputs this when I run it like 'python run.wsgi':

['/home/flask-dev/es_app/venv/lib/python3.4/site-packages', '/home/flask-dev/es_app', '/usr/lib/python3.4', '/usr/lib/python3.4/plat-x86_64-linux-gnu', '/usr/lib/python3.4/lib-dynload', '/usr/lib/python3/dist-packages']


i.e. a path to the 2.7 packages is nowhere in sight.  Also, all the required modules are installed in my virtualenv, which is why it works fine when I run the dev server.

Totally stumped on this.  Any help appreciated.
",,,,false,,,
https://stackoverflow.com/questions/69386606,false,The issue does not meet the criteria for deeper analysis as it is related to receiving strange requests on a Flask server and does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Strange requests posted to my flask server,"I have set up a little flask server on a vm as a sort of API for a simple Python app that I am working on using the kivy framework. The other night I was testing some of the requests and I accidentally left the server running. I got some strange POST and HEAD requests from an IP I don't recognize. I took a screenshot attached below. I was wondering if anyone could help shed some light on what these requests are?
output:

","It is always a good idea not to expose your API under development to the public internet. However, when you are ready to host in production, I suggest adding an additional layer of security by utilizing services like the ones offered by Cloudflare - they can give you a reverse proxying to your API and in that layer, you can define several rules of access - like block a region, a user agent, bad requests altogether, etc. You can also define usage typical sequences so that any rogue entity trying to make calls to your API can get blocked in that level itself, and such spurious requests will never even reach your server.
","Someone, or several people, is/are probing your webserver for common security vulnerabilities, probably to exploit them for malicious purposes. It doesn't look like anything was successful. If flask and any other supporting software is up to date you probably don't have anything to worry about.
It's hard to give specific system hardening advice without knowing more about your setup, but running this in a VM, installing fail2ban, and maybe setting up a reverse proxy is going to be good enough for what sounds like a small personal project.
",,false,,,
https://stackoverflow.com/questions/68281452,true,The issue involves a problem with mermaid.js where the text within boxes gets cut off. This API exhibits unexpected behavior under specific runtime conditions.,,,,,,,Mermaid.js issues with box width cutting text,"I'm looking to integrate mermaid.js into my flask application but I am encountering a strange error.
The text within boxes get's cut short by about 5-10 pixels
The following code creates this output:
&lt;div class=""mermaid""&gt;
    %%{init: {
        'theme': 'forest', 
        ""flowchart"" : { ""curve"" : ""basis"" } 
    } }%%
    graph LR
        id1[This is the text in the box]
&lt;/div&gt;


As you see the two last letters are cropped, this happens for all boxes.
Any Idea as to how I should remidy this?
","Fixed it by reducing the font-size to 90%
",,,false,,,
https://stackoverflow.com/questions/62466371,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,dev_appserver wont use my index.yaml python3.7,"I'm in the process of upgrading a python2.7 gae std app to python3.7. 
Everything is great except my indices just wont work.

I have a simple looking index.yaml file:

indexes:

- kind: Response
  ancestor: yes
  properties:
  - name: __key__
    direction: desc


And when I run certain commands then I get this 

google.api_core.exceptions.FailedPrecondition: 400 no matching index found. recommended index is:
- kind: Response
  ancestor: yes
  properties:
  - name: __key__
    direction: desc


The command I'm using to run dev_appserver is: dev_appserver.py --application=my_project_id app.yaml. 
My index.yaml file lives in the same directory as my app.yaml file. 

Nothing else is running. The application itself is a Flask api, the error is coming up when I curl one of the endpoints.

What I've tried

After poking around docs and SO for a bit it seems like I might need to run the datastore emulator locally. So made sure that my gcloud components were up to date then:

gcloud beta emulators datastore env-init

# which gave me:

export DATASTORE_DATASET=firestore-datastore-280307
export DATASTORE_EMULATOR_HOST=::1:8608
export DATASTORE_EMULATOR_HOST_PATH=::1:8608/datastore
export DATASTORE_HOST=http://::1:8608
export DATASTORE_PROJECT_ID=firestore-datastore-280307

# then

gcloud beta emulators datastore start --project=my_project_id

# which gave me 

stuff...

[datastore] API endpoint: http://::1:8679
[datastore] If you are using a library that supports the DATASTORE_EMULATOR_HOST environment variable, run:
[datastore] 
[datastore]   export DATASTORE_EMULATOR_HOST=::1:8679
[datastore] 
[datastore] Dev App Server is now running.


So by combining these outputs it looks like my environment should be like:

export DATASTORE_DATASET=my_project_id
export DATASTORE_EMULATOR_HOST=::1:8679
export DATASTORE_EMULATOR_HOST_PATH=::1:8679/datastore
export DATASTORE_HOST=http://::1:8679
export DATASTORE_PROJECT_ID=my_project_id


Cool. So I leave the emulator running and try to get my dev_appserver to connect to it:

export DATASTORE_DATASET=my_project_id
export DATASTORE_EMULATOR_HOST=::1:8679
export DATASTORE_EMULATOR_HOST_PATH=::1:8679/datastore
export DATASTORE_HOST=http://::1:8679
export DATASTORE_PROJECT_ID=my_project_id
dev_appserver.py --application=my_project_id app.yaml



It starts up but when I curl my endpoint I get the same index error.

So then I kill dev_appserver and try it like this:

# same env vars as before
dev_appserver.py --support_datastore_emulator=true --application=my_project_id app.yaml


Then I get a new error:

RuntimeError: Cannot use the Cloud Datastore Emulator because the packaged grpcio is incompatible to this system. Please install grpcio using pip


I pip installed grpcio in a python2.7 env to get over that error. Now it looks like everything is running. But I'm still getting the missing index error.

And another strange thing: If I go to http://localhost:8000 and try navigating to anythin to do with datastores then I get errors like:

ConnectionError: Cannot connect to Cloud Datastore Emulator on ::1:{THE_PORT}

Which is very weird. 

I'm considering going back to 2.7. 
","Don't go back to 2.7!  If you have this problem in production, go to your developer console and check your indexes: https://console.cloud.google.com/.....
See if they are still building. It does take some time for the indexes to build.
If this only happens in development:
dev_appserver is buggy in Windows.  I couldn't tell if you in on Windows or not.  I had problems using dev_appserver in a virtual environment even on Mac when porting an app to Python 3.7.
You state you are using Flask.  Try using the Flask server in development instead of dev_appserver.  That is what worked for me. There is good documentation on this.  You will start it with something like:
cd /Users/myname/venv37
source ./bin/activate
export FLASK_APP=/Users/myname/path_to_app
FLASK_ENV=development flask run --port 5000

edit:
ndb is not compatible with python 3.7.  They have developed a new service Google Cloud NDB which makes the old ndb data usable:  https://cloud.google.com/appengine/docs/standard/python3/migrating-to-cloud-ndb
New apps should use Cloud Datastore or Firestore.  But legacy ndb apps can migrate to Google Cloud NDB.
",,,false,,,
https://stackoverflow.com/questions/60301394,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Strange output to console flask server,"I was pull my project on another PC and start flask server. Now for everyone requst for server I have strange output like this:

[19/Feb/2020 15:54:49] ""?[31m?[1mPOST /api/auth HTTP/1.1?[0m"" 401 -


I mean this symbols like '?[31m'. What is this?
","They are accessing your program using https:// other than http:// . Allow access for https:// or make the default redirect to http://
",,,false,,,
https://stackoverflow.com/questions/58426540,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,How to host Jekyll and static HTML sites under a slash of a Flask Jinja2 site?,"Okay, what I want to do seems simple but isn't. Here is what I have and want: 


A website created with Flask and Jinja 2: https://www.neuraxio.com/
A documentation website for an open-source library created with sphinx. The output is raw static HTML files: https://www.neuraxle.neuraxio.com/stable/index.html However, I would like to move this website to https://www.neuraxio.com/neuraxle/stable/index.html with redirects from the old subdomain to the new one. The static HTML site is hosted with github pages for now. 
I want to create a jekyll blog with github pages because it's simple to manage and create new articles from markdown. Or perhaps a Wordpress blog, but something. I'd like to host that blog under https://www.neuraxio.com/blog/ and not under https://www.blog.neuraxio.com/


I know subdomains are easy to manage from a DNS and hosting standpoint, but I'd like to centralize everything under the same subdomain: www.neuraxio.com. 

So, how would you approach solving this problem? 

For the static HTML of part 2, it might be as simple as moving the static HTML to a subfolder of the public static HTML of the Jinja 2 theme, except the fact that it might break relative links (?). 

For the Jekyll or Wordpress site, I'd like it hosted under a slash of the domain and not a subdomain. How would you approach that?

Thank you for suggesting fixes and various creative ways to approach the problem. If that can be solved simply with the existing Flask and Jinja 2 code, that'd be cool. Or by using strange DNS tricks considering I'm already set up with the hosting of each subsites. 

I expect to have relative HTML links errors, however. How should I prepare agains that, too, or automatically fix each link?
","I suggest adding a CNAME dns record that can point https://www.neuraxle.neuraxio.com/stable/index.html 
to 
https://www.neuraxio.com/neuraxle/stable/index.html

This is pretty easy to do thats why I would have just gave you a link if I could but I will write a long answer instead : 

1 - Log in to your DNS management service (GoDaddy.com, googlecloud dns service...) For my part, my website is hosted on google cloud DNS.

2- Click on your website. 

3- Select Add a Record Set

4- Select CNAME record

5- I the DNS name form add https://www.neuraxle.neuraxio.com/

6- In the canonical name (the alias) add : https://www.neuraxio.com/neuraxle/

I wouldnt put this part /stable/index.html because your server should be abble to take care of pointing to it.

Hope this helps !
",,,false,,,
https://stackoverflow.com/questions/58186438,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Decoding URI Component in a Flask Application,"I am writing a Flask application. In this, I have exposed an API like the following: 

@app.route(""/&lt;project&gt;/&lt;changeId&gt;/&lt;change&gt;/&lt;patch&gt;/&lt;branch&gt;"")
def home(project, changeId, change, patch, branch):
    ...................


Now, I call this API from my front end code. 

Over here, the project variable value that I get is going to be URL Encoded (https://www.w3schools.com/jsref/jsref_encodeuricomponent.asp), such that, if the project in Javascript is 
A/B, that will be converted to A%B

Now, I want to convert it back to A/B in my flask application. How can I do that? 

I had tried looking at this: https://blog.revathskumar.com/2011/10/python-url-encoding-and-decoding.html

But this doesn't work on what I wish to achieve.

Edit:

So, I did the following:

from urllib import parse

@app.route(""/&lt;project&gt;/&lt;changeId&gt;/&lt;change&gt;/&lt;patch&gt;/&lt;path:branch&gt;"")
def home(project, changeId, change, patch, branch):

app.logger.info('project is %s, changeId is %s, change is %s, patch is %s, branch is %s', project, changeId, change, patch, branch)

    projectnew = parse.unquote(project)

app.logger.info('project is %s, changeId is %s, change is %s, patch is %s, branch is %s', projectnew, changeId, change, patch, branch)


Now, strangely when I look at the log lines, the OP for project is same (A) in both the cases even though I pass an encoded string. 

For example, the value of project getting is passed is something like: A%2FB. 

The output after parsing should be project = A/B, whereas, in both the cases, the OP is project = A

Am I doing something wrong here?
","In Python3:

&gt;&gt;&gt; from urllib import parse
&gt;&gt;&gt; parse.unquote('https%3A%2F%2Fw3schools.com%2Fmy%20test.asp%3Fname%3Dst%C3%A5le%26car%3Dsaab')
'https://w3schools.com/my test.asp?name=ståle&amp;car=saab'


In Python2

&gt;&gt;&gt; import urllib
&gt;&gt;&gt; urllib.unquote('https%3A%2F%2Fw3schools.com%2Fmy%20test.asp%3Fname%3Dst%C3%A5le%26car%3Dsaab')
'https://w3schools.com/my test.asp?name=st\xc3\xa5le&amp;car=saab'

",,,false,,,
https://stackoverflow.com/questions/49917098,true,The issue involves the incorrect usage of io.BytesIO when passing input files to Textract in a Flask application.,,,,,,,"TypeError: coercing to Unicode: need string or buffer, _io.BytesIO found","I am trying for a week how to give input files to Textract from flask POST option. 

@app.route('/input', methods=['POST'])
def input():
    request_file = request.files.get('file')
    r = textract.process(io.BytesIO(request_file.read()))
    return r 


The above code throws me error 


  TypeError: coercing to Unicode: need string or buffer, _io.BytesIO
  found


And I tried a small test with send_file to check if it actually takes the input and to check if BytesIO works well in my case: 

@app.route('/input', methods=['POST'])
def input():
    request_file = request.files.get('file')
    return send_file(io.BytesIO(request_file.read()),attachment_filename=
request_file.filename)


the above code works fine for pdf files and send responses(to download pdf file). And when i tried .docx,.txt files it show some strange outputs on the screen :   PK

My questions, how do i send this io.bytes(request_file.read()) as a file to Textract now ? I tried to find answer everywhere but i couldn't.

Am i supposed to decode or encode now?
","textract.process() expects a string, but you send io.BytesIO(request_file.read()) instead. I'm not really sure why you're using io.BytesIO. Can you try:

textract.process(request_file.read())

",,,false,,,
https://stackoverflow.com/questions/49135272,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Created logger makes duplicated outputs after raised Exception,"Problem solved!

By disabeling the flask logger the duplicated outputs seems to have dissapeared.

app.logger.disabled = True


Seems to have done the trick.



Honestly I do not really understand how logger seem to work, but I run in to a strange problem.

I initiate my logger by this code:

utilities_module:

def get_logger(name):
    logger = logging.getLogger(name)
    if not logger.handlers:
        handler = logging.StreamHandler()
        formatter = logging.Formatter(
            ""%(asctime)s %(levelname)s %(name)s %(message)s"",
            ""%Y-%m-%d %H:%M:%S""
        )
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        logger.setLevel(logging.INFO)
    return logger


Main module:

import utilities
logger = utilities.get_logger(""Any_Name:"")

logger.info(""My heart will go on!"")


This outputs ""YYYY-MM-DD time Any_Name: My heart will go on!"" As it should.

The problem is:

It works untill an exception is raised and then the output becomes duplicated, but without date and time.

Like this:

2018-03-06 15:33:23 INFO Any_Name:  My heart will go on! 
INFO:Any_Name:: My heart will go on!


Note the 2 extra :

The logger is created at instantiation of a class and used in the class as self.logger and is only instantiated once.

Good to know:

This is a microservice but the duplicated logs are both in k8 and when running it locally, it uses Flask restfull. and those are the pip modules used

 - flask == 0.12 
 - flask-restful == 0.3.6  
 - PyYaml == 3.12  
 - Requests == 2.18.3 
 - requests-toolbelt == 0.8.0

",,,,false,,,
https://stackoverflow.com/questions/45717911,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Posting from React to Flask: Uncaught (in promise) SyntaxError: Unexpected token &lt; in JSON,"Before I get linked to another thread, I've checked the other answers on this forum about this problem.  My JSON is formatted correctly and the JSON doesn't contain HMTL. I know 'Key' is in single quotes but double quotes doesn't fix the problem. The request is going to local host.

Here's the POST from the react file:

fetch(URL + '/api/' + this.props.choice, {
              method: 'POST',
              headers: {
              'Accept': 'application/json',
              'Content-Type': 'application/json',
              },
              body:JSON.stringify({'Key': this.state.value})
              })


Here's the GET from the Flask file:

@app.route('/api/Junk', methods = ['GET', 'POST'])
    def junk():
        junk_request = request.get_json(force = True)
        print junk_request
        junk_date_var = junk_request[""Key""]


The error message from Chrome Debugger:

fetch uncaught (in promise) syntaxerror: unexpected token &lt; in JSON at position 0


Output from the terminal:

{u'Key': u'Select'}


u just means it's a unicode character. What's also strange is that this EXACT code was working a few days ago. This makes me think that some permission is off or something is going wrong with Node.
",,,,false,,,
https://stackoverflow.com/questions/51269053,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,How does searching with pip work?,"Yes, I'm dead serious with this question. How does searching with pip work?

The documentation of the keyword search refers to a ""pip search reference"" at https://pip.pypa.io/en/stable/user_guide/#searching-for-packages which is everything but a reference.

I can't conclude from search attempts how searching works. E.g. if I search for ""exec"" I get a variety of results such as exec-pypeline (0.4.2) - an incredible python package. I even get results with package names that have nothing to do with ""exec"" as long as the term ""exec"" is in the description.

But strangely I don't see one of my own packages in the list though one of the packages contains exec in it's name. That alone now would lead us to the conclusion that pip (at least) searches for complete search terms in the package description (which my package doesn't have).

But building on that assumption if I search for other terms that are provided in the package description I don't get my package listed either. And that applies to other packages as well: E.g. if I search for ""projects"" I don't get flask-macros in the result set though the term ""projects"" clearly exists in the description of flask-macros. So as this contradicts the assumption above this is clearly not the way how searching works.

And interestingly I can search for ""macro"" and get ""flask-macros"" as a result, but if I search for ""macr"" ""flask-macros"" is not found.

So how exactly is searching performed by pip? Where can a suitable reference be found for this?
",,,,false,,,
https://stackoverflow.com/questions/46093103,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Flask-Mysql type error when update data,"I'm having a strange bug when I write a website with flask and package flask-mysql.

Here is the code of the bug function:

@app.route('/calendar/editeventtitle',methods=['POST'])
def editeventtitle():
    if not session.get('logged_in'):
      abort(401)

    try:
      id = request.form.get('id',type=int)
      title = request.form['title']
      color = request.form['color']
      delete = request.form.get('delete')
    except:
      pass

    conn = mysql.connect()
    cursor = conn.cursor()
    print(id,type(id))
    # try:
    #   print(delete,type(delete))
    # except:
    #   pass

    if id and delete:
        cursor.execute('delete from events where id = %d',id)
        conn.commit()
        flash('Event canceled!')
        return redirect(url_for('calendar'))
    elif id and title and color:
        cursor.execute('update events set title = %s, color = %s where id = %d',(title,color,id))
        conn.commit()
        flash('Event updated!')
        return redirect(url_for('calendar'))


When I post the four variables to this page. I succesfully get them. And the result of print(id,type(id)) is like:  

6 &lt;class 'int'&gt;


We see it's really an integer, but when the code starts to update or delete data from db, here is the error message:


  TypeError: %d format: a number is required, not str


Really don't know the reason =-=, anyone can help me? Thank you.

PS: Python3.6.1, Flask 0.12.2, Flask-Mysql 1.4.0
",,,,false,,,
https://stackoverflow.com/questions/49917098,true,The issue involves the incorrect usage of io.BytesIO when passing input files to Textract in a Flask application.,,,,,,,"TypeError: coercing to Unicode: need string or buffer, _io.BytesIO found","I am trying for a week how to give input files to Textract from flask POST option. 

@app.route('/input', methods=['POST'])
def input():
    request_file = request.files.get('file')
    r = textract.process(io.BytesIO(request_file.read()))
    return r 


The above code throws me error 


  TypeError: coercing to Unicode: need string or buffer, _io.BytesIO
  found


And I tried a small test with send_file to check if it actually takes the input and to check if BytesIO works well in my case: 

@app.route('/input', methods=['POST'])
def input():
    request_file = request.files.get('file')
    return send_file(io.BytesIO(request_file.read()),attachment_filename=
request_file.filename)


the above code works fine for pdf files and send responses(to download pdf file). And when i tried .docx,.txt files it show some strange outputs on the screen :   PK

My questions, how do i send this io.bytes(request_file.read()) as a file to Textract now ? I tried to find answer everywhere but i couldn't.

Am i supposed to decode or encode now?
","textract.process() expects a string, but you send io.BytesIO(request_file.read()) instead. I'm not really sure why you're using io.BytesIO. Can you try:

textract.process(request_file.read())

",,,false,,,
https://stackoverflow.com/questions/50381867,false,The issue does not meet the criteria for deeper analysis as it does not involve unexpected behavior or failures of an API.,,,,,,,uwsgi timeout after a few POST request,"I'm trying to host a python program. It works with hosting it via flask, but when I change the setup to flask + uwsgi + nginx, something strange happens: The request (POST) was returned with the proper result. However after a few requests, it will just timeout. After that, even if I restart all the service, the request will also timeout.

I have a UI for test using Ajax and jquery. Each keystroke will call my API searching inside elasticsearch. The timeout starts after a few attempts, the number of attempts is depending on how fast I type.

Everything is running inside docker, glued by docker-compose.

I tried multiple things:


set the uwsgi timeout in nginx configuration file to a larger value
set all the timeout parameters in nginx to a larger value
changed POST method to GET
added harakiri=30 in uwsgi.ini
added socket-timeout=60 in uwsgi.ini
host with uwsgi only by uwsgi --http 0.0.0.0:86 --wsgi-file main.py --callable application --post-buffering 1


None of them worked, it always timeout at the second request. If the request returns an empty body, it wouldn't timeout. 

Something interesting is that when the socket-timeout is set to 60s, it actually starts timeout from the third request sometimes.

Below are my setups:

Nginx


server {listen &lt;myport&gt;;
server_name &lt;myip&gt;;
root /usr/share/nginx/html;
location / {
    uwsgi_read_timeout 60s;
    include uwsgi_params;
    uwsgi_pass unix:///tmp/uwsgi.sock;
} }



uwsgi


[uwsgi] 
socket = /tmp/uwsgi.sock 
chown-socket = www-data:www-data
chmod-socket = 664 
uid = www-data 
gid = www-data 
cheaper = 0 
processes = 1
socket-timeout = 60 
single-interpreter = true
wsgi-file = main.py 
callable = application



main.py

from flask import Flask, jsonify, render_template, request
from &lt;myfile&gt; import _myapiworker
application = Flask(__name__)
@application.route('/_myapi', methods=['POST'])
def myapi():
    req_data = request.get_json()
    &lt;assembling post body&gt;
    res_str = _myapiworker(&lt;post body&gt;)
    return jsonify(res_str)
@application.route('/')
def index():
    return render_template('index.html')
if __name__ == '__main__':
    application.run(host='0.0.0.0', debug=True, port=80)

","Change the http to http-socket, like this:

uwsgi --http-socket 0.0.0.0:86 --wsgi-file main.py --callable
application --post-buffering 1

Please refer the uwsgi-docs https://uwsgi-docs.readthedocs.io/en/latest/WSGIquickstart.html
Note: Do not use --http when you have a frontend webserver or you are doing some form of benchmark, use --http-socket. Continue reading the quickstart to understand why.
",,,false,,,
https://stackoverflow.com/questions/21136676,false,The issue does not have enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,pycharm flask project is not supported,,,,,false,,,
https://stackoverflow.com/questions/50485329,false,The issue does not have enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Pymongo only returning id field when empty object is passed,"I have working with python and MongoDB.  To connect to mongo I am using python module Pymongo.  As I can see from documentation which is very abstract and small.  It seems most of the things works as it works in normal MongoDB collection. But there is a strange part related to find query.  

In Mongo Shell:   

 db.my_collection.find({}, {})
 Results Array Fields:  { _id, field1, field1, field3 ..... etc} 
 //Notice:  Returning all Fields of each Document


In Python Shell:  

 pymonogoMongoClient(""localhost"", 27017)['DB']['my_collection'].find({}, {})
 Results Array Fields:  {_id} 
 Notice  // Only Id is returning for all Docs


I understand that I get my desired results by not specifying empty {} in second argument of find but that is not what my code design allow. I am creating a kind of ORM for my Flask Application where I have to write generic Database function. And it is not allow. 

Any help or get around to get all the Documents by passing an argument will be appreciated.   Thanks in advance
",,,,false,,,
https://stackoverflow.com/questions/25136140,false,The issue does not have enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,py-bcrypt giving different hash results than flask-bcrypt - possible?,,,,,false,,,
https://stackoverflow.com/questions/66431069,true,"The issue involves an API exhibiting unexpected behavior when sending an OpenCV image via Flask_socketIO to the client. The API in question is cv2.imencode, which raises a TypeError when attempting to serialize an ndarray object. The solution is to encode the ndarray as bytes using the .tobytes() method before sending it.",,,,,,,Sending openCV image via Flask_socketIO to client causes TypeError: Object of type ndarray is not JSON serializable,"I have a base64 image being sent from the browser to my flask server. When the server gets the base64 string, it converts it to a format for OpenCV:
image = '{}'.format(image64).split(',')[1]

im_bytes = base64.b64decode(image)
im_arr = np.frombuffer(im_bytes, dtype=np.uint8)  # im_arr is one-dim Numpy array
frame = cv2.imdecode(im_arr, flags=cv2.IMREAD_COLOR)

Some processing happens on the frame and then, using flask_signalio, is sent back to the browser using:
encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 90]
result, encimg = cv2.imencode('.jpg', updated_frame, encode_param)
socketio.emit('response_back', {'image_data': encimg}, namespace='/test')

In the browser, I have some JS to display the image that it receives:
socket.on('response_back', function(image){
    ....
});

I have two issues.

Calling socketio.emit('response_back', {'image_data': encimg}, namespace='/test') results in an exception on the server: TypeError: Object of type ndarray is not JSON serializable.

How can I fix this? What is wrong here? It's strange because I am sure I am sending ('emitting') the data correctly, as shown here and here. I've also tried setting up SocketIO to use binary data: socketio = SocketIO(app, binary=True). Nothing works. Always the same error.

How do I deal with the image data back on the client/browser? (i.e. in the socket.on('response_back', function(image) code)?

","After nearly an hour, I've found the solution.
First, flask_socketio can send byte data, but NOT ndarray! The solution is to encode to bytes, with .tobytes(). For example, on the server:
encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 90]
result, encimg = cv2.imencode('.jpg', updated_frame, encode_param)
socketio.emit('response_back', {'frame': encimg.tobytes()}, namespace='/test')

For the second problem, we need to convert the ArrayBuffer data:
var arrayBufferView = new Uint8Array( result.frame );
var blob = new Blob( [ arrayBufferView ], { type: ""image/jpeg"" } );
var urlCreator = window.URL || window.webkitURL;
var imageUrl = urlCreator.createObjectURL( blob );
var image_id = document.getElementById('imagebox');
image_id.src = imageUrl;

",,,false,,,
https://stackoverflow.com/questions/61913509,false,The issue does not have enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,How to increase speed when writing Spark DataFrame to Redis?,"I am developing a book recommendation API based on Flask, and it was found that to manage multiple requests I'll need to pre-calculate similarity matrix and store it somewhere for future queries. This matrix is created using PySpark based on ~1.5 million of database entries with book id, name and metadata, and the result can be described by this schema (i and j are for book indexes, dot is for similarity of their metadata):

StructType(List(StructField(i,IntegerType,true),StructField(j,IntegerType,true),StructField(dot,DoubleType,true)))


Initially, it was my intention to store it on Redis, using spark-redis connector. However, the following command appears to work with a very slow speed (even if initial book database query size is limited to a very modest 40k batch):

similarities.write.format(""org.apache.spark.sql.redis"").option(""table"", ""similarities"").option(""key.column"", ""i"").save()


It took around 6 hours to advance through 3 of the 9 stages Spark separated the initial task into. Strangely, storage memory usage by Spark executors was very low, around 20kb. A typical stage active stage is described as such by Spark Application UI:

org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:271)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
py4j.Gateway.invoke(Gateway.java:282)
py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
py4j.commands.CallCommand.execute(CallCommand.java:79)
py4j.GatewayConnection.run(GatewayConnection.java:238)
java.lang.Thread.run(Thread.java:748)


Is it possible to somehow speed up this process? My Spark session is set up this way:

SUBMIT_ARGS = ""  --driver-memory 2G --executor-memory 2G --executor-cores 4 --packages mysql:mysql-connector-java:5.1.39 pyspark-shell""
os.environ[""PYSPARK_SUBMIT_ARGS""] = SUBMIT_ARGS
conf = SparkConf().set(""spark.jars"", ""spark-redis/target/spark-redis_2.11-2.4.3-SNAPSHOT-jar-with-dependencies.jar"").set(""spark.executor.memory"", ""4g"")
sc = SparkContext('local','example', conf=conf) 
sql_sc = SQLContext(sc)

","You may try to use Append save mode to avoid checking if the data already exists in the table:

similarities.write.format(""org.apache.spark.sql.redis"").option(""table"", ""similarities"").mode('append').option(""key.column"", ""i"").save()


Also, you may want to change

sc = SparkContext('local','example', conf=conf) 


to 

sc = SparkContext('local[*]','example', conf=conf) 


to utilize all cores on your machine.

BTW, is it correct to use i as a key in Redis? Shouldn't it be a composition of both i and j?
",,,false,,,
https://stackoverflow.com/questions/54524290,false,The issue does not have enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Nginx not working with socket.io on production server,"I have a flask-app which is using flask-socketio extension. It works fine on local machine using 'socketio.run()' or 'flask run' dev server. I want to make it work with a nginx proxy, and it works on local machine with this nginx server config:

file /etc/nginx/sites-available/server.conf

server {
    listen 8080;
    location / {
        proxy_pass http://localhost:5000;
    }
}


The actual app is running on port 5000 with socketio.run(), which as i heard is also a good production server. The strange thing is that it works even with this message: ""WebSocket transport not available. Install eventlet or gevent and gevent-websocket for improved performance."" It also works with this warning: ""Flask-SocketIO is Running under Werkzeug, WebSocket is not available."" (first when i use socketio.run(), second with flask run)

Yet if I try to run the same thing on the production server, only http part works, and sockets don't. As i read everywhere on the Internet I should specify headers Connection and Upgrade in nginx server config which i do not understand why and which i tried too:

file /etc/nginx/sites-available/server.conf

server {
        listen 80;
        server_name servername.com;

        location / {
            proxy_pass http://127.0.0.1:5000;
        }

        location /socket.io/ {
            proxy_pass http://127.0.0.1:5000/socket.io;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection ""upgrade"";
        }
}


Result is the same, sockets are not working. Using 'flask run' with any of configs i get these debug messages: 
127.0.0.1 - - [04/Feb/2019 20:55:52] ""GET /socket.io?EIO=3&amp;transport=polling&amp;t=MYwIxxF HTTP/1.1"" 404 -
The indicate not working socketio, yet the server gets it and replyes with 404, which i see no reason for.

My local computer runs Kali linux and nginx 1.13.12, remote is Ubuntu 18.04 with nginx 1.14.0
Right now I really don't understand which configuration is proper, why is the first configuraion working on my local machine and why none of configurations work on production server and how do i interpreter this 404 message. Even though there are several guides on the Internet, it doesn't work with me.

Any help appreciated!
","Maybe nginx was unable to match /socket.io/ location to /socket.io?EIO=3&amp;transport=polling&amp;t=MYwIxxF path. Take a look at nginx documentation on location to find out how you can write location matcher that fits your needs.
",,,false,,,
https://stackoverflow.com/questions/23634511,false,The issue does not have enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,load data to server using jquery,,,,,false,,,
https://stackoverflow.com/questions/71993489,false,The issue does not have enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Implementing Cross-Domain CSRF Protection,"I know this question has been asked several times, but I have never found a clear solution. How does one protect a web application against a CSRF attack?
I currently have two domains, frontend.com and backend.com. The backend uses flask-wtf to create a session (stored as a cookie on frontend browser) and returns a CSRF token in the header of the response.
I am able to get the token and send requests with the token attached to the header. However, I noticed the cookie was never set. As a result, I am assuming this is why I'm getting an error a 400: Bad Request. After continuous reading and researching, I am almost convinced that it's meant to be used in the same domain.
My current technology stack is:
DNS: Cloudflare
Hosting:
Heroku

React client
Python (Flask) API

I can't see how CSRF tokens can be used in this scenario, unless I am missing something that is critical for it to work.
That said, what would be the best approach addressing CSRF protection in a cross-domain setting given my situation?
In addition, this all works in my local development environment. I'm not sure why it suddenly stopped working in production.
A sample request looks like this:
const headers = {
   'Content-Type': 'application/json',
   'X-CSRF-Token': csrfToken 
};
...
const handleFormSubmission = async e =&gt; {
    e.preventDefault();
    await axios.post('https://backend.com/add-results', { tokenId: tokenId }, { withCredentials: true, headers: headers })
}

And the backend has the following settings:
...
    CORS(app, origins=[""https://www.frontend.com""], expose_headers=[""Content-Type"", ""X-CSRFToken""], supports_credentials=True)  
...
    app.config['SESSION_COOKIE_SECURE'] = True
    app.config['SESSION_COOKIE_HTTPONLY'] = True
    app.config['REMEMBER_COOKIE_SECURE'] = True
    app.config['REMEMBER_COOKIE_HTTPONLY'] = True
    app.config['SESSION_COOKIE_SAMESITE'] = 'Lax'

It's very strange as this works on development environment.
","You actually seem to have a working CSRF protection in place.
You said:

I am able to get the token and send requests with the token attached to the header. However, I noticed the cookie was never set.

So your problem seems to be that you are not getting the session cookie which is a different thing.
This is a classic problem for cross-domain requests.
By default, browsers won't send cookies to another domain because of security reasons.
You either need to enable CORS via Access-Control-* headers or use an alternative token storage mechanism instead of cookies (e.g. Web Storage).
I can very much recommend the Api Security in Action book that deals with this topic in Chapter 5 (specifically 5.1 and then 5.2 for Web Storage)
",,,false,,,
https://stackoverflow.com/questions/66260185,false,The issue does not have enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Flask: Download a .zip file using a GET request,"Flask v1.1.2, Python v3.7
I'm trying to get Flask to send me a .zip file it generates based on the GET request.
I have a page where the user can click a download button, which issues a GET request and parses a key as value. Based on this key the .zip file is created and moved to my /static folder. Below the handler that gets executed:
    def download(self):
        key = request.args['action']
        zip_location = os.path.join(app.static_folder, ""files.zip"")
        res = self.recorder.down.download(key, zip_location)
        return send_file(""static/files.zip"", as_attachment=True)

I tried sending the file using send_file, send_from_directory, app.send_static_file, but they all result in the same strange error occurring:
Serving Flask app ""webapp.webUI"" (lazy loading) 
Environment: production
WARNING: This is a development server. Do not use it in a production deployment.
Use a production WSGI server instead.
Debug mode: on
Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)
Debugging middleware caught exception in streamed response at a point where response headers were already sent.
Traceback (most recent call last):
  File ""/home/pi/somepath/env/lib/python3.7/site-packages/werkzeug/wsgi.py"", line 506, in __next__
    return self._next()
  File ""/home/pi/somepath/env/lib/python3.7/site-packages/werkzeug/wrappers/base_response.py"", line 45, in _iter_encoded
    for item in iterable:
TypeError: 'Response' object is not iterable
127.0.0.1 - - [18/Feb/2021 13:34:58] ""GET /download?action=20210216+16u11s19 HTTP/1.1"" 200 -

Google doesn't help much, I've been searching the cause of the error for hours.
","Try
from flask import Flask, request
# set the project root directory as the static folder, you can set others.
app = Flask(__name__, static_url_path='')

@app.route('/download')
def download():
    return app.send_static_file('files.zip')

",,,false,,,
https://stackoverflow.com/questions/64442195,false,The issue does not have enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Flask - sending data through with GET request,"I am building simple Flask web-app using Google books API. I am a beginner and maybe overthinking details, but something tells me I haven't designed this very well.
Problem I am facing:

Find book through search bar
Button on each search result to post review page: review/book/&lt;book_id&gt; - POST request
Actual page where you write review and submit: summary/add/&lt;book_id&gt; - POST request

What I find strange is that I have POST request following another POST request, just because I couldn't find a way how to send &lt;book_id&gt; over to the write review page. There is also problem redirecting user back since this page is @login_required but there is no GET request on it.
So my main question is: Is there a way to send &lt;book_id&gt; over without making the initial post request (from search result to post review page)? Maybe with javascript?
Thank you
","If I understood correctly, you have to send &lt;book_id&gt; in a GET request ?
If yes, you can do something on following lines
@api_blueprint.route('/books/&lt;int:book_id&gt;', methods=['GET'])  #you can use the decorator yor have 
def get_by_id(book_id):
    print(book_id)


I had defined the blueprints for my application. But it's okay even if you don't have that. You can use simply @app.route, or the one which you have for other POST apis.
from flask import Flask

app = Flask(__name__)


@app.route('/')
def hello():
    return 'Hello, World!'

",,,false,,,
https://stackoverflow.com/questions/60594940,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Infinite page reload on Flask app served using Nginx + Gunicorn,"I am running a Flask app on a DigitalOcean droplet using Gunicorn and Nginx on a Ubuntu 18.04 VPS. I followed this tutorial for the setup.

I am facing two strange issues when I access the app from my domain –


The JavaScript elements are either unresponsive or take too long to respond. This has primarily to do with the buttons that trigger the JS that make Ajax calls and render the results. All other non-Ajax JS runs fine.
On a particular route, the app seems to enter an infinite reload loop. This has to do with the blueprint I use to display and browse tags. The route - @tags_bp.route('/&lt;language&gt;/tags/&lt;tag_search&gt;', methods=['GET']) - renders a template with some responses from server. An allied route - @tags_bp.route('/&lt;language&gt;/tags/&lt;tag_search&gt;/&lt;variable&gt;', methods=['GET']) - only returns server responses as JSON that gets rendered on the page.


Interestingly, none of these issues show up when I run the app on localhost (port 5000) using Gunicorn on &lt;Droplet IP&gt;:5000. It's only when I access the &lt;domain&gt; that the issues occur.

My configuration files are exactly as suggested in the tutorial. I am using a separate server block for my domain instead of the default.

I am suspecting the problem lies somewhere between Nginx and Gunicorn. I tried changing the headers in Nginx based on this page on the Flask documentation but that didn't help either.

In addition, the site has an SSL certificate issued by Let's Encrypt using certbot.

Any suggestions for how to debug/fix this? 

Cheers.

Edit:
The config files are as follows – 

systemmd unit file at /etc/systemd/system/myproject.service

[Unit]
Description=Gunicorn instance to serve myproject
After=network.target

[Service]
User=sammy
Group=www-data
WorkingDirectory=/home/&lt;USER&gt;/myproject
Environment=""PATH=/home/&lt;USER&gt;/myproject/myprojectenv/bin""
ExecStart=/home/&lt;USER&gt;/myproject/myprojectenv/bin/gunicorn --workers 3 --bind unix:myproject.sock -m 007 wsgi:app

[Install]
WantedBy=multi-user.target


Server block at /etc/nginx/sites-available/myproject

server {
    listen 80;
    server_name your_domain www.your_domain;

    location / {
        include proxy_params;
        proxy_pass http://unix:/home/&lt;USER&gt;/myproject/myproject.sock;
    }

  # Let's Encrypt credentials ...
}


The nginx.conf is exactly as the default except that server_names_hash_bucket_size 64; is un-commented.
","Fixed it with help from some more experienced friends. 

The reload loop issue lay in the URL string I was using to make Ajax calls to the database. I was masking the database IDs using the Python Cryptography package but that yielded really long strings (~100 characters). This caused some problems with XHR - I don't entirely understand what or how.

I switched instead to creating shorter strings using the secrets.token_urlsafe(X) function from the built-in secrets module in Python.

The first issue had to do with latency as correctly diagnosed by @JoranBeasley. Fixed that by changing the caching technique on the back-end using Flask Caching.
",,,false,,,
https://stackoverflow.com/questions/58289105,false,The issue does not meet the criteria for deeper analysis as it appears to be a question about paginating a subquery in Flask rather than an API-related problem.,,,,,,,paginate a subquery in flask,"This is an abbreviated version of the problem posted in Strange paginate behaviour when paginating a subquery in flask.

I need to paginate the result of the following query and display the results:

sub = db.session.query(Magazine).join(Magazine.subscribers).filter(User.id == 2).subquery()
subscribers = db.session.query(User).select_from(sub).join(Magazine.subscribers)


and I try to do it with the following code:

page=request.args.get('page', 1, type=int)
friends=subscribers.paginate(page, 3, False)
next_url=url_for('index', page=friends.next_num) if friends.has_next else None
prev_url=url_for('index', page=friends.prev_num) if friends.has_prev else None
return render_template(""index.html"", title=""My friends"", friends=friends.items, next_url=next_url, prev_url=prev_url)


This gives a weird result. To start with it returns only 2 results when 3 are asked and friends.has_next is false when it should be true (there are more items in the databse). In Strange paginate behaviour when paginating a subquery in flask there are more details and also a test I run. I am suspecting the error comes from the subquery. Am I missing something obvious??!!!

In the following example I work with some ""fake"" data in a flask shell:

&gt;&gt;&gt; sub = db.session.query(Magazine).join(Magazine.subscribers).filter(User.id == 2).subquery()
&gt;&gt;&gt; subscribers = db.session.query(User).select_from(sub).join(Magazine.subscribers)
&gt;&gt;&gt; friends=subscribers.paginate(1, 3, False)
&gt;&gt;&gt; subscribers.all()
[&lt;User 2&gt;, &lt;User 3&gt;, &lt;User 4&gt;, &lt;User 5&gt;, &lt;User 6&gt;]
&gt;&gt;&gt; friends.items
[&lt;User 2&gt;, &lt;User 3&gt;]
&gt;&gt;&gt; friends.has_next
False
&gt;&gt;&gt; friends.has_prev
False


Any insights?
","You can use sqlalchemy_paginator. Check out this link for detailed example.

from sqlalchemy_paginator import Paginator
query = session.query(MyModel)
paginator = Paginator(query, 5)
for page in paginator:
    print ""page number of current page in iterator"", page.number
    print ""this is a list that contains the records of current page"", page.object_list

",,,false,,,
https://stackoverflow.com/questions/53710907,false,The issue does not meet the criteria for deeper analysis as it involves communication issues between Docker containers and does not directly relate to an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Flask and selenium-hub are not communicating when dockerised,"I am having issues with getting data back from a docker-selenium container, via a Flask application (also dockerized).

When I have the Flask application running in one container, I get the following error on http://localhost:5000, which goes to the selenium driver using a Remote driver that is running on http://localhost:4444/wd/hub

The error that is generated is:
urllib.error.URLError: &lt;urlopen error [Errno 99] Cannot assign requested address&gt;

I have created a github repo with my code to test, see here.

My docker-compose file below seems ok:

version: '3.5'
services:
  web:
    volumes:
      - ./app:/app
    ports:
      - ""5000:80""
    environment:
      - FLASK_APP=main.py
      - FLASK_DEBUG=1
      - 'RUN=flask run --host=0.0.0.0 --port=80'
    command: flask run --host=0.0.0.0 --port=80
    # Infinite loop, to keep it alive, for debugging
    # command: bash -c ""while true; do echo 'sleeping...' &amp;&amp; sleep 10; done""

  selenium-hub:
    image: selenium/hub:3.141
    container_name: selenium-hub
    ports:
      - 4444:4444

  chrome:
    shm_size: 2g
    volumes:
      - /dev/shm:/dev/shm
    image: selenium/node-chrome:3.141
#    image: selenium/standalone-chrome:3.141.59-copernicium
    depends_on:
      - selenium-hub
    environment:
      - HUB_HOST=selenium-hub
      - HUB_PORT=4444


What is strange is that when I run the Flask application in Pycharm, and the selenium grid is up in docker, I am able to get the data back through http://localhost:5000.  The issue is only happening when the Flask app is running inside docker.

Thanks for the help in advance, let me know if you require further information.



Edit

So I amended my docker-compose.yml file to include a network (updated the code in github.  As I've had the Flask app code running in debug and in a volume, any update to the code results in a refresh of the debugger.

I ran docker network inspect on the created network, and found the local docker IP address of selenium-hub.  I updated the app/utils.py code, in get_driver() to use the IP address in command_executor rather than localhost.  Saving, and re-running from my browser results in a successful return of data.

But I don't understand why http://localhost:4444/wd/hub would not work, the docker containers should see each other in the network as localhost, right?
",,,,false,,,
https://stackoverflow.com/questions/44666837,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,"Flask producing HTML table as a string, not a table (Python 2)",,,,,false,,,
https://stackoverflow.com/questions/43961313,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Routing Flask HTML table entires to individual SQL queries,,,,,false,,,
https://stackoverflow.com/questions/41651823,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Flask-MySQL How to effectively INSERT INTO table with parameterized queries,,,,,false,,,
https://stackoverflow.com/questions/38280334,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,POST request through AJAX results in error 404 in Firefox only,,,,,false,,,
https://stackoverflow.com/questions/14473211,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,uwsgi flask application got nginx variables unexpanded,,,,,false,,,
https://stackoverflow.com/questions/38087283,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,python flask can&#39;t find &#39;__main__&#39; module in &#39;&#39;,,,,,false,,,
https://stackoverflow.com/questions/32885710,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,flask_login sometimes mixes logins; I&#39;m logged in as somebody else,,,,,false,,,
https://stackoverflow.com/questions/40730312,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Order of registering Flask Blueprints,,,,,false,,,
https://stackoverflow.com/questions/62206156,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,How to deal with python3 multiprocessing in __main__.py,"Il posed question, I did not understand the ture cause of the issue (it seems to have been related to my usage of flask in one of the subprocesses).

PLEASE IGNORE THIS (can't delete due to bounty)

Essentially, I have to start some Processes and or a pool when running a python library as a module.

However, since __name__ == '__main__' is always true in __main__.py this proves to be an issue (see multiprocessing docs: https://docs.python.org/3/library/multiprocessing.html)

I've attempted multiple solutions ranging from: pytgquabr.com:8182/58288945/using-multiprocessing-with-runpy to a file-based mutext to only allow the contents of main to run once but multiprocessing still behaves strangely (e.g. Processes die almost as soon as they start with no error logs).

Any idea of what the ""proper"" way of going about this is ?
","Guarding the __main__ module is only needed if an object defined inside __main__ is used in another process. Looking up this definition is what causes the execution of __main__ in the subprocess.

When using a __main__.py, restrict all definitions used with multiprocessing to other modules. __main__.py should only import and use these.

# my_package/some_module.py
def module_print(*args, **kwargs):
    """"""Function defined in some module - fine for use inside multiprocess""""""
    print(*args, **kwargs)

# my_package/__main__.py
import multiprocessing                 # imports are allowed
from .some_module import module_print

def do_multiprocess():
    """"""Function defined in __main__ module - fine for use wrapping multiprocess""""""
    with multiprocessing.Pool(processes=12) as pool:
        pool.map(module_print, range(20))  # multiprocessing external function is allowed

do_multiprocess()  # directly calling __main__ function is allowed

",,,false,,,
https://stackoverflow.com/questions/52087743,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Flask Restful NoAuthorizationError Missing Authorization Header,,,,,false,,,
https://stackoverflow.com/questions/47083304,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Flask redirects to wrong view when redirecting to index,,,,,false,,,
https://stackoverflow.com/questions/24552415,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,&quot;Query has no attribute &#39;whoosh_search&quot; AttributeError in Flask + Whoosh + SQLAlchemy,,,,,false,,,
https://stackoverflow.com/questions/60774761,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Flask Teardown Appcontext Too Many Arguments,"I'm getting a strange error when trying to run my Flask app. I set the teardown_appcontext to be a function I have to close the database: app.teardown_appcontext(close_db). When I visit the site or initialize the database, I get the error: TypeError: close_db() takes 0 positional arguments but 1 was given. 

In testing, I set the arguments for close_db to *arg and it worked without issues, but when I print *arg it returns None. Why is it angry about getting too many arguments if nothing is being passed to close_db?
","As you decorated your close_db function with app.teardown_appcontext(), the close_db function will be appended to teardown_appcontext_funcs list.
Then when the application context tears down Flask will call do_teardown_appcontext() for you.
As we can see Flask source code: app.py
def do_teardown_appcontext(self, exc=_sentinel):
    if exc is _sentinel:
        exc = sys.exc_info()[1]
    for func in reversed(self.teardown_appcontext_funcs):
        func(exc)  &lt;-- here
    appcontext_tearing_down.send(self, exc=exc)

In the place I marked an arrow above, it passed the argument exc. That means to avoid the TypeError exception, your close_db need an corresponding argument.
",,,false,,,
https://stackoverflow.com/questions/53979084,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Unable to use --extra-index-url with pip after upgrading to 18.1,,,,,false,,,
https://stackoverflow.com/questions/33945725,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Python doesn&#39;t work: ImportError: No module named &#39;logging&#39;,,,,,false,,,
https://stackoverflow.com/questions/22679776,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Flask POST 400 Error on accessing request JSONObject,,,,,false,,,
https://stackoverflow.com/questions/69101244,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,How to retrieve and save to Blob a binary file video from Flask?,"I know few things about video encoding and I encountered an issue that is blocking me for few days.
Goal:

Record a video from my laptop's webcam with a VueJS front end application.
Send this video to a Python flask app in the backend within a FormData through Axios and Flask.
Receive the video in the Flask app.
Simply send back the video to the frontend with a Flask response (without applying any changes to the video).
Store and display this video on front end side.

Code:

By default, ev element type is: ""video/x-matroska;codecs=avc1"", I do not choose it.

// Start webcam stream
startCameraStream() {
    const windowConstraints = (window.constraints = {
        audio: false,
        video: true
    });
    navigator.mediaDevices
        .getUserMedia(windowConstraints)
        .then(stream =&gt; {
            this.$refs.webcamStream.srcObject = stream;
        }).catch(error =&gt; {
            alert(""Browse doesn't support or there is some errors."" + error);
        });
},

// Stop webcam stream
stopCameraStream() {
    let tracks = this.$refs.webcamStream.srcObject.getTracks();
    tracks.forEach(track =&gt; {
        track.stop();
    });
},

// Start to record webcam and save it into chunks array and create a blob object
startRecordCameraStream(stream) {
    this.mediaRecorder = new MediaRecorder(stream);

    this.mediaRecorder.ondataavailable = (ev) =&gt; {
        this.chunks.push(ev.data);
    };

    this.mediaRecorder.onstop = () =&gt; {
        this.blob = new Blob(this.chunks, {
            'type': ""video/x-matroska;codecs=avc1""
        });
        this.chunks = [];
    };
    this.mediaRecorder.start();
},

// Stop to record webcam 
stopRecordCameraStream() {
    this.mediaRecorder.stop();
},          

The blob file is readable and I am able to display it with these few coding lines:
let videoURL = window.URL.createObjectURL(this.blob);
let vidSave = this.$refs.webcamRecord;
vidSave.src = videoURL;


I send the blob within a formData with the key 'webcam' and send it on Flask url with axios

submitVideo(state, blob) {
    let formData = new FormData();
    formData.append('webcam', blob);
    return new Promise((resolve, reject) =&gt; {
        try {
            axios.post('http://127.0.0.1:5000/', formData, { 
                headers: {
                'Content-Type': 'multipart/form-data',
                }
            }).then((response) =&gt; {
                // TOO SEE IN STEP 5
                resolve();
            }).catch((error) =&gt; {
                console.log(error);
            })
        } catch (error) {
            reject(error)
        }
    });

}


On the flask app, the formData has been sent and received and we are able to save and read the video on the backend side showing that everything is working well.

from flask import Flask, request
from flask_cors import CORS
import flask

#Instance of Flask class
app = Flask(__name__)
cors = CORS(app, resources={r""/*"": {""origins"": ""*""}})

#Route function
@app.route('/', methods=[""POST"",""GET""])
def model():
    if request.method == ""POST"":
        video = request.files['webcam'].stream.read()
        return flask.Response(video, mimetype='video/x-matroska')

I simply return back the binary object from Python to the VueJS frontend:

video is a python bytes object which looks like this:

b'\x1aE\xdf\xa3\xa3B\x86\x81\x01B\xf7\x81\x ... '

We simply return this bytes object in a flask response:
return flask.Response(video, mimetype='video/x-matroska')


We received the flask response and store it in a blob file (response part from point 2)

}).then((response) =&gt; {
    let data = response.data;
    let video = new Blob([data],{'type': ""video/x-matroska;codecs=avc1;""})
    state.modelVideo = video;
    resolve();
})

Once, we try to display the blob as explain in point 1, nothing happens:
let videoURL = window.URL.createObjectURL(this.modelVideo);
let vidSave = this.$refs.webcamRecord;
vidSave.src = videoURL;

Something really strange is that the initial and new blob files do not have the same size and when we read binary from both blob object we have this:
Initial blob binary from frontend (with a FileReader and readAsBinaryString function) :
""\u001aEß££B†\u0001B÷\u0001Bò\u...""

Received blob binary from backend (with a FileReader and readAsBinaryString function):
""\u001aEß£ï¿½Bï¿½ï¿½\u0001Bï¿½ï¿½\...""

Opinion:
My thought is that when sending back video from backend side, there is an encryption misunderstanding between Python and Javascript. I tried to encode in base64 on backend side and decode on frontend side but nothing changes.
The raw data response I received from backend is:
{
    ""data"": ""\u001aEߣ�B��\u0001B��\u0001B��...""
    ""status"": 200,
    ""statusText"": ""OK"",
    ""headers"": {
        ""content-length"": ""15661"",
        ""content-type"": ""video/x-matroska""
    },
    ""config"": {
        ""url"": ""http://127.0.0.1:5000/"",
        ""method"": ""post"",
        ""data"": {},
        ""headers"": {
            ""Accept"": ""application/json, text/plain, */*""
        },
        ""transformRequest"": [
            null
        ],
        ""transformResponse"": [
            null
        ],
        ""timeout"": 0,
        ""xsrfCookieName"": ""XSRF-TOKEN"",
        ""xsrfHeaderName"": ""X-XSRF-TOKEN"",
        ""maxContentLength"": -1,
        ""maxBodyLength"": -1
    },
    ""request"": {}
}

","add responseType blob to request init option:
axios.post('http://127.0.0.1:5000/', formData, { 
  headers: {
    'Content-Type': 'multipart/form-data',
  },
  responseType: 'blob' // default is ""json""
})

",,,false,,,
https://stackoverflow.com/questions/22591174,false,"The issue does not meet the criteria for deeper analysis as it is a question about the behavior of logical operators and conditions in pandas, rather than an API-related problem.",,,,,,,,,,,,false,,,
https://stackoverflow.com/questions/61191757,false,"The issue does not meet the criteria for deeper analysis as it is a question about pip install failing for certain packages within a Docker container, which is not an API-specific problem.",,,,,,,Package not getting installed inside docker container using pip,"I am baffled by a strange issue that I am facing with docker-compose. Pip install is failing for certain packages within requirements.txt file.

docker version

Client:
 Version:           18.09.9
 API version:       1.39
 Go version:        go1.13.4
 Git commit:        1752eb3
 Built:             Sat Nov 16 01:05:26 2019
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          18.09.9
  API version:      1.39 (minimum version 1.12)
  Go version:       go1.13.4
  Git commit:       9552f2b
  Built:            Sat Nov 16 01:07:48 2019
  OS/Arch:          linux/amd64
  Experimental:     false


My docker-compose.yml file is:

version: ""3.7""

services:

  flask:
    build: ./flask
    container_name: flask
    restart: always
    environment:
      - APP_NAME=MyFlaskApp
    expose:
      - 8080

  nginx:
    build: ./nginx
    container_name: nginx
    restart: always
    ports:
      - ""80:80""


The contents of Dockerfile inside ./flask directory is:

# Use the Python3.7.5 image
FROM python:3.7.5

# Set the working directory to /app
WORKDIR /app

# Copy the current directory contents into the container at /app
ADD . /app

# Install the dependencies
RUN pip3 install -r requirements.txt

# run the command to start uWSGI
CMD [""uwsgi"", ""app.ini""]


My requirements.txt file is (first few lines):

appdirs==1.4.3
apturl==0.5.2
asn1crypto==0.24.0
bcrypt==3.1.6
blinker==1.4


However, when I run docker-compose up command, it fails to install the second package in requirements.txt file.

Building flask
Step 1/6 : FROM python:3.7.5
 ---&gt; fbf9f709ca9f
Step 2/6 : WORKDIR /app
 ---&gt; Using cache
 ---&gt; 39ab3ee34991
Step 3/6 : ADD . /app
 ---&gt; Using cache
 ---&gt; 8968809ff844
Step 4/6 : RUN python3 -m pip install --upgrade pip
 ---&gt; Using cache
 ---&gt; 15f717de5181
Step 5/6 : RUN pip3 install -r requirements.txt
 ---&gt; Running in 7068f09498dc
Collecting appdirs==1.4.3
  Downloading appdirs-1.4.3-py2.py3-none-any.whl (12 kB)
ERROR: Could not find a version that satisfies the requirement apturl==0.5.2 (from -r requirements.txt (line 2)) (from versions: none)
ERROR: No matching distribution found for apturl==0.5.2 (from -r requirements.txt (line 2))
ERROR: Service 'flask' failed to build: The command '/bin/sh -c pip3 install -r requirements.txt' returned a non-zero code: 1


I have tried a lot of possible options, but of no use. Some examples being:


Running pip upgrade inside the container.
Updating the DNS in docker as per the thread here.

","If using a base container isn't an issue, try the Ubuntu environment and install python.
apturl is provided by ubuntu, specifically as it uses apt
# Use the ubuntu
FROM ubuntu:lts


# Set the working directory to /app
WORKDIR /app

# install python and pip, and delete cache
RUN apt update &amp;&amp; apt install -y python3 python3-pip &amp;&amp; rm -rf /var/lib/apt/lists/*

# Copy the current directory contents into the container at /app
ADD . /app

# Install the dependencies
RUN pip3 install -r requirements.txt

# run the command to start uWSGI
CMD [""uwsgi"", ""app.ini""]

",,,false,,,
https://stackoverflow.com/questions/18401287,false,The issue does not have enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. Further analysis is required.,,,,,,,Sphinx - file not found - sys.path issue,,,,,false,,,
https://stackoverflow.com/questions/15995524,false,The issue does not have enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. Further analysis is required.,,,,,,,Flask templates including incorrect files,,,,,false,,,
https://stackoverflow.com/questions/77155289,false,"The issue does not meet the criteria for deeper analysis as it is a question about Keycloak HTTPS redirect on localhost, which is not an API-specific problem.",,,,,,,Flask-OIDC Keycloak HTTPS Redirect on Localhost,"This is the development setup I have. All host references are localhost.
I am using Flask-OIDC 2.0.3 along with Keycloak 22.0.3 (running on Docker as a service). The Flask app runs on port 8080, Keycloak on 9080 and I have a React UI running on port 9001.
All these services are running on http and not https
My Keycloak docker-compose file is as follows
version: '3.8'
name: keycloak
services:
  keycloak:
    image: quay.io/keycloak/keycloak:22.0.3
    command: ['start-dev --import-realm']
    volumes:
      - ./realm-config:/opt/keycloak/data/import
    environment:
      - KC_DB=dev-file
      - KEYCLOAK_ADMIN=admin
      - KEYCLOAK_ADMIN_PASSWORD=admin
      - KC_FEATURES=scripts
      - KC_HTTP_PORT=9080
      - KC_HEALTH_ENABLED=true
      - KC_HTTPS_REQUIRED=false
    # If you want to expose these ports outside your dev PC,
    # remove the ""127.0.0.1:"" prefix
    ports:
      - 127.0.0.1:9080:9080
      - 127.0.0.1:9443:9443

My client_secrets.json is as follows
{
  ""web"": {
    ""client_id"": ""&lt;client&gt;"",
    ""client_secret"": ""&lt;secret&gt;"",
    ""auth_uri"": ""http://127.0.0.1:9080/realms/jhipster/protocol/openid-connect/auth"",
    ""token_uri"": ""http://127.0.0.1:9080/realms/jhipster/protocol/openid-connect/token"",
    ""issuer"": ""http://127.0.0.1:9080/realms/jhipster"",
    ""userinfo_uri"": ""http://127.0.0.1:9080/realms/jhipster/protocol/openid-connect/userinfo"",
    ""token_introspection_uri"": ""http://127.0.0.1:9080/realms/jhipster/protocol/openid-connect/token/introspect""
  }
}

I configure my Flask app as follows
OIDC_CLIENT_SECRETS = ""src/main/python/config/client_secrets.json""
OIDC_REDIRECT_URI = ""http://127.0.0.1:8080/oidc_callback""

My Keycloak client configuration is as follows

When I click on the sign-in URL of my UI, it takes me to the Keycloak sign-in page of the new realm I created. But I see that the redirect_uri has been changed to https.

If I proceed with the login, I get an error Secure Connection Failed
I have tried the following

Removed https from the redirect_uri list in Keycloak for the client

Then I get an error on the Keycloak sign-in page saying ""Invalid redirect_uri""


Removed https from the URL in the browser address bar manually and signed-in

Then I get an error ""invalid_grant: Incorrect redirect_uri""



Actual question:
Part 1: Since this entire setup is running entirely on my local machine, I an not sure where the https redirect is being picked up and how to prevent it? This looks like a Keycloak issue (just a guess) of redirection preference to https but it seems strange since the traffic originates from http.
Part 2: Do I need to explicitly implement /oidc_callback. I assume Flask-OIDC will take care of handling this.
","Sudeep Hasra's answer is right.
A workaround would be to use flask's ssl_context option. This way all your app would run over ssl. Two of the most simple options are:

Use ssl_context=""adhoc""
Use ssl_context=(""/path/to/cert.pem"", ""/path/tokey.pem"")

Example:
if __name__ == ""__main__"":
    app.run('0.0.0.0', debug=True, ssl_context=(""/path/to/cert.pem"", ""/path/tokey.pem""))

If you go by the second option, you must create the certificate pair. In linux you could do as follows:
openssl req -x509 -newkey rsa:4096 -nodes -out cert.pem -keyout key.pem -days 365
Hope it helps you.
","This article is mentioned in the github issue Conversion of HTTP URLs to HTTPS in request_uris.  A config setting OIDC_OVERWRITE_REDIRECT_URI was added as a part of the fix for the issue.
You can see the relevant code in /flask_oidc/views.py.
My reading of the code is: if you have OIDC_CALLBACK_ROUTE it will get converted to https. You can override by setting OIDC_OVERWRITE_REDIRECT_URI.
This worked for me:
APP.config.update({
    ...
    'OIDC_CALLBACK_ROUTE': '/authorization-code/callback',
    'OIDC_OVERWRITE_REDIRECT_URI': 'http://localhost:5000/authorization-code/callback'
})

","The problem seems to be with Flask-OIDC. The library has a commit that forces redirect URLs to be over HTTPS.
If I change the _scheme to http in line 55, the entire flow works as expected.

",false,,,
https://stackoverflow.com/questions/60328549,false,"The issue does not meet the criteria for deeper analysis as it is a question about making a call to a Flask Restful API with invoke-restmethod and JWT auth, which does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.",,,,,,,Making a call to a Flask Restful API with invoke-restmethod and JWT auth,"I have this API that I made with Flask (Python) and I am unable to get powershell to successfully make an API request to it. The problem is not the API because I tested it with postman and everything works as it should. More precisely it's when I add JWT token auth that it's not working with powershell, in my api the Create, Update and delete functions are protected with JWT token auth and the basic Read function have no auth at all. Below is the powershell code i am using:

Here is the function that generate my token (that part is working, note that I removed username and password from the function for security purposes):

function get-token {
param (
    [Parameter(Position=0, Mandatory=$false)]
    [string]$user,
    [Parameter(Position=1, Mandatory=$false)]
    [string]$password
)
$body = @{
    username=""$user""
    password=""$password""
}
$jsonbody = $body | ConvertTo-Json
$uri = ""https://codegenius.live/api/auth""
$headers = New-Object ""System.Collections.Generic.Dictionary[[String],[String]]""
$headers.Add(""Accept"",""application/json"")
$headers.Add(""Content-Type"",""application/json"")
$response = Invoke-RestMethod -Uri $uri -Method Post -Body $jsonbody -Headers $headers
$response.access_token
}


This function will generate a token like this:

eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJleHAiOjE1ODIyMzA2OTUsImlhdCI6MTU4MjIzMDM5NSwibmJmIjoxNTgyMjMwMzk1LCJpZGVudGl0eSI6MX0.8wZZJEGxV7P4ZzN23eZ3d5-MGJ00N5zKHuCZXn9XRuw


Here is the call i am trying to make that doesn't work:

$body = @{
tpl_name=""my template name""
tpl_subject=""my template subject""
tpl_plaintext_content=""bla bla bla""
tpl_html_content=""bla bla bla""
} 

$authheader = ""JWT "" + (get-token)
$headers = New-Object ""System.Collections.Generic.Dictionary[[String],[String]]""
$headers.Add(""Accept"",""application/json"")
$headers.Add(""Content-Type"",""application/json"")
$headers.Add(""Authorization"",$authheader)
$jsonbody = $body | ConvertTo-Json
$uri = ""https://codegenius.live/api/add-email""
$response = Invoke-RestMethod -Uri $uri -Method Post -Body $jsonbody -Headers $headers


The request response message is this one:

Invoke-RestMethod :
500 Internal Server Error
Internal Server Error
The server encountered an internal error and was unable to complete your request. Either the server         
is overloaded or
there is an error in the application.
Au caractère Ligne:25 : 17
+ ... $response = Invoke-RestMethod -Uri $uri -Method Post -Body $jsonbody  ...
+                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ CategoryInfo          : InvalidOperation : (System.Net.HttpWebRequest:HttpWebRequest) [Invoke-    
RestMethod], WebEx
ception
+ FullyQualifiedErrorId : 
WebCmdletWebResponseException,Microsoft.PowerShell.Commands.InvokeRestMethodCommand


This is very strange because as I said it is working with Postman (see below images), I have tried googling the issue but I found no clue on how to actually solve this.
EDIT: the images show that in postman i used http instead of https, this is not the issue. In powershell http or https nothing works!






",,,,false,,,
https://stackoverflow.com/questions/58823429,false,The issue does not meet the criteria for deeper analysis as it does not indicate any specific runtime conditions or unexpected behavior related to an API.,,,,,,,clients = self.AVAILABLE_CLIENTS[name] KeyError: &#39;requests&#39; flask authlib client,,,,,false,,,
https://stackoverflow.com/questions/58051775,false,"The issue does not meet the criteria for deeper analysis as it appears to be a question about routes not responding in a Python Flask application, without any specific indication of API-related problems.",,,,,,,Python Flask on Google App Engine - Routes Not Responding,,,,,false,,,
https://stackoverflow.com/questions/51039756,false,The issue does not meet the criteria for deeper analysis as it is related to an import error and does not involve unexpected failures or behaviors of an API.,,,,,,,How is this kind of import considered circular (or why am I getting &quot;ImportError: cannot import name EmailMessage&quot; error),,,,,false,,,
https://stackoverflow.com/questions/38197930,true,"The issue involves Flask validation failing due to the presence of a CSRF token, which suggests an API-related problem. Further analysis is required.",,,,,,,Flask validation failing due to presence of CSRF token,"am using flask in my python application. I am having a strange issue from the past 2 days and I didn't do any change in my code. My login is redirecting me back to my login page itself as the function form.validate_on_submit() is returning false. When I debugged I found that the below function is giving success as false. This function is present in wtforms/form.py

def validate(self, extra_validators=None):
    """"""
    Validates the form by calling `validate` on each field.

    :param extra_validators:
        If provided, is a dict mapping field names to a sequence of
        callables which will be passed as extra validators to the field's
        `validate` method.

    Returns `True` if no errors occur.
    """"""
    self._errors = None
    success = True
    for name, field in iteritems(self._fields):
        if extra_validators is not None and name in extra_validators:
            extra = extra_validators[name]
        else:
            extra = tuple()
        if not field.validate(self, extra):
            success = False
    return success


This is what my forms.py class looks like

from wtforms import StringField, BooleanField, PasswordField, validators, ValidationError, HiddenField
from flask_wtf import Form

class RedirectForm(Form):
    ref = HiddenField()

    def __init__(self, *args, **kwargs):
        Form.__init__(self, *args, **kwargs)
        if not self.ref.data:
            self.ref.data = get_redirect_target() or ''

    def redirect(self, endpoint='index', **values):
        if is_safe_url(self.ref.data):
            return redirect(self.ref.data)
        target = get_redirect_target()
        return redirect(target or url_for(endpoint, **values))

class LoginForm(RedirectForm):
    email = StringField('Email', [
        validators.DataRequired(),
        validators.Email('Invalid Email Address')
    ])

    password = PasswordField('Password', [
        validators.DataRequired()
    ])

    def validate(self):
        if not Form.validate(self):
            return False

        user = User.query.filter_by(email=self.email.data.lower()).first()
        if user and user.check_password(self.password.data):
            self.user = user
            return True
        else:
            self.email.errors.append(""Invalid e-mail or password"")

        return False

    def get_user(self):
        return self.user


Am using Flask-WTF version 0.10.3 and WTForms version 2.0.1. If I comment out the Form.validate(self) function in forms.py class, it works but I will be risking my site security. What should be the problem here ? No clue.
","I was having the exact same issue till I found out I needed to render the csrf token in the template containing the form (rendered as a hidden field) so that the client could send it back to the server along with the form data to validate it
&lt;form action=""/user"" method=""POST""&gt;
{{ form.csrf_token }}
{% if form.csrf_token.errors %}
    &lt;div class=""warning""&gt;You have submitted an invalid CSRF token&lt;/div&gt;
{% endif %}
&lt;div&gt;{{ form.name }} {{ form.name.label }}&lt;/div&gt;
&lt;div&gt;{{ form.age }}{{ form.age.label }}&lt;/div&gt;

",,,false,,,
https://stackoverflow.com/questions/31650236,false,The issue does not meet the criteria for deeper analysis as it does not involve unexpected failures or behaviors of an API.,,,,,,,Flask decorators not working together nicely,,,,,false,,,
https://stackoverflow.com/questions/31486207,false,The issue does not meet the criteria for deeper analysis as it does not involve unexpected failures or behaviors of an API.,,,,,,,"POST request results in &quot;internal server error&quot;, most of the times but not all (!?)",,,,,false,,,
https://stackoverflow.com/questions/30851873,false,"The issue does not meet the criteria for deeper analysis as it is related to AngularJS and Flask-WTF, without any specific indication of API-related problems.",,,,,,,Angularjs + Flask-wtf: Bad request 400,,,,,false,,,
https://stackoverflow.com/questions/24131713,false,The issue does not meet the criteria for deeper analysis as it is related to packaged Python apps and does not involve unexpected failures or behaviors of an API.,,,,,,,json.load / simplejson.load fails in packaged Python app (PyInstaller or cx_freeze),,,,,false,,,
https://stackoverflow.com/questions/22234607,false,The issue does not meet the criteria for deeper analysis as it is related to importing installed packages in Python and does not involve unexpected failures or behaviors of an API.,,,,,,,Unable to import installed packages in python after updating OSX and python,,,,,false,,,
https://stackoverflow.com/questions/21561123,false,The issue does not meet the criteria for deeper analysis as it is related to setting up virtualenv for different Python versions and does not involve unexpected failures or behaviors of an API.,,,,,,,How do you setup virtualenv on linux for both python 2.7 and python 3.2?,,,,,false,,,
https://stackoverflow.com/questions/75088652,false,The issue does not meet the criteria for deeper analysis as it is related to exceeding soft memory limits and does not involve unexpected failures or behaviors of an API.,,,,,,,Reasons for &quot;Exceeded soft memory limit of 256 MiB...&quot;,"Before I get dinged for a dup, I've actually gone through many of the other posts on soft memory limit, and they never really explain what the common causes are. My question here is about what could be causing this, and whether it's just a function or if it could by my yaml settings or being slammed by bots.
Here are my logs histogram:

As you can see I'm getting an error of this type about once an hour, and some intermittent warnings, but it's not the lions share of the service. I recently learned that this has been happening since early December, and increasingly so. I figured it was just an issue of inefficient code (Python/Flask), refactored my index page, but it's still happening and not significantly diminishing even after a serious refactor:

Exceeded soft memory limit of 256 MiB with 280 MiB after servicing 956 requests total. Consider setting a larger instance class in app.yaml.



293 MiB after servicing 1317 requests



260 MiB after servicing 35 requests

The strange thing is that it's happening on pages like

/apple-touch-icon.png

that should just 404.
Here are some other things that may be causing the problem. First my app.yaml page has settings that I added before my site was as popular that are extremely lean to say the least:
# instance_class: F1 (default)

automatic_scaling:
    max_instances: 3
    min_pending_latency: 5s
    max_pending_latency: 8s
    #max_concurent_requests: 20
    target_cpu_utilization: 0.75
    target_throughput_utilization: 0.9

The small instances, min and max latency, and cpu utilization are all obviously set for slower service, but I'm not made of money, and the site isn't generating revenue.
Secondly, looking at the logs recently, I'm getting absolutely slammed by webcrawlers. I've added them to robots.txt:
User-Agent: MJ12bot
Crawl-Delay: 20
User-Agent: AhrefsBot
Crawl-Delay: 20
User-Agent: SemrushBot
Crawl-Delay: 20

It looks like all but Semrush have died down a bit.
Anyway, thoughts? Do I just need to upgrade to F2, or is there something in the settings that I've definitely got wrong.
Again, I've very seriously refactored the main pages that trigger the alert, but it seems not to have helped. The real issue is that I'm just a coder without a networking background, so I honestly don't even know what's happening.
","In my experience, only really simple apps will fit in an F1 without periodic memory errors.  I don't know if the cause is Python or GAE, but memory cleanup does not work well on Python/GAE.
Though GAE automatically restarts instances when there is a memory error so you can probably ignore it unless occasional slow responses to end users is a deal breaker for you.
I would just upgrade to F2 unless you are really on a budget.
",,,false,,,
https://stackoverflow.com/questions/71942115,false,The issue does not meet the criteria for deeper analysis as it is related to Access-Control-Allow-Origin headers and does not involve unexpected failures or behaviors of an API.,,,,,,,"Access-Control-Allow-Origin is added to the header when request is made from Python(Google Colab), but not when the request is made from ReactJS","My app is structured as follows: React frontend -&gt; Azure Api Management -&gt; Flask backend.
The Flask app allows all origins.
app = Flask(__name__)
CORS(app, resources={r""/*"": {""origins"": ""*""}})

The Azure Api Management inbound and outbound policy looks like this:
&lt;policies&gt;
    &lt;inbound&gt;
        &lt;base /&gt;
        &lt;set-backend-service id=""apim-generated-policy"" backend-id=""webapp_test"" /&gt;
        &lt;cors allow-credentials=""true""&gt;
            &lt;allowed-origins&gt;
                &lt;origin&gt;https://va-prod-dashboard.azurewebsites.net&lt;/origin&gt;
                &lt;origin&gt;http://localhost:9000&lt;/origin&gt;
                &lt;origin&gt;http://localhost:3000&lt;/origin&gt;
            &lt;/allowed-origins&gt;
            &lt;allowed-methods&gt;
                &lt;method&gt;GET&lt;/method&gt;
                &lt;method&gt;POST&lt;/method&gt;
            &lt;/allowed-methods&gt;
        &lt;/cors&gt;
    &lt;/inbound&gt;
    &lt;backend&gt;
        &lt;base /&gt;
    &lt;/backend&gt;
    &lt;outbound&gt;
        &lt;base /&gt;
    &lt;/outbound&gt;
    &lt;on-error&gt;
        &lt;base /&gt;
    &lt;/on-error&gt;
&lt;/policies&gt;

The issue started when I tried to make a POST request from the React frontend. When making the request from python(google colab), I printed the response header and it had Access-Control-Allow-Origin: *(all).
The React post request fails with: No 'Access-Control-Allow-Origin' header is present on the requested resource.
What is strange to me is that only post requests fail, only in javascript.
Does anybody have any idea what might be the culprit?
Thank you for taking the time to read this!
","Thanks to Daniel W, for your valuable suggestion. Posting as an answer to help other community members.

You need to add &lt;cors&gt; directive also to &lt;outbound&gt;.


CORS are sent by the server, not by the client, pretty sure it's to do with the MS Proxy.


Please refer this Microsoft-Doc-CORS-APIM for more information.

",,,false,,,
https://stackoverflow.com/questions/70454349,false,The issue does not meet the criteria for deeper analysis as it is related to a Flask application not exposing to the external world in Docker and does not involve unexpected failures or behaviors of an API.,,,,,,,Flask application is not exposing to external world in docker,"I'm hosting a flask application in docker container through AWS EC2, which will display the contents of the file that is uploaded to it.
I'm facing an strange issue is that my application is not exposing to the external world, but it works on localhost. When I try to hit on my public ip of the machine, it is showing ""refused to connect"" (Note: Security groups are fine)
docker ps command showing my container is running fine on the expected port number. Can you please let me know how can i resolve it to make it work? Thanks in advance
Docker version 20.10.7, build f0df350
Here is my Dockerfile,
  FROM ubuntu:latest
  RUN mkdir /testing
  WORKDIR /testing
  ADD . /testing
  RUN apt-get update&amp;&amp;apt-get install -y pip
  RUN pip install -r requirements.txt
  CMD flask run

In my requirements.txt file, I'm having flask to be installed in docker.
Here is my flask code and html file,
    from flask import Flask,render_template,request
    app = Flask(__name__)
    @app.route(""/"")
    def file():
        return render_template(""index.html"")
    @app.route(""/upload"", methods= ['POST','GET'])
    def test():
             print(""test"")
             if request.method == 'POST':
                   print(""test3"")
                   file = request.files['File'].read()
                   return file

   if __name__ == ""__main__"":
             app.run(debug=True,host='0.0.0.0')

index.html:
    &lt;html&gt;
       &lt;body&gt;
         &lt;form action = ""http://&lt;publiciIPofmachine&gt;:5000/upload"" method = ""POST"" enctype = 
        ""multipart/form-data""&gt;
        &lt;input type = ""file"" name = ""File"" /&gt;
        &lt;input type = ""submit"" value = ""Submit"" /&gt;
    &lt;/form&gt;
  &lt;/body&gt;
&lt;/html&gt;

docker logs:
Serving Flask app 'app' (lazy loading)

Environment: production
WARNING: This is a development server. Do not use it in a production deployment.
Use a production WSGI server instead.
Debug mode: on
Running on all addresses.
WARNING: This is a development server. Do not use it in a production deployment.
Running on http://172.17.0.2:5000/ (Press CTRL+C to quit)

Here are my docker commands that is used,
    docker build -t &lt;name&gt; .
    docker run -d -t -p 5000:80 &lt;imagename&gt;

","You have a typo in the docker run command:
Background
That is what docs say:
-p=[]      : Publish a container's port or a range of ports to the host
               format: ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort | containerPort
               Both hostPort and containerPort can be specified as a
               range of ports. When specifying ranges for both, the
               number of container ports in the range must match the
               number of host ports in the range, for example:
                   -p 1234-1236:1234-1236/tcp

So you are publishing port in format: hostPort:containerPort
Solution
Instead of your code:
    docker run -d -t -p 5000:80 &lt;imagename&gt;

You should do
     docker run -d -t -p 80:5000 &lt;imagename&gt;

But it's good practice to define the EXPOSE layer in your container :)
The EXPOSE has two roles:

Its kind of documentation, whoever is reading your Dockerfile, they know what port should be exposed.
You can use the --publish-all | -P flag to publish all exposed ports.

",,,false,,,
https://stackoverflow.com/questions/69784117,false,The issue does not meet the criteria for deeper analysis as it is related to accessing a Flask web application by a domain name and does not involve unexpected failures or behaviors of an API.,,,,,,,Flask web: can not open the site by domain name,"I have deployed my flask Web in AWS ubuntu ec2 using Nginx, supervisor, and gunicorn.
Some strange points:
(1) Sometimes I can access my site by the domain name in the safari browser, but after some time, I can not access it by the domain name. The accessed site images by the domain name (test.com)will be the following one:
      test.com
parked free, courtesy of GoDaddy.com.

(2) I can access it by IP address using the all browsers.
(3) sometimes I tried another browsers, it can be accessed by the domain. but after I while, the same issue as (1).
My setting files as follows:
sudo vim /etc/nginx/sites-available/default
server {
    listen 80 default_server;
    listen [::]:80 default_server;

    # SSL configuration
    #
    # listen 443 ssl default_server;
    # listen [::]:443 ssl default_server;
    #
    # Note: You should disable gzip for SSL traffic.
    # See: https://bugs.debian.org/773332
    #
    # Read up on ssl_ciphers to ensure a secure configuration.
    # See: https://bugs.debian.org/765782
    #
    # Self signed certs generated by the ssl-cert package
    # Don't use them in a production server!
    #
    # include snippets/snakeoil.conf;

    # root /var/www/html;

    # Add index.php to the list if you are using PHP
    # index index.html index.htm index.nginx-debian.html;

    server_name test.com; # 
    access_log /var/log/nginx/access.log; 
    error_log /var/log/nginx/error.log;

    location / {
        # First attempt to serve request as file, then
        # as directory, then fall back to displaying a 404.
        # try_files $uri $uri/ =404;
        proxy_pass http://127.0.0.1:8000; 
        proxy_redirect off;
        
        proxy_set_header Host           $host;
        proxy_set_header X-Real_IP      $remote_addr;
        proxy_set_header X-Forwarded-For    $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto  $scheme;        
    }
    

    location /static { # 
        alias /home/ubuntu/blog/app/static/;
        expires 30d; # 
        
    }
    
}

sudo vim /etc/supervisor/conf.d/blog.conf
[program:flask-blog-owner]
command=/home/ubuntu/blog/bash.sh
directory=/home/ubuntu/blog
user=root
autostart=true
autorestart=true
stopasgroup=true
killasgroup=true

bash.sh
#! /bin/bash
cd /home/ubuntu/blog
exec gunicorn -w 4 wsgi:app

DNS information in Godaddy
Records
Last updated 29/10/21 4:35 PM
Type    Name    Value   TTL Actions
A   @   xx.xx.x.x   1/2 Hour    Edit
A   @   Parked  600 seconds Edit
CNAME   www @   1 Hour  Edit
CNAME   _domainconnect  _domainconnect.gd.domaincontrol.com 1 Hour  Edit
NS  @   ns23.domaincontrol.com  1 Hour  
NS  @   ns24.domaincontrol.com  1 Hour  
SOA @   Primary nameserver: ns23.domaincontrol.com. 1 Hour

  

","I have solved it ! Just deleted Parked value DNS setting in the domain name setting of your godaddy account. This may cause the above issue.
",,,false,,,
https://stackoverflow.com/questions/69064265,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,page.js with svelte `The requested URL was not found` when entering URL manually or refreshing despite passing --single flag in package.json,"I'm new to the whole Javascript &amp; svelte ecosystem and am trying to build an app with svelte.js and using flask to serve it. The issue is I get The requested URL was not found when i enter the path manually or refresh the page. This happens despite passing the --single flag in package.json. The strange thing is, I face the issue only when the route has associated params eg. /article/:id . However if I enter the path /article manually or refresh it, there is no issue.
Here's a snippet of package.json
{
  ""name"": ""svelte-app"",
  ""version"": ""1.0.0"",
  ""scripts"": {
    ""build"": ""rollup -c"",
    ""dev"": ""rollup -c -w"",
    ""start"": ""sirv public --single"",
    ""start:dev"": ""sirv public --dev --single""
  },
  ""devDependencies"": {
    ""rollup"": ""^2.3.4"",
    ""rollup-plugin-livereload"": ""^2.0.0"",
  },
  ""dependencies"": {
    ""gridjs"": ""^5.0.2"",
  }
}

Here's a snippet of my App.svelte file
&lt;script&gt;
  import {onMount} from 'svelte';
  import page from 'page';
  import Home from './pages/Home.svelte';
  import ArticleOverview from './pages/ArticleOverview.svelte';
  import SingleArticle from './pages/SingleArticle.svelte';

  let current;
  let params;

  onMount(async () =&gt; {
        const res = await fetch(`/some_api`);
        const outcome = await res.json().then((outputDetails) =&gt; {
        console.log(outputDetails);
      });
    });

  page('/', () =&gt; (current = Home));
  page('/article', () =&gt; (current = ArticleOverview));
  page('/article/:id', 
    (ctx, next) =&gt; {
      params = ctx.params
      next()
    },
    () =&gt; (current = SingleArticle));
    page('/*', () =&gt; (current = NotFound));

    page.start();
&lt;/script&gt;

&lt;svelte:component this=""{current}"" params=""{params}""/&gt;

","The issue was with flask routes. I added an extra route and it worked.
Previous routes:
@authoring.route('/', defaults={'path': ''})
    @authoring.route('/&lt;path:path&gt;')
    @authoring.route('/&lt;string:path&gt;')
    @authoring.route('/&lt;path:path&gt;')
    @authenticated_view
    def catch_all(path):
        return authoring.send_static_file(""index.html"")

Added routes starting with /article/&lt;path:path&gt;
@authoring.route('/', defaults={'path': ''})
    @authoring.route('/&lt;path:path&gt;')
    @authoring.route('/&lt;string:path&gt;')
    @authoring.route('/&lt;path:path&gt;')
    @authoring.route('/workspace/&lt;path:path&gt;')
    @authenticated_view
    def catch_all(path):
        return authoring.send_static_file(""index.html"")

Somehow the images aren't loaded but should not be a big issue.
",,,false,,,
https://stackoverflow.com/questions/65624935,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,TikTokApi throws an error in Flask but works outside of it,"I have a strange problem when using flask + TikTok API that I can't figure out.
I have the following code:
from flask import Flask
from flask_restful import Resource, Api
from TikTokApi import TikTokApi
 
tikTokApi = TikTokApi()
app = Flask(__name__)
api = Api(app)

@app.errorhandler(404)
def page_not_found(e):
    return {'status': 'fail'}, 404
 
class TikTokProfile(Resource):
    def get(self):
        profileResponse = tikTokApi.getUserObject('rosiethepygmygoat')
        return {'user' : profileResponse}
 
class TikTokMedia(Resource):
    def get(self):
        data = tikTokApi.getUserObject('rosiethepygmygoat')

        response = tikTokApi.userPage(data[""id""],data[""secUid""])
   
        return response
 
api.add_resource(TikTokProfile, '/profile')
api.add_resource(TikTokMedia, '/media')
 
if __name__ == '__main__':
    app.run(debug=True)

When I visit /profile I get the user object, but when I try to get his user page via the /media route I get the following error:
INFO:werkzeug:127.0.0.1 - - [08/Jan/2021 09:20:45] ""GET /media HTTP/1.1"" 500 -
Traceback (most recent call last):
  File ""C:\Users\user\AppData\Local\Programs\Python\Python38-32\Lib\site-packages\flask\app.py"", line 2464, in __call__
    return self.wsgi_app(environ, start_response)
  File ""C:\Users\user\AppData\Local\Programs\Python\Python38-32\Lib\site-packages\flask\app.py"", line 2450, in wsgi_app
    response = self.handle_exception(e)
  File ""C:\Users\user\AppData\Local\Programs\Python\Python38-32\Lib\site-packages\flask_restful\__init__.py"", line 272, in error_router
    return original_handler(e)
  File ""C:\Users\user\AppData\Local\Programs\Python\Python38-32\Lib\site-packages\flask\app.py"", line 1867, in handle_exception
    reraise(exc_type, exc_value, tb)
  File ""C:\Users\user\AppData\Local\Programs\Python\Python38-32\Lib\site-packages\flask\_compat.py"", line 38, in reraise
    raise value.with_traceback(tb)
  File ""C:\Users\user\AppData\Local\Programs\Python\Python38-32\Lib\site-packages\flask\app.py"", line 2447, in wsgi_app
    response = self.full_dispatch_request()
  File ""C:\Users\user\AppData\Local\Programs\Python\Python38-32\Lib\site-packages\flask\app.py"", line 1952, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File ""C:\Users\user\AppData\Local\Programs\Python\Python38-32\Lib\site-packages\flask_restful\__init__.py"", line 272, in error_router
    return original_handler(e)
  File ""C:\Users\user\AppData\Local\Programs\Python\Python38-32\Lib\site-packages\flask\app.py"", line 1821, in handle_user_exception
    reraise(exc_type, exc_value, tb)
  File ""C:\Users\user\AppData\Local\Programs\Python\Python38-32\Lib\site-packages\flask\_compat.py"", line 38, in reraise
    raise value.with_traceback(tb)
  File ""C:\Users\user\AppData\Local\Programs\Python\Python38-32\Lib\site-packages\flask\app.py"", line 1950, in full_dispatch_request
    rv = self.dispatch_request()
  File ""C:\Users\user\AppData\Local\Programs\Python\Python38-32\Lib\site-packages\flask\app.py"", line 1936, in dispatch_request
    return self.view_functions[rule.endpoint](**req.view_args)
  File ""C:\Users\user\AppData\Local\Programs\Python\Python38-32\Lib\site-packages\flask_restful\__init__.py"", line 468, in wrapper
    resp = resource(*args, **kwargs)
  File ""C:\Users\user\AppData\Local\Programs\Python\Python38-32\Lib\site-packages\flask\views.py"", line 89, in view
    return self.dispatch_request(*args, **kwargs)
  File ""C:\Users\user\AppData\Local\Programs\Python\Python38-32\Lib\site-packages\flask_restful\__init__.py"", line 583, in dispatch_request
    resp = meth(*args, **kwargs)
  File ""D:\server\norway_group\tokmatic-sass\python\start.py"", line 22, in get
    response = tikTokApi.userPage(data[""id""],data[""secUid""])
  File ""C:\Users\user\AppData\Local\Programs\Python\Python38-32\Lib\site-packages\TikTokApi\tiktok.py"", line 562, in userPage
    return self.getData(url=api_url, **kwargs)
  File ""C:\Users\user\AppData\Local\Programs\Python\Python38-32\Lib\site-packages\TikTokApi\tiktok.py"", line 159, in getData
    verify_fp, did, signature = self.browser.sign_url(**kwargs)
  File ""C:\Users\user\AppData\Local\Programs\Python\Python38-32\Lib\site-packages\TikTokApi\browser.py"", line 164, in sign_url
    page = self.create_page()
  File ""C:\Users\user\AppData\Local\Programs\Python\Python38-32\Lib\site-packages\TikTokApi\browser.py"", line 116, in create_page
    context = self.browser.newContext(**iphone)
  File ""C:\Users\user\AppData\Local\Programs\Python\Python38-32\Lib\site-packages\playwright\sync_api.py"", line 6710, in newContext
    self._sync(
  File ""C:\Users\user\AppData\Local\Programs\Python\Python38-32\Lib\site-packages\playwright\_sync_base.py"", line 95, in _sync
    self._dispatcher_fiber.switch()
greenlet.error: cannot switch to a different thread

I thought that there is an issue with the TikTokApi package but when I try the same code outside the flask resource:
data = tikTokApi.getUserObject('rosiethepygmygoat')
response = tikTokApi.userPage(data[""id""],data[""secUid""])
print(response)

I get the object I need.
So am I missing a specific configuration for flask or something else? Any insights will be much appreciated.
","Run your flask application using this comands:
flask run --without-threads

",,,false,,,
https://stackoverflow.com/questions/63622914,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Flask send_file and send_from_directory cause session cookie to be too large,"Hi this is a bit of a strange issue. It doesn't occur on my local server when running with flask run but when using gunicorn and nginx the flask send_file() method or send_from_directory() which I use to allow users to download a .pdf file I crash with this error:
/home/ben/newvenv/lib/python3.7/site-packages/werkzeug/wrappers/base_response.py:479: UserWarning: The ""b'session'"" cookie is too large: the value was 10004 bytes but the header required 26 extra bytes. The final size was 10030 bytes but the limit is 4093 bytes. Browsers may silently ignore cookies larger than this.
  samesite=samesite,

Here is the code where I call this method:
return send_from_directory(directory= directory,filename=filename, as_attachment=True)

I tried updating my nginx config to allow for larger cookies but this didn't work and also is not an ideal solution. What am I missing? Is this an issue with nginx or with the way I call the flask method? The .pdf file is not too big only ten pages long.
","I fixed this by clearing the session before sending the file. Here is the code I used to clear the session variables:
def clear_session_variables(exclude=[]):
    """"""deletes all session variables. Useful to reset before starting new task.""""""
    print(list(session.keys()))
    for key in list(session.keys()):
        if(key != '_flashes' and key != 'csrf_token' and key not in exclude):
            print(key)
            session.pop(key)
    print(list(session.keys()))

Here is where I call the method:
clear_session_variables(exclude=['db','historical'])
return send_from_directory(directory= directory,filename=filename, as_attachment=True, mimetype='application/pdf')

",,,false,,,
https://stackoverflow.com/questions/61992108,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Unable to parse URL parameters in Flask,"I have deployed a Flask application using Apache on a CentOS VPS. Here is the link I followed to deploy my app: https://medium.com/@mohdejazsiddiqui/deploy-flask-app-in-apache-shared-hosting-5b3c82c8fd5e. For some strange reason my Flask app is unable to detect url parameters which is working perfectly in my local environment. I have raised this already to my VPS provider but I just want to check if anybody here have the same experience.

Sample url: mydomain.net/login?error=error_message
Here is my code:

from flask import Blueprint, redirect, request, url_for, render_template
import requests

from myapp.forms import Login, Signup

auth = Blueprint('auth', __name__) #This is imported in the main view

@auth.route('/login', methods=['GET'], strict_slashes=False)
def login():
    loginform = Login()
    signupform = Signup()

    ...
    current_url = request.url
    err = request.args.get('error', '')
    ...

    return something



When I print out current_url it only returns my base url mydomain.net, and err is an empty string. I have also tried request.form to no avail.

Here is my .htaccess file just in case if this is an apache related issue:

# .htaccess
Options +ExecCGI 
AddHandler cgi-script .py
RewriteEngine On
RewriteCond %{REQUEST_FILENAME} !-f 
RewriteRule ^(.*)$ /home/servername/public_html/mydomain.net/app.cgi/$1 [L]


Thanks.
","            from flask import render_template, request, redirect, url_for
            @app.route('/',methods=['GET'])
            def login():    
                return ""Hello World!""
                # return render_template('/auth/login.html')

            @app.route('/auth/login',methods=['POST'])
            def post_login():
                error = None
                email = request.form.get('email')
                password = request.form.get('password')

                if email!='nandhini@gmail.com' or password !='nandhini':
                    error=""invalid email and password""
                    return render_template('/auth/login.html',error=error, email=email,password=password)
                else:
                    flash('you were successfully logged in','success')
                    return redirect(url_for('register'))

",,,false,,,
https://stackoverflow.com/questions/58428894,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Prevent Flask from double logging when running in console,"I'm using Python Flask and Connexion to create a REST API. It's hard to figure out how logging is working with using these two libraries, and I've run in to a strange issue with double logging when trying to run/debug locally.

app/log.py

import logging
from flask import g, has_request_context
import uuid

def request_id():
    if 'request_id' not in g:
        g.request_id = uuid.uuid4()

    return g.request_id

class AppFilter(logging.Filter):
    def filter(self, record):
        record.request_id = request_id() if has_request_context() else 'app'
        return True

formatter = logging.Formatter('%(asctime)s %(request_id)s %(module)s:%(levelname)s %(message)s')
handler = logging.StreamHandler()
handler.setFormatter(formatter)
handler.addFilter(AppFilter())


main.py

import connexion
from config import config
import json
import logging
from app.log import handler

# initiate swagger/connexion
application = connexion.App(__name__, specification_dir='./')
application.add_api('swagger.yml')

# logging
application.app.logger.handlers.pop() 
application.app.logger.addHandler(handler)
application.app.logger.setLevel(logging.DEBUG)
application.app.logger.debug('application starting...')

# if we're running in standalone mode, run the application
if __name__ == '__main__':
    application.run(host='0.0.0.0', port=5000)


The above code lets me use a custom log format whereby each request gets a UUID for the duration of the requests. Whilst this works, I can not figure out how to stop double logging. As you can see in main.py I pop the (only) handler and add my own, and when I print the handlers to the console there is only one - the one I add.

This works, but after a certain number of messages it just starts double logging:

2019-10-17 10:00:22,737 09031bdb-5105-4b73-9e7d-a609f42a471e inbound:application starting...
2019-10-17 10:00:22,747 09031bdb-5105-4b73-9e7d-a609f42a471e inbound:INFO inbound
2019-10-17 10:00:22,755 09031bdb-5105-4b73-9e7d-a609f42a471e config:DEBUG Cache miss: 90002
2019-10-17 10:00:22,755 09031bdb-5105-4b73-9e7d-a609f42a471e firewall:DEBUG Connecting to x
2019-10-17 10:00:22,861 09031bdb-5105-4b73-9e7d-a609f42a471e firewall:DEBUG Get x for ""90002""
2019-10-17 10:00:23,062 09031bdb-5105-4b73-9e7d-a609f42a471e firewall:DEBUG interfaces: source=v1 dest=v2
DEBUG:flask.app:interfaces: source=v1 dest=v2
2019-10-17 10:00:23,062 09031bdb-5105-4b73-9e7d-a609f42a471e firewall:DEBUG Found matching policy: 980cf552-5aaf-51e9-6c39-6480d51af2ad
DEBUG:flask.app:Found matching policy: 980cf552-5aaf-51e9-6c39-6480d51af2ad
2019-10-17 10:00:23,062 09031bdb-5105-4b73-9e7d-a609f42a471e firewall:DEBUG Found matching policy: eff53daa-b4f6-51e9-b79f-25b26b9f8537
DEBUG:flask.app:Found matching policy: eff53daa-b4f6-51e9-b79f-25b26b9f8537


As if the handler has been added back in. I'm not sure if the handler is being re-added, or if I'm going about this the wrong way.

Here's how I am logging throughout the app, example:

inbound.py

from flask import request, current_app

def index():
    current_app.logger.info('inbound')
    # do stuff....




","I had the same issue. It was because the app was logging before the logging was configured. If you can configure logging before app is created then good, else do not log before configuring logging.
If using factory patter configure logging before create_app is called.
",,,false,,,
https://stackoverflow.com/questions/58096781,false,The issue does not have any information provided for analysis.,,,,,,,Flask SocketIO messages not received,,,,,false,,,
https://stackoverflow.com/questions/53951884,false,The issue does not have any information provided for analysis.,,,,,,,ImportError: cannot import name routes,,,,,false,,,
https://stackoverflow.com/questions/49998219,false,The issue does not have any information provided for analysis.,,,,,,,Unable to understand how flask uses url_for,,,,,false,,,
https://stackoverflow.com/questions/48212717,false,The issue does not have any information provided for analysis.,,,,,,,Testing a Flask endpoint using peewee transactions and pytest,,,,,false,,,
https://stackoverflow.com/questions/43563417,false,The issue does not have any information provided for analysis.,,,,,,,pip setuptools missing in ubuntu 17.04,,,,,false,,,
https://stackoverflow.com/questions/33389810,false,The issue does not have any information provided for analysis.,,,,,,,jQuery AJAX call works if and only if debugging in FF/Chrome,,,,,false,,,
https://stackoverflow.com/questions/26445122,false,The issue does not have any information provided for analysis.,,,,,,,Errors loading JSON with Flask and Angular,,,,,false,,,
https://stackoverflow.com/questions/69134062,false,The issue does not have any information provided for analysis.,,,,,,,Module not found error when running script as wsgi within Apache,,,,,false,,,
https://stackoverflow.com/questions/59367978,false,The issue does not have any information provided for analysis.,,,,,,,CORS error with flask-socket.io in Chrome,,,,,false,,,
https://stackoverflow.com/questions/63480238,false,The issue does not have any information provided for analysis.,,,,,,,Deployment in Heroku Fails Due to issue in requirements.txt,,,,,false,,,
https://stackoverflow.com/questions/16680456,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Unable to run 2 different flask apps on same server,"Here is my nginx config

server {
    listen       80;
    server_name site.com;

    location / {
        include uwsgi_params;
        uwsgi_pass unix:/tmp/uwsgi.sock;
        uwsgi_param UWSGI_PYHOME /var/www/site/env;
        uwsgi_param UWSGI_CHDIR /var/www/site;
        uwsgi_param UWSGI_MODULE app;
        uwsgi_param UWSGI_CALLABLE app;
    }

    location /site2 {
        include uwsgi_params;
        uwsgi_pass unix:/tmp/uwsgi.sock;
        uwsgi_param UWSGI_PYHOME /var/www/site2/env;
        uwsgi_param UWSGI_CHDIR /var/www/site2;
        uwsgi_param UWSGI_MODULE app;
        uwsgi_param UWSGI_CALLABLE app;
    }
}


When I visit site.com, sometimes I'm being served from /var/www/site, and other times from /var/www/site2. Also, when I try to visit site.com/site2, I'm sometimes being served from var/www/site2 and sometimes from /var/www/site.

What is the reason for this inconsistent behavior, and how to resolve it so that I can use 2 different flask apps without actually using 2 different domains?
","You are connecting both of your applications through the same socket unix:/tmp/uwsgi.sock. You would have same problem if you used different domains.
",,,false,,,
https://stackoverflow.com/questions/4766792,false,The issue does not meet the criteria for deeper analysis as it is related to inconsistent loading of an iframe and does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Need help with inconsistent loading iframe,"I'm trying to include a Facebook share iframe on a site that's served using Flask and Apache. The iframe loads inconsistently however and I am at a loss for possible explanations. Here is what I have observed:


The iframe loads correctly in Firefox and Safari but not Chrome 10.0 dev, on Mac
In Chrome, the iframe never loads correctly when I load the entire page
If I strip half of the elements from the page, the iframe loads correctly maybe three times out of ten - doesn't matter which half I remove.
If I strip all of the elements from the page, the iframe loads correctly every time.


The inconsistent behavior makes me think there's some sort of race going on, but I don't understand what the problem would be, or why it would only appear in Chrome. Anyway, I appreciate your help. You can view the site here. Thanks, Kevin
","I think they key is in this statement: 


  If I strip half of the elements from
  the page, the iframe loads correctly
  maybe three times out of ten - doesn't
  matter which half I remove.


I'd dump the output to a text file and would run tidy(1) or xmllint(1) over the response to see if you have a mis-matched HTML tag. Chances are Chrome is not handling the error correctly, but Firefox and Safari are able to recover.
",,,false,,,
https://stackoverflow.com/questions/58716157,true,The issue involves inconsistent .zip download behavior from a Flask app over nginx/gunicorn. It meets the criteria for deeper analysis as it exhibits unexpected behavior under specific runtime conditions.,,,,,,,Inconsistent .zip download from Flask app over nginx/gunicorn,"I have a Flask app deployed with Nginx and Gunicorn. The app has an endpoint that lets users download a specified zip file. Many of the zip files are small, but I have one large one - about 2.4GB - that is showing inconsistent download behavior. I have had no issues downloading the smaller files (which aren't larger than 500MB); the issues only seem to arise around the 2GB+ file size.

My initial code was: 

@app.route('/zip')
def zip_download(name):

    file_name = '{}.zip'.format(name)
    
    zip_file = os.path.join(app.config['ZIP_PATH'], file_name)

    if os.path.exists(zip_file):
        return send_file(
                zip_file,
                as_attachment=True,
                attachment_filename=file_name)
    else:
         # tell user file doesn't exist


With this endpoint, I have not been able to download the entire 2.4GB file. 


Using Chrome on Windows: the download would get to ~1GB and then restart the download completely. This cycle would seemingly repeat in a loop. 
Using Chrome on MacOS: same behavior.  


I proceeded to edit the code slightly to use the send_from_directory method instead:  

@app.route('/zip')
def zip_download(name):

    file_name = '{}.zip'.format(name)
    
    zip_file = os.path.join(app.config['ZIP_PATH'], file_name)

    if os.path.exists(zip_file):
        return send_from_directory(app.config['ZIP_PATH'],
                                   file_name,
                                   as_attachment=True,
                                   mimetype='application/zip')


This time around the behavior is slightly different - better - but not completely right. 


Chrome on Windows: Download completed after some time, but the zip was corrupted/damaged and I couldn't open the files (PDFs) inside. 
Chrome on MacOS: No problems. Download worked and could open files.  


So essentially, I'm trying to determine if these issues can be improved through Flask (e.g., config options relevant to downloads) or if I should explore options within nginx/gunicorn.
","I ended up just using Nginx to serve the .zip files directly, and the download issues were resolved. 

None of the python solutions I attempted solved the issue, and most of what I read online indicated python/Flask was the sub-optimal solution for serving files. 

In my sites-available file for my app, I made a simple location {} to achieve this: 

location /download/url {
    alias /path/to/static/directory;
}

",,,false,,,
https://stackoverflow.com/questions/24098318,true,The issue involves a background thread in Flask seeing a non-empty queue as empty. It meets the criteria for deeper analysis as it exhibits unexpected behavior under specific runtime conditions.,,,,,,,Flask: Background thread sees a non-empty queue as empty,"When I run a Flask app in uwsgi, the background thread and the app functions see different values when querying size of the same Queue.

Components


A Flask application with a thread-safe queue.
A GET call returns the queue size.
A POST call adds an element to the Queue.
A background thread prints the Queue size


The problem

When the app is from the shell using python tester.py, I get the expected result:

2014-06-07 14:20:50.677995 Queue size is: 0
127.0.0.1 - - [07/Jun/2014 14:20:51] ""POST /addMessage/X HTTP/1.1"" 200 -
2014-06-07 14:20:51.679277 Queue size is: 1
2014-06-07 14:20:52.680425 Queue size is: 1
2014-06-07 14:20:53.681566 Queue size is: 1
2014-06-07 14:20:54.682708 Queue size is: 1
127.0.0.1 - - [07/Jun/2014 14:20:55] ""POST /addMessage/Y HTTP/1.1"" 200 -
2014-06-07 14:20:55.687755 Queue size is: 2
2014-06-07 14:20:56.688867 Queue size is: 2


However, when the app is executed using uwsgi, I get the following in the logs:

2014-06-07 14:17:42.056863 Queue size is: 0
2014-06-07 14:17:43.057952 Queue size is: 0
[pid: 9879|app: 0|req: 6/6] 127.0.0.1 () {24 vars in 280 bytes} [Sat Jun  7 14:17:43 2014] POST /addMessage/X =&gt; generated 16 bytes in 0 msecs (HTTP/1.1 200) 2 headers in 71 bytes (1 switches on core 0)
2014-06-07 14:17:44.059037 Queue size is: 0
2014-06-07 14:17:45.060118 Queue size is: 0
[pid: 9879|app: 0|req: 7/7] 127.0.0.1 () {24 vars in 280 bytes} [Sat Jun  7 14:17:45 2014] POST /addMessage/X =&gt; generated 16 bytes in 0 msecs (HTTP/1.1 200) 2 headers in 71 bytes (1 switches on core 0)
2014-06-07 14:17:46.061205 Queue size is: 0
2014-06-07 14:17:47.062286 Queue size is: 0


When running under uwsgi, the background thread does not see the same queue as the app. Why is that? How can I make these two threads look at the same Queue object?

Updates


I see inconsistent behaviour even when it's executed as a Python script: Sometimes it does not manage to log messages (using app.logger), and I can only see prints. This means that the thread is running, but it can't do anything with app.logger.


uwsgi .ini configuration

[uwsgi]
http-socket    = :9002
plugin         = python
wsgi-file      = /home/ubuntu/threadtest-uwsgi.py
enable-threads = true
workers        = 1
chdir          = /home/ubuntu/thread-tester/thread_tester


Code

from flask import Flask, jsonify
import Queue
from threading import Thread
import time
import datetime
import logging
import sys

logging.basicConfig(stream=sys.stderr,
                    format='%(asctime)s %(levelname)s - %(message)s')

app = Flask(__name__)
messages = Queue.Queue()

def print_queue_size():
    while True:
        app.logger.debug(""%s Queue size is: %d"" % (datetime.datetime.now(),
                                        messages.qsize()))
        time.sleep(1)

t = Thread(target=print_queue_size, args=())
t.setDaemon(True)
t.start()

@app.route(""/queueSize"", methods=[""GET""])
def get_queue_size():
    return jsonify({""qsize"": messages.qsize()}), 200

@app.route(""/addMessage/&lt;message&gt;"", methods=[""POST""])
def add_message_to_queue(message):
    messages.put(message)
    return jsonify({""qsize"": messages.qsize()}), 200

if __name__ == ""__main__"":
    app.run(port=6000)

","From the Things to Know documenation page:


  uWSGI tries to (ab)use the Copy On Write semantics of the fork() call whenever possible. By default it will fork after having loaded your applications to share as much of their memory as possible. If this behavior is undesirable for some reason, use the lazy option. This will instruct uWSGI to load the applications after each worker’s fork(). Lazy mode changes the way graceful reloading works: instead of reloading the whole instance, each worker is reloaded in chain. If you want “lazy app loading”, but want to maintain the standard uWSGI reloading behaviour, starting from 1.3 you can use the lazy-apps option.


Your Flask app is started when uWSGI starts, then the one worker process is forked. On forking, the Queue object is empty, and no longer shared with the original process. The thread isn't taken along.

Try setting the lazy-apps option  to delay the loading of the Flask app until the worker is started.
","The documentation link in @Martijn Pieters' answer notes that lazy-apps may consume more memory than preforking. If you're concerned about this, you may also wish to consider the @postfork decorator to have more granular control over what gets run after forking. You could create your Queue inside a @postfork-decorated function and it will get created in each worker.
",,false,,,
https://stackoverflow.com/questions/20942982,false,The issue does not meet the criteria for deeper analysis as it is related to VirtualEnv/Pip trying to install packages globally and does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,VirtualEnv/Pip trying to install packages globally,"Edit #2 Solution found; see below.

I'm writing a small application in Flask using VirtualEnv. This is far from the first time I've done this, but the this time and past two times I've tried I've encountered the same problem. When I .  flask/bin/activate and try to install a package -- pip install flup, for instance -- it keeps being installed globally, and not in the VirtualEnv. The weird thing is, it only happens after I deactivate, and it does so inconsistently at that.

To wit, I seem to be able to install everything I need if I do it all at once, and even occasionally after I deactivate, but after a certain interval it just stops working and it starts trying to install into my global Python site-packages. (Naturally, it's also asking for permissions when it does this. Before I understood what was going on I tried to force it with sudo, thinking I'd brought it upon myself by accidentally sudo virtualenv flask-ing or something, but nope, it's going global for some other reason.)

I'm not doing anything funny like using the --system-site-packages argument, and I hadn't changed anything in my VirtualEnv configuration before it started happening. The first time it happened, I chalked it up to a fluke. Now it's becoming seriously irritating because I'm not in the mood to uninstall everything and reinstall it each time, or pray that I'll think of everything I need in a bootstrap script.

I'm not including any error messages because they aren't (or don't seem to be) particularly valuable; it's just requirement already satisfied yelling at me over and over.

Edit #1 I'm winnowing down the problem a little bit, but I still don't have a solution. I created a new Flask project in the same directory, cd-ed into it, activated its VirtualEnv, etc., then ran which pip. It was the new VirtualEnv's pip -- the right pip. I deactivated, cd-ed to my original project, activated VirtualEnv, and ran which pip. It spit out the other project's -- the new one's -- pip. I rm -r-ed the new test project, went back to the original, ran which pip again, and it spit out /usr/local/bin/pip. Oh. OK.

Edit #2: Solution I may not have figured out the exact cause, but I did find the solution. The bin/activate and bin/pip scripts themselves were altered somehow, possibly from accidentally running two VirtualEnvs at the same time(?). Maybe it's just coincidence that it happened three times in a row after never happening before. Dunno.

I cat-ed activate and sure enough, on line 42, was

VIRTUAL_ENV=""/Users/chaseries/blueprint/python/flask2/flask""


instead of

VIRTUAL_ENV=""/Users/chaseries/blueprint/python/flask/flask""


I changed it, ran which pip again, and got the right result. Tried installing, got a stack trace that led me to bin/pip, and found its shebang was wrong. Changed it to the right path, and everything works perfectly.
","If you have renamed your project directory containing ENV - virtual environment directory, try wiping out ENV directory and recreate virtualenv and activate it and reinstall pip dependencies.

TL-DR;
Delete virtual environment, create new one, activate it and issue pip commands again.
","I had the same problem. For me, the cause was that my virtualenv had spaces in the path.

Moving the virtualenv to a spaceless path solved the problem.
","In my case, my pip.ini file had specified a target value: removing the target resolved the problem.
broken pip.ini
[global]
index-url = work-artifactory-cloud-api-key
trusted-host = work-artifactory-cloud
proxy = http://work-artifactory-cloud.com:2000/
target = ~/site-packages

fixed pip.ini
[global]
index-url = work-artifactory-cloud-api-key
trusted-host = work-artifactory-cloud
proxy = http://work-artifactory-cloud.com:2000/

you may not need ""index-url"", ""trusted-host"" and ""proxy"" if you're using a personal machine. I'm not great at python, and I'm much worse at SysAdmin, but thankfully I stumbled across the right GitHub Issue that helped debug this issue for me: https://github.com/pypa/pip/issues/11154
You can find where your pip.ini file is by running pip config debug and you can see what's inside this pip.ini by running pip config list
",false,,,
https://stackoverflow.com/questions/53269323,false,The issue does not meet the criteria for deeper analysis as it is related to inconsistency in Flask's jsonify function and does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Flask&#39;s jsonify function inconsistent with flask-marshmallow,"I am developing an API using flask-RESTful and am having an issue with Flask's jsonify function. I am using flask-marshmallow for JSON serialization. Below is a very simplified code snippet:

result = activities_schema.dump(activities)
return jsonify(result)


Locally, the endpoint will return json that has keys 'data' and 'errors'; however, when running on a Linux server, this returns a result that contains a list and a dict, without the 'data' and 'errors' keys.

I have determined this inconsistency is caused by Flask's jsonify function by printing out results before they are returned by the API. Both locally and on the server, 'result' equals:

MarshalResult(data=[], errors={})


However, when I print the response after using Flask's jsonify, I get this locally:

('{\n  ""data"": [], \n  ""errors"": {}\n}', '\n')


while this is printed on the server:

('[\n  [], \n  {}\n]', '\n')


Anyone know why these don't match?
","I researched some more, and found one solution to the problem (I feel a bit silly since the solution is right in the docs), but cannot explain why the original problem happens.

The solution (found here) is to either use:

jsonify(result.data)


or:

activities_schema.jsonify(result)


Either method will return just the data, not the errors.

I still cannot explain why doing it the other way was inconsistent between the server and my local machine, but maybe that's a different question.
",,,false,,,
https://stackoverflow.com/questions/64017435,false,The issue is not related to an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is a problem with cache directory permissions and potential conflicts between different environments.,,,,,,,World Bank WBDATA on Anaconda3 and pip uninstall/install is throwing a cache directory error,"FileExistsError: [WinError 183] Cannot create a file when that file already exists: 'C:\\Users\\name\\AppData\\Local\\wbdata\\wbdata\\Cache'

I run Anaconda3 and my virtualenv lost that ability to run wbdata. After reinstalling the World Bank wbdata  0.3.0 script, it's throwing the error above on my Windows development machine
The real problem is that Python doesn't always alert that the Cache file conflict is the problem. This leaves the programmer to wonder why the script has simply stopped running.
I find that my mix of interwoven flask apps and python background scripts (I use ""popen"") confuses the wbdata cache into recognizing a cache permissions issue.
It might be that popen is not also activating my virtual python environment - so that a virtual env and conda's native env are now competing for the same wbdata cache directory?
I suspected initially that this cache conflict could also be (could be = not certain) a result of installing Conda first and then having to rely on ""PIP install"" for libraries that Conda does offer. I don't think conda supports the installation of wbdata - for one example.
I have two ""Lib"" directories on my installations on Windows 8.1. This probably appears normal, but sometimes python is looking into a different Lib directory for background run scripts - and sometimes not (maybe a popen issue where it's not activating my virtual env?):

\users\name\Anaconda3\envs\envname\Lib
\users\name\Anaconda3\Lib

To solve the problem, I have added full access permissions to all users on this Windows 8.1 OS for the cache directory. That doesn't seem to solve the problem - although it does seem? to reduce the rate of occurrence to ""very infrequent"".
I tried:

(re)installing with:
conda install -c anaconda wbdata


No WBDATA was found
I also ran a conda uninstall wbdata just in case ...

pip install wbdata

This installed wbdata without error until I ran wbdata to collect api info

pip uninstall wbdata ; pip install wbdata

Reinstalling in this way with pip didn't eliminate the problem.
I looked at online documentation and can't find a similar error.
Questions are:

What is the best best-practice method of cleaning up this inconsistency between Anaconda3 conda and PIP installed wbdata caches?
Does popen need to be instructed which virtual env to open - to prevent this python cache conflict - and, if this is an obvious problem that never previously occurred to me, then what would that popen command look like?

","It turns out after a lot of research that WBDATA caches are simply files that can be deleted in Windows using a file explorer or any other method. Once the file is removed WBDATA resumed to full functionality ...
My cache directory (on a Windows 8.1 development windows PC) is C:\\Users\\USERID\\AppData\\Local\\wbdata\\wbdata\\cache
I delete this cache and all returns to normal.
As for the cause of this problem, it might/probably/absolutely has to do with how you are invoking Python.exe; each ENV has its own python.exe that you should be running, so if you are running the generic base python.exe, you could create a conflict as the two apps compete for the same cache directory.
Hope this helps
","I run Anaconda,too. It works if you install it with
pip install -U wbdata

Check the details here
https://wbdata.readthedocs.io/en/stable/
",,false,,,
https://stackoverflow.com/questions/60425466,false,"The issue is related to inconsistent sort order in Flask-Admin using SQLAlchemy, but it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.",,,,,,,Erratic sort order for hybrid_property sum expression in Flask-Admin using SQLAlchemy,"Given the following models, I would like to add a sortable column to Flask Admin that shows all upcoming payments for an Organisation:

organisation_payments = db.Table(
    'organisation_payments',
    db.Column('payment_id', MyUUID(), db.ForeignKey('payment.id')),
    db.Column('organisation_id', MyUUID(), db.ForeignKey('organisation.id'))
)

class Organisation(db.Model):
    id = Column(ModelUUID(), primary_key=True)

    @hybrid_property
    def upcoming_payments(self):
        payments = Payment.query.filter(
            Payment.organisations.any(id=self.id),
            Payment.status == 'active'
        ).all()

        return sum([payment.amount for payment in payments])

    @upcoming_payments.expression
    def upcoming_payments(cls):
        return select([
            func.sum(Payment.amount)
        ]).where(and_(
            organisation_payments.c.organisation_id == cls.id,
            Payment.status == 'active'
        )).label('upcoming_payments')

class Payment(db.Model):
    id = Column(ModelUUID(), primary_key=True)
    amount = db.Column(db.Integer())
    status = db.Column(db.Unicode(255), default='active')
    organisations = db.relationship(
        'Organisation',
        secondary=organisation_payments,
        backref=db.backref('payments', lazy='dynamic')
    )



Note that a Payment could theoretically be mapped to multiple Organisations, hence the many-to-many relationship.

I have added upcoming_payments to column_sortable_list in a Flask-Admin ModelView, but when sorting on that column the results are erratic: https://i.stack.imgur.com/VxrAE.png

This is the most minimal version of the code, but I've also tried:


using coalesce to force 0 for rows with no upcoming payments
using as_scalar() in place of .label()
Payment.organisations.any(id=cls.id) in place of organisation_payments.c.organisation_id == cls.id (this produced even more confusing and inconsistent results, and sorting asc/desc made no difference)


The values returned from the regular hybrid_property are correct, as is the result if I run this in the shell:

stmt = select([
        func.sum(Payment.amount)
    ]).where(and_(
        Payment.organisations.any(id=org.id),
        Payment.status == 'active',
    ))

res = db.engine.execute(stmt)
res.fetchone() 
(4036200L,)


However the result is wildly inaccurate if I run this:

stmt = select([
        func.sum(Payment.amount)
    ]).where(and_(
        organisation_payments.c.organisation_id == org.id,
        Payment.status == 'active',
    ))

res = db.engine.execute(stmt)
res.fetchone() 
(1204440000L,)


But neither the any() or association table method returns the correct sort order in Flask-Admin. What am I doing wrong here? I feel like I must be missing a distinct or a subquery, but I'm stumped.

UPDATE: All thanks to Ilja Everilä for guiding me to the answer:

    @upcoming_payments.expression
    def upcoming_payments(cls):
        q = select([coalesce(func.sum(Payment.amount), 0)])
        q = q.where(and_(
            organisation_payments.c.charity_id == cls.id,
            Payment.status == 'active',
            Payment.deleted.isnot(True)
        ))

        j = Payment.__table__.join(organisation_payments)
        q = q.select_from(j)

        return q.label('upcoming_donations')

","UPDATE: All thanks to Ilja Everilä for guiding me to the answer:

    @upcoming_payments.expression
    def upcoming_payments(cls):
        q = select([coalesce(func.sum(Payment.amount), 0)])
        q = q.where(and_(
            organisation_payments.c.charity_id == cls.id,
            Payment.status == 'active',
            Payment.deleted.isnot(True)
        ))

        j = Payment.__table__.join(organisation_payments)
        q = q.select_from(j)

        return q.label('upcoming_donations')

",,,false,,,
https://stackoverflow.com/questions/57007828,false,The issue is not related to an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is a question about running code in Flask after initialization.,,,,,,,How to run code in Flask APP after it finishes initializing (&quot;Running on htttp://127.0.0.1:5000/...),"I am writing a Flask application to run on a local machine and do some things.  I want my flask application to automatically open the web browser once it finishes initializing.  The problem is that when I package it all together, sometimes the webdriver loads much faster than the Flask APP is able to initialize.

I have tried time delays and threading, but for the most part I keep getting inconsistent results.  I have tried using Flask's @before_first_request, but that is still once a request has been put in from the browser.

if __name__ == '__main__':

    port = 5000 + random.randint(0, 999)
    url = ""http://127.0.0.1:{0}"".format(port)

    options = webdriver.ChromeOptions()

    # options.add_argument(""--start-maximized"")
    options.add_argument(""--kiosk"")
    options.add_argument(""disable-infobars"")

    browser = webdriver.Chrome(chrome_options=options)
    # threading.Timer(5, lambda: browser.get(url)).start()
    browser.get(url)

    app.run(port=port, debug=Flase)


I expect the actual webdriver to open AFTER Flask has finished initializing.  I can't put it after app.run because that starts the flask ""loop"" and will not execute.  Is there any function to run once Flask has fully initialized but not yet accepted any requests?  

Thanks!
","
  Is there any function to run once Flask has fully initialized but not yet accepted any requests? 


Try registering a callback for before_first_request:

@app.before_first_request
def run_browser():
    # ...


https://flask.palletsprojects.com/en/1.0.x/api/#flask.Flask.before_first_request
",,,false,,,
https://stackoverflow.com/questions/53788885,false,The issue is not related to an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is about bulk insertion into multiple tables using SQLAlchemy ORM.,,,,,,,Bulk insert into multiple tables using SQLAlchemy ORM,"I am trying to do a bulk insert into 2 tables using Flask-SQLAlchemy. The 2 tables are:


author table: PK author_id (auto-increment) 
book table: PK book_id (ai), FK author_author_id  


In the body of the JSON, I have a list of dictionaries. Each dictionary entry has some author-related info and some book-related info. Something like this, there can be many more dictionaries being sent in one go:

[
    {
        ""author_first_name"": ""John"",
        ""author_last_name"": ""Doe"",
        ""author_yob"": ""1988"",
        ""book_name"": ""Mournings of a nun"",
        ""book_genre"": ""Drama""
    },
    {
        ""author_first_name"": ""Jane"",
        ""author_last_name"": ""Doe"",
        ""author_yob"": ""1987"",
        ""book_name"": ""Need for speed"",
        ""book_genre"": ""Action""
    }
]


Currently, I am looping through each dictionary, inserting data into the author table, and then into book table. When I insert into the author table and commit, I get a primary key back, which is author_id. That is the foreign key for my book table.

I repeat this step for every entry in this list. Is there a way to do bulk inserts so that if any insert fails everything is rolled back and I don't have inconsistent data in my database? So if there are 15 dictionaries in the JSON above, if the 12th one has some invalid data or the the database goes down, I want that none of the data sent in the JSON should be posted to the AWS RDS. Below, ""results"" refers to the JSON I have mentioned above.

    @classmethod
    def post_to_database(cls, results):
        for result in results:
            BookModel.post_entry_to_database(result)


    @classmethod
    def post_entry_to_database(cls, result):
        BookModel.insert_author_entry(result)
        author_id = BookModel.get_author_id(result)
        BookModel.insert_book_entry(author_id, result)


    @classmethod
    def insert_book_entry(cls, author_id, result):
        book_data = BookModel(result[""testname""], result[""result""], author_id)
        db.session.add(book_data)
        db.session.commit()


Similarly, I have insert_author_entry as well.

Thanks,
Aditya
","You could consider using flush() to flush changes to the database, which will update your primary key field.

From the SqlAlchemy Docs: flush


  Database operations will be issued in the current transactional context and do not affect the state of the transaction, unless an error occurs, in which case the entire transaction is rolled back. You may flush() as often as you like within a transaction to move changes from Python to the database’s transaction buffer.


When calling flush, The database maintains your CRUD operations as pending in a transaction and are not permanently persisted until the database receives a COMMIT for that current transaction.  This will happen when you subsequently call commit().
",,,false,,,
https://stackoverflow.com/questions/51215349,false,The issue is not related to an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is about displaying only unique messages when using flash in Flask.,,,,,,,How to display only unique messages when using flash in flask,"When using the flash functionality in flask, I have a couple of functions. I call f1, which calls f2 x times, which calls f3 y times. I get a inconsistency in f3, so I want to flash it in f3. However, I don't want to pass the inconsistency all the way down to f1 again, which results in the fact that the message in currently being flashed multiple times because the inconsistency occurs multiple times. Letting the user know 1 time is enough to determine the cause of it.

So I want to only display unique messages.

Minimal example:

from flask import Flask, flash, render_template_string

app = Flask(__name__)
app.secret_key = 'arstarst'


@app.route('/')
def index():
    flash('banana', 'red')
    flash('apple', 'green')
    flash('banana', 'red')
    flash('pear', 'blue')
    return render_template_string('''
      {% with messages = get_flashed_messages(with_categories=true) %}
        {% if messages %}
          {% for category, message in messages %}
            &lt;p style=""color: {{category}}""&gt;{{message}}&lt;/p&gt;
          {% endfor %}
      {% endif %}
    {% endwith %}
    ''')

","Solution:


Make an emtpy dict in jinja
Loop over messages
Check if the message is in the dict
If not, add to the dict and print the message
If so, do nothing


Example:

from flask import Flask, flash, render_template_string
app = Flask(__name__)
app.secret_key = 'arstarst'

@app.route('/')
def index():
    flash('banana', 'red')
    flash('apple', 'green')
    flash('banana', 'red')
    flash('pear', 'blue')
    return render_template_string('''
      {% with messages = get_flashed_messages(with_categories=true) %}
        {% if messages %}
          {% set printed_messages = dict() %}
          {% for category, message in messages %}
            {% if message not in printed_messages %}
              &lt;p style=""color: {{category}}""&gt;{{message}}&lt;/p&gt;
              {% set x = printed_messages.__setitem__(message, ""value"")  %}
            {% endif %}
          {% endfor %}
      {% endif %}
    {% endwith %}
    ''')

",,,false,,,
https://stackoverflow.com/questions/42810198,false,The issue is not related to an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is about streaming a Flask response that relies on an API call.,,,,,,,Streaming a flask response that relies on an API call,"I have two applications, a flask api (backend) and a frontend app. Recently I have had to implement a streaming mechanism so the frontend can call the api to retrieve some data (paginated) and stream its contents back.

I followed the guide described here on how to stream back a Response in Flask.

My pseudo-code in the frontend essentially looks like this:

 return Response(stream_with_context(generate()))


Within generate() I do the following:

def generate():
    # make blocking api call 
    data = requests.get(url)
    for x in data:
        yield x


I am finding that the results produced are inconsistent. My gut feeling is that it's something to do with the blocking API call. Is it okay to have a blocking api call within a generator that is streamed back to the user?
","Since we're dealing with the library requests you should probably pass in stream=True and use that generator in the response. flask.Response can either take a string or iterable.

@app.route(""/foo"")
def foo():
    _resp = requests.get(url, stream=True)
    _resp.raise_for_status()

    resp = Response(
        response=stream_with_context(_resp.iter_content(chunk_size=1024*10)),
        status=200,
        content_type=_resp.headers[""Content-Type""],
        direct_passthrough=False)
    return resp


Note that the Content-Type is also transparently proxied.

To answer your question, it doesn't matter if you use a blocking call in your generator - but I don't see why you would want to do that, given your example.
",,,false,,,
https://stackoverflow.com/questions/37203649,false,The issue is not related to an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is about inconsistent results in BaseQuery.paginate() in Flask-SQLAlchemy.,,,,,,,BaseQuery.paginate() return inconsistent results,"When I manually execute this query in MySQL, the number of results I get is 28:
    SELECT *
    FROM position_reporting_structures prs
    INNER JOIN positions AS pos ON pos.id = prs.reports_to
    INNER JOIN jobs ON jobs.id = pos.job_id
    INNER JOIN position_fulfillments AS pf ON pf.position_id = pos.id
    INNER JOIN parties ON parties.id = pf.party_id
    WHERE jobs.title LIKE '%QA/QC%' OR parties.name LIKE '%QA/QC%';

This is the interpreted SQLAlchemy value of the query above:
    query = (
          PositionReportingStructure.query 
          .join(Position,
                Position.id == PositionReportingStructure.reports_to)
          .join(Job,
                Job.id == Position.job_id)
          .join(PositionFulfillment,
                PositionFulfillment.position_id == Position.id)
          .join(Party,
                Party.id == PositionFulfillment.party_id)
          .filter(db.or_(
                Job.title.like('%QA/QC%'),
                Party.name.like('%QA/QC%')))
     )

I have a pagination decorator that wraps a function whose returning value is a BaseQuery. Inside the decorator, these are the code snippets that I've used:
    query = f(*args, **kwargs)

    page = 1 // just a dummy value
    per_page = 5 // just a dummy value
    paginate = query.paginate(page=page, per_page=per_page)

I'm expecting that it will return more or less 6 pages and 28 items in total, but it's not. The outcome is 1 page, 4 items per page, 4 total items and no previous/next pages which is incorrect. For further investigation, I have tried changing the value of page variable to compare each one:

page = 1 : 1 page, 4 items, 4 total items
page = 2 : 6 pages, 3 items, 28 total items
page = 3 : 6 pages, 2 items, 28 total items
page = 4 : 6 pages, 3 items, 28 total items
page = 5 : 6 pages, 5 items, 28 total items
page = 6 : 6 pages, 3 items, 28 total items

As you may notice, per page items is too inconsistent. Anybody who can explain what causes this contingency? I am currently using Flask-SQLAlchemy-2.0.
","I already knew the root cause of this problem. My query returns some duplicate rows which I think is not acceptable to SQLAlchemy so in return automatically gives the distinct ones (even without using GROUP BY or DISTINCT). 

As the context of my problem stated, I passed a count of 5 items in the per_page parameter of the paginate function, at the first page, it would only return 4 items since it groups the duplicate ones, thus, satisfies the paginate function's conditional statement (the one that has an emphasis):

    **if page == 1 and len(items) &lt; per_page:
        total = len(items)**
    else:
        total = self.order_by(None).count()

",,,false,,,
https://stackoverflow.com/questions/35267743,false,The issue does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is a question about how to model a scenario using Flask SQLAlchemy.,,,,,,,Subscription modelling in Flask SQLAlchemy,"I am trying to model the following scenario in Flask SQLAlchemy:

There are a list of SubscriptionPacks available for purchase. When a particular User buys a SubscriptionPack they start an instance of that Subscription.

The model is as follows:



A User can have many Subscriptions (only one of which will be Active at a time) and each Subscription will be referencing one SubscriptionPack.

How would this be modelled in SQLAlchemy?

Currently I have the User.id and SubscriptionPack.id referenced as db.ForeignKey in the Subscriptions model. And I have Subscriptions referenced as a db.Relationship in the Users table. This seems inconsistent and wrong and is leading me to have to hand-code a lot of SQL statements to return the right results.

Any help as to how to do this right?
","For those who stumble upon this, what I was looking for was the bidirectional SQLAlchemy Association Object pattern.

This allows the intermediate table of a Many-to-Many to have it's own stored details. In my instance above the Subscription table needed to be an Association Object (has it's own class).
",,,false,,,
https://stackoverflow.com/questions/68332808,false,The issue does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is a question about conda environment configuration.,,,,,,,conda environment using/calling incorrect python version,"I've tried to find answers like the ones here, but they don't work for me.
I have a python3.6 environment called py36. If I conda activate py36 and then run flask with
export FLASK_APP=main.py
flask run --port=5050

I get the following error:
Traceback (most recent call last):
  File ""/Users/USERNAME/anaconda/bin/flask"", line 6, in &lt;module&gt;
    sys.exit(flask.cli.main())
  File ""/Users/USERNAME/anaconda/lib/python3.5/site-packages/flask/cli.py"", line 513, in main
    cli.main(args=args, prog_name=name)
  File ""/Users/USERNAME/anaconda/lib/python3.5/site-packages/flask/cli.py"", line 380, in main
    return AppGroup.main(self, *args, **kwargs)
  File ""/Users/USERNAME/anaconda/lib/python3.5/site-packages/click/core.py"", line 697, in main
    rv = self.invoke(ctx)
  File ""/Users/USERNAME/anaconda/lib/python3.5/site-packages/click/core.py"", line 1066, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File ""/Users/USERNAME/anaconda/lib/python3.5/site-packages/click/core.py"", line 895, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File ""/Users/USERNAME/anaconda/lib/python3.5/site-packages/click/core.py"", line 535, in invoke
    return callback(*args, **kwargs)
  File ""/Users/USERNAME/anaconda/lib/python3.5/site-packages/click/decorators.py"", line 64, in new_func
    return ctx.invoke(f, obj, *args[1:], **kwargs)
  File ""/Users/USERNAME/anaconda/lib/python3.5/site-packages/click/core.py"", line 535, in invoke
    return callback(*args, **kwargs)
  File ""/Users/USERNAME/anaconda/lib/python3.5/site-packages/flask/cli.py"", line 423, in run_command
    app = DispatchingApp(info.load_app, use_eager_loading=eager_loading)
  File ""/Users/USERNAME/anaconda/lib/python3.5/site-packages/flask/cli.py"", line 152, in __init__
    self._load_unlocked()
  File ""/Users/USERNAME/anaconda/lib/python3.5/site-packages/flask/cli.py"", line 176, in _load_unlocked
    self._app = rv = self.loader()
  File ""/Users/USERNAME/anaconda/lib/python3.5/site-packages/flask/cli.py"", line 237, in load_app
    rv = locate_app(self.app_import_path)
  File ""/Users/USERNAME/anaconda/lib/python3.5/site-packages/flask/cli.py"", line 90, in locate_app
    __import__(module)
  File ""/Users/USERNAME/Documents/Google_Drive/Projects/project/main.py"", line 3, in &lt;module&gt;
    import MySQLdb
ImportError: No module named 'MySQLdb'

The issue isn't that there is no 'MySQLdb' installed, because it is installed under that environment.
if I do conda list I get
mysql-connector-c         6.1.11               h42a37c1_0  
mysqlclient               1.4.6            py36h0a44026_0  

which confirms that mysql is installed on this environment.
and if I run python I get
$ python
Python 3.6.1 |Anaconda custom (64-bit)| (default, May 11 2017, 13:04:09) 
[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
&gt;&gt;&gt; 

which confirms that default python is 3.6.
As you can see everything is supposed to be python3.6, but the error comes from my python code for some reason launching python3.5 instead of python3.6. I don't have any prefixes or any headers telling which python it is supposed to run.
In fact this is the top of my main.py
from flask import Flask, request, render_template, jsonify
from flask_cors import CORS
from flask_pymongo import PyMongo
import MySQLdb
import json
import math
import pandas as pd
import numpy as np
from collections import OrderedDict
import pprint
import sys

app = Flask(__name__)
cors = CORS(app, resources={r""/*"": {""origins"": ""*""}})

In other words, my conda environment, which is supposed to safely contain a single python version (python 3.6), is failing to activate the correct python version inconsistently.
I'm scared to modify the paths but this is what I get if I echo $PATH
&gt;&gt;&gt;echo $PATH
/Users/USERNAME/anaconda/envs/py36/bin:/usr/local/opt/openssl/bin:/usr/local/opt/openssl/bin:/usr/local/opt/openssl/bin:/usr/local/opt/openssl/bin:/usr/local/fsl/bin:/Users/USERNAME/anaconda/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin:/usr/local/git/bin:/Library/Frameworks/Mono.framework/Versions/Current/Commands

The only way I fixed it is if I did the following:
conda activate /Users/USERNAME/anaconda
pip install pymysql

While this fixes my problem, it's a bandaid and it is not solving the issue. Because the base environment is not the one I want to be using when I conda activate py36.
Any help would be deeply appreciated!
Thank you!
","My suggestion would be for you to re-create your virtual environment.
Let's create a completely fresh virtual environment (let's call it appleslice for fun):
First, make sure you are not currently running in any virtual environment by executing deactivate. Then run this:
conda create --name appleslice python=3.6
Then execute: activate appleslice and proceed to install all your required packages.
If still stuck, have a look at this article.
",,,false,,,
https://stackoverflow.com/questions/72587474,false,"The issue does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. The issue body is empty, and there are no answers provided.",,,,,,,Not able to set up gcc in aws sagemaker notebook,"I am working in a jupyter notebook in aws sagemaker and want to use prophet for time-series forecast. I am using the conda_python3 kernel. According to the installation instruction from https://facebook.github.io/prophet/docs/installation.html#python I need to set up gcc before installing prophet, but when I try '%conda install gcc', I get the error message that the environment is inconsistent.
Does anyone know how to solve this issue?
Error message:
Collecting package metadata (current_repodata.json): done
Solving environment: /
The environment is inconsistent, please check the package plan carefully
The following packages are causing the inconsistency:

conda-forge/noarch::nbclient==0.5.2=pyhd8ed1ab_0
conda-forge/linux-64::matplotlib==3.3.4=py36h5fab9bb_0
conda-forge/noarch::qdarkstyle==2.8.1=pyhd8ed1ab_2
conda-forge/linux-64::scikit-image==0.16.2=py36hb3f55d8_0
conda-forge/noarch::python-language-server==0.36.2=pyhd8ed1ab_0
conda-forge/linux-64::widgetsnbextension==3.5.1=py36h5fab9bb_4
conda-forge/noarch::flake8==3.8.4=py_0
conda-forge/noarch::ipywidgets==7.6.3=pyhd3deb0d_0
conda-forge/noarch::typing-extensions==3.7.4.3=0
conda-forge/noarch::path.py==12.5.0=0
conda-forge/noarch::dask==2021.2.0=pyhd8ed1ab_0
conda-forge/noarch::nbformat==5.1.2=pyhd8ed1ab_1
conda-forge/linux-64::path==15.1.2=py36h5fab9bb_0
conda-forge/linux-64::nbconvert==6.0.7=py36h5fab9bb_3
conda-forge/linux-64::distributed==2021.2.0=py36h5fab9bb_0
conda-forge/noarch::anaconda-client==1.7.2=py_0
conda-forge/noarch::aioitertools==0.7.1=pyhd8ed1ab_0
conda-forge/linux-64::matplotlib-base==3.3.4=py36hd391965_0
conda-forge/linux-64::pluggy==0.13.1=py36h5fab9bb_4
conda-forge/noarch::black==20.8b1=py_1
conda-forge/linux-64::blaze==0.11.3=py36_0
conda-forge/noarch::pyls-spyder==0.3.2=pyhd8ed1ab_0
conda-forge/noarch::odo==0.5.1=py_1
conda-forge/linux-64::keyring==22.0.1=py36h5fab9bb_0
conda-forge/noarch::anaconda-project==0.9.1=pyhd8ed1ab_0
conda-forge/noarch::importlib_metadata==3.7.0=hd8ed1ab_0
conda-forge/linux-64::jupyter==1.0.0=py36h5fab9bb_6
conda-forge/noarch::jupyterlab_server==2.3.0=pyhd8ed1ab_0
conda-forge/noarch::seaborn-base==0.11.1=pyhd8ed1ab_1
conda-forge/noarch::imageio==2.9.0=py_0
conda-forge/noarch::numpydoc==1.1.0=py_1
conda-forge/linux-64::yarl==1.6.3=py36h8f6f2f9_1
conda-forge/noarch::jsonschema==3.2.0=py_2
conda-forge/noarch::flask==1.1.2=pyh9f0ad1d_0
conda-forge/noarch::seaborn==0.11.1=hd8ed1ab_1
conda-forge/noarch::helpdev==0.7.1=pyhd8ed1ab_0
conda-forge/linux-64::nb_conda==2.2.1=py36h5fab9bb_4
conda-forge/noarch::nbclassic==0.2.6=pyhd8ed1ab_0
conda-forge/noarch::sphinx==3.5.1=pyhd8ed1ab_0
conda-forge/noarch::jupyterlab_launcher==0.13.1=py_2
conda-forge/linux-64::spyder==4.2.0=py36h5fab9bb_0
conda-forge/linux-64::importlib-metadata==3.7.0=py36h5fab9bb_0
conda-forge/linux-64::pytest==6.2.2=py36h5fab9bb_0
conda-forge/noarch::pyls-black==0.4.6=pyh9f0ad1d_0
/ ^C
failed with initial frozen solve. Retrying with flexible solve.

CondaError: KeyboardInterrupt
Note: you may need to restart the kernel to use updated packages.
","Have you confirmed GCC is not installed already?  I ran the below on a SageMaker Notebook Instance with conda_python3 kernel selected.
!gcc --version
gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-28)
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

",,,false,,,
https://stackoverflow.com/questions/58490035,false,"The issue does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. The issue body is empty, and there are no answers provided.",,,,,,,Unable to import method from another python file,,,,,false,,,
https://stackoverflow.com/questions/51631455,true,"The issue involves routing tasks to different queues with Celery and Django, which can exhibit unexpected behavior if not configured correctly.",,,,,,,How to route tasks to different queues with Celery and Django,"I am using the following stack:


Python 3.6
Celery v4.2.1 (Broker: RabbitMQ v3.6.0)
Django v2.0.4.


According Celery's documentation, running scheduled tasks on different queues should be as easy as defining the corresponding queues for the tasks on CELERY_ROUTES, nonetheless all tasks seem to be executed on Celery's default queue. 

This is the configuration on my_app/settings.py:

CELERY_BROKER_URL = ""amqp://guest:guest@localhost:5672//""
CELERY_ROUTES = {
 'app1.tasks.*': {'queue': 'queue1'},
 'app2.tasks.*': {'queue': 'queue2'},
}
CELERY_BEAT_SCHEDULE = {
    'app1_test': {
        'task': 'app1.tasks.app1_test',
        'schedule': 15,
    },
    'app2_test': {
        'task': 'app2.tasks.app2_test',
        'schedule': 15,
    },

}


The tasks are just simple scripts for testing routing:

File app1/tasks.py:

from my_app.celery import app
import time


@app.task()
def app1_test():
    print('I am app1_test task!')
    time.sleep(10)


File app2/tasks.py:

from my_app.celery import app
import time


@app.task()
def app2_test():
    print('I am app2_test task!')
    time.sleep(10)


When I run Celery with all the required queues:

celery -A my_app worker -B -l info -Q celery,queue1,queue2


RabbitMQ will show that only the default queue ""celery"" is running the tasks:

sudo rabbitmqctl list_queues
# Tasks executed by each queue:
#  - celery 2
#  - queue1 0
#  - queue2 0


Does somebody know how to fix this unexpected behavior?

Regards,
","I have got it working, there are few things to note here:
According Celery's 4.2.0 documentation, CELERY_ROUTES should be the variable to define queue routing, but it only works for me using CELERY_TASK_ROUTES instead. The task routing seems to be independent from Celery Beat, therefore this will only work for tasks scheduled manually:
app1_test.delay()
app2_test.delay()

or
app1_test.apply_async()
app2_test.apply_async()

To make it work with Celery Beat, we just need to define the queues explicitly in the CELERY_BEAT_SCHEDULE variable. The final setup of the file my_app/settings.py would be as follows:
CELERY_BROKER_URL = ""amqp://guest:guest@localhost:5672//""
CELERY_TASK_ROUTES = {
 'app1.tasks.*': {'queue': 'queue1'},
 'app2.tasks.*': {'queue': 'queue2'},
}
CELERY_BEAT_SCHEDULE = {
    'app1_test': {
        'task': 'app1.tasks.app1_test',
        'schedule': 15,
        'options': {'queue': 'queue1'}
    },
    'app2_test': {
        'task': 'app2.tasks.app2_test',
        'schedule': 15,
        'options': {'queue': 'queue2'}
    },

}

And to run Celery listening on those two queues:
celery -A my_app worker -B -l INFO -Q queue1,queue2

Where

-A: name of the project or app.
-B: Initiates the task scheduler Celery beat.
-l: Defines the logging level.
-Q: Defines the queues handled by this worker.

I hope this saves some time to other developers.
","adding queue parameter to the decorator may help you,

@app.task(queue='queue1')
def app1_test():
    print('I am app1_test task!')
    time.sleep(10)
","Okay as i have tried the same command that you have used to run the worker so I found that you just have to remove the ""celery after the -Q parameter and that'll be fine too.
So the old command is
celery -A my_app worker -B -l info -Q celery,queue1,queue2

And the new command is
celery -A my_app worker -B -l info -Q queue1,queue2

",false,,,
