ISSUE_LINK,AI_VERDICT,REASON,LIBRARY_NAME,API_NAME,ISSUE_DESCRIPTION,NORMAL_CONDITIONS,TRIGGER_CONDITIONS,REASON_FOR_DIFFICULTY_IN_DETECTION,ISSUE_TITLE,ISSUE_BODY,ANSWER_1,ANSWER_2,ANSWER_3,HUMAN_CLASSIFICATION,HUMAN_REASON,ISSUE_SCORE,ISSUE_VIEWS
https://stackoverflow.com/questions/59150064,true,The issue involves the incorrect behavior of the seaborn lineplot when plotting all observations. The API in question is the seaborn.lineplot.,Seaborn,seaborn.lineplot,"When using the seaborn.lineplot to plot each row of a dataframe, the API only displays the mean for each month instead of plotting all observations.","The seaborn.lineplot is applied to a dataframe with multiple rows, where each row represents monthly production of a solar panel.","The issue is triggered when the seaborn.lineplot is used to plot a dataframe with multiple rows, resulting in the plot showing only the mean for each month instead of all observations.",This issue might be challenging to detect for users who are not familiar with the specific behavior of the seaborn.lineplot function or those who expect it to plot all observations by default.,Seaborn line plot: don&#39;t aggregate and plot all observations,"My raw data look like:

&gt;df
   Jan   Feb    ...  Dec
0   2     4           4
1   5     3           3


where each row is monthly production of a solar panel. I wanted to plot each row, so I can visually check if some panel were having unexpected behavior. So I convert to long and plot it using seaborn:

df = pd.melt(df)
ax = sns.lineplot(x = variable, y = value, data  = df)


However this just give mean for each month.
","IIUC, you can just do:
df.T.plot()

and output:

If you insist on seaborn, you need to pass hue, something like
sns.lineplot(data=df.stack().reset_index(name='val'),
             x='level_1',
             y='val',
             hue='level_0')

where level_0 and level_1 come from .reset_index of unnamed sources index.
You need to do more for correct ordering of x-axis.
",,,false,,,
https://stackoverflow.com/questions/47488856,false,The behavior is due to a misunderstanding of logical operators and conditions in pandas rather than a problem with the API itself.,,,,,,,seaborn in Python : barplot appears upside down,"I am learning seaborn and I am getting some unexpected behavior.

This reproducible example uses the surveys.csv dataset that can be found in this link: http://www.datacarpentry.org/python-ecology-lesson/setup/

My code is the following:

import pandas as pd
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns
sns.set(style=""whitegrid"", color_codes=True)

surveys_df = pd.read_csv(""surveys.csv"")
avg_weight = surveys_df.groupby(""plot_id"")[""weight""].mean().to_frame()
avg_weight
    weight
plot_id 
1   51.822911
2   52.251688
3   32.654386
4   47.928189
5   40.947802
6   36.738893
7   20.663009
8   47.758001
9   51.432358
10  18.541219
11  43.451757
12  49.496169
13  40.445660
14  46.277199
15  27.042578
16  24.585417
17  47.889593
18  40.005922
19  21.105166
20  48.665303
21  24.627794
22  54.146379
23  19.634146
24  43.679167

sns.barplot(x = avg_weight.index.values, y = ""weight"", 
            data = avg_weight, palette = sns.palplot(sns.diverging_palette(150, 275, s=80, l=55, n=9)))
plt.xlabel('Animal id')
plt.ylabel('Average Weight')
plt.title('Average Weight by Animal')




The barplot appears upside down.

Why this happens and how can I correct it?

Your advice will be appreciated.

PS: Somehow this problem relates to the value passed to the palette argument, as it was resolved when I chose palette = sns.color_palette(""coolwarm"", 7). Still, I can not understand why.
","By invoking sns.palplot, you are making another plot, which causes the figure properties to be set incorrectly. Remove that, and you should be good:

sns.barplot(x = avg_weight.index.values, y = ""weight"", 
            data = avg_weight, palette = sns.diverging_palette(150, 275, s=80, l=55, n=9))
plt.xlabel('Animal id')
plt.ylabel('Average Weight')
plt.title('Average Weight by Animal')



",,,false,,,
https://stackoverflow.com/questions/32117579,false,The behavior is not related to an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,pandas plots on Seaborn FacetGrid,"I have a problem in a Qt application when I attempt to plot my dataframe as an area plot with a time index using pandas plotting function in combination with Seaborn's FacetGrids. What happens is that a grid layout is correctly created, but the plots do not appear in these grids. Using a Seaborn plotting function works as expected, though.

I tried to figure out what's going on by isolating the drawing routines from the rest of my code, and I've found a rather unexpected behaviour as shown below (using ipython notebook):



%matplotlib inline

import pandas as pd
import seaborn as sns

df = pd.DataFrame({
        ""Home"": [76, 64, 38, 78, 63,    45, 32, 46, 13, 40],
        ""Away"": [55, 67, 70, 56, 59,    69, 72, 24, 45, 21],
        ""Team"": [""T1""] * 5 +            [""T2""] * 5,
        ""Year"": [""1991"", ""1992"", ""1993"", ""1994"", ""1995""] * 2})




Now, what I want to do is to draw two facets, one for each team. Each facet should show the 'Away' and 'Home' columns as two separate time series. In line with the suggestion in another question (Plotting time series using Seaborn FacetGrid), I wrote a function that calls the pandas plotting function for the subset passed to it by map_dataframe():



def plot_area(data, color):
    data[[""Home"", ""Away""]].index = pd.to_datetime(data[""Year""])
    data[[""Home"", ""Away""]].plot(kind=""area"")




However, when using this function, the result is rather unexpected: the FacetGrid is created and initialized correctly, but the two calls to the pandas method do not use this grid as their plotting region, and they appear elsewhere. 



g = sns.FacetGrid(df, col=""Team"")
g.map_dataframe(plot_area)




&lt;seaborn.axisgrid.FacetGrid at 0x1a25110&gt;


Screenshot of output: 



In the post I linked above, @mwaskom notes that methods called in this way 


  must draw a plot on the ""currently active"" matplotlib Axes.


Perhaps that is the problem here? The code as such appears to be correct, because with a different plotting function, everything works as expected, e.g. with a sns.heatmap():



def plot_heatmap(data, color):
    sns.heatmap(data[[""Home"", ""Away""]])    

g = sns.FacetGrid(df, col=""Team"")
g.map_dataframe(plot_heatmap)




&lt;seaborn.axisgrid.FacetGrid at 0x4a6d110&gt;


Screenshot of output: 



So, my question boils down to this: how do I have to change the function plot_area() so that the axes produced by the pandas plotting function appear on the subplots created by Seaborn's FacetGrid?

(pandas version 0.16.0, Seaborn version 0.6.0, ipython 3.2.1, Python 2.7)


","The comment by mwaskom set me on the right track: I have to provide the current axes to the plot function (now this seems so obvious...). For future reference, this is a working solution to my problem: 

def plot_area(data, color):
    data.index = pd.to_datetime(data[""Year""])
    data[[""Home"", ""Away""]].plot(kind=""area"", ax=plt.gca())

g = sns.FacetGrid(df, col=""Team"")
g.map_dataframe(plot_area)

",,,false,,,
https://stackoverflow.com/questions/40748838,false,"The issue is related to problems with updating Anaconda and installing new packages, which is not an API-specific problem.",,,,,,,Problems with updating anaconda and installing new packages,"I am trying to install seaborn on anaconda on Ubuntu-Linux. 

conda install -c anaconda seaborn=0.7.1


I am getting the following error message:

Fetching package metadata .../home/moritz/Python/anaconda3/lib/python3.5/site-packages/requests/packages/urllib3/connection.py:337: SubjectAltNameWarning: Certificate for conda.anaconda.org has no `subjectAltName`, falling back to check for a `commonName` for now. This feature is being removed by major browsers and deprecated by RFC 2818. (See https://github.com/shazow/urllib3/issues/497 for details.)
  SubjectAltNameWarning
/home/moritz/Python/anaconda3/lib/python3.5/site-packages/requests/packages/urllib3/connection.py:337: SubjectAltNameWarning: Certificate for conda.anaconda.org has no `subjectAltName`, falling back to check for a `commonName` for now. This feature is being removed by major browsers and deprecated by RFC 2818. (See https://github.com/shazow/urllib3/issues/497 for details.)
  SubjectAltNameWarning
..An unexpected error has occurred.
Please consider posting the following information to the
conda GitHub issue tracker at:

    https://github.com/conda/conda/issues

Current conda install:

           platform : linux-64
      conda version : 4.2.12
   conda is private : False
  conda-env version : 4.2.12
conda-build version : 1.19.0
     python version : 3.5.2.final.0
   requests version : 2.12.1
   root environment : /home/moritz/Python/anaconda3  (writable)
default environment : /home/moritz/Python/anaconda3
   envs directories : /home/moritz/Python/anaconda3/envs
      package cache : /home/moritz/Python/anaconda3/pkgs
       channel URLs : https://repo.continuum.io/pkgs/free/linux-64
                      https://repo.continuum.io/pkgs/free/noarch
                      https://repo.continuum.io/pkgs/pro/linux-64
                      https://repo.continuum.io/pkgs/pro/noarch
        config file : None
       offline mode : False


When I run

$ /home/moritz/Python/anaconda3/bin/conda install -c anaconda seaborn=0.7.1


I am getting the following error message:

Traceback (most recent call last):
  File ""/home/moritz/Python/anaconda3/lib/python3.5/site-packages/conda/exceptions.py"", line 479, in conda_exception_handler
    return_value = func(*args, **kwargs)
  File ""/home/moritz/Python/anaconda3/lib/python3.5/site-packages/conda/cli/main.py"", line 145, in _main
    exit_code = args.func(args, p)
  File ""/home/moritz/Python/anaconda3/lib/python3.5/site-packages/conda/cli/main_install.py"", line 80, in execute
    install(args, parser, 'install')
  File ""/home/moritz/Python/anaconda3/lib/python3.5/site-packages/conda/cli/install.py"", line 238, in install
    prefix=prefix)
  File ""/home/moritz/Python/anaconda3/lib/python3.5/site-packages/conda/api.py"", line 24, in get_index
    index = fetch_index(channel_urls, use_cache=use_cache, unknown=unknown)
  File ""/home/moritz/Python/anaconda3/lib/python3.5/site-packages/conda/fetch.py"", line 310, in fetch_index
    repodatas = [(u, f.result()) for u, f in zip(urls, futures)]
  File ""/home/moritz/Python/anaconda3/lib/python3.5/site-packages/conda/fetch.py"", line 310, in &lt;listcomp&gt;
    repodatas = [(u, f.result()) for u, f in zip(urls, futures)]
  File ""/home/moritz/Python/anaconda3/lib/python3.5/concurrent/futures/_base.py"", line 398, in result
    return self.__get_result()
  File ""/home/moritz/Python/anaconda3/lib/python3.5/concurrent/futures/_base.py"", line 357, in __get_result
    raise self._exception
  File ""/home/moritz/Python/anaconda3/lib/python3.5/concurrent/futures/thread.py"", line 55, in run
    result = self.fn(*self.args, **self.kwargs)
  File ""/home/moritz/Python/anaconda3/lib/python3.5/site-packages/conda/fetch.py"", line 74, in func
    res = f(*args, **kwargs)
  File ""/home/moritz/Python/anaconda3/lib/python3.5/site-packages/conda/fetch.py"", line 116, in fetch_repodata
    timeout=(3.05, 60))
  File ""/home/moritz/Python/anaconda3/lib/python3.5/site-packages/requests/sessions.py"", line 501, in get
    return self.request('GET', url, **kwargs)
  File ""/home/moritz/Python/anaconda3/lib/python3.5/site-packages/requests/sessions.py"", line 488, in request
    resp = self.send(prep, **send_kwargs)
  File ""/home/moritz/Python/anaconda3/lib/python3.5/site-packages/requests/sessions.py"", line 609, in send
    r = adapter.send(request, **kwargs)
  File ""/home/moritz/Python/anaconda3/lib/python3.5/site-packages/requests/adapters.py"", line 423, in send
    timeout=timeout
  File ""/home/moritz/Python/anaconda3/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py"", line 594, in urlopen
    chunked=chunked)
  File ""/home/moritz/Python/anaconda3/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py"", line 350, in _make_request
    self._validate_conn(conn)
  File ""/home/moritz/Python/anaconda3/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py"", line 835, in _validate_conn
    conn.connect()
  File ""/home/moritz/Python/anaconda3/lib/python3.5/site-packages/requests/packages/urllib3/connection.py"", line 330, in connect
    cert = self.sock.getpeercert()
  File ""/home/moritz/Python/anaconda3/lib/python3.5/site-packages/requests/packages/urllib3/contrib/pyopenssl.py"", line 324, in getpeercert
    'subjectAltName': get_subj_alt_name(x509)
  File ""/home/moritz/Python/anaconda3/lib/python3.5/site-packages/requests/packages/urllib3/contrib/pyopenssl.py"", line 171, in get_subj_alt_name
    ext = cert.extensions.get_extension_for_class(
AttributeError: 'Extensions' object has no attribute 'get_extension_for_class'`


Any idea what the issue could be here? Many thanks in advance.
","please see here:
https://github.com/conda/conda/issues/3929

The issue was an old version of the cryptography package. It could be fixed by running:

CONDA_SSL_VERIFY=false conda update pyopenssl

","Another way to disable verification of SSL certificates that will work on Windows as well:

add ssl_verify: False to .condarc file.

.condarc file is not included by default, but it is automatically created in the user’s home directory the first time you run the conda config command.

To set ssl_verify the following command can be used:

conda config --set ssl_verify False.
",,false,,,
https://stackoverflow.com/questions/36663613,true,The issue involves the unexpected results of column colors in the clustermap generated by the seaborn library. The API in question is the seaborn.clustermap.,Seaborn,seaborn.clustermap,"When using the seaborn.clustermap to visualize clusters of columns with different colors, the colors do not accurately represent the labels assigned to the columns.","The seaborn.clustermap is applied to a dataframe with columns representing different clusters, and the col_colors parameter is used to assign colors to the columns based on their labels.","The issue is triggered when the seaborn.clustermap is used with the col_colors parameter, and the assigned colors do not accurately represent the labels assigned to the columns.",This issue might be challenging to detect for users who are not familiar with the specific behavior of the seaborn.clustermap function or those who assume that the assigned colors will accurately represent the labels.,Python Seaborn Matplotlib setting line style as legend,"I have the following plot build with seaborn using factorplot() method.
Is it possible to use the line style as a legend to replace the legend based on line color on the right?  
graycolors = sns.mpl_palette('Greys_r', 4)
g = sns.factorplot(x=""k"", y=""value"", hue=""class"", palette=graycolors,
                   data=df, linestyles=[""-"", ""--""])

Furthermore I'm trying to get both lines in black color using the color=""black"" parameter in my factorplot method but this results in an exception ""factorplot() got an unexpected keyword argument 'color'"". How can I paint both lines in the same color and separate them by the linestyle only?
","I have been looking for a solution trying to put the linestyle in the legend like matplotlib, but I have not yet found how to do this in seaborn. However, to make the data clear in the legend I have used different markers:
import seaborn as sns
import numpy as np
import pandas as pd

# creating some data
n = 11
x = np.linspace(0,2, n)
y = np.sin(2*np.pi*x)
y2 = np.cos(2*np.pi*x)
data = {'x': np.append(x, x), 'y': np.append(y, y2),
        'class': np.append(np.repeat('sin', n), np.repeat('cos', n))}
df = pd.DataFrame(data)

# plot the data with the markers
# note that I put the legend=False to move it up (otherwise it was blocking the graph)
g=sns.factorplot(x=""x"", y=""y"", hue=""class"", palette=graycolors,
                 data=df, linestyles=[""-"", ""--""], markers=['o','v'], legend=False)
# placing the legend up
g.axes[0][0].legend(loc=1)
# showing graph
plt.show()


","you can try the following:

h = plt.gca().get_lines()
lg = plt.legend(handles=h, labels=['YOUR Labels List'], loc='best')


It worked fine with me.
",,false,,,
https://stackoverflow.com/questions/46826093,false,"The issue is not related to an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is a permission problem with anaconda, which is not an API-specific problem.",,,,,,,Permission Error For Conda Update,"Python newbie here. I have encountered a permission problem with anaconda. Everything runs ok, but I do not seem to be able to update conda, create new environments or install new packages.

When I try to update (conda update conda) it I get:


  Fetching package metadata ..... An unexpected error has occurred.
    Please consider posting the following information to the
    conda GitHub issue tracker at:
  
  https://github.com/conda/conda/issues


Current conda version:

platform : osx-64
conda version : 4.3.29
conda is private : False
conda-env version : 4.3.29
conda-build version : not installed
python version : 2.7.11.final.0
requests version : 2.14.2
root environment : /anaconda  (writable)
default environment : /anaconda
envs directories : /anaconda/Users/Tina/.conda/envs
package cache : /anaconda/Users/Tina/.conda/pkgs
channel URLs : https://conda.anaconda.org/anaconda-fusion/osx-64
               https://conda.anaconda.org/anaconda-fusion/noarch
               https://repo.continuum.io/pkgs/main/osx-64
               https://repo.continuum.io/pkgs/main/noarch
               https://repo.continuum.io/pkgs/free/osx-64
               https://repo.continuum.io/pkgs/free/noarch
               https://repo.continuum.io/pkgs/r/osx-64
               https://repo.continuum.io/pkgs/r/noarch
               https://repo.continuum.io/pkgs/pro/osx-64
               https://repo.continuum.io/pkgs/pro/noarch
config file : /Users/Tina/.condarc
netrc file : None
offline mode : False
user-agent : conda/4.3.29 requests/2.14.2 CPython/2.7.11 Darwin/15.5.0 OSX/10.11.5    
UID:GID : 501:20


$ /anaconda/bin/conda update conda

Traceback (most recent call last):
  File ""/anaconda/lib/python2.7/site-packages/conda/exceptions.py"", line 640, in conda_exception_handler
    return_value = func(*args, **kwargs)
  File ""/anaconda/lib/python2.7/site-packages/conda/cli/main.py"", line 140, in _main
    exit_code = args.func(args, p)
  File ""/anaconda/lib/python2.7/site-packages/conda/cli/main_update.py"", line 65, in execute
    install(args, parser, 'update')
  File ""/anaconda/lib/python2.7/site-packages/conda/cli/install.py"", line 231, in install
    unknown=index_args['unknown'], prefix=prefix)
  File ""/anaconda/lib/python2.7/site-packages/conda/core/index.py"", line 101, in get_index
    index = fetch_index(channel_priority_map, use_cache=use_cache)
  File ""/anaconda/lib/python2.7/site-packages/conda/core/index.py"", line 120, in fetch_index
    repodatas = collect_all_repodata(use_cache, tasks)
  File ""/anaconda/lib/python2.7/site-packages/conda/core/repodata.py"", line 75, in collect_all_repodata
    repodatas = _collect_repodatas_serial(use_cache, tasks)
  File ""/anaconda/lib/python2.7/site-packages/conda/core/repodata.py"", line 485, in _collect_repodatas_serial
    for url, schan, pri in tasks]
  File ""/anaconda/lib/python2.7/site-packages/conda/core/repodata.py"", line 115, in func
    res = f(*args, **kwargs)
  File ""/anaconda/lib/python2.7/site-packages/conda/core/repodata.py"", line 467, in fetch_repodata
    touch(cache_path)
  File ""/anaconda/lib/python2.7/site-packages/conda/gateways/disk/update.py"", line 64, in touch
    utime(path, None)
OSError: [Errno 13] Permission denied: '/anaconda/pkgs/cache/9cd9d6b5.json'```


I get the same error when trying to install seaborn or creating an environment. I am reluctant to use sudo because I do not want to break things.

I do not understand what is going on here, so any help would be highly appreciated. 

Thanks so much; 
T
","For humble Windows users that cannot use sudo: You have to open the conda console as Administrator by right clicking on the console icon and then select run as administrator. Then conda update conda should work fine.
","The user that you are using to run conda update conda does not have write permission on /anaconda/pkgs/cache/.

If you don't want to manage anaconda as the superuser, I would recommend that you create a new user group (i.e. anaconda_admin) and run:

sudo groupadd anaconda_admin
sudo chown -R :anaconda_admin /anaconda


Then you will need to ensure that permissions are something like:

sudo chmod -R 775 /anaconda


And finally that your user is in the anaconda_admin group:

sudo adduser &lt;&lt;&lt;your_user&gt;&gt;&gt; anaconda_admin

","You ought to use sudo in order to write certain files into system. It is perfectly fine and will not break you OS, unless you work with sophisticated and rudimentary packages and installers (conda and python libraries are absolutely fine).

sudo conda update conda should do the thing not only with updating conda, but also with other dependencies and packages you wish to install.

In short, the installer tries to write a file into a certain directory (or modify a file in a directory) that it has not got an access to. With sudo you make them do that as you run it with appended priviliges.
",false,,,
https://stackoverflow.com/questions/33423758,false,"The issue is related to creating a multiple-series scatter plot with connected points using seaborn. However, the problem is not caused by an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is a misunderstanding of how to achieve the desired plot using seaborn.",,,,,,,How to create multiple series scatter plot with connected points using seaborn?,"I have a set of data stored in a pandas dataframe. I'm trying to use seaborn's pointplot() to create a multiple-series scatter plot with connected points. Each series has different (x,y) values, and they are stored as floats in my data frame. Each row has a label, differentiating each series. I'm using Python 2.7, seaborn version 0.5.1, and matplotlib version 1.4.3. 

Everything I've managed to find tells me that I can achieve this with the following:

import matplotlib.pyplot as plt
import seaborn as sns

# Suppose my dataframe is called 'df', with columns 'x', 'y', and 'label'.
sns.pointplot(x = 'x', y = 'y', hue = 'label', data = df)


However, this results in some strange behavior:


The colors are correctly identified, but only some of the points are connected 
The numbers on the x-axis overlap and it appears as though each data point is being labeled with it's value rather than scaling it with appropriate, clean values (seems to be treating the x data as a string/label rather than floats).


I attempted to work around this by splitting my data frame into pieces. This is not ideal because I may have about 10+ series to plot simultaneously, and I'd prefer to not split the data manually:

df1 = df[df.test_type.values == ""label 1""]
df2 = df[df.test_type.values == ""label 2""]

ax = sns.pointplot(x = 'x',y='y', color = ""blue"", data = df1)
sns.pointplot(x = 'x', y = 'y', data = df2, color=""red"", ax = ax)


In this case, all points are connected and they are colored appropriately, but again, the x axis is showing very strange behavior. Even though my x-values from each data frame are different, the plot aligns them so that they appear to be the same.

Now, I'm not sure how to post my output/plots cleanly, but some of my problems can be recreated with the following:

#import the necessary modules
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

#Here is some sample data. The 'x2' data is slightly offset from 'x1'
x1 = range(0,100,10)
x2 = range(1,100,10)
x = x1+x2

#The y-values I generate here mimic the general shape of my actual data
y1 = x1[::-1]
y2 = [i+25 for i in x1[::-1]]
y = y1+y2

#Two levels of labels that will be applied to the data
z1 = [""1""]*10
z2 = [""2""]*10
z = z1+z2

#A pandas data frame from the above data
df = pd.DataFrame({'x': x, 'y': y, 'z': z})

#Pointplot using the above data
sns.pointplot(x = 'x', y = 'y', data = df, hue = 'z')


Running this code results in the following:


All x values across all series are spaced evenly. Note that the 'x2' values are the same as 'x1' translated by '1' and they are spaced at intervals of 10 within each series. I did not expect this behavior.
The x axis doesn't have a ""clean"" looking scale. It literally labels each point's corresponding x-value. It labels the points correctly, but does not scale it appropriately. It seems like it's treating the x values as labels, similar to how a bar graph might behave.
The points are colored correctly, but no points are connected.


To summarize my question:

Is there an easier/better/more elegant way to plot multiple-series scatter plots with connected points using data stored in a pandas data frame? Seaborn's pointplot looked ideal, but it is not functioning as I expected and I'm suspecting that it might serve a purpose different from what I need to accomplish. I'm open to other solutions that can achieve this (preferably using python).

Thanks in advance. I will update my question if I can figure out how to upload the output and plots from my code.

I'm 100% new to stackoverflow. I'd love to clarify my question by posting the plots being generated by my code, but I could not figure this out. Any pointers on how to do this would be much appreciated as well so I can update the question.

EDIT: It turns out that seaborn's pointplot uses the x-axis as a categorical axis, which explains the strange behavior I've mentioned above. Is there a way to manually change the x-axis behavior from categorical to numerical? This seems like the easiest approach but I'm not very familiar with fine-tuning plots in python.
","I had a similar problem and I finally solved it using Seaborn's FacetGrid. I used plt.scatter for the points and the plt.plot for lines connecting the points.
g = sns.FacetGrid(df, hue=""z"", size=8)
g.map(plt.scatter, ""x"", ""y"")
g.map(plt.plot, ""x"", ""y"")


Note, this is done in Seaborn version 0.6.0 and version 0.5.1.
","With the help of @mwaskom and this question, I've managed to find a solution to my posted question:

#Assuming df is a pandas data frame with columns 'x', 'y', and 'label'
for key,grp in df.groupby('label'):
    plt.plot(grp.x,grp.y,'o-',label = key)
plt.legend(loc = 'best')

",,false,,,
https://stackoverflow.com/questions/29253027,false,"The issue is related to a strange behavior when using pandas and seaborn to plot a scatter plot with only three points. However, the problem is not caused by an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is a known bug in pandas, seaborn, and matplotlib that leads to inconsistent colors in the scatter plot.",,,,,,,pandas scatter plot colors with three points and seaborn,"There is a strange behavior when using pandas and seaborn to plot a scatter plot that has only three points: the points don't have the same color. The problem disappears when seaborn is not loaded or when there are more than three points, or when plotting with matplotlib's scatter method directly. See the following example:

from pandas import DataFrame #0.16.0
import matplotlib.pyplot as plt #1.4.3
import seaborn as sns #0.5.1
import numpy as np #1.9.2

df = DataFrame({'x': np.random.uniform(0, 1, 3), 'y': np.random.uniform(0, 1, 3)})
df.plot(kind = 'scatter', x = 'x', y = 'y')
plt.show()




df = DataFrame({'x': np.random.uniform(0, 1, 4), 'y': np.random.uniform(0, 1, 4)})
df.plot(kind = 'scatter', x = 'x', y = 'y')
plt.show()



","I've tracked down the bug. The bug is in pandas technically, not seaborn as I originally thought, though it involves code from pandas, seaborn, and matplotlib...

In pandas.tools.plotting.ScatterPlot._make_plot the following code occurs to choose the colours to be used in the scatter plot

if c is None:
    c_values = self.plt.rcParams['patch.facecolor']
elif c_is_column:
    c_values = self.data[c].values
else:
    c_values = c


In your case c will be equal to None, which is the default value, and so c_values will be given by plt.rcParams['patch.facecolor'].

Now, as part of setting itself up, seaborn modifies plt.rcParams['patch.facecolor'] to (0.5725490196078431, 0.7764705882352941, 1.0) which is an RGB tuple. If seaborn is not used then the value is the matplotlib default which is 'b' (a string indicating the colour ""blue"").

c_values is then used later on to actually plot the graph within ax.scatter

scatter = ax.scatter(data[x].values, data[y].values, c=c_values,
                     label=label, cmap=cmap, **self.kwds)


The issue arises because the keyword argument c can accept multiple different types of argument, it can accept:- 


a string (such as 'b' in the original matplotlib case); 
a sequence of color specifications (say a sequence of RGB values); 
a sequence of values to map onto the current colormap. 


The matplotlib docs specifically state the following, highlighting mine


  c can be a single color format string, or a sequence of color specifications of length N, or a sequence of N numbers to be mapped to colors using the cmap and norm specified via kwargs (see below). Note that c should not be a single numeric RGB or RGBA sequence because that is indistinguishable from an array of values to be colormapped. c can be a 2-D array in which the rows are RGB or RGBA, however.


What basically happens is that matplotlib takes the c_values value (which is a tuple of three numbers) and then maps those colours onto the current colormap (which is set by pandas to be Greys by default). As such, you get three scatter points with different ""greyishness"". When you have more than 3 scatter points, matplotlib assumes that it must be a RGB tuple because the length doesn't match the length of the data arrays (3 != 4) and so uses it as a constant RBG colour.

This has been written up as a bug report on the pandas Github here.
","You might want to try this:

import seaborn.apionly as sns


And see This question for more details.
",,false,,,
https://stackoverflow.com/questions/49185427,false,"The issue is related to plotting two plots on top of each other in seaborn, where the regplot appears to be off by one. However, the problem is not caused by an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is a discrepancy in the behavior of seaborn's barplot and regplot, which can be resolved by using pure matplotlib or adjusting the x-axis locations.",,,,,,,Seaborn two plots on one fig: x-values are is off by one,"I'm experience strange behavior when plotting two plots on top of each other in seaborn. The bar plot appears to work fine, but the regplot appears to be off by one. Note the lack of a reg data point for x=1, and compare the x=2 value to the value in the table for x below, it's clearly off by one.



My pandas Dataframe looks like this:

    Threshold per Day   # Alarms    Percent Reduction
0   1                   791         96.72
1   2                   539         93.90
2   3                   439         91.94
3   4                   361         89.82
4   5                   317         88.26
5   6                   263         85.94
6   7                   233         84.41
7   8                   205         82.78
8   9                   196         82.17
9   10                  176         80.66


The code I'm using here is:

%matplotlib inline

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

fig, ax = plt.subplots()

ax2 = ax.twinx()
sns.barplot(x='Threshold per Day', y=""# Alarms"", data=results_df, ax=ax, color='lightblue')
sns.regplot(x='Threshold per Day', y='Percent Reduction', data=results_df, marker='x', fit_reg=False, ax=ax2)


Any ideas what's going on or how to fix it?
","Caveat: This only addresses a possible fix, I don't know why that is happening in seaborn (but see Edit and comment)

If you're looking just to get a decent plot in the meantime, I would recommend just switching to pure matplotlib, at least just for this plot and any others with similarly strange behaviour. You can get a very similar plot with the following code:

fig, ax = plt.subplots(1,1, sharex=True)
ax2 = ax.twinx()

ax.bar(results_df['Threshold per Day'], results_df['# Alarms'], color='lightblue')
ax2.scatter(results_df['Threshold per Day'], results_df['Percent Reduction'], marker='x')
ax.set_ylabel('# of Alarms')
ax2.set_ylabel('Percent Reduction')
ax.set_xlabel('Threshold Per Day')
plt.xticks(range(1,11))
plt.show()




Edit to take into account ImportanceOfBeingErnest's comment:

You can obtain this plot in seaborn using:

fig, ax = plt.subplots()
ax2 = ax.twinx()

sns.barplot(x=results_df['Threshold per Day'], 
            y=results_df[""# Alarms""], ax=ax, color='lightblue')
sns.regplot(x=np.arange(0,len(results_df)), 
            y=results_df['Percent Reduction'], marker='x', 
            fit_reg=False, ax=ax2)
plt.show()


Turns out that in matplotlib, a barplot's category seems to be interpreted as a numeric when possible, whereas in seaborn, it is interpreted as a string, and the locations start at location 0 by default; as your regplot is evenly spaced on the x axis, you can just force their locations onto a range from 0 to the length of your dataframe as above.
",,,false,,,
https://stackoverflow.com/questions/48197738,false,"The issue is related to recreating seaborn's fill-only confidence interval plotting in raw matplotlib, where the fill_between function leaves gaps. However, the problem is not caused by an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is likely due to the data not being sorted, which can be resolved by sorting the data before plotting.",,,,,,,matplotlib fill_between leaves gaps,"I'm trying to recreate seaborn's fill-only confidence interval plotting in raw matplotlib.  In doing so, I'm running into strange behavior where the fill_between function leaves gaps between the stuff it's supposed to be filling.

I'm using real-world data on this, but it's well-behaved data: the x values are on the range of about 0-15, and the y values on a range of about 25-85.  I'm using statsmodels to fit the line and generate the confidence intervals with essentially the code from this prior SO, and the fitted values as well as the upper and lower bounds of the confidence intervals are as they should be (the ranges are appropriate, etc.).  So there's nothing wrong with the data.

Here's the relevant part of the code:

def make_plot(x, y):
    fig = plt.figure(figsize=(12, 9))
    ax = fig.add_subplot(1, 1, 1)
    ax.plot(x, y, 'k.', ms=5)
    ax.locator_params(nbins=3)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    regline =  sm.OLS(y,sm.add_constant(x)).fit()
    fitted = regline.fittedvalues
    ax.plot(x, fitted, color=(0.2, 0.2, 0.2, 0.2), linewidth=2)
    ci_low, ci_high = get_ci_values(regline)
    ax.fill_between(x, ci_low, fitted, facecolor=(0.4, 0.4, 0.9, 0.2))
    ax.fill_between(x, ci_high, fitted, facecolor=(0.9, 0.4, 0.4, 0.2))
    return fig


The line fill works fine until it hits around x=10, y=50, and then it starts to leave bizarre gaps where it doesn't come all the way to the regression line.  Here's an example: 



What have I done wrong here?  I've tried a bunch of stuff, including: 


adding lines for the low and high confidence intervals
adding interpolate=True to the fill_between calls
adding where=x&gt;0 to the fill_between calls


but none of that makes any difference.

I also note that seaborn manages to make its beautiful fills using fill_between, using exactly the same strategy, and seaborn's plotting works correctly on the data I'm using...
","One cannot know for sure because the question is missing the essential part, namely the data itself (see Minimal, Complete, and Verifiable example). 

The strong suspicion here would however be that the data is not sorted. 

The (untested) solution would be to sort the data, 

ax.plot(np.sort(x), fitted[np.argsort(x)])
ax.fill_between(np.sort(x), ci_low[np.argsort(x)], fitted[np.argsort(x)])


To understand why values need to be sorted, maybe a picture can tell more than a thousands words.


",,,false,,,
https://stackoverflow.com/questions/69810007,false,The issue does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is a question about customizing tick labels in a seaborn catplot.,,,,,,,How to customize the text ticklabels for each subplot of a seaborn catplot,"Let us consider the following example (from Seaborn documentation):
titanic = sns.load_dataset(""titanic"")

fg = sns.catplot(x=""age"", y=""embark_town"",
                hue=""sex"", row=""class"",
                data=titanic[titanic.embark_town.notnull()],
                orient=""h"", height=2, aspect=3, palette=""Set3"",
                kind=""violin"", dodge=True, cut=0, bw=.2)

Output:

I want to change the tick labels on the y axis, for example by prepending a number in parenthesis: (1) Southampton, (2) Cherbourg, (3) Queenstown. I have seen this answer, and I have tried to use a FuncFormatter, but I obtain a strange result. Here is my code:
titanic = sns.load_dataset(""titanic"")

fg = sns.catplot(x=""age"", y=""embark_town"",
                hue=""sex"", row=""class"",
                data=titanic[titanic.embark_town.notnull()],
                orient=""h"", height=2, aspect=3, palette=""Set3"",
                kind=""violin"", dodge=True, cut=0, bw=.2)

from matplotlib.ticker import FuncFormatter
for ax in fg.axes.flat:
    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f'({1 + pos}) {x}'))

And here is the output:

It looks like x is the same as pos in the lambda. I was expecting x to be the value of the tick label (i.e. Southampton, Cherbourg, Queenstown). What am I doing wrong?

Software versions:
matplotlib                         3.4.3
seaborn                            0.11.2

","
Similar to the answers for How to rotate xticklabels in a seaborn catplot, but requiring customized text for each tick of each subplot.
Text labels work differently than numeric labels that are in the other example. Numeric labels match the tick position, but that is not the case for text labels.
.get_yticklabels() gets [Text(0, 0, 'Southampton'), Text(0, 1, 'Cherbourg'), Text(0, 2, 'Queenstown')] for each subplot
As shown below, extract the text and position, and the use .set_yticklabels to set the new text label
Tested in python 3.8.12, matplotlib 3.4.3, seaborn 0.11.2

import seaborn as sns

titanic = sns.load_dataset(""titanic"")

fg = sns.catplot(x=""age"", y=""embark_town"",
                hue=""sex"", row=""class"",
                data=titanic[titanic.embark_town.notnull()],
                orient=""h"", height=2, aspect=3, palette=""Set3"",
                kind=""violin"", dodge=True, cut=0, bw=.2)

for ax in fg.axes.flat:  # iterate through each subplot
    labels = ax.get_yticklabels()  # get the position and text for each subplot
    for label in labels:
        _, y = label.get_position()  # extract the y tick position
        txt = label.get_text()  # extract the text
        txt = f'({y + 1}) {txt}'  # update the text string
        label.set_text(txt)  # set the text
    ax.set_yticklabels(labels)  # update the yticklabels


",,,false,,,
https://stackoverflow.com/questions/22591174/pandas-multiple-conditions-while-indexing-data-frame-unexpected-behavior,false,The issue does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is a question about the behavior of logical operators in pandas indexing.,,,,,,,,,,,,false,,,
https://stackoverflow.com/questions/48232563,false,The issue does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is a question about the behavior of seaborn heatmaps when plotted in a sequence.,,,,,,,Difficulty plotting sequence of seaborn heatmaps,"Whenever I plot a single seaborn heatmap, I get a beautiful result which looks like this:



But, when I try to plot a sequence of seaborn heatmaps, as follows, I get really strange output:

for i in range(5):

    # create mesh grid:
    res = 0.1 ## set resolution
    X,Y = 10, 10
    xy = np.mgrid[0:int(X):res, 0:int(Y):res].reshape(2,-1).T
    values = np.sum(xy,1)
    sns.heatmap(values.reshape((int(X/res),int(Y/res))),cmap=""YlGnBu"")

    plt.savefig(folder+""_""+str(i)+""_.png"")


The first image in the sequence is perfect but the second looks like this:



The third looks like this:



...and so forth. For reasons I can't understand it appears that seaborn is somehow adding a new colour bar each time. 

This problem is non-existent when I set cbar to False but I actually want a colour bar for each individual heatmap. 
","It seems you rather want to create 5 individual figures. In order to create a figure, you may use plt.figure()

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

for i in range(5):
    plt.figure()
    # create mesh grid:
    res = 0.1 ## set resolution
    X,Y = 10, 10
    xy = np.mgrid[0:int(X):res, 0:int(Y):res].reshape(2,-1).T
    values = np.sum(xy,1)
    sns.heatmap(values.reshape((int(X/res),int(Y/res))),cmap=""YlGnBu"")

    plt.savefig(""seaborn_""+str(i)+""_.png"")

plt.close(""All"")


Alternatively you may clear the figure with plt.clf().

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

for i in range(5):
    plt.clf()
    # create mesh grid:
    res = 0.1 ## set resolution
    X,Y = 10, 10
    xy = np.mgrid[0:int(X):res, 0:int(Y):res].reshape(2,-1).T
    values = np.sum(xy,1)
    sns.heatmap(values.reshape((int(X/res),int(Y/res))),cmap=""YlGnBu"")

    plt.savefig(""seaborn_""+str(i)+""_.png"")

",,,false,,,
https://stackoverflow.com/questions/53730486,false,The issue does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is a question about removing lines between cells in a seaborn heatmap.,,,,,,,Seaborn Heatmap without lines between cells,"I´m trying to create a heatmap with seaborn with a transparent colormap since an image should be displayed in the background. The heatmap creation works fine so far, however some lines between the cells are still visible even though the linewidth of the heatmap is set to 0.0.

The code for the creation of the heatmap looks like the following:

ax = sns.heatmap(image, cmap=""rocket_r"", linewidths=0.0)
ax.collections[0].set_alpha(0.5)


Where image is 64x64 numpy array. The resulting heatmap looks like this:
Heatmap (sorry not enough repuation for embedding pictures)

The problem are the thin lines between the cells. Strangely they aren´t at every edge.

Anyone knows how to get rid of those lines?

Many Thanks



Update 1 (Complete working example):

image = np.array([[1, 1, 2, 2], [3, 3, 3, 3], [4, 5, 4, 5], [6, 6, 6, 6]])
ax = sns.heatmap(image, cmap=""rocket_r"", linewidths=0.0)
ax.collections[0].set_alpha(0.5)
plt.show()


Results is this heatmap: 



Here you can see that there are thin lines between every column but there isn´t any line between the first and second row.
","The lines are the overlapping of semitransparent patches which cannot be perfectly aligned on the pixel grid.
alpha blending
An option is to not use transparency, but instead create opaque colors with alpha blending.
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
import numpy as np
import seaborn as sns

def get_alpha_blend_cmap(cmap, alpha):
    cls = plt.get_cmap(cmap)(np.linspace(0,1,256))
    cls = (1-alpha) + alpha*cls
    return ListedColormap(cls)

image = np.array([[1, 1, 2, 2], [3, 3, 3, 3], [4, 5, 4, 5], [6, 6, 6, 6]])
ax = sns.heatmap(image, cmap=get_alpha_blend_cmap(""rocket_r"", 0.5), linewidths=0.0)

plt.show()


An obvious advantage of this is that the colorbar has the same colors as the heatmap.
increase dpi
If the above is not an option you may increase the dpi when saving.
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

image = np.array([[1, 1, 2, 2], [3, 3, 3, 3], [4, 5, 4, 5], [6, 6, 6, 6]])
ax = sns.heatmap(image, cmap=""rocket_r"", linewidths=0.0, edgecolor=""none"", alpha=0.5)
plt.savefig(""test.png"", dpi=1000)


This does of course not have any effect on the figure shown on screen though.
imshow
Finally, consider not using seaborn here, but instead a matplotlib imshow plot.
import matplotlib.pyplot as plt
import seaborn as sns
plt.style.use(""seaborn-dark"")
plt.rcParams[""axes.facecolor""] = ""white""
import numpy as np

image = np.array([[1, 1, 2, 2], [3, 3, 3, 3], [4, 5, 4, 5], [6, 6, 6, 6]])
im = plt.imshow(image, cmap=""rocket_r"", alpha=0.5)
plt.colorbar(im)
plt.gca().set(xticks=(range(image.shape[1])),yticks=(range(image.shape[0])))
plt.show()


","I have just come across this problem. I need to upload the plot to overleaf, so I do not like the dpi solutions. Here is what I came up with, based on the solution of OP:
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

image = np.array([[1, 1, 2, 2], [3, 3, 3, 3], [4, 5, 4, 5], [6, 6, 6, 6]])
ax = sns.heatmap(image, cmap=""rocket_r"", linewidths=0.1)
colors = ax.collections[0].get_facecolors()
ax.collections[0].set_edgecolors(colors)
plt.imshow()

The idea is to create a thin edge around each cell with the cell's facecolor. This removes the lines without changing the original cell colors.
",,false,,,
https://stackoverflow.com/questions/71161147,false,The issue does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is a question about plotting lineplots and barplots on the same plot with seaborn.,,,,,,,How to plot seaborn lineplot and barplot on the same plot with same number of y-axes tickers and both y-axes aligned at 0 in Python,"I am having trouble plotting a lineplot and barplot (with the same inexes) on the same seaborn plot using data from the ‘results’ dataframe which I will show below (with ‘a’ data, ‘b’ data, and ‘percentiles’) in Python.
When I plot them separately, I am able to plot the lineplot fine (using ‘a’ data), however, the x-axis values of the barplot I am trying to plot (using 'b' data) does not show up. Strangely, I can plot a lineplot without any problem using the same data I am trying to plot the barplot with (‘b’ data)
When I try to plot them on the same plot, the x-axis starts from a date that is not even present in the ‘results’ dataframe.
I have even tried exporting the results dataframe as a csv and re-importing it to see if that works, but I run into the same problems.
What I would like to achieve:

Plotting the ‘a’ data as a lineplot, and the ‘b’ data as a bar plot on the same seaborn plot with different y-axes
I would like to have the same number of y-axis tickers and for the 0’s of both the y-axes to be aligned
Finally, I would like the colour of the barplot to be dependent on whether the percentile column indicated ‘low’, ‘mid’, ‘high’ (a different colour for each of these)

# Here is the 'a' and 'b' data that I start with

a = pd.read_csv(r'a.csv',sep="","", parse_dates=['date'], dayfirst=True, index_col=0)

b = pd.read_csv(r'b.csv',sep="","", parse_dates=['date'], dayfirst=True, index_col=0)

'a' DataFrame
'b' DataFrame
# After manipulating the data, here is the 'results' DataFrame I end up with

'results' DataFrame
# Plotting them separately

# Plotting lineplot using 'a' column from 'results' DataFrame

sns.lineplot(data=result.iloc[:, 0], color=""g"")

lineplot
# Plotting barplot using 'b' column from 'results' DataFrame

b_plot = sns.barplot(data=result, x=result.index, y=result.iloc[:, 2], color=""b"")

b_plot.xaxis.set_major_locator(md.YearLocator(base=4)) 
b_plot.xaxis.set_major_formatter(md.DateFormatter('%Y'))
b_plot.margins(x=0)

barplot
# Attempting to plot the lineplot and barplot on the same plot

matplotlib.rc_file_defaults()
ax1 = sns.set_style(style=None, rc=None)
fig, ax1 = plt.subplots(figsize=(12,6))

a_plot = sns.lineplot(data=result.iloc[:, 0], color=""g"", ax=ax1)
ax2 = ax1.twinx()
b_plot = sns.barplot(data=result, x=result.index, y=result.iloc[:, 2], color=""b"", ax=ax2)

b_plot.xaxis.set_major_locator(md.YearLocator(base=4)) 
b_plot.xaxis.set_major_formatter(md.DateFormatter('%Y'))
b_plot.margins(x=0)

lineplot and barplot on same plot
EDIT: I have answered the questions below
","Here are the answers to my questions:
matplotlib.rc_file_defaults()
ax1 = sns.set_style(style=None, rc=None)
fig, ax1 = plt.subplots(figsize=(12,6))
ax2 = ax1.twinx()

# plot the bar plot and make the colours dependent on the values in a seperate column
result_date = result.reset_index()
    
palette = {""low"":""lightgreen"",
           ""mid"":""darkseagreen"", 
           ""high"":""green""}

b_plot = sns.barplot(data = result_date, x=result_date.iloc[:, 0], 

y=result_date.iloc[:, 3], ax=ax1, hue='percentile', palette=palette, dodge = False)

# plot the lineplot
a_plot = sns.pointplot(data=result, x=result.index, y=result.iloc[:, 0], color=""black"", ax=ax2, markers = 'o', scale=0.4)

# set the x tickers to be those of the bar plot
ax1.set_xticks(np.arange(len(result_date)))
ax1.set_xticklabels(result_date.date.apply(lambda x: str(x.year)))
ax1.xaxis.set_major_locator(ticker.AutoLocator())
    
# align axis at 0, and get same number of ticks on both y-axes
max1 = np.nanmax(np.abs(ax1.get_ybound())) 
max2 = np.nanmax(np.abs(ax2.get_ybound()))
nticks = 7 
    
ax1.set_yticks(np.linspace(-max1, max1, nticks))
ax2.set_yticks(np.linspace(-max2, max2, nticks))


","Here's an example of what I suggested in the comments.
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

data = pd.DataFrame({'Day': [1, 2, 3, 4], 'Value': [3, 7, 4, 2], 'Value 2': [1, 7, 4, 5]})

f, ax = plt.subplots()
sns.barplot(data=data, x='Day', y='Value')

Edit: use pointplot here to align the entries.
sns.pointplot(data=data, x='Day', y='Value 2')


",,false,,,
https://stackoverflow.com/questions/69864891,true,The issue involves an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. The solution involves converting the counts for one gender group to negative values to create a population pyramid effect.,,,,,,,How to build a population pyramid with pandas dataframe,"How to  plot a population pyramid based on the following starting dataframe?
           Age  Gender  Count
0  50-45 years    male      4
1  50-45 years  female      5
2  55-65 years    male      6
3  55-65 years  female      7
4  65-70 years    male     11
5  65-70 years  female     12

I tried the following, Population Pyramid with Python and Seaborn, but the resulting plot looks strange:
import pnadas as pd
import seaborn as sns

# data
data = {'Age': ['50-45 years', '50-45 years', '55-65 years', '55-65 years', '65-70 years', '65-70 years'],
        'Gender': ['male', 'female', 'male', 'female', 'male', 'female'], 'Count': [4, 5, 6, 7, 11, 12]}

df = pd.DataFrame(data)

# plot
sns.barplot(data=df, x='Count', y='Age',
            hue='Gender', orient='horizontal', 
            dodge=False)

I think the problem is that my age is a string.

","
Unlike in the linked question, 'Count' for both 'Gender' groups is positive, so with dodge=False, the 'Female' bars are drawn on top of the 'Male' bars.
Convert one of the groups to negative values, using .loc and Boolean selection.

# convert male counts to negative
df.loc[df.Gender.eq('male'), 'Count'] = df.Count.mul(-1)

# plot
sns.barplot(data=df, x='Count', y='Age', hue='Gender', orient='horizontal', dodge=False)


",,,false,,,
https://stackoverflow.com/questions/62480198,false,The issue does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is a question about the date format in seaborn pointplots.,,,,,,,Date format changed using seaborn pointplot,"When I use seaborn to draw a pointplot, the date on the x-axis changes to this strange format 2020-01-06T00:00:00.000000000. The dates from the 'Current Year Week Ending' column are converted to DateTime object before drawing this figure. My other graph (lineplot) uses similar inputs and format, but it doesn't have this issue, the dates are like 2020-01-06.

Does anyone know how to fix this problem?

*The total_us dataframe and sub dataframe I use in my plots are subsets of the same dataset. And I converted the date on that big dataset before creating those two subsets. So the value in 'Current Year Week Ending' column of total_us and sub should have the same DateTime format.

#create a pointplot to capture the variability                             
plt.figure(figsize = (8, 6))                                                  
sns.pointplot(x = 'Current Year Week Ending',                                               
              y = 'ASP Current Year', 
              hue ='Type', 
              data = sub, 
              markers=[""o"", ""x""],
              linestyles=[""-"", ""--""])                                
plt.xticks(rotation=45, horizontalalignment='right', fontweight='light', fontsize='medium')
plt.ticklabel_format(style='plain', axis='y')




#create a lineplot 
plt.figure(figsize=(10,7))
sns.lineplot(x='Current Year Week Ending', 
             y='Total Bulk and Bags Units', 
             hue='Type', 
             data = total_us);
plt.xticks(rotation=45, horizontalalignment='right', fontweight='light', fontsize='medium')
plt.ticklabel_format(style='plain', axis='y')




this is what sub looks like, so the values in 'Current Year Week Ending' column are like ""2020-01-06"". I don't know why it changes when I draw a pointplot.

","I think your date column may just include these trailing zeros, and seaborn deals with it differently depending on how much room there is on the plot. So try the following for your date column:
sub.iloc[:,1] = sub.iloc[:,1].dt.strftime('Y/%m/%d')

If for some reason that doesn't fix the problem (perhaps seaborn point plots and line plots do something different under the hood), then a possible workaround would be to split the text 2020-01-06T00:00:00.000000000 at the letter 'T' and throw out the trailing zeros after. We can use the fact that sns.pointplot returns a matplotlib.Axes object (from the documentation), setting the variable ax equal to your point plot:
ax = sns.pointplot(x = 'Current Year Week Ending',                                               
          y = 'ASP Current Year', 
          hue ='Type', 
          data = sub, 
          markers=[""o"", ""x""],
          linestyles=[""-"", ""--""]) 
ax.set_xticklabels([date_text.get_text().split(""T"")[0] for date_text in ax.get_xticklabels()])

",,,false,,,
https://stackoverflow.com/questions/54533396,false,The issue does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is a question about the axis limits in seaborn pairplots with regression plots.,,,,,,,Issue with axis limits when using seaborn pairplot with kind=&#39;reg&#39;,"I'm having a problem when trying to introduce a regression plot into a pairplot with seaborn.

Without trying to introduce any form of upper or lower plots I have the following:

ff = sns.pairplot(test3,hue='Kp',vars=['L','dtheta','D'],palette=""husl"")


which produces 


However, if I do the following:

ff = sns.pairplot(test3,hue='Kp',vars=['L','dtheta','D'],palette=""husl"")
ff.map_upper(sns.regplot)
ff.map_lower(sns.residplot)


The axis on the regplot behave very strangely


Does anybody know why this might be so? I have also tried with seaborn pairgrid but the same issue occurs!

EDIT: I know how to manually change the axes limits I'm mostly just wondering if there is something going on with seaborn
","A regplot extends the limits of the plot by a certain percentage to let the fitting line sit tight against the axis spines. But if this procedure is performed repeatedly, the second regplot will take the previously determined limits and again extend them, and so forth. This is what you observe in the plots: Starting from orange, each new regplot is some 10% larger then the previous.

An options would be to limit the regression line to the actual point spread. This is done by regplot's truncate keyword argument. 

g.map_upper(sns.regplot, truncate=True)


Note that you wouldn't want to use a pairplot in case you do custom mapping to the upper/lower part of the grid because that would lead to the points appear twice in the grid. Instead use a PairGrid.

df = sns.load_dataset(""iris"", cache=True)

g = sns.PairGrid(df, hue=""species"")

g.map_diag(sns.kdeplot)
g.map_upper(sns.regplot, truncate=True, scatter_kws=dict(alpha=0.2))
g.map_lower(sns.residplot)

plt.show()



",,,false,,,
https://stackoverflow.com/questions/71475575,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,cudf instllation issue on centos7,"I'm new to rapids ai libraries. I've an existing conda environment yaml file where I'm using python 3.8.5, tensorflow 2.7.0, opencv-python-headless 4.5.5.62, numpy 1.22.2, pandas 1.4.1, pandas-profiling 3.1.0, seaborn 0.11.2,  matplotlib 3.5.1, jupyterlab 3.2.9.
I've added below 2 channels to the file:

rapidsai
nvidia

And the below packages:

cudf=22.02
cudatoolkit=11.5

The installation is going on for hours and while trying to find incompatible packages, it seems to be in some sort of loop as I keep seeing below message multiple times in the terminal:
Found conflicts! Looking for incompatible packages.
Is there any known issue/limitations that I should be aware of?
Since we don't get interactive shell on GPU h/w easily, I'm trying the conda environment update on non-GPU machine and once installed, I'll try cudf package on GPU machine.
EDIT1:
This is what I have as working without tensorflow and tensorflow-hub

    name: cudf-env
        channels:
          - default
          - rmg
          - rapidsai
          - nvidia
          - numba
          - conda-forge
          - anaconda
        dependencies:
          - glibc=2.19
          - libgcc-ng=11.2.0
          - python=3.8.5
          - cudf=22.02
          - cudatoolkit=11.2
          - pytest=6.1.2
          - pandas=1.3.5
          - numpy=1.21.5
          - requests=2.25.0
          - scikit-learn=0.24.2
          - dill=0.3.4
          - tqdm=4.62.3
          - ruamel.yaml=0.17.19
          - yappi=1.3.3
          - black=22.1.0
          - pillow=9.0.1
          - jupyterlab=3.2.9
          - matplotlib=3.5.1
          - seaborn=0.11.2
          - plotly=5.6.0
          - pandas-profiling=3.1.0
          - black=22.1.0
        #  - pip
        #  - pip:
        #      - tensorflow==2.7.0
        #      - tensorflow-hub==0.12.0
        #      - opencv-python-headless==4.5.5.62
        #      - opencv-contrib-python-headless==4.5.5.62

Now, if I uncomment the pip section, the anaconda crashes while creating the environment. Since pip may not be supported with cudf, I tried following as well, the conda create env hangs while solving the environment (strangely, it's not resolving from conda-forge channel):

    name: cudf-env
        channels:
          - default
          - rmg
          - rapidsai
          - nvidia
          - numba
          - conda-forge
          - anaconda
        dependencies:
          - glibc=2.19
          - libgcc-ng=11.2.0
          - python=3.8.5
          - cudf=22.02
          - cudatoolkit=11.2
          - pytest=6.1.2
          - pandas=1.3.5
          - numpy=1.21.5
          - requests=2.25.0
          - scikit-learn=0.24.2
          - dill=0.3.4
          - tqdm=4.62.3
          - ruamel.yaml=0.17.19
          - yappi=1.3.3
          - black=22.1.0
          - pillow=9.0.1
          - jupyterlab=3.2.9
          - matplotlib=3.5.1
          - seaborn=0.11.2
          - plotly=5.6.0
          - pandas-profiling=3.1.0
          - black=22.1.0
          - tensorflow
          - tensorflow-hub

My system details are following:
$ cat /etc/os-release
NAME=""CentOS Linux""
VERSION=""7 (Core)""

$ uname -r
3.10.0-1127.10.1.el7.x86_64

EDIT2: I forgot to mention that if I comment out glibc, cudf and cudatoolkit, the tensorflow installation through pip works fine.
","Challenges updating conda environments can be tricky to untangle, but in this case the issue (in terms of cuDF) is likely the pinning of pandas to 1.4.1.
cuDF does not yet support pandas=1.4.1. The cuDF nightly packages currently support pandas &gt;=1.0,&lt;1.4.0dev0 (everything from 1.0 up to a dev build of 1.4.0). For the moment, if you switch to
pandas=1.3.5 things will work (assuming the other packages are compatible -- Tensorflow likely will require CUDA Toolkit 11.2, not 11.5, and some others might not be either). You can also let conda solve for the appropriate pandas version.
","I was finally able to complete the installation of cudf along with all the required packages after I reimaged my machine to Ubuntu20.04.
And I dropped below 2 packages as with Ubuntu20.04 I don't need those -
 - glibc=2.19
 - libgcc-ng=11.2.0

",,false,,,
https://stackoverflow.com/questions/58141158,false,The issue does not meet the criteria for deeper analysis as it is a general programming question and does not involve an API-related problem.,,,,,,,Seaborn renders plots slowly in apache zeppelin notebooks,"I am currently trying to generate visualizations in zeppelin (0.8.1) notebooks using the pyspark interpreter with python 3.7.3.

Generating the following simple plot with seaborn (0.9.0) takes around 5 minutes (with very high CPU usage throughout the duration): 

%pyspark
import seaborn as sns
import numpy as np
import pandas as pd

data = pd.DataFrame(np.random.rand(100,3))

sns.pairplot(data)


This behavior is rather inconsistent as the following (much more data intensive) plot is rendered instantly

%pyspark
import seaborn as sns
import numpy as np
import pandas as pd

df = pd.DataFrame(data = np.random.rand(10000,2))

sns.lineplot(x = 0, y = 1, data = df)


I noticed that using matplotlib (3.1.0) is generally much faster for and almost as snappy as I am used to from jupyter notebook environments.

I have already read about issue ZEPPELIN-1894 but I can render the mentioned scatterplot instantly as well.
","Ok, after posting here the solution is to use the %spark.ipyspark interpreter, this might require installing additional packages:

pip install protobuf grpcio

",,,false,,,
https://stackoverflow.com/questions/54145967,false,The issue does not meet the criteria for deeper analysis as it is a specific question about using seaborn and does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Not able to plot the heatmap of one column with respect to others,"With the help of the question: Correlation heatmap, I have tried the following: 

import pandas
import seaborn as sns 
dataframe = pandas.read_csv(""training.csv"", header=0,index_col=0)
for a in list(['output']):
    for b in list(dataframe.columns.values):
        corr.loc[a, b] = dataframe.corr().loc[a, b]
        print(b)
print(corr)
sns.heatmap(corr['output'])


I got the following error:  

IndexError: Inconsistent shape between the condition and the input (got (8, 1) and (8,))


I do not want to have the all values correlation heatmap with all values. I only want to have the correlation of one column with respect to others.   

Kindly, let me know what I am missing.
","You are trying to build a heatmap from pd.Series - this does not work. pd.Series is a 1D object, while seaborn.heatmap() is commonly used for 2D data structures. 

sns.heatmap(corr[['output']]) - will do the job

df = pd.DataFrame(data=[[1,2,3],[5,4,3],[5,4,12]],index=[0,1,2],columns=['A','B','C'])
df.corr().loc['A',:]


Out[13]:

A    1.0

B    1.0

C    0.5

Name: A, dtype: float64

sns.heatmap(df.corr().loc[['A'],:])



","In the line

sns.heatmap(corr['output'])


corr['output'] is a pd.Series. The documentation states


  
    
      data : rectangular dataset 
      
      2D dataset that can be coerced into an ndarray. If a Pandas DataFrame is provided, the index/column information will be used to label the columns and rows.
    
  


You write


  
    
      I do not want to have the all values correlation heatmap with all values. I only want to have the correlation of one column with respect to others.
    
  


In this case, why a heatmap? Your data is one dimensional. You might want to use a barchart, for example, using pd.DataFrame.corrwith:

dataframe.corrwith(dataframe['some_specific_column']).plot(kind='barh')

",,false,,,
https://stackoverflow.com/questions/65281536,false,The issue does not meet the criteria for deeper analysis as it is a specific question about installing a library and does not involve an API-related problem.,,,,,,,How to solve the PyGSLIB library installation error?,"I am trying to install the PyGSLIB library and the following error is occurring:
(base) C:\Users\...&gt; conda install -c opengeostat pygslib
Collecting package metadata (current_repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.
Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.
Solving environment: /
Found conflicts! Looking for incompatible packages.
This can take several minutes.  Press CTRL-C to abort.
Determining conflicts:   0%|                                                                     | 0/5 [00:00&lt;?, ?it/s]/failed

UnsatisfiableError: The following specifications were found
to be incompatible with the existing python installation in your environment:

Specifications:

  - pygslib -&gt; python[version='&gt;=3.5,&lt;3.6.0a0|&gt;=3.7,&lt;3.8.0a0|&gt;=3.9,&lt;3.10.0a0']

Your python: python=3.8

If python is on the left-most side of the chain, that's the version you've asked for.
When python appears to the right, that indicates that the thing on the left is somehow
not available for the python version you are constrained to. Note that conda will not
change your python version to a different minor version unless you explicitly specify
that.

I installed Anaconda3 5.2.0
(base) C:\WINDOWS\system32&gt;ipython
Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]
Type 'copyright', 'credits' or 'license' for more information
IPython 6.4.0 -- An enhanced Interactive Python. Type '?' for help.

And library conflicts happen again
(base) C:\WINDOWS\system32&gt;conda install -c opengeostat pygslib
Collecting package metadata (repodata.json): done
Solving environment: \
The environment is inconsistent, please check the package plan carefully
The following packages are causing the inconsistency:

  - defaults/win-64::anaconda==5.2.0=py36_3
  - defaults/win-64::astropy==3.0.2=py36h452e1ab_1
  - defaults/win-64::bkcharts==0.2=py36h7e685f7_0
  - defaults/win-64::blaze==0.11.3=py36h8a29ca5_0
  - defaults/win-64::bokeh==0.12.16=py36_0
  - defaults/win-64::bottleneck==1.2.1=py36hd119dfa_0
  - defaults/win-64::dask==0.17.5=py36_0
  - defaults/win-64::datashape==0.5.4=py36h5770b85_0
  - defaults/win-64::h5py==2.7.1=py36h3bdd7fb_2
  - defaults/win-64::imageio==2.3.0=py36_0
  - defaults/win-64::matplotlib==2.2.2=py36h153e9ff_1
  - defaults/win-64::mkl_fft==1.0.1=py36h452e1ab_0
  - defaults/win-64::mkl_random==1.0.1=py36h9258bd6_0
  - defaults/win-64::numba==0.38.0=py36h830ac7b_0
  - defaults/win-64::numexpr==2.6.5=py36hcd2f87e_0
  - defaults/win-64::numpy==1.14.3=py36h9fa60d3_1
  - defaults/win-64::numpy-base==1.14.3=py36h555522e_1
  - defaults/win-64::odo==0.5.1=py36h7560279_0
  - defaults/win-64::pandas==0.23.0=py36h830ac7b_0
  - defaults/win-64::patsy==0.5.0=py36_0
  - defaults/win-64::pytables==3.4.3=py36he6f6034_1
  - defaults/win-64::pytest-arraydiff==0.2=py36_0
  - defaults/win-64::pytest-astropy==0.3.0=py36_0
  - defaults/win-64::pytest-doctestplus==0.1.3=py36_0
  - defaults/win-64::pywavelets==0.5.2=py36hc649158_0
  - defaults/win-64::scikit-image==0.13.1=py36hfa6e2cd_1
  - defaults/win-64::scikit-learn==0.19.1=py36h53aea1b_0
  - defaults/win-64::scipy==1.1.0=py36h672f292_0
  - defaults/win-64::seaborn==0.8.1=py36h9b69545_0
  - defaults/win-64::statsmodels==0.9.0=py36h452e1ab_0
failed with initial frozen solve. Retrying with flexible solve.
Solving environment: \
Found conflicts! Looking for incompatible packages.
This can take several minutes.  Press CTRL-C to abort.
failed

UnsatisfiableError: The following specifications were found to be incompatible with each other:

Output in format: Requested package -&gt; Available versions

I installed Python versions 3.5 and 3.6 and the same error occurs, could someone tell me a way to solve this problem or do you know any other library similar to the one that has the same purpose?
","I also notice such behaviour, where it doesn't matter what python version you install.
BAD:
conda install -c opengeostat pygslib

CORRECT:
conda config --add channels conda-forge
conda config --set channel_priority flexible
conda install pygslib -c opengeostat -c conda-forge

In github, correct command is found. Wherease on website, was incorrect.
","It seems that your conda environment has python3.8 installed but this not supported by looking at the requirements.
You can create a new conda environment by changing the python version or try to install it from source
git clone https://github.com/opengeostat/pygslib.git
cd pygslib
python setup.py build
python setup.py install

",,false,,,
https://stackoverflow.com/questions/57888688,false,The issue does not meet the criteria for deeper analysis as it is a specific question about plotting a heatmap and does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Inconsistent shape between the condition and the input while using seaborn,"I am trying to plot a heatmap with seaborn. Here is the list that I am trying to plot:

b = [5, 4, 4, 4, 13, 4, 4, 1, 9, 4, 3, 9, 1, 4, 4, 1, 7, 1, 5, 3, 7, 1, 9, 4, 3, 9, 5, 4, 2, 1, 4, 1, 9, 4, 3, 9, 4, 8, 1, 7, 1, 9, 4, 8, 1, 7, 1, 4, 8, 1, 7, 1, 4, 1, 7, 1, 4, 10, 4, 3, 4, 7, 1, 8, 5, 10, 8, 9, 4, 1, 3, 9, 4, 1, 9, 4, 3, 7, 7, 1, 1, 3, 4, 9, 5, 5, 4, 1, 1, 9, 4, 9, 4, 7, 1, 9, 4, 10, 9, 4, 4, 4, 8, 10, 3, 9, 5, 4, 4, 1, 3, 9, 4, 10, 5, 4, 1, 1, 8, 1, 7, 5, 1, 8, 8, 5, 3, 1, 8, 8, 8, 1, 3, 4, 2, 1, 2, 9, 4, 10, 1, 5, 3, 9, 5, 4, 4, 4, 1, 1, 7, 1, 8, 2, 1, 8, 5, 9, 5, 10, 9, 5, 4, 1, 10, 7, 1, 8, 5, 2, 1, 3, 4, 7, 1, 2, 1, 7, 1, 4, 4, 8, 5, 3, 7, 1, 2, 1, 10, 9, 4, 1, 2, 1, 3, 9, 4, 10, 9, 1, 9, 5, 4, 3, 9, 4, 1, 8, 5, 9, 4, 1, 1, 3, 9, 4, 9, 5, 4, 1, 1, 9, 4, 3, 4, 10, 1, 9, 4, 3, 4, 10, 7, 1, 7, 1, 9, 4, 3, 4, 4, 1, 1, 9, 5, 4, 3, 5, 4, 1, 8, 5, 7, 1, 3, 9, 4, 10, 9, 4, 9, 1, 8, 5, 3, 9, 4, 1, 3, 9, 5, 3, 9, 4, 1, 3, 4, 4, 4, 8, 8, 3, 9, 5, 4, 3, 5, 4, 10, 4, 7, 1, 5, 7, 1, 1, 3, 9, 4, 10, 4, 4, 1, 9, 4, 1, 1, 5, 4, 4, 3, 5, 4, 3, 5, 4, 3, 4, 4, 1, 1, 2, 1, 4, 3, 5, 4, 3, 4, 4, 4, 4, 4, 1, 1, 8, 8, 9, 5, 8, 4, 7, 1, 2, 4, 3, 9, 4, 10, 1, 1, 3, 4, 7, 1, 4, 1, 1, 8, 5, 3, 9, 5, 4, 10, 8, 3, 4, 4, 1, 1, 3, 9, 4, 2, 5, 5, 4, 4, 1, 1, 2, 1, 7, 3, 4, 9, 1, 4, 10, 9, 4, 9, 6, 4, 11, 5, 4, 10, 4, 4, 1, 9, 5, 4, 3, 9, 4, 3, 9, 5, 12, 4, 4, 4, 1, 1, 3, 9, 5, 4, 1, 3, 5, 4, 4, 4, 10, 1, 4, 4, 10, 4, 1, 5, 3, 5, 4, 4, 7, 1, 8, 4, 1, 2, 1, 9, 4, 3, 7, 1, 9, 5, 4, 4, 10, 9, 5, 4, 4, 3, 5, 10, 5, 4, 4, 1, 9, 4, 7, 1, 5, 3, 1, 4, 3, 4, 5, 3, 1, 5, 4, 5, 3, 4, 10, 8, 5, 3, 9, 4, 3, 4, 3, 7, 9, 1, 9, 4, 4, 3, 9, 4, 4, 4, 8, 9, 4, 3, 9, 5, 4, 4, 2, 5, 4, 1, 8, 3, 9, 4, 4, 10, 7, 1, 1, 9, 4, 3, 4, 9, 4, 1, 2, 1, 10, 1, 9, 4, 2, 1, 4, 1, 8, 5, 4, 3, 9, 4, 1, 9, 4, 3, 9, 3, 9, 4, 1, 4, 4, 1, 7, 7, 1, 2, 1, 3, 4, 2, 1, 4, 10, 1, 7, 1, 3, 7, 1, 11, 1, 3, 9, 4, 1, 9, 4, 7, 1, 1, 4, 2, 1, 9, 4, 3, 4, 1, 8, 1, 9, 4, 3, 4, 1, 8, 4, 1, 7, 7, 1, 7, 1, 4, 3, 9, 5, 4, 7, 1, 8, 9, 5, 4, 7, 1, 3, 9, 4, 3, 4, 7, 1, 1]


This is the code that I am trying to use to plot:

import numpy as np
import seaborn as sns
from matplotlib.colors import ListedColormap
data = np.asarray(b)
sns.heatmap( data,cmap=ListedColormap(['green', 'yellow', 'red']))


After running the above code, this is the error I am getting:


  IndexError: Inconsistent shape between the condition and the input (got (633, 1) and (633,))


I did check some other answers but none of them answered my concerns.

I am not quite sure as to where the problem lies. Here is the result that I get when run data.shape:

(633,)


Any help will be appreciated. Thanks!
","import numpy as np
import seaborn as sns
from matplotlib.colors import ListedColormap
import matplotlib.pyplot as plt
data = np.asarray(b).reshape(633,1)
sns.heatmap(data,cmap=ListedColormap(['green', 'yellow', 'red']))
plt.show()


heatmap requires 2D dataset
https://seaborn.pydata.org/generated/seaborn.heatmap.html
","From the docs:


  data : rectangular dataset 2D dataset that can be coerced into an
  ndarray. If a Pandas DataFrame is provided, the index/column
  information will be used to label the columns and rows.


You have to transform your data into a 2D dataset.

One way to do so is:

sns.heatmap(data[:, np.newaxis], cmap=ListedColormap(['green', 'yellow', 'red']))

",,false,,,
https://stackoverflow.com/questions/59294900,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,How to prepare training data for image classification,"I'm new to Machine Learning and have some problems with image classification. Using a simple classifier technique K Nearest Neighbours I'm trying to distinguish Cats from Dogs. 

My code so far:

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

%matplotlib inline

DATADIR = ""/Users/me/Desktop/ds2/ML_image_classification/kagglecatsanddogs_3367a/PetImages""
CATEGORIES = ['Dog', 'Cat']

IMG_SIZE = 30
data = []
categories = []

for category in CATEGORIES:
    path = os.path.join(DATADIR, category) 
    categ_id = CATEGORIES.index(category)
    for img in os.listdir(path):
        try:
            img_array = cv2.imread(os.path.join(path,img), 0)
            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))
            data.append(new_array)
            categories.append(categ_id)
        except Exception as e:
            # print(e)
            pass

print(data[0])


s1 = pd.Series(data)
s2 = pd.Series(categories)
frame = {'Img array': s1, 'category': s2}
df = pd.DataFrame(frame) 


from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

knn = KNeighborsClassifier()
knn.fit(X_train, y_train)


And here I get an error when trying to fit the data:

   ---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-76-9d98d7b11202&gt; in &lt;module&gt;
      2 from sklearn.neighbors import KNeighborsClassifier
      3 
----&gt; 4 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
      5 
      6 print(X_train)

~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py in train_test_split(*arrays, **options)
   2094         raise TypeError(""Invalid parameters passed: %s"" % str(options))
   2095 
-&gt; 2096     arrays = indexable(*arrays)
   2097 
   2098     n_samples = _num_samples(arrays[0])

~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py in indexable(*iterables)
    228         else:
    229             result.append(np.array(X))
--&gt; 230     check_consistent_length(*result)
    231     return result
    232 

~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py in check_consistent_length(*arrays)
    203     if len(uniques) &gt; 1:
    204         raise ValueError(""Found input variables with inconsistent numbers of""
--&gt; 205                          "" samples: %r"" % [int(l) for l in lengths])
    206 
    207 

ValueError: Found input variables with inconsistent numbers of samples: [24946, 22451400]


How to prepare the training the data properly?
Btw. I don't want to use deep learning. This will be the next step for me.

Would appreciate any help here..
","If you don`t use deep learning for image classification,you have to prepare your data that fit to the supervised learning classification.

steps

1) Resize all images to same size.You can loop over each image and resize and save.

2) get the pixel vector of each image and create the dataset.As a example if your cat images are in ""Cat"" folder and Dog images are in ""Dog"" folder,iterate over all images inside the folder and get the pixel values.same time label the data as ""cat""(cat=1) and ""non-cat""(non-cat=0)

import os
import  imageio
import pandas as pd

catimages = os.listdir(""Cat"")
dogimages = os.listdir(""Dog"")
catVec = []
dogVec = []
for img in catimages:
       img = imageio.imread(f""Cat/{img}"")
       ar = img.flatten()
       catVec.append(ar)    
catdf = pd.DataFrame(catVec)    
catdf.insert(loc=0,column =""label"",value=1)

for img in dogimages:
       img = imageio.imread(f""Dog/{img}"")
       ar = img.flatten()
       dogVec.append(ar)    
dogdf = pd.DataFrame(dogVec)    
dogdf.insert(loc=0,column =""label"",value=0)


3) concat catdf and dogdf and shuffle the dataframe

data = pd.concat([catdf,dogdf])      
data = data.sample(frac=1)


now you have dataset with lable for your images.

4) split dataset to train and test and fit to the model.
","For using classical machine learning for image classification, as mentioned earlier, you would need transform the raw images in vectors or numpy arrays and extract features from it.

As suggested, often the preprocessing steps includes:


Rescaling the images and normalizating it
Converting the images to grayscale if colour does not play a vital role in classification
Doing feature extraction, like creating feature vectors by applying varies computer vision filters for edge detection, pixel
density detection etc.
Finally dividing in to train-test split, before feeding  into the model.


I found the following link that might be helpful to you,
https://medium.com/@dataturks/understanding-svms-for-image-classification-cf4f01232700

From the issue that you had posted, I feel you should check the dimensions of X_train, y_train and X_test, y_test. The training data is probably not matching with your training labels.

Do, a quick X_train.shape and y_train.shape to see what are the dimensions coming.
",,false,,,
https://stackoverflow.com/questions/46383645,false,"The issue does not meet the criteria for deeper analysis as it is a question about the behavior of seaborn and pd.scatter_matrix in R, rather than an issue with an API.",,,,,,,Seaborn and pd.scatter_matrix() plot color issues,"I am making a pd.scatter_matrix() plot from a DataFrame based on the Iris dataset colored by the target variable (plant species). When I run the code below I get a scatter matrix with black, grey and white (!) colored scattering points which hinders visualization. The grid seems inconsistent too, apparently only the plots close to the axis get the respective gridding. I wanted a nice grid and scatter matrix following the sns default color palette (blue, green, red).

Why is seaborn plot style and the use of pd.scatter_matrix() enforcing a different (awful!) color palette then the defaults for the scatter plots and inconsistent grid lines? How can I solve these visualization issues?

I already updated seaborn to a fairly recent version (0.8 of July 2017). Also tried the non-deprecated version the scatter_matrix plot for pandas pd.plotting.scatter_matrix() and had no luck. If I use the 'ggplot' style the color palette is correct for the scatter plots but the grids are still inconsistent.

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
plt.style.use('seaborn')
from sklearn import datasets

iris = datasets.load_iris()
X = iris.data
y = iris.target
df = pd.DataFrame(X, columns = iris.feature_names)

pd.scatter_matrix(df, c=y, figsize = [8,8],
                      s=80, marker = 'D');




Package versions:

pandas version: 0.20.1
matplotlib version: 2.0.2
seaborn version:0.8.0  
","I am not sure if this answers your question but you could use the pairplot. let me know..

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline

from sklearn import datasets

iris = datasets.load_iris()
X = iris.data
y = iris.target
df = pd.DataFrame(X, columns = iris.feature_names)

pd.plotting.scatter_matrix(df, c=y, figsize = [8,8],
                      s=80, marker = 'D');
df['y'] = y

sns.pairplot(df,hue='y')


which gives you:



If you want to avoid that the last line of the visualizations then:

import seaborn as sns
sns.set(style=""ticks"", color_codes=True)
iris = sns.load_dataset(""iris"")
%matplotlib inline

iris = sns.load_dataset(""iris"")
sns.pairplot(iris, hue=""species"")



","Default matplotlib setting are not very aesthetic; however, do not underestimate the power of matplotlib.

The simplest solution to your problem might be:

plt.style.use('ggplot') # this is the trick

from sklearn import datasets

iris = datasets.load_iris()
X = iris.data
y = iris.target
df = pd.DataFrame(X, columns = iris.feature_names)

pd.scatter_matrix(df, c=y, figsize = [10,10], s=50);




(full list of styles available can be accessed via plt.style.available)

You may further customize the plot to your needs adjusting matplotlibrc file. An example of what could be done with it could be found here
",,false,,,
https://stackoverflow.com/questions/72587474,false,"The issue does not meet the criteria for deeper analysis as it is a question about setting up gcc in AWS SageMaker notebook, rather than an issue with an API exhibiting unexpected failures or unpredictable behaviors.",,,,,,,Not able to set up gcc in aws sagemaker notebook,"I am working in a jupyter notebook in aws sagemaker and want to use prophet for time-series forecast. I am using the conda_python3 kernel. According to the installation instruction from https://facebook.github.io/prophet/docs/installation.html#python I need to set up gcc before installing prophet, but when I try '%conda install gcc', I get the error message that the environment is inconsistent.
Does anyone know how to solve this issue?
Error message:
Collecting package metadata (current_repodata.json): done
Solving environment: /
The environment is inconsistent, please check the package plan carefully
The following packages are causing the inconsistency:

conda-forge/noarch::nbclient==0.5.2=pyhd8ed1ab_0
conda-forge/linux-64::matplotlib==3.3.4=py36h5fab9bb_0
conda-forge/noarch::qdarkstyle==2.8.1=pyhd8ed1ab_2
conda-forge/linux-64::scikit-image==0.16.2=py36hb3f55d8_0
conda-forge/noarch::python-language-server==0.36.2=pyhd8ed1ab_0
conda-forge/linux-64::widgetsnbextension==3.5.1=py36h5fab9bb_4
conda-forge/noarch::flake8==3.8.4=py_0
conda-forge/noarch::ipywidgets==7.6.3=pyhd3deb0d_0
conda-forge/noarch::typing-extensions==3.7.4.3=0
conda-forge/noarch::path.py==12.5.0=0
conda-forge/noarch::dask==2021.2.0=pyhd8ed1ab_0
conda-forge/noarch::nbformat==5.1.2=pyhd8ed1ab_1
conda-forge/linux-64::path==15.1.2=py36h5fab9bb_0
conda-forge/linux-64::nbconvert==6.0.7=py36h5fab9bb_3
conda-forge/linux-64::distributed==2021.2.0=py36h5fab9bb_0
conda-forge/noarch::anaconda-client==1.7.2=py_0
conda-forge/noarch::aioitertools==0.7.1=pyhd8ed1ab_0
conda-forge/linux-64::matplotlib-base==3.3.4=py36hd391965_0
conda-forge/linux-64::pluggy==0.13.1=py36h5fab9bb_4
conda-forge/noarch::black==20.8b1=py_1
conda-forge/linux-64::blaze==0.11.3=py36_0
conda-forge/noarch::pyls-spyder==0.3.2=pyhd8ed1ab_0
conda-forge/noarch::odo==0.5.1=py_1
conda-forge/linux-64::keyring==22.0.1=py36h5fab9bb_0
conda-forge/noarch::anaconda-project==0.9.1=pyhd8ed1ab_0
conda-forge/noarch::importlib_metadata==3.7.0=hd8ed1ab_0
conda-forge/linux-64::jupyter==1.0.0=py36h5fab9bb_6
conda-forge/noarch::jupyterlab_server==2.3.0=pyhd8ed1ab_0
conda-forge/noarch::seaborn-base==0.11.1=pyhd8ed1ab_1
conda-forge/noarch::imageio==2.9.0=py_0
conda-forge/noarch::numpydoc==1.1.0=py_1
conda-forge/linux-64::yarl==1.6.3=py36h8f6f2f9_1
conda-forge/noarch::jsonschema==3.2.0=py_2
conda-forge/noarch::flask==1.1.2=pyh9f0ad1d_0
conda-forge/noarch::seaborn==0.11.1=hd8ed1ab_1
conda-forge/noarch::helpdev==0.7.1=pyhd8ed1ab_0
conda-forge/linux-64::nb_conda==2.2.1=py36h5fab9bb_4
conda-forge/noarch::nbclassic==0.2.6=pyhd8ed1ab_0
conda-forge/noarch::sphinx==3.5.1=pyhd8ed1ab_0
conda-forge/noarch::jupyterlab_launcher==0.13.1=py_2
conda-forge/linux-64::spyder==4.2.0=py36h5fab9bb_0
conda-forge/linux-64::importlib-metadata==3.7.0=py36h5fab9bb_0
conda-forge/linux-64::pytest==6.2.2=py36h5fab9bb_0
conda-forge/noarch::pyls-black==0.4.6=pyh9f0ad1d_0
/ ^C
failed with initial frozen solve. Retrying with flexible solve.

CondaError: KeyboardInterrupt
Note: you may need to restart the kernel to use updated packages.
","Have you confirmed GCC is not installed already?  I ran the below on a SageMaker Notebook Instance with conda_python3 kernel selected.
!gcc --version
gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-28)
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

",,,false,,,
https://stackoverflow.com/questions/44950570,false,"The issue does not meet the criteria for deeper analysis as it is a question about the color legend in R plotly subplot, rather than an issue with an API exhibiting unexpected failures or unpredictable behaviors.",,,,,,,Color legend not consequent in R plotly subplot,"I want to make a plotly bar chart of two synchronized variables. Origin is visits of individuals to a site where two properties are measured in time. In this example individual ""a"" visits the site twice.

Bars should display the measurement value, be ordered in time and colored according to tag (not variable!).

Let's create some data first.

# R version 3.4.0
set.seed(123)
df &lt;- data.frame(id=factor(rep(c(""a"", ""b"", ""c"", ""a""), each=10)),
                 time=as.POSIXct(1:40, origin=""2017-01-01""),
                 var1=abs(rnorm(40)),
                 var2=abs(rnorm(40)))

# &gt; head(df)
#   id                time        var1      var2
# 1  a 2017-01-01 01:00:01 0.005764186 0.1176466
# 2  a 2017-01-01 01:00:02 0.385280401 0.9474746
# 3  a 2017-01-01 01:00:03 0.370660032 0.4905574
# 4  a 2017-01-01 01:00:04 0.644376549 0.2560922
# 5  a 2017-01-01 01:00:05 0.220486562 1.8438620
# 6  a 2017-01-01 01:00:06 0.331781964 0.6519499


Now make two plots of each separate variable, assign to same legend group and hide the legend of the second plot.

library(plotly) # version 4.7.0
p1 &lt;- plot_ly(df, x=~time, y=~var1, color=~id, type=""bar"",
              legendgroup=~id)
p2 &lt;- plot_ly(df, x=~time, y=~var2, color=~id, type=""bar"",
              legendgroup=~id, showlegend=FALSE)


Then add both plots to a single plot with shared X axis.

subplot(p1, p2, shareX=TRUE, nrows=2)


I'm not sure how to add an HTML page in an SO question, but the above code should provide a reproducible example. PNGs added below for reference.



Looks good, right? But for some reason, the legend ""selector"" does not work properly. Deselecting ""a"" only affects plot 1 (unexpected behavior), while deselecting ""c"" affects both plots (expected).



What's going on here? Possible bug, or am I missing something?

I'm aware of ggplotly and could get similar plot by using facets. The problem there is that I cannot output a ggplotly HTML that scales with page width (at least not to my knowledge). I want the resulting image to be an HTML that scales with the browser window, which is what plotly does by default.
","probably It could be a bug. I noticed reordering the data according to the variable get the right result.
It's not the first time btw, I noticed a similar behaviour

df&lt;-df[order(df$id),]
library(plotly) # version 4.7.0
p1 &lt;- plot_ly(df, x=~time, y=~var1, color=~id, type=""bar"",
              legendgroup=~id)
p2 &lt;- plot_ly(df, x=~time, y=~var2, color=~id, type=""bar"",
              legendgroup=~id, showlegend=FALSE)
subplot(p1, p2, shareX=TRUE, nrows=2)

",,,false,,,
https://stackoverflow.com/questions/59776874,false,"The issue does not meet the criteria for deeper analysis as it is a question about Flask log entries being duplicated when using Plotly dashboards, rather than an issue with an API exhibiting unexpected failures or unpredictable behaviors.",,,,,,,Flask log entries duplicated when using Plotly dashboards,"I'm seeing unexpected behavior when introducing Plotly dashboards into my Flask application. Each Plotly dashboard causes Flask log entries to be duplicated. 

For example, if I attach two Plotly dashboards to my Flask application, log entries (e.g. current_app.logger.info('hi')) will appear three times in my logs. If I remove the Plotly dashboards, the log entry appears once, which is the expected behavior.

I've tried removing existing handlers in my logging config code via app.logger.handlers.clear() and by setting dictConfig's disable_existing_loggers to True, both of which result in nothing being logged. I've also tried using the singleton approach to configuring the logger (again, using dictConfig) and I still see the log entries repeated multiple times.

How can I prevent Plotly dashboards from causing duplicate log entries?

UPDATE:

Here's a simplified version of how Dash apps are being initialized:

def register_dashapp(app):
    from dashboards.dash_files.my_dash import (
        define_layout,
        define_callbacks,
    )
    my_dashapp = dash.Dash(__name__,
                         server=app,
                         url_base_pathname='/my_dash/',
                         assets_folder=""../dashboards/foo/bar/assets"",
                         )
    with app.app_context():
        my_dashapp.title = ""Test""
        define_layout(my_dashapp)
        define_callbacks(my_dashapp)

def create_app():
    app = Flask(__name__, instance_relative_config=False)
    app.config.from_object('config.Config')

    with app.app_context():
        register_extensions(app)
        app.register_blueprint(main)
        register_dash_app(app)
        return app

","I was having a log duplication issue and solved it using the same HasHandlers logic, however I call logs in a slight different way. This requires the python arrow library, which I find superior to datetime in most use cases.
I define the site_logger in my main app.py or _init_.py file.
# define logger
def site_logger(log_name):
    now = arrow.now('US/Eastern').format('YYYY_MM_DD')
    handler = logging.FileHandler('logs/' + log_name + '_' + now + '.log')
    formatter = logging.Formatter('%(asctime)s %(levelname)s %(name)s: %(message)s')
    handler.setFormatter(formatter)
    logger = logging.getLogger(log_name)
    logger.setLevel(""DEBUG"")
    if logger.hasHandlers():
        logger.handlers.clear()
    logger.addHandler(handler)
    logger.propagate = False
    return logger

I then call the logger in the following way in any views.py file or function, you can also pass the logger into a function you call in a views.py, keeping logs results of a function in the correct page file it was called from.
from app import site_logger
logger = site_logger('page_name')

I can then log events in the usual way. Two examples are below, and using f strings in logger is a great way to easily pass vars into log data.
logger.info(f'{user} logged in successfully')
logger.warning(f'{user} password failure!')

This will provide uniformly named log handlers and log files you can more easily trace back to the page or function call made. The date formatted files should auto rotate when the arrow.now('timezome') value rotates to the next day.
","I was able to work around this by removing the logging handler added by the Dash library.

my_dash = dash.Dash(__name__,
    server=app,
    url_base_pathname='/my_dash/',
    assets_folder=""../dashboards/foo/bar/assets""
)

if (my_dash.logger.hasHandlers()):
    my_dash.logger.handlers.clear()


There doesn't appear to be any downside to doing this, but it is possible I'm overlooking something and I'd be interested to see if anyone else has a better approach. I'll hold off on accepting my own answer for a few more days.

On a related note, I'd think this would be configurable via the Dash constructor. I'd also be curious to know if anyone has thoughts about that. I may open a ticket with the project to see what they think about the possibility.
","if not DashboardDAO.validate_create_title(dashboard_title, unique()):
      exceptions.append(DashboardTitleExistsValidationError())
   

",false,,,
https://stackoverflow.com/questions/65009862,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Plotly.js with vue disappearing charts on resize and data change,"I'm using Ploty with Vue wrapper Vue-Plotly and I want to dynamically change the data on the plot
I use a function that changes the value of the data that is sent to the Ploty plot (which is responsive).
methods: {
    changelayout() {
      this.data[1].x = [10];
    },
  }

It works well, the data is updated and plot is also updated.
However there is some unexpected behavior happening, when I resize the window, the plot kind of collapses and other components cover it (it seems to collapse to the top, so when there are multiple plots they all collapse into one place).
For instance if I have two plots positioned one above the other, the second one will cover the first one.
You can see this behavior in action here:
https://codesandbox.io/s/vuetify-playground-xbgcv?file=/src/layout.vue
When you click on the button, and resize window this will happen ( or resize then click i think also works to reproduce the issue)
In the options I set the responsive to true for the plot and this is what seems to be breaking the chart:
  options: {
        displayModeBar: false,
        responsive: true,
      },

Is there a way to have the plot anchored so that it wont hide behind other components on window resize and still keeps being responsive?
","The SVGs have position: absolute which means they take up no space in their parent divs.
To compensate for that, their parent divs, .svg-container, have a fixed height of 90px (pixel).
After the button click .svg-container changes to height: 100% (percent), which is not fixed, so they shrink.
If you give them a fixed height (with !important) they will keep it:
.svg-container {
   height: 90px !important;
}

",,,false,,,
https://stackoverflow.com/questions/36437879,true,The issue involves unexpected behavior when using the plotly package with ggplot2's geom_tile. It meets the criteria for deeper analysis as it exhibits unexpected behavior under specific runtime conditions.,,,,,,,Unexpected output using plotly and geom_tile,"I'm trying to print a heatmap using ggplot2's geom_tile and display it using the package plotly, but I get some unexpected behavior.

There is a reproducible example in plotly's website  https://plot.ly/ggplot2/geom_tile/

To make it easier, I paste the code here:

library(plotly)
library(reshape2)

p &lt;- volcano %&gt;%
  melt() %&gt;% 
  ggplot(aes(Var1, Var2, fill = value)) + geom_tile()

ggplotly(p)


According to the website, I'm supposed to get something like this:



But the result I get is the next one:



The funny thing is that if I print the ggplot object p with print(p) I get the outcome I was supposed to get:



which makes me think that the problem is plotly and not ggplot. 

I've run the code from other examples using ggplot and plotly and it all works perfectly, the issue seems to be with geom_tile.

My SessionInfo() is:

R version 3.2.4 Revised (2016-03-16 r70336)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 15.10


And the versions of ggplot an plotly are:


ggplot2: 2.1.0 
plotly: 3.4.1


I also tested this code with a Mac and got the same unexpected results.
","So, I found three possible solutions for this:


As Laterow said, downgrading to the 2.0.16 version works.
The people from plotly told me that installing the development version 3.4.13 with devtools::install_github('ropensci/plotly') should fix it. I tried it and it does work.
Transposing the original data and changing the order of variables in the aes in geom_tile also works.


The code for the third solution would be:

p &lt;- t(volcano) %&gt;%
melt() %&gt;% 
ggplot(aes(x=Var2, y=Var1)) + geom_tile(aes(fill=value))
ggplotly(p)

",,,false,,,
https://stackoverflow.com/questions/71655326,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,R plotly waterfall with offset base: hovertext activated on hover at wrong position,"Recently, when using an offset (a non-zero base parameter) in a waterfall plot in plotly, I noticed that the boxes with hoverinfo were activated when the mouse pointer was in a completely wrong/unexpected place. Below I've pasted in screenshots to illustrate the problem.

Mouse pointer just to the left of the value in the base parameter:


Mouse pointer just to the right of the base:


Mouse pointer just to the left of the green box:


Mouse pointer inside the green box (same behavior to the right of the box):



Just found a similar question on the Plotly forum for the Python Dash users here, but it looks like it hasn't been answered.
Any ideas what might be wrong here?
I'm attaching the code below for reproducing the example shown in the pictures:
library(dplyr)
library(plotly)


set.seed(123)
test_x &lt;- rnorm(10)
test_y &lt;- c(LETTERS[1:10], ""all"") %&gt;% factor(., levels = .)
test_base &lt;- -15

test_data &lt;- tibble(
  x = c(test_x, 0),
  y = test_y,
  text = c(paste(""test"", 1:10), ""all""),
  measure = c(rep(""relative"", 10), ""total"")
)


plot_ly(
  test_data,
  type = ""waterfall"",
  orientation = ""h"",
  measure = ~measure,
  x = ~x,
  y = ~y,
  base = test_base,
  text = ~text,
  textposition = ""none"",
  hoverinfo = ""text"",
  decreasing = list(marker = list(color = ""orange""))
) %&gt;%
  layout(
    yaxis = list(autorange = ""reversed"", title = ""y""),
    xaxis = list(title = ""x"")
  )

","I filed a detailed issue report on the plotly.js GitHub repo, and, unfortunately, it was recognized as a bug. As such, this doesn't seem to have much to do with SO, so I'm posting this answer in case anybody faces the same problem, and said bug hasn't been fixed yet.
",,,false,,,
https://stackoverflow.com/questions/50490887,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,set x and y range of plotly heatmap,"Plotly.js: Initial Zoom

Similar to the above question, is there a way to set the zoom for plotly heatmap produced with geom_tile() and ggplotly().
Say for instance, I wanted an x range of 5:10 and a y range of 20:30, how would I get a zoomed heatmap of that region? The whole goal of this is to zip quickly to important points of the heatmap in a large dataset in a shiny framework.
Here's some example code of a basic plotly heatmap:

p &lt;- t(volcano) %&gt;%
melt() %&gt;% 
ggplot(aes(x=Var2, y=Var1)) + geom_tile(aes(fill=value))
ggplotly(p)

reference: https://stackoverflow.com/questions/36437879/unexpected-output-using-plotly-and-geom-tile?utm_medium=organic&amp;utm_source=google_rich_qa&amp;utm_campaign=google_rich_qa).

","plotly bascially takes options through layout. This page might be helpful https://plot.ly/r/axes/#manual-ranges

ggplotly(p, dynamicTicks = T) %&gt;%
   layout(xaxis=list(autorange=F, range=c(5,10)), yaxis=list(autorange=F, range=c(20,30)))

",,,false,,,
https://stackoverflow.com/questions/67072696,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Python Dash how to show all rows in a data table?,"I have made an interactive table using dash and plotly in python, currently the table only gives the first few rows, is there a way to make the table have pages or be scrollable so all rows are interactively viewable?
Here is the code I'm using:
data = X_interactive

app = JupyterDash(__name__)

app.layout = html.Div([
    dash_table.DataTable(
        id='datatable-interactivity',
        columns=[
            {""name"": i, ""id"": i, ""deletable"": True, ""selectable"": True} for i in X_interactive.columns
        ],
        data=X_interactive.to_dict('records'),
        editable=True,
        filter_action=""native"",
        sort_action=""native"",
        sort_mode=""multi"",
        column_selectable=""single"",
        row_selectable=""multi"",
        row_deletable=True,
        selected_columns=[],
        selected_rows=[],
        page_action=""native"",
        page_current= 0,
        page_size= 10,
    ),
    html.Div(id='datatable-interactivity-container')
])

@app.callback(
    Output('datatable-interactivity', 'style_data_conditional'),
    Input('datatable-interactivity', 'selected_columns')
)
def update_styles(selected_columns):
    return [{
        'if': { 'column_id': i },
        'background_color': '#D2F3FF'
    } for i in selected_columns]

@app.callback(
    Output('datatable-interactivity-container', ""children""),
    Input('datatable-interactivity', ""derived_virtual_data""),
    Input('datatable-interactivity', ""derived_virtual_selected_rows""))
def update_graphs(rows, derived_virtual_selected_rows):

    if derived_virtual_selected_rows is None:
        derived_virtual_selected_rows = []

    dff = X_interactive if rows is None else pd.DataFrame(rows)

    colors = ['#7FDBFF' if i in derived_virtual_selected_rows else '#0074D9'
              for i in range(len(dff))]

    return [
        dcc.Graph(
            id=column,
            figure={
                ""data"": [
                    {
                        ""x"": dff[""Gene""],
                        ""y"": dff[column],
                        ""type"": ""bar"",
                        ""marker"": {""color"": colors},
                    }
                ],
                ""layout"": {
                    ""xaxis"": {""automargin"": True},
                    ""yaxis"": {
                        ""automargin"": True,
                        ""title"": {""text"": column}
                    },
                    ""height"": 250,
                    ""margin"": {""t"": 10, ""l"": 10, ""r"": 10},
                },
            },
        )
        # check if column exists - user may have deleted it
        # If `column.deletable=False`, then you don't
        # need to do this check.
        for column in [""col1"", ""col2"", ""col3""] if column in dff
    ]

    
app.run_server(mode='inline',port=8056)

From trying to find similar questions I've been trying to get pages with pagination_settings but I'm new to python and not sure how to properly get it into my current code without losing how the table currently is (interactive with being able to filter columns).
Just trying to add pagination_settings within html.Div()  gives me an error:
TypeError: The `dash_table.DataTable` component (version 4.11.2) with the ID ""datatable-interactivity"" received an unexpected keyword argument: `pagination_settings
","pagination-settings isn't a valid arguement as seen by the error below:
TypeError: The `dash_table.DataTable` component (version 4.10.1) with the ID 

""table"" received an unexpected keyword argument: `pagination_settings`
Allowed arguments: active_cell, cell_selectable, column_selectable, columns, css, data, data_previous, data_timestamp, derived_filter_query_structure, derived_viewport_data, derived_viewport_indices, derived_viewport_row_ids, derived_viewport_selected_columns, derived_viewport_selected_row_ids, derived_viewport_selected_rows, derived_virtual_data, derived_virtual_indices, derived_virtual_row_ids, derived_virtual_selected_row_ids, derived_virtual_selected_rows, dropdown, dropdown_conditional, dropdown_data, editable, end_cell, export_columns, export_format, export_headers, fill_width, filter_action, filter_query, fixed_columns, fixed_rows, hidden_columns, id, include_headers_on_copy_paste, is_focused, loading_state, locale_format, markdown_options, merge_duplicate_headers, page_action, page_count, page_current, page_size, persisted_props, persistence, persistence_type, row_deletable, row_selectable, selected_cells, selected_columns, selected_row_ids, selected_rows, sort_action, sort_as_null, sort_by, sort_mode, start_cell, style_as_list_view, style_cell, style_cell_conditional, style_data, style_data_conditional, style_filter, style_filter_conditional, style_header, style_header_conditional, style_table, tooltip, tooltip_conditional, tooltip_data, tooltip_delay, tooltip_duration, virtualization

And by looking at the official documentation to get pagination in a datatable
Code from the documentation:
import dash
from dash.dependencies import Input, Output
import dash_table
import pandas as pd


df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/gapminder2007.csv')

df[' index'] = range(1, len(df) + 1)

app = dash.Dash(__name__)

PAGE_SIZE = 5

app.layout = dash_table.DataTable(
    id='datatable-paging',
    columns=[
        {""name"": i, ""id"": i} for i in sorted(df.columns)
    ],
    page_current=0,
    page_size=PAGE_SIZE,
    page_action='custom'
)
if __name__ == '__main__':
    app.run_server(debug=True)

You can see that the required and accepted arguments are page_current, page_size, page_action, page_count (from the error).
In your code, I think adding the page_count argument should end up being the fix.
","If you want to display all dataframe rows in your datatable set this option:
pd.set_option('display.max_rows',None)

",,false,,,
https://stackoverflow.com/questions/50222396,true,The issue involves an error when displaying more details in a plotly tooltip. It meets the criteria for deeper analysis as it exhibits unexpected behavior under specific runtime conditions.,,,,,,,error when displaying more details in plotly tooltip,"Im trying to display more data on hoover over a point, than default point coordinates. 
It works when I display only one extra information for example:

 output$myplot &lt;- renderPlotly({
    if (is.null(filtered())) {
      return()
    }
    ggplot(filtered(), aes_string(x=input$xvar, y=input$yvar, text=filtered()$Ep.name)) +
      geom_point()
  })


Works just fine and I get what I want to achieve (which is the data that i pass to text variable. But when I tried passing more variables, using paste:

 ggplot(filtered(), aes_string(x=input$xvar, y=input$yvar, text=paste(""name: "",filtered()$Ep.name, ""season: "", filtered()$Season, ""number: "", filtered()$Ep.Number))) +
      geom_point()


I get this error:

Warning: Error in parse: &lt;text&gt;:1:12: unexpected symbol
1: name:  The Kingsroad


Which means there is something wrong with the value when it is pasted.
However I have no idea how to inlcude all three variables from the filtered() dataframe onto aes_string so that they are all displayed in the tooltip.
Anyone has idea how to solve this?

EDIT: Here is code that allows you to reproduce the error, along with the sample of the dataset im using for this:

library(shiny)
library(ggplot2)
library(dplyr)
library(plotly)


shows &lt;- read.csv(""finalR1.csv"", header=TRUE)

ui &lt;- fluidPage(
  tabsetPanel(
    tabPanel(h1(""Plot""),
             plotlyOutput(""myplot""),
             hr()),
    tabPanel(h1(""Table""), tableOutput(""results""))
  ),

  fluidRow(
    column(3,
           h4(""Episode explorer""), 
           sliderInput(""voteInput"", ""Votes"", min = 0, max = 155000, value = c(2500, 40000)),
           br(),
           sliderInput(""lenInput"", ""Length"", min = 0, max = 110, value = c(0, 60)),
           br(),
           uiOutput(""ratingOutput"")

    ),

   column(4,offset = 0.5,
          h4('Axis display options'),
          selectInput('xvar', 'X', choice=c(""Length"", ""Ep.Rating"", ""Votes"", ""Year""), selected=""Ep.Rating""),
          selectInput('yvar', 'Y', choice=c(""Length"", ""Ep.Rating"", ""Votes"", ""Year""), selected=""Votes"")
          ))

)


server &lt;- function(input, output) {
  output$ratingOutput &lt;- renderUI({
    selectInput(""ratingInput"", ""Ratings"",
                c(""All"", as.character(sort(unique(shows$TV.Rating)))),
                selected = ""All"")
  })


  filtered&lt;-reactive({
    if (is.null(input$ratingInput)) {
      return(NULL)
    }

    shows %&gt;%
    filter(Votes &gt;= input$voteInput[1],
           Votes &lt;= input$voteInput[2],
           Length &gt;= input$lenInput[1],
           Length &lt;= input$lenInput[2],
           if (input$ratingInput != ""All"") {
             TV.Rating == input$ratingInput
           } else TRUE

    )

  })

  output$myplot &lt;- renderPlotly({
    if (is.null(filtered())) {
      return()
    }
    ggplot(filtered(), aes_string(x=input$xvar, y=input$yvar, text=paste(""name: "",filtered()$Ep.name, ""season: "", filtered()$Season, ""number: "", filtered()$Ep.Number))) +
      geom_point()
  })

  output$results &lt;- renderTable({
    filtered()
  })
}

shinyApp(ui = ui, server = server)


https://drive.google.com/file/d/15ZqzY_msBBlBnrrqsqeagZSpJxifKKjM/view?usp=sharing
","Maybe you could try this:

  output$myplot &lt;- renderPlotly({
    if (is.null(filtered())) {
      return()
    }

  a &lt;- ggplot(filtered(), aes_string(x=input$xvar, y=input$yvar))  +
      geom_point(aes(text=paste('name:',filtered()$Ep.name, '&lt;br&gt;season:', filtered()$Season, '&lt;br&gt;number:', filtered()$Ep.Number)))

  ggplotly(a, tooltip = c(""x"", ""y"", ""text""))

  })

",,,false,,,
https://stackoverflow.com/questions/74948525,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,FutureWarning: save is not part of the public API in Python,"I am using Python to convert Pandas df to .xlsx (in Plotly-Dash app.). All working well so far but with this warning tho:
""FutureWarning:
save is not part of the public API, usage can give unexpected results and will be removed in a future version""
How should I modify the code below in order to keep its functionality and stability in future? Thanks!
 writer = pd.ExcelWriter(""File.xlsx"", engine = ""xlsxwriter"")

 workbook  = writer.book

 df.to_excel(writer, sheet_name = 'Sheet', index = False)
  
 writer.save()

","just replace save with close.
 writer = pd.ExcelWriter(""File.xlsx"", engine = ""xlsxwriter"")

 workbook  = writer.book

 df.to_excel(writer, sheet_name = 'Sheet', index = False)
  
 writer.close()

","You can try any of these options, and it should work:
Replace:
writer.save()

by
    writer._save()
or
    writer.close()

",,false,,,
https://stackoverflow.com/questions/62825975,false,"The issue does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is related to the usage of Plotly for creating horizontal bar plots, but there is no indication of API-related problems or unexpected behavior.",,,,,,,Plotly horizontal bar plots giving unexpected results,"I'm trying to create a horizontal bar plot similar to this one.
I can generate a vertical plot, but when I change it to horizontal the plot is a mess. I'm trying this two ways, using go and px. I don't understand the problem and am not sure how to proceed. Here is my code:
Using go:
import pandas as pd
import chart_studio.plotly as py
import plotly.graph_objects as go

dfs = pd.read_html('https://coronavirus.jhu.edu/data/mortality', header=0)
df = dfs[0]

df['Case-Fatality'] = list(map(lambda x: x[:-1], df['Case-Fatality'].values))

df['Case-Fatality'] = pd.to_numeric(df['Case-Fatality'], downcast='float')
df_sort = df.sort_values(by='Case-Fatality')
fig = go.Figure(go.Bar(
    x=df_sort['Country'],
    y=df_sort['Case-Fatality'],
    ))
fig.update_layout(
    title='',
    xaxis_title='',
    yaxis_title='')
fig.show()

Using px:
import plotly.express as px
fig = px.bar(df_sort, x='Country', y = 'Case-Fatality', orientation='h')
fig.show()

Following the plotly documentation, I should be able to add orientation='h' argument to either go.bar or px.bar. When I do, there is no error but the plot does not look correct.
Here is vertical, plotted properly but not the preferred orientation:

Here is with the horizontal orientation, it looks the same with either go or px:

Any help or guidance on why this is not working would be most appreciated.
","Change x and y values around in either go.bar or px.bar (still add orientation = 'h').
Both methods work identically well.
Output:

",,,false,,,
https://stackoverflow.com/questions/68178930,false,"The issue does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is a question about creating a set of images as Plotly traces, but there is no indication of API-related problems or unexpected behavior.",,,,,,,Is there a way to create a set of images as plotly traces,"I'm attempting to create a series of Plotly traces where each trace is an image, thus allowing the use of of a slider to slide between them.
I've tried multiple methods and run into problems with each:
1.) Create an empty scatter plot and load background images into it. This just resulted in no images being shown and just a blank figure showing
2.) To create an go.Image figure, but all that results in 'Image has no add_trace attribute'
3.) Create a blank scatter and make each subsequent trace an Image, but i get an 'add_trace() got an unexpected keyword argument 'type'' error
Code(Method 3):
import plotly
import plotly.graph_objects as go
import plotly.express as px
import numpy as np
from PIL import Image
import os

img_width = 1600
img_height = 1600

imh=Image.open('/Users/######/Documents/Project_1/By_Hour/00_00.png',)
# Create figure
fig = go.Figure()

fig.add_trace(
    go.Scatter(
        x=[0, img_width],
        y=[0, img_height],
        mode=""markers"",
        marker_opacity=0
    )
)
# Add traces, one for each slider step
for step in np.arange(5):
    fig.add_trace(str(step),type='image',
                  visible = False,
                  source= imh)
                  
      



# Create and add slider
steps = []
for i in range(5):
    step = dict(
        method=""animate"",
        args=[{""visible"": [False] * (5)},
              {""title"": ""Slider switched to step: "" + str(i)}],  # layout attribute
    )
    step[""args""][0][""visible""][i] = True  # Toggle i'th trace to ""visible""
    steps.append(step)

sliders = [dict(
    active=0,
    visible=True,
    currentvalue={""prefix"": ""Time: ""},
    pad={""t"": 50},
    steps=steps
)]

fig.update_layout(
    sliders=sliders
)

fig.show()

Is there any way of loading images in such a way?
Thank you for any help.
","I found this answer that uses an animation to simulate a discrete slider.
Basically you have to load all images and its labels before creating the figure. This is a partial answer as I have not found any working examples using traces.
",,,false,,,
https://stackoverflow.com/questions/60393253,true,"The issue involves unexpected behavior in a Plotly bar chart when using Crosstalk. The behavior is related to the interaction between Crosstalk and Plotly, and it requires advice on how to avoid the gaps in the bar chart when selecting through the Crosstalk filter.",,,,,,,Unselected entries displayed on axis - Crosstalk+Plotly bar-chart,"
EDIT
This seems to be an issue already known to the plotly community
github plotly issue #689
and there is an analogous question here on SO.
Unfortunately, it seems no solution is available yet. Any advice would be greatly appreciated.

I am trying to use Crosstalk and Plotly to create a dashboard and I have come across an unexpected behaviour.
When selecting through the Crosstalk filter, the Plotly bargraph leaves ""gaps"" for the unselected entries.
As a reproducible example, let's say I want to compare cities populations, what I am getting is this (code at the bottom):

It might very well be that I am missing something, is there a way to get rid of the gap? any advice on viable ways to do a similar comparison avoiding the issue?
Thanks in advance.
Code:
---
title: ""Crosstalk+Plotly bargraph selection""
---
 
```{r setup, include=FALSE}
options(stringsAsFactors = FALSE)
library(crosstalk) 
library(dplyr)
library(plotly)  

#data on cities' population
city_pop &lt;- data.frame(""City"" = c(""Florence"",  ""Milan"", ""Venice""),
                    ""Population"" = c(382258, 1352000, 261905))

#setting up Crosstalk shared data
sd &lt;- SharedData$new(city_pop, key = city_pop$city)

#filter for the cities
filt &lt;- filter_select(
  id = ""select_name"",
  label = ""Selected City"",
  sharedData = sd,
  group = ~City)

#barplot of cities' population
bars_pop &lt;- plot_ly(sd, x = ~City, y = ~Population) %&gt;% 
add_bars(width=0.2,
           x =  ~City,
       y =  ~Population,
       color = I(""#89CFF0""),
       name = """",
       opacity=.9,
       hoverinfo = 'y',
       hovertemplate = paste('%{x} &lt;br&gt; number of Residents: %{y}&lt;extra&gt;&lt;/extra&gt;')
       ) 
  
  

```

```{r, echo=FALSE}
filt

bars_pop
```

","This worked for me - on the axis where it's happening, set categoryorder = ""trace"".
e.g.,
plot_ly(...) %&gt;% layout(yaxis = list(categoryorder = ""trace""))

",,,false,,,
https://stackoverflow.com/questions/69870017,false,"The issue does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is a problem with the Jinja syntax in a Flask web app when using Plotly, and it requires guidance on resolving the syntax conflict.",,,,,,,Plotly Graphs - Conflict between Javascript and Jinja,"I've tried plotting graphs in my Flask web app using Plotly which didn't work for some reason so I started to simplify the issue to find the error.
It seems like there is an issue with the Jinja Syntax {{ myJSONfile | safe }} in javascript.
Aslong as I pass an empty string """" to the variable the graph renders but obviously without datapoints.
(Inspect Element Console gives an Unexpected token '{' Error referring to the first opening bracket of my Jinja variable)
According to this post I should have written the the syntax inside the javascript block correctly in order to pass a JSON-File to the javascript variable and I am out of ideas right now.
I'd appreciate if somebody has further ideas and can help me out here :)
Code example:
   {% extends ""layout.html"" %} {% block content %}

&lt;div class="" row p-4 ""&gt;
    &lt;div class=""card m-auto "" style=""width: 90%; "" data-aos=""fade-left ""&gt;
        &lt;div class=""card-body ""&gt;
            &lt;div id=""chart1 ""&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;


&lt;script src=""https://cdn.plot.ly/plotly-latest.min.js ""&gt;&lt;/script&gt;
&lt;script&gt;
    var graphs1 = {
        {
            graph1JSON | safe
        }
    };
    Plotly.plot(""chart1 "", graphs1, {});
&lt;/script&gt;

I've since tested out another test code from a tutorial github repository to eliminate the possibility that it may have been some typing errors in my code I wasn't able to identify.
But those copy paste examples gave me the same issue.
I've tried different things suggested in some posts I've found here on Stackoverflow

checked again if my data was saved to the JSON variable in app.py correctly (which it does)
using quotes like: var graph1 = '{{ graph1JSON | safe }}'
using block code syntax: var graph1 = {%block code %} {{ graph1JSON | safe }} {%endblock code %}
Several combinations of above syntax

During debug I clearly see that the JSON file is created successfully and holds the desired data, Flask/Jinja just doesnt want to communicate with Javascript
Here's an additional Screenshot of how the syntax highlighting looks in my VS Code. (Other than in this particular case my Flask app is running fine, being able to render pages dynamically etc.)

(Syntax not recognized in the javascript part)
","The problem here lies with VSCode, especially with Syntax Highlighting and Formatting Extensions.
There is some conflict between some of your enabled extensions which - on save - format the javascript code in above way.

Disable all enabled formatting extensions in VSCode
I only activated the following:


Python
Python Extension Pack by Jayamanne
Better Jinja by Samuel Colvin

This way on save the syntax doesn't get shredded anymore making the JavaScript recognize your JSON-File correctly.
","Please do not pull apart the jinja instruction. Jinja looks for double curly brackets in the template, which follow one another directly with no whitespace in between.
var graphs1 = {{ graph1JSON | safe }};
Plotly.plot('chart1', graphs1, {});

",,false,,,
https://stackoverflow.com/questions/59379227,true,"The issue involves a problem with a ggplot2 line chart in an R Shiny app when using the ""key"" property and facet_grid. The behavior is unexpected as the lines do not show up when using the ""key"" property and facet_grid together. It requires guidance on resolving the issue and achieving the desired behavior.",,,,,,,R Shiny ggplot2 line chart won&#39;t show lines when using &quot;key&quot; property and facet_grid,"I have an R shiny app that is displaying a line chart with a facet grid. I therefore use ggplot2 and plotly.

Now I want to make it possible to click a position on a line and retrieve the corresponding data row from the data frame.

I learned fetching the click event is possible by catching the ""plotly_click"" click event via event_data(""plotly_click""). This works; I get a curve number, x- and y- coordinates. Now to get a reference to my data row I learned I have to use a ""key"" property for ggplot like stated here: How can I grab the row of data from a ggplotly in shiny.

Now when I add the ""key"" property to my ggplot suddenly the lines won't show up anymore (it seems the chart stays empty). Interestingly, when I remove facet_grid, some lines will show up and clicking it provides the ""key""-information with the event like stated in the link above.

EDIT:

I reproduced the behavior with the mtcars exmaple:

library(shiny)
library(plotly)
library(tidyr)

mtcars$key &lt;- row.names(mtcars)

ui &lt;- fluidPage(
    plotlyOutput(""originalLinePlot""),
    plotlyOutput(""keyLinePlot""),
    verbatimTextOutput(""click""),
)

server &lt;- function(input, output) {

    output$originalLinePlot &lt;- renderPlotly({
        # here I want to add click event with data row selection - click doesn't return key info

        data_long &lt;- gather(mtcars, condition, measurement, c(drat, wt), factor_key=TRUE)

        g &lt;- ggplot(data_long, aes(x=mpg))
        # won't work
        # g &lt;- ggplot(data_long, aes(x=mpg, key=key))

        g &lt;- g + facet_grid(rows = vars(condition), scales=""free_y"")
        g &lt;- g + geom_line(aes(y=measurement))
        g
    })


    output$keyLinePlot &lt;- renderPlotly({
        data_long &lt;- gather(mtcars, condition, measurement, c(drat, wt), factor_key=TRUE)

        g &lt;- ggplot(data_long, aes(x=mpg, key=key))

        # won't work
        # g &lt;- g + facet_grid(rows = vars(condition), scales=""free_y"")
        g &lt;- g + geom_line(aes(y=measurement))
        g
    })

    output$click &lt;- renderPrint({
        d &lt;- event_data(""plotly_click"")
        if (is.null(d)) ""Click events appear here (double-click to clear)"" else data.frame(d) 
    })
}

shinyApp(ui = ui, server = server)


May it be that due to the key-property the line chart gets confused as how to draw its lines? The lines appearing when removing the facet_grid and having the ""key""-propery included look quite strange..

Any ideas how to resolve this? Can I solve my issue also in a different way than using the key-property?

Thanks and BR!
","I've found a solution of how to solve this: by combining points and lines and adding the key information to the points instead of the lines - see second plot:

library(shiny)
library(plotly)
library(tidyr)

mtcars$key &lt;- row.names(mtcars)

ui &lt;- fluidPage(
    plotlyOutput(""originalLinePlot""),
    plotlyOutput(""keyLinePlot""),
    verbatimTextOutput(""click""),
)

server &lt;- function(input, output) {

    output$originalLinePlot &lt;- renderPlotly({
        # here I want to add click event with data row selection - click doesn't return key info

        data_long &lt;- gather(mtcars, condition, measurement, c(drat, wt), factor_key=TRUE)

        g &lt;- ggplot(data_long, aes(x=mpg))
        # won't work
        # g &lt;- ggplot(data_long, aes(x=mpg, key=key))

        g &lt;- g + facet_grid(rows = vars(condition), scales=""free_y"")
        g &lt;- g + geom_line(aes(y=measurement))
        g
    })


    output$keyLinePlot &lt;- renderPlotly({
        data_long &lt;- gather(mtcars, condition, measurement, c(drat, wt), factor_key=TRUE)

        g &lt;- ggplot(data_long, aes(x=mpg))

        g &lt;- g + facet_grid(rows = vars(condition), scales=""free_y"")
        g &lt;- g + geom_line(aes(y=measurement))
        g &lt;- g + geom_point(aes(y=measurement, key=key))
        g
    })

    output$click &lt;- renderPrint({
        d &lt;- event_data(""plotly_click"")
        if (is.null(d)) ""Click events appear here (double-click to clear)"" else data.frame(d) 
    })
}

shinyApp(ui = ui, server = server)



",,,false,,,
https://stackoverflow.com/questions/71399250,true,The issue involves synchronizing zoom and pan between two graphs in a Dash + Plotly dashboard when using imshow. The behavior is unexpected as the second graph does not update when zooming on the first graph. It requires guidance on resolving the synchronization issue and achieving the desired behavior.,,,,,,,Dash+Plotly Synchronize zoom and pan between two plots using imshow,"I try to synchronize zoom and pan between two graphs in a dashboard (dash + plotly). I obtain strange behavior when I zoom on a graph, the second graph does not update. I need to zoom on the second graph to make both graphs update but not with the same zoom nor the same location on the graphs. Furthermore the shapes of the two graphs change.
Below is the code I am in. I do not see I am doing wrong.
import os

from dash import Dash, html, dcc, Input, Output, State
import plotly.express as px
import numpy as np
import rasterio as rio

app2 = Dash(__name__)

data_folder = r'.\data'
store = {}

for filename in os.listdir(data_folder):
    if os.path.isfile(os.path.join(data_folder, filename)):
        band_name = filename.replace('.', '_').split(sep='_')[-2]
        with rio.open(os.path.join(data_folder, filename)) as dataset:
            nb_band = dataset.count
            if nb_band == 1:
                data = dataset.read(1)
            else:
                data = dataset.read(tuple(range(1, nb_band + 1)))

            if band_name == 'triband':
                data = np.swapaxes(data, 2, 0)
                data = np.swapaxes(data, 0, 1)
                store[band_name] = data.astype(float)
            else:
                store[f'B{band_name}'] = data.astype(float)

fig1 = px.imshow(store['triband'])
fig1.update_xaxes(showticklabels=False, showgrid=False, zeroline=False)
fig1.update_yaxes(showticklabels=False, showgrid=False, zeroline=False)
fig1.update_layout(
    margin=dict(l=0, r=0, t=0, b=0),
    plot_bgcolor='rgba(0, 0, 0, 0)',
    paper_bgcolor='rgba(0, 0, 0, 0)',
)


# Application structure and content
app2.layout = html.Div(className='main', children=[
    html.H1(children='Hello Dash', style={'padding': 10}),

    html.Div(children=[

        html.Div(children=[
            dcc.Graph(
                id='graph1',
                figure=fig1,
                responsive=True
            )
        ], style={'padding': 5, 'flex': 1}),

        html.Div(children=[
            dcc.Graph(
                id='graph2',
                figure=fig1,
                responsive=True
            )
        ], style={'padding': 5, 'flex': 1})

    ], style={'display': 'flex', 'flex-direction': 'row'}),
])


@app2.callback(Output('graph2', 'figure'),
               Input('graph1', 'relayoutData'),
               State('graph2', 'figure'))
def graph_event1(select_data, fig):
    if select_data is not None:
        try:
            fig['layout']['xaxis']['range'] = [select_data['xaxis.range[0]'], select_data['xaxis.range[1]']],
            fig['layout']['yaxis']['range'] = [select_data['yaxis.range[0]'], select_data['yaxis.range[1]']]
        except KeyError:
            pass
    return fig


@app2.callback(Output('graph1', 'figure'),
               Input('graph2', 'relayoutData'),
               State('graph1', 'figure'))
def graph_event2(select_data,  fig):
    if select_data is not None:
        try:
            fig['layout']['xaxis']['range'] = [select_data['xaxis.range[0]'], select_data['xaxis.range[1]']],
            fig['layout']['yaxis']['range'] = [select_data['yaxis.range[0]'], select_data['yaxis.range[1]']]
        except KeyError:
            pass
    return fig


if __name__ == '__main__':
    app2.run_server(debug=True)

","I found a solution : rather than creating two graphs, I created a graph with several subplots and force zoom and pan between subplots.
fig = make_subplots(rows=1, cols=3, shared_xaxes=True, shared_yaxes=True)
fig.add_trace(
    px.imshow(store['triband']).data[0],
    row=1, col=1
)

fig.add_trace(
    px.imshow(index_store['NDVI']).data[0],
    row=1, col=2
)

fig.add_trace(
    px.imshow(np.where(index_store['NDVI'] &gt;= np.median(index_store['NDVI']),
                       0.8 * np.max(index_store['NDVI']),
                       0.8 * np.min(index_store['NDVI']))
              ).data[0],
    row=1, col=3
)

fig.update_xaxes(matches='x', showticklabels=False, showgrid=False, zeroline=False)
fig.update_yaxes(matches='y', showticklabels=False, showgrid=False, zeroline=False)

",,,false,,,
https://stackoverflow.com/questions/62646432,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Verbose response after install conda package,"I've encountered the following problem when I attempted to install a couple of packages. I'll use sqlite3 as an example.
When I entered conda install -c blaze sqlite3 in the Anaconda prompt (""base"" environment), I received the output below.
I'm uncertain exactly when this problem started. I checked my revisions using conda list -r. Revision #35 - conda  {4.8.3 (conda-forge/win-64) -&gt; 4.8.3 (anaconda/win-64)} - looks odd.
Therefore, I entered conda install revision 34. When I did so, I was informed that conda-forge/win-64 cannot be found, which seems strange. As mentioned earlier, I'm unclear if there's a correlation between revision 34 and this error.
The sqlite3 package listed in the ""base"" environment in the Anaconda Navigator.
How do I prevent conda from automatically running the additional code?
Collecting package metadata (current_repodata.json): done
Solving environment: /
Warning: 2 possible package resolutions (only showing differing packages):
  - anaconda/win-64::conda-4.8.3-py37_0
  - defaults/win-64::conda-4.8.3-py37done

## Package Plan ##

  environment location: C:\Users\morga\Anaconda3

  added / updated specs:
    - sqlite3


The following NEW packages will be INSTALLED:

  sqlite3            blaze/win-64::sqlite3-3.8.6-0


Proceed ([y]/n)? y

Preparing transaction: done
Verifying transaction: done
Executing transaction: done

C:\Users\morga&gt;SET DISTUTILS_USE_SDK=1

C:\Users\morga&gt;SET MSSdk=1

C:\Users\morga&gt;SET platform=

C:\Users\morga&gt;IF /I [AMD64] == [amd64] set ""platform=true""

C:\Users\morga&gt;IF /I [] == [amd64] set ""platform=true""

C:\Users\morga&gt;if defined platform (set ""VSREGKEY=HKEY_LOCAL_MACHINE\SOFTWARE\Wow6432Node\Microsoft\VisualStudio\14.0"" )  ELSE (set ""VSREGKEY=HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\VisualStudio\14.0"" )

C:\Users\morga&gt;for /F ""skip=2 tokens=2,*"" %A in ('reg query ""HKEY_LOCAL_MACHINE\SOFTWARE\Wow6432Node\Microsoft\VisualStudio\14.0"" /v InstallDir') do SET ""VSINSTALLDIR=%B""
ERROR: The system was unable to find the specified registry key or value.

C:\Users\morga&gt;if """" == """" (set ""VSINSTALLDIR="" )

C:\Users\morga&gt;if """" == """" (
ECHO ""WARNING: Did not find VS in registry or in VS140COMNTOOLS env var - your compiler may not work""
 GOTO End
)
""WARNING: Did not find VS in registry or in VS140COMNTOOLS env var - your compiler may not work""
The system cannot find the batch label specified - End

&lt;&lt;&lt;&lt;EDIT - ADDITIONAL COMMENT&gt;&gt;&gt;
I did more research it seems that the package  vs2015_win-64 is causing the problem. Others had similar experiences.
I executed conda uninstall  vs2015_win-64. The uninstallation was initiated then stopped and I received the error below.
The same thing occurred when I tried to install plotly using conda install plotly.
Error processing line 1 of C:\Users\morga\Anaconda3\lib\site-packages\matplotlib-3.1.0-py3.7-nspkg.pth:

  Traceback (most recent call last):
    File ""C:\Users\morga\Anaconda3\lib\site.py"", line 168, in addpackage
      exec(line)
    File ""&lt;string&gt;"", line 1, in &lt;module&gt;
    File ""&lt;frozen importlib._bootstrap&gt;"", line 580, in module_from_spec
  AttributeError: 'NoneType' object has no attribute 'loader'

","It is very unlikely this has anything to do with the change in the conda package in that revision (where it switched from sourcing at Conda Forge to Anaconda channel). Instead, some packages include additional installation scripts that must be run during installation for the package to function. There is currently not any way to prevent Conda from executing such scripts.
It might be worth reflecting here that this is a good example of why one should not install packages from channels that one does not explicitly trust. That is, searching Anaconda Cloud to find a package on a random user channel could lead to running arbitrary code that the user has included in the package build.
",,,false,,,
https://stackoverflow.com/questions/68628153,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Y Ticks in Wrong Order,"I have a dataset that I'm plotting using plotly with python and for some reason the y-axis ticks are in the wrong order. When the value on the y-axis decreases the line on the chart is going higher.
Here is a small example of how the dataset is structured:
dfmeds = 

Start       Name                Medication  End           Dose
2020-12-09  Yosemite Sam        Lexapro     2021-06-30    5
2020-12-10  Yosemite Sam        Lexapro     2021-06-30    5
2020-12-11  Yosemite Sam        Lexapro     2021-06-30    5
2020-12-12  Yosemite Sam        Lexapro     2021-06-30    5
2020-12-13  Yosemite Sam        Lexapro     2021-06-30    5
2020-12-14  Yosemite Sam        Lexapro     2021-06-30    5
2020-12-15  Yosemite Sam        Lexapro     2021-06-30    4
2020-12-16  Yosemite Sam        Lexapro     2021-06-30    4
2020-12-17  Yosemite Sam        Lexapro     2021-06-30    4
2020-12-18  Yosemite Sam        Lexapro     2021-06-30    4
2020-12-19  Yosemite Sam        Lexapro     2021-06-30    4
2020-12-20  Yosemite Sam        Lexapro     2021-06-30    3
2020-12-21  Yosemite Sam        Lexapro     2021-06-30    3
2020-12-22  Yosemite Sam        Lexapro     2021-06-30    3
2020-12-23  Yosemite Sam        Lexapro     2021-06-30    3
2020-12-24  Yosemite Sam        Lexapro     2021-06-30    3
2020-12-25  Yosemite Sam        Lexapro     2021-06-30    2
2020-12-26  Yosemite Sam        Lexapro     2021-06-30    2
2020-12-27  Yosemite Sam        Lexapro     2021-06-30    2
2020-12-28  Yosemite Sam        Lexapro     2021-06-30    2

and the code I'm using to create the graph...
    fig2 = px.line(dfmeds, x='Start', y=""Dose"", color = ""Medication"",
        # labels={""Episode_Count"": tally + "" per Shift"",
        #         ""Target"":""Target"",
        #         ""Yr_Mnth"": ""Date"" },
        title=""Medication Dosages"")
    fig2.update_xaxes(tickangle=45,)
    fig2.update_yaxes(tickmode='linear')
    fig2.update_layout(template = 'plotly_white',hovermode=""x unified"")

and frustratingly this is my output:

Note the green trace in particular. Have any of you kind souls out there in the annals of the web came across this strange phenomenon?! I've looked at the docs for y-ticks and can't find any method of controlling the order...
############################# EDIT ##################################
As two people have pointed out in the comments the reason the for the lack of numerical order was that the ""Dose"" column was being passed in as an object and was therefore being handled as a categorical.
So I changed the dtype to numerical to address:
    dfmeds[""Dose""] = pd.to_numeric(dfmeds[""Dose""])

Though that introduced a new problem, due to the substantial range of dosage values the y-axis ticks is all bunched up:

I feel I should be able to fix that by formatting the y-ticks though the best case scenario would be to keep the categorical input and control the order as means the value of each trace can clearly be seen on the y-axis.
If anyone has any suggestions they would be greatly appreciated.
","As pointed out in the comments part of the issue was that the y-axis values were being passed in as an object and therefore were treated categorically.
Easily addressed by converting dfmeds['Dose'] to numeric, in my case I also had to extract text from some cells also which is handled in the first line:
#strip non numeric characters
dfmeds['Dose'] = dfmeds['Dose'].str.extract('(\d+)', expand=False)
#convert to numeric
dfmeds['Dose'] = pd.to_numeric(dfmeds['Dose'])

The issue referred to in the ""edit"" was that I had ""tickmode"" set to linear. Which was also easily addressed by removing:
fig2.update_yaxes(tickmode='linear')

I hope this helps some other poor soul in need out there, happy programming!
",,,false,,,
https://stackoverflow.com/questions/67749574,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,"Python: Plotly &amp; Dash | Real time graph dcc.Interval, function called twice... bug?","First post here, I hope you can help me with this weird situation… I’m working on some realtime plotting with plotly (dcc.Interval) and I just find one of the functions I’m using for getting my data is being called twice during the execution. This is very strange as I’m just calling this function once and it’s really messing with my code:
import dash
from dash.dependencies import Output, Input
import dash_core_components as dcc
import dash_html_components as html
import plotly
import plotly.graph_objs as go

import random

X = []; X.append(0)
Y = []; Y.append(1)

# THIS IS AN EXAMPLE OF A FUNCTION
def formula():
    er = 'text'
    return(er)

# CALLING THE FORMULA, JUST PRINTING THE TEXT
print(formula())

app = dash.Dash(__name__)

app.layout = html.Div(children=[
    html.H1(children='Ejemplo grafica'),
    dcc.Graph(id='live-graph', animate=True),
    dcc.Interval(
        id='graph-update',
        interval=1000
        ),
    ]
)

@app.callback(Output('live-graph', 'figure'),
              [Input('graph-update', 'n_intervals')])

def update_graph(input_data):
    X.append(X[-1]+1)
    Y.append(Y[-1]+Y[-1]*random.uniform(-0.1,0.1))

    data = plotly.graph_objs.Scatter(
            x=list(X),
            y=list(Y),
            name='Scatter',
            mode= 'lines'
            )

    return {'data' : [data],
            'layout' : go.Layout(
                xaxis=dict(range=[X[0],X[-1]]),
                yaxis=dict(range=[min(Y)-0.1,max(Y)+0.1]),)
            }

if __name__ == '__main__':
    app.run_server(host='127.0.0.1', port=8080 ,debug=True)

The output of the program is:
C:\Users\s3853339\Miniconda3\envs\spec\python.exe C:/pythonprojects/spectrometer/test_plotly.py
text # FUNCTION HAS BEEN CALLED ONCE
Dash is running on http://127.0.0.1:8080/

 * Serving Flask app 'test_plotly' (lazy loading)
 * Environment: production
   WARNING: This is a development server. Do not use it in a production deployment.
   Use a production WSGI server instead.
 * Debug mode: on
text # SECOND CALLING OF THE FUNCTION... WHAT HAPPENED HERE???

","The code is run twice because you are in debug mode. Set debug=False, and it should execute only once.
",,,false,,,
https://stackoverflow.com/questions/45947951,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,"plotly, not showing coordinates with np.array dataset","I wish to display a dataset of 1000 float, I have decided to do this with plotly, and I want to do it offline, I am getting in to a problem I really can't understand - I simply don't know what I am doing wrong at all.

Let's jump in to the code. First of I will show that the code should work, with a small np.array

import numpy as np
import plotly as py
import plotly.graph_objs as go

list = [1.2,2.3,3.3,4.4,5.4,6.4] 
x_data = np.array(list)
y_data = np.array(list)

#x_data = np.array(graph_test_q())
#y_data = np.array(graph_test_h())

trace = go.Scatter(
   x = x_data,
   y = y_data,
)

data = [trace]
fig = dict(data=data)
py.offline.plot(fig, filename='hejsa.html')
print data


The output of the above code:

Seems to work fine, but:
Below is the code, where I use a np.array created from a function, that extracts it from a postgrSQL db. I have checked, and it does print the data in the terminal.

def graph_test_q():
    conn = psycopg2.connect(""dbname='database1' user='postgres'        password='FFgg1905560' host='localhost' port='5432'"")
    cur  = conn.cursor()
    cur.execute(""SELECT q FROM pump_data_test WHERE pump_id = 1229"")
    rows = cur.fetchall()
    conn.commit()
    conn.close()
    return rows

def graph_test_h():
    conn = psycopg2.connect(""dbname='database1' user='postgres'    password='FFgg1905560' host='localhost' port='5432'"")
    cur  = conn.cursor()
    cur.execute(""SELECT h FROM pump_data_test WHERE pump_id = 1229"")
    rows = cur.fetchall()
    conn.commit()
    conn.close()
    return rows

#list = [1.2,2.3,3.3,4.4,5.4,6.4]
#x_data = np.array(list)
#y_data = np.array(list)

x_data = np.array(graph_test_q())
y_data = np.array(graph_test_h())

trace = go.Scatter(
    x = x_data,
    y = y_data,
)

data = [trace]
fig = dict(data=data)
py.offline.plot(fig, filename='hejsa.html')
print data


Now here is what I find strange, the output of these new np.arrays is this empty graph:


When I click on the link in the bottom right corner - ""export to plot.ly"" this is now the output I get:

Here I can see see the graph on the left, just as it's supposed to be. I would be very appreciated if anyone can help me find out what I'm doing wrong.

EDIT:
From comments: Code for showing dtypes of x_data &amp; y_data ( x_data = np.array(graph_test_q()) &amp; y_data = np.array(graph_test_h())):

print(x_data.dtype)
print(y_data.dtype)


output:



float64
float64
0:96: execution error: ""file://hejsa.html"" doesn’t understand the “open location” message. (-1708)
70:78: execution error: Can’t get application ""firefox"". (-1728)
 * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)
","fetchall returns tuples, so you end up with a Numpy array which has a shape of (n, 1) where n is the number of results. You could get the data in the correct format for Plotly using the following index:

np.array(graph_test_q())[:,0]


See below for a complete demo.

import plotly
import numpy as np
import random
import sqlite3

def graph_test_q():
    cur  = conn.cursor()
    cur.execute(""SELECT q FROM pump_data_test WHERE pump_id = 1229"")
    rows = cur.fetchall()
    return rows

def graph_test_h():
    cur  = conn.cursor()
    cur.execute(""SELECT h FROM pump_data_test WHERE pump_id = 1229"")
    rows = cur.fetchall()
    return rows

plotly.offline.init_notebook_mode()

# Create some mockup data
conn = sqlite3.connect(':memory:')
c = conn.cursor()
c.execute(""CREATE TABLE pump_data_test (h, q, pump_id)"")
for i in range(10):
    c.execute(""INSERT INTO pump_data_test VALUES ('{}','{}',1229)"".format(i, i + random.random()))
conn.commit()

trace1 = plotly.graph_objs.Scatter(
    name='works',
    x=np.array(graph_test_q())[:,0],
    y=np.array(graph_test_h())[:,0],
)
trace2 = plotly.graph_objs.Scatter(
    name='does not work',
    x=np.array(graph_test_q()),
    y=np.array(graph_test_h()),
)

data = [trace1, trace2]
fig = dict(data=data)
plotly.offline.iplot(fig)



",,,false,,,
https://stackoverflow.com/questions/45707351,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Shiny - Plotly Time Series and dateRangeInput,"I've got a Shiny dashboard with an Plotly time series, the range of which is adjusted via a reactive dateRangeInput I put together (please see code below). 

Everything was working fine, but then I updated my packages. Since then, the variables do not automatically show in the first instance, you have to choose the date ranges instead of the plot loading in with a default time range.

What's more the dateRangeInput is using strange language such as monate, tueate, wedate etc.

I need some help to establish what my issue may be.

Session info

Prior to the update I was using Plotly 3.6.0, shinyDashboard 0.5.1 and shiny 0.13.2.

After the update I am using Plotly 4.5.6, shinyDashboard 0.5.3 and shiny 0.14.2

Please see the respective code below

ui - plotlyOuput Time Series code

box(width = 8, 
    solidHeader = TRUE, 
    plotlyOutput(""Time_Ser"", height =""300px""))


ui - dateRangeInput code

dateRangeInput(""date"",""Date:"", 
              label = h4(""Time Series: select dates""),
              start = ""2017-05-02"",
              end = ""2017-07-30"", 
              min = ""2017-05-02"",
              max = ""2017-06-30"", 
              startview = ""2017-06-30"")


server - Reactive input code

        Time2 &lt;- Time
                 reactiveTime &lt;- reactive({
                 Time2 %&gt;% filter(Date.received&gt;=input$date[1] &amp; 
                 Date.received&lt;input$date[2])
                 })


server - output

       output$Time_Ser &lt;- renderPlotly({
                          Time_Ser &lt;- plot_ly(reactiveTime(), 
                          x = ~Date.received, 
                          y = ~n, 
                          type = ""scatter"", 
                          mode = ""lines"") %&gt;%
                          layout(title = ""Enquiries Time Series"")
                          })


Supporting images




","Try using something like the following for your dateRangeInput.  I can't explain why your code worked before, but note that startview should be a categorical string, you can specify date format shown (to overwrite the fact that it seems to be defaulting to DD), and you can force language (but shouldn't actually need to). 

dateRangeInput(""date"", ""Date:"", 
          label = h4(""Time Series: select dates""),
          start = ""2016-05-02"",
          end = ""2016-12-31"",
          min = ""2016-01-01"",
          max = ""2016-12-31"",
          startview = ""year"",
          weekstart=0,
          language=""en"",
          format=""yyyy-mm-dd"")



Note that the dates in the above apply to some dummy data I created for testing purposes.

",,,false,,,
https://stackoverflow.com/questions/45992342,true,"The issue involves unexpected behavior in the plotly package's color palette when a color is removed from the palette. This can lead to the replacement of the expected color with an unexpected color (e.g., magenta instead of blue).",,,,,,,Plotly is blending palette colors in R,"When I'm trying to define a custom palette, say of blue and red colors, I get magenta instead of blue. Let's consider an example taken from plotly documentation:

library(plotly)
pal &lt;- c(""red"", ""blue"", ""green"")
p &lt;- plot_ly(data = iris, x = ~Sepal.Length, y = ~Petal.Length, 
      color = ~Species, colors = pal)
p


This works as expected. Each of three species get it's own color: red, blue or green.

Then I prepare a new data set, removing ""virginica"", and plotting the result:

library(dplyr)
pal &lt;- c(""red"", ""blue"", ""green"")
iris_new&lt;- filter(iris, Species == ""setosa"" | Species == ""versicolor"")
p &lt;- plot_ly(data = iris_new, x = ~Sepal.Length, y = ~Petal.Length, 
      color = ~Species, colors = pal)
p


Now ""setosa"" is red and ""versicolor"" is blue. We don't use green color, so it seems reasonable to remove it:

pal &lt;- c(""red"", ""blue"")
iris_new&lt;- filter(iris, Species == ""setosa"" | Species == ""versicolor"")
p &lt;- plot_ly(data = iris_new, x = ~Sepal.Length, y = ~Petal.Length, 
      color = ~Species, colors = pal)
p


The result, obviously, should be the same, as in previous chunk of code, but in fact it isn't: the blue color is replaced by magenta, and that is very strange.
","I think this is probably just because you have a 2 colour palette mapped to a 3 level factor - until you drop the unused level from the Species factor, it's still considered an attribute of the Species variable and will affect how it is plotted.

Dropping the factor level makes the colours behave as you expected:

iris_new&lt;- filter(iris, Species == ""setosa"" | Species == ""versicolor"") %&gt;%
    mutate(Species = droplevels(Species))
p &lt;- plot_ly(data = iris_new, x = ~Sepal.Length, y = ~Petal.Length, 
             color = ~Species, colors = pal)
p

",,,false,,,
https://stackoverflow.com/questions/74954985,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Adding Mapbox Layer to Plotly Map Positioned Over Data Layer,"I'm trying to understand how to situate a data layer within a stack of vector layers using Plotly's Mapbox functionality. I think this is possible with the following approach. Using Mapbox Studio, I've created two map styles: one which represents the base map that all data layers should be placed on top of and another which represents the remaining map layers that should be layered on above the data layers.
This example from the Plotly documentation seems to point to the viability of this approach.
Here's demo code that I put together to try and realize the result I'm after. The last update_layout statement is not adding the Mapbox layer. Not sure what I'm missing here. Any suggestions? Maybe the Mapbox style spec can't be passed for additional layers?
import plotly.graph_objects as go
import pandas as pd

us_cities = pd.read_csv(""https://raw.githubusercontent.com/plotly/datasets/master/us-cities-top-1k.csv"")

fig = go.Figure(go.Scattermapbox(lat=us_cities[""lat""], lon=us_cities[""lon""]))
fig.update_layout(mapbox_style=""mapbox://styles/diehl/cl9gh775w000014n2jwfncok7"", mapbox_accesstoken=MAPBOX_ACCESS_TOKEN)
fig.update_layout(mapbox_center_lat=38, mapbox_center_lon=-97, mapbox_zoom=3.25)
fig.update_layout(margin={""r"":0,""t"":0,""l"":0,""b"":0})

fig.update_layout(
    mapbox_layers=[
    {
        ""sourcetype"": ""vector"",
        ""source"": [""mapbox://styles/diehl/cl9gha8ta000914qm137qf52q""]
    }
])

fig.show()

UPDATE: Took a small step forward in that I got something to render. Replacing the last fig.update_layout statement with the following causes additional circles to be rendered instead of the vector tiles which is strange. The vector tiles referred to here correspond to the border for the state of New Mexico. Not complex by any means. Why that vector tile layer is showing up as additional circles I assume is due to the plot being a scatter plot. Any thoughts about how to get around this would be greatly appreciated!
fig.update_layout(
  mapbox_layers=[
  {
      ""sourcetype"": ""vector"",
      ""source"": ['https://api.mapbox.com/v4/diehl.3rvgqhks/{z}/{x}/{y}.mvt'],
      ""sourcelayer"": ""new_mexico_bnd""
  }  ])

For what it is worth, I noticed in the Chrome dev console the following message: ""Geometry exceeds allowed extent, reduce your vector tile buffer size""
","After much digging in the documentation, it became clear that my strategy is misguided. The more appropriate approach is to specify the full vector stack for the basemap and then use the below functionality to tell Plotly where to slot a particular trace into the basemap. Here's a working example.
import plotly.graph_objects as go
import pandas as pd

us_cities = pd.read_csv(""https://raw.githubusercontent.com/plotly/datasets/master/us-cities-top-1k.csv"")
token = &lt;MAPBOX_ACCESS_TOKEN&gt;

fig = go.Figure(go.Scattermapbox(lat=us_cities[""lat""], lon=us_cities[""lon""]))
fig.update_layout(mapbox_style=""mapbox://styles/mapbox/light-v10"", mapbox_accesstoken=token)
fig.update_layout(mapbox_center_lat=38, mapbox_center_lon=-97, mapbox_zoom=3.25)
fig.update_layout(margin={""r"":0,""t"":0,""l"":0,""b"":0})

# Statement that tells Plotly where to insert the trace into the basemap
fig.update_traces(below=""aeroway-polygon"", selector=dict(type='scattermapbox'))

fig.show()

","I am not sure if this answers your question in its entirety (because I am only rendering the small New Mexico sample layer on top of what you already have), but according to the plotly documentation, the default type of a mapbox layer will be ""circle"", so if we add the argument ""type"": ""line"", then the border of New Mexico renders as follows:
fig = go.Figure(go.Scattermapbox(lat=us_cities[""lat""], lon=us_cities[""lon""]))

fig.update_layout(mapbox_style=""mapbox://styles/diehl/cl9gh775w000014n2jwfncok7"", mapbox_accesstoken={MAPBOX_ACCESS_TOKEN})
fig.update_layout(mapbox_center_lat=38, mapbox_center_lon=-97, mapbox_zoom=3.25)
fig.update_layout(margin={""r"":0,""t"":0,""l"":0,""b"":0})

## update:
fig.update_layout(
    mapbox_layers=[
    {
        ""sourcetype"": ""vector"",
        ""source"": ['https://api.mapbox.com/v4/diehl.3rvgqhks/{z}/{x}/{y}.mvt'],
        ""sourcelayer"": ""new_mexico_bnd"",
        ""type"": ""line""
    }  
])

fig.show()


",,false,,,
https://stackoverflow.com/questions/56233934,false,The issue does not meet the criteria for deeper analysis as it is related to formatting and display preferences rather than an API-related problem.,,,,,,,How to keep only time on plotly graph axis,"I'm trying to create a graph with plotly and cufflinks that has dates on the xaxis, some amounts on the primary y, and time on the secondary y.

The data looks like this:

        automatic   manual  time
2019-02-25  206.0   1206.0  2019-02-26 16:58:09
2019-02-26  225.0   136.0   2019-02-27 08:33:49
2019-02-27  213.0   554.0   2019-02-28 07:25:19
2019-02-28  244.0   103.0   2019-03-01 07:32:37
2019-03-01  102.0   119.0   2019-03-04 12:06:37


The setup for the figure is as follows:

fig = go.Figure(**cf.tools.merge_figures([
    df.figure(columns=[""automatic"", ""manual""], kind=""bar"", barmode=""stack""),
    df.figure(columns=[""time""])
])).set_axis([""time""], side=""right"")


The only way I've gotten the graph I want is by setting the date part of each date in the df.time column to the same arbitrary date, like so:

df.loc[:, ""time""] = df.time.apply(lambda d: d.replace(year=1967, month=1, day=1))


However, this way I get the wrong hover text and that arbitrary date is displayed at the bottom of the secondary y.

I've tried to set the range on yaxis2 manually like so:

sotimes = [d for d in df.time.tolist() if not pd.isnull(d)]
fig[""layout""].update({""yaxis2"": {""range"": [f""{min(sotimes):%H:%M:%S}"", f""{max(sotimes):%H:%M:%S}""]}})


Strangely, this results in yaxis2 being a date range as well.

I've also tried to convert df.time to time only, either as a string or as datetime.time like so:

df.loc[:, ""time""] = df.time.apply(
    lambda d: d.time() if not pd.isnull(d) else pd.NaT)
df.loc[:, ""time""] = df.time.apply(
    lambda d: f""{d:%H:%M:%S}"" if not pd.isnull(d) else """")


Both of these result in yaxis2 not being ordered at all, the times are displayed in the order in which they appear in df.time.



EDIT 1 - add complete code

import cufflinks as cf
import plotly.graph_objs as go
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot
import pandas as pd


# plotly stuff
cf.go_offline()

dct = {
    ""date"": [""2019-02-25"", ""2019-02-26"", ""2019-02-27"", ""2019-02-28"", ""2019-03-01""],
    ""auto"": [206, 225, 213, 244, 102],
    ""manual"": [1206, 136, 554, 103, 119],
    'time': [pd.Timestamp(2019, 2, 26, 16, 58, 9), pd.Timestamp(2019, 2, 27, 8, 33, 49),
             pd.Timestamp(2019, 2, 28, 7, 25, 19), pd.Timestamp(2019, 3, 1, 7, 32, 37),
             pd.Timestamp(2019, 3, 4, 12, 6, 37)]
}
df = pd.DataFrame(dct).set_index(""date"")
df.loc[:, ""time""] = df.time.apply(lambda d: d.replace(year=1967, month=1, day=1))

fig = go.Figure(**cf.tools.merge_figures([
    df.figure(columns=[""auto"", ""manual""], kind=""bar"", barmode=""stack""),
    df.figure(columns=[""time""])
])).set_axis([""time""], side=""right"")
# sotimes = [d for d in df.time.tolist() if not pd.isnull(d)]
# fig[""layout""].update({""yaxis2"": {""range"": [f""{min(sotimes):%H:%M:%S}"", f""{max(sotimes):%H:%M:%S}""]}})
plot(fig)

","This isn't an answer to the whole question, but creates a working graph the way you would want it to. Using the approach of setting every datetime instance to the same date, you could adapt the tick labels using:
    fig[""layout""].update({""yaxis2"": {""tickformat"": ""%H:%M""}})

",,,false,,,
https://stackoverflow.com/questions/62654316,false,The issue does not meet the criteria for deeper analysis as it is related to setting tick labels and formatting the y-axis rather than an API-related problem.,,,,,,,Why this problem when showing the heatmap with Plotly?,"I want to create a simple annoted heatmap with plotly.
But I get something strange when the y values contains years ('2017','2018','2019')
for example:
import plotly.figure_factory as ff

# create a x list (month)
x = ['January',
     'February',
     'March']

#create a y list (year)
y=['2017', '2018', '2019', 'Mean']

#create a z list (the values)
z = [[1,2,3],
    [4,5,6],
    [7,8,9],
    [4,5,6]]

fig = ff.create_annotated_heatmap(z,x=x,y=y)
fig.show()

this code above give me this result :
But, if I change the y list with other string. il's ok and I get what I want.
import plotly.figure_factory as ff

# create a x list (month)
x = ['January',
     'February',
     'March']

#create a y list (year)
y=['year 1', 'year 2', 'year 3', 'Mean']

#create a z list (the values)
z = [[1,2,3],
    [4,5,6],
    [7,8,9],
    [4,5,6]]

fig = ff.create_annotated_heatmap(z,x=x,y=y)
fig.show()



How could I solve this?
","Try adding fig.update_layout(yaxis=dict(type='category')). This should ensure that the values on the y-axis are interpreted as strings.
import plotly.figure_factory as ff

# create a x list (month)
x = ['January',
     'February',
     'March']

#create a y list (year)
y=['2017', '2018', '2019', 'Mean']

#create a z list (the values)
z = [[1,2,3],
    [4,5,6],
    [7,8,9],
    [4,5,6]]

fig = ff.create_annotated_heatmap(z,x=x,y=y)

fig.update_layout(yaxis=dict(type='category'))

fig.show()

",,,false,,,
https://stackoverflow.com/questions/67216705,false,"The issue does not meet the criteria for deeper analysis as it is related to creating an envelope function and finding local maxima and minima, rather than an API-related problem.",,,,,,,How to create a bar plot with shared x-axis using plotly.express with sub-titles on top?,"I wonder how to correctly create a bar plot with shared x-axis in plotly? I created this bar plot and specified fig.update_xaxes(matches='x') which to my understanding is supposed to match the axes, but apparently this is not working. Does this look like a bug or am I doing something wrong? As you can see, it looks good except for one sub-figure, which is totally off. Sometimes, using facet_row instead of facet_col gives better results, but then the titles appear at the side of the plot. The titles are sometimes quite long and would not fit there. Therefore, I am using facet_col.
fig = px.bar(data_frame=df, x='RawFile', y=plot_column, 
             facet_col='Majority protein IDs', facet_col_wrap=1, color=color, 
             color_discrete_sequence=px.colors.qualitative.Dark24,
             color_continuous_scale=px.colors.sequential.Rainbow)

n_rows = len(df['Majority protein IDs'].drop_duplicates())

height = 300*(1+n_rows)

fig.update_layout(
        height=height,        
        margin=dict( l=50, r=10, b=200, t=50, pad=0 ),
        hovermode='closest')

fig.for_each_annotation(lambda a: a.update(text=a.text.split(""="")[-1]))
fig.update(layout_showlegend=True)
fig.update_xaxes(matches='x')


Strangely the y-axes are shared, but the x-axes are not. That is quite the opposite of what I am looking for.

# django-plotly-dash        1.6.3
# plotly                    4.14.3

I guess one solution to this would be to use facet_row however, then then I would need to move the titles from the righthand side to the top.
","My understanding is that you'd like all plot title to appear right on top of all subplots. There does not seem to be any built-in functionality to do this for plotly express. You always have the possility to adjust the elements of the figure, but it's a bit tricky in this case since you would have to adjust the heights of all subplots to make room for the titles. Here's my best attempt so far with a sample dataset:

If this is something you can use, we can take a closer look at the details.
Complete code:
import plotly.express as px
df = px.data.tips()
fig = px.scatter(df, x=""total_bill"", y=""tip"", color=""smoker"", facet_row=""sex"")
f = fig.full_figure_for_development(warn=False)

yrefs = []
for i, elem in enumerate(fig.layout):
    if elem[:5] == 'yaxis':
        yrefs.append(fig.layout[elem].domain[1])

for i, title in enumerate(fig.layout.annotations):
    title.textangle = 0
    title.y = yrefs[i] - 0.03
#     title.x = 0.5 - ((len(title.text)+1) / 100)
    title.x = 0.40
    title.align = 'center'
    title.bgcolor='rgba(0,0,0,0.25)'
    
fig.show()

",,,false,,,
https://stackoverflow.com/questions/68808298,false,"The issue does not meet the criteria for deeper analysis as it is related to adjusting the smoothing of a trendline using plotly express, rather than an API-related problem.",,,,,,,"TypeError: scatter() got an unexpected keyword argument &#39;trendline_options&#39; (Plotly, Python)","I'm getting the error:
TypeError: scatter() got an unexpected keyword argument 'trendline_options'

When trying to adjust the smoothing of the lowess tendline using plotly express.
Here is my code for the graph:
fig = px.scatter(dfg, x=""Yr_Mnth"", y=""Episode_Count"", color = ""Target"",
                        labels={""Episode_Count"": tally + "" per Shift"",
                                ""Target"":""Target"",
                                ""Yr_Mnth"": ""Date"" },
                        trendline='lowess',trendline_options= dict(frac=0.1), title=""Aggregate Behavior Data: "" + patient + "" - "" + today)
        fig.update_xaxes(tickangle=45,)
        fig.update_layout(template = 'plotly_white',hovermode=""x unified"")

Dataset (dfg):
Yr_Mnth                         Target              Episode_Count
2020-08-01                     Aggression           0.09
2020-08-01                      Elopement           0.00
2020-08-01                    Self-injury           0.97
2020-09-01                     Aggression           0.65
2020-09-01                      Elopement           0.00
2020-09-01                    Self-injury           1.58
2020-10-01                     Aggression           0.24
2020-10-01                      Elopement           0.00
2020-10-01                    Self-injury           0.75
2020-11-01                     Aggression           0.03
2020-11-01                      Elopement           0.01
2020-11-01                    Self-injury           0.89
2020-12-01                     Aggression           0.14
2020-12-01                      Elopement           0.00
2020-12-01                    Self-injury           0.94
2021-01-01                     Aggression           0.05
2021-01-01                      Elopement           0.00
2021-01-01                    Self-injury           0.30
2021-02-01                    Self-injury           0.42
2021-02-01                      Elopement           0.03
2021-02-01                     Aggression           0.16
2021-03-01                      Elopement           0.00
2021-03-01                    Self-injury           0.68
2021-03-01                     Aggression           0.20
2021-04-01                     Aggression           0.10
2021-04-01                      Elopement           0.03
2021-04-01                    Self-injury           0.33
2021-05-01                      Elopement           0.20
2021-05-01                     Aggression           0.21
2021-05-01                    Self-injury           1.63
2021-06-01                    Self-injury           0.90
2021-06-01                     Aggression           0.29
2021-06-01                      Elopement           0.14

I find this strange as I'm directly following the documentation - https://plotly.com/python/linear-fits/
Is this a known issue? I can't find any examples with a google search...
","As Henry helpfully pointed out this was just a version problem, easily addressed by updating plotly using:
pip install plotly==5.2.1

",,,false,,,
https://stackoverflow.com/questions/72261594,false,"The issue does not meet the criteria for deeper analysis as it is related to creating a bar plot with shared x-axis and adjusting plot titles, rather than an API-related problem.",,,,,,,Extract local max and min and Plot an envelope function,"My dataset:
I have the following dataset which when plotted using Plotly produces the following result (simplified):

My task:
I want to create an envelope function that extracts the local maxima and minima from data from the above dataset and plots an envelope curve. It would roughly look like this:

I have tried approaching the solutions provided here and the one for the envelope provided here. However, none of them works for me in this approach. For some strange reason, the scatter plots are producing the following results (for local min), which is not exactly what I need.
Here's my code for the initial plot:
import plotly.express as px
import plotly.graph_objects as go

fig= go.Figure()

fig.add_traces(go.Scatter(x= mem_df['time'], y=mem_df['volatge']))

fig.update_layout(xaxis_title = r'$\text{Time } T \text{ in s}  $',
                      yaxis_title = r'$\text{Deflection angle } \text{ in radians}$')
fig.update_layout(title= r'$\text{Deflection angles versus time for the damping sheet}$')
fig.show()

Any help, in this case, would be appreciated!
Thank you in advance!
","The problem is that your data contains a bit of noise. One possible approach is to find an appropriate curve fit, then find the local maximum and minimum on the fit. scipy comes to help:
import plotly.express as px
import plotly.graph_objects as go
import pandas as pd
import numpy as np
from scipy.optimize import curve_fit
from scipy.signal import argrelextrema

mem_df = pd.read_csv(""path/to/file"")
x = mem_df['time'].values
y = mem_df['deflection'].values
# dampened oscillator
func = lambda x, xi, k, phi, a, b: a * np.sin(k * x - phi) * np.exp(-xi * x) + b
popt, pcov = curve_fit(func, x, y)

fig= go.Figure()
fig.add_traces(go.Scatter(x=x, y=y, name=""data""))

# plot the curve fit
xx = np.linspace(0, 20, 150)
yy = func(xx, *popt)
fig.add_traces(go.Scatter(x=xx, y=yy, name=""fit""))

idx_max = argrelextrema(yy, np.greater)
idx_min = argrelextrema(yy, np.less)
fig.add_traces(go.Scatter(x=xx[idx_max], y=yy[idx_max], name=""top""))
fig.add_traces(go.Scatter(x=xx[idx_min], y=yy[idx_min], name=""bottom""))

fig.update_layout(xaxis_title = r'$\text{Time } T \text{ in s}  $',
                      yaxis_title = r'$\text{Deflection angle } \text{ in radians}$')
fig.update_layout(title= r'$\text{Deflection angles versus time for the damping sheet}$')
fig.show()


",,,false,,,
https://stackoverflow.com/questions/68808298,false,"The issue does not meet the criteria for deeper analysis as it is related to adjusting the smoothing of a trendline using plotly express, rather than an API-related problem.",,,,,,,"TypeError: scatter() got an unexpected keyword argument &#39;trendline_options&#39; (Plotly, Python)","I'm getting the error:
TypeError: scatter() got an unexpected keyword argument 'trendline_options'

When trying to adjust the smoothing of the lowess tendline using plotly express.
Here is my code for the graph:
fig = px.scatter(dfg, x=""Yr_Mnth"", y=""Episode_Count"", color = ""Target"",
                        labels={""Episode_Count"": tally + "" per Shift"",
                                ""Target"":""Target"",
                                ""Yr_Mnth"": ""Date"" },
                        trendline='lowess',trendline_options= dict(frac=0.1), title=""Aggregate Behavior Data: "" + patient + "" - "" + today)
        fig.update_xaxes(tickangle=45,)
        fig.update_layout(template = 'plotly_white',hovermode=""x unified"")

Dataset (dfg):
Yr_Mnth                         Target              Episode_Count
2020-08-01                     Aggression           0.09
2020-08-01                      Elopement           0.00
2020-08-01                    Self-injury           0.97
2020-09-01                     Aggression           0.65
2020-09-01                      Elopement           0.00
2020-09-01                    Self-injury           1.58
2020-10-01                     Aggression           0.24
2020-10-01                      Elopement           0.00
2020-10-01                    Self-injury           0.75
2020-11-01                     Aggression           0.03
2020-11-01                      Elopement           0.01
2020-11-01                    Self-injury           0.89
2020-12-01                     Aggression           0.14
2020-12-01                      Elopement           0.00
2020-12-01                    Self-injury           0.94
2021-01-01                     Aggression           0.05
2021-01-01                      Elopement           0.00
2021-01-01                    Self-injury           0.30
2021-02-01                    Self-injury           0.42
2021-02-01                      Elopement           0.03
2021-02-01                     Aggression           0.16
2021-03-01                      Elopement           0.00
2021-03-01                    Self-injury           0.68
2021-03-01                     Aggression           0.20
2021-04-01                     Aggression           0.10
2021-04-01                      Elopement           0.03
2021-04-01                    Self-injury           0.33
2021-05-01                      Elopement           0.20
2021-05-01                     Aggression           0.21
2021-05-01                    Self-injury           1.63
2021-06-01                    Self-injury           0.90
2021-06-01                     Aggression           0.29
2021-06-01                      Elopement           0.14

I find this strange as I'm directly following the documentation - https://plotly.com/python/linear-fits/
Is this a known issue? I can't find any examples with a google search...
","As Henry helpfully pointed out this was just a version problem, easily addressed by updating plotly using:
pip install plotly==5.2.1

",,,false,,,
https://stackoverflow.com/questions/55539395,true,"The issue involves the 'sizeref' property in the Plotly library, which affects the scaling of cone sizes in a 3D animated cone plot. The user encountered unexpected behavior due to a lack of understanding of how this factor is computed and applied.",Plotly,sizeref,The 'sizeref' property in Plotly is used to adjust the scaling of cone sizes in a 3D animated cone plot. The factor is computed internally and is based on the minimum 'time' required to travel between two successive positions at the average velocity. The user encountered strange behavior in their animations due to a lack of understanding of how this factor is calculated.,The 'sizeref' property works as expected when the user understands how to compute and set the appropriate factor for their specific use case.,"The issue arises when the user lacks understanding of how to compute and set the 'sizeref' factor correctly, leading to unexpected behavior in their animations.",This issue might be challenging to detect for users who are not familiar with the internal calculations and requirements of the 'sizeref' property in Plotly.,Size of cones in 3d animated cone plot with variable animation speed,"The docstring of the property sizeref in plotly.graph_objs._cone.py says:

        Adjusts the cone size scaling. The size of the cones is
        determined by their u/v/w norm multiplied a factor and
        `sizeref`. This factor (computed internally) corresponds to the
        minimum ""time"" to travel across two successive x/y/z positions
        at the average velocity of those two successive positions. All
        cones in a given trace use the same factor. With `sizemode` set
        to ""scaled"", `sizeref` is unitless, its default value is 0.5
        With `sizemode` set to ""absolute"", `sizeref` has the same units
        as the u/v/w vector field, its the default value is half the
        sample's maximum vector norm.

        The 'sizeref' property is a number and may be specified as:
          - An int or float in the interval [0, inf]

        Returns
        -------
        int|float


where there is this mysterious factor that is computed  and for the life of me I cannot find where it is actually computed. Since I do not understand how this weird factor is computed I get very strange behaviour in my animations as follows:

import numpy as np
import plotly.graph_objs as go
import plotly.offline as pl

###np.around used because plotly.js doesn't like full precision float64s
t = np.linspace(0,2*np.pi,100)
x = np.around(np.vstack((np.cos(t), np.cos(t+np.pi))),decimals=6)
y = np.around(np.vstack((np.sin(t), np.sin(t+np.pi))),decimals=6)
z = np.around(np.vstack((np.ones(len(t)),np.ones(len(t)))),decimals=6)

v = np.around(np.vstack((np.cos(t), np.cos(t+np.pi))),decimals=6)
u = np.around(-np.vstack((np.sin(t), np.sin(t+np.pi))),decimals=6)
w = np.around(np.vstack((np.zeros(len(t)),np.ones(len(t)))),decimals=6)

fig3=go.Figure([dict(anchor=""cm"",showscale=False,sizemode=""scaled"",type=""cone"",x=x[:,0],y=y[:,0]
                                        ,z=z[:,0]
                                        ,u=u[:,0],v=v[:,0]
                                        ,w=w[:,0])],layout=go.Layout(
    scene=dict(aspectratio=dict(x=1,y=1,z=0.25),
                    xaxis=dict(range=[-2,2], tickmode=""linear""),
                    yaxis=dict(range=[-2,2], tickmode=""linear""),
                    zaxis=dict(range=[0,5]))))

fig3.frames= [go.Frame(data=[dict(type=""cone"",x=x[:,i],y=y[:,i],z=z[:,i],u=u[:,i],v=v[:,i],w=w[:,i])], 
                             layout=go.Layout(annotations=[dict(text=""frame {}"".format(i))]))for i in np.array(range(len(t)))]

pl.plot(fig3, animation_opts=""{frame: {duration: 1}}"")


Note that you must first either remove the animation_opts kwarg or use plotly from my repo since the official version doesn't support animation_opts yet (see the issue I raised here).



Where is this factor calculated? I have scoured the code but found nothing.
Thanks in advance!

P.S Yes I included a lot of extraneous information. I have never seen an example of 3d cone animations in plotly yet so I wanted to provide one and I worked on the animation interface in plotly.py which will definitely be useful to someone!

EDIT: see this issue on github
","Found out there was an internal scaling factor in Plotly.js that was causing this mess. I have fixed this in my current repo version of plotly here.
",,,false,,,
https://stackoverflow.com/questions/55927668,true,"The issue involves a misunderstanding of logical operators and conditions in pandas, rather than a problem with the API itself.",pandas,DataFrame indexing,The user encountered unexpected behavior while filtering rows in a pandas DataFrame using multiple conditions. The issue stems from a misunderstanding of how logical operators (AND and OR) work in DataFrame indexing.,The DataFrame indexing works as expected when the user correctly understands and applies logical operators (AND and OR) in their filtering conditions.,The issue is triggered when the user misunderstands or misuses logical operators (AND and OR) in their DataFrame filtering conditions.,"This issue might be challenging to detect during development and testing, as it involves a misconception of logical operators rather than a problem with the pandas API itself.",Plotly histogram is missing data,"I'm trying to create a histogram which involves a lot of repeated values in one of the cases. One of the data points is not being represented in the graph. Here is the smallest, simplest subset I could find that still reproduced my issue.

cleanVar &lt;- c(rep(1,9),1.25,1.5)
plot_ly(data.table(cleanVar),
x = ~cleanVar,
type = ""histogram"")


The above graph shows only two bars. One centered at 1 of height 9, and one centered at 1.2 of height 1.
Also strangely, the hover-over shows ""1"" for the first bar, despite it covering the range [.9,1.1], and it shows ""1.25"" for the second bar, despite it covering the range [1.1,1.3].

If we change the 1 to only be repeated 8 times cleanVar &lt;- c(rep(1,8),1.25,1.5), so that there are 10 total values in the histogram, it works better, but still, the three bins it creates are .25 wide according to the hover-over, yet they are only .2 wide on the graph itself.

What is plotly doing? How can I properly show 3 bins of height 9,1,1 and width .25? binning options in layout() aren't working.
","By default plotly uses the following procedure to define the bins:

start:


  Sets the starting value for the x axis bins. Defaults to the minimum data value, shifted down if necessary to make nice round values and to remove ambiguous bin edges. For example, if most of the data is integers we shift the bin edges 0.5 down, so a size of 5 would have a default start of -0.5, so it is clear that 0-4 are in the first bin, 5-9 in the second, but continuous data gets a start of 0 and bins [0,5), [5,10) etc. Dates behave similarly, and start should be a date string. For category data, start is based on the category serial numbers, and defaults to -0.5. If multiple non-overlaying histograms share a subplot, the first explicit start is used exactly and all others are shifted down (if necessary) to differ from that one by an integer number of bins.


end:


  Sets the end value for the x axis bins. The last bin may not end
  exactly at this value, we increment the bin edge by size from
  start until we reach or exceed end. Defaults to the maximum data
  value. Like start, for dates use a date string, and for category
  data end is based on the category serial numbers.


You can find this information via:

library(listviewer)
schema(jsonedit = interactive())


Navigate as follows: object ► traces ► histogram ► attributes ► xbins ► start

To avoid the default behaviour just make your x variable a factor:

library(plotly)
library(data.table)

cleanVar &lt;- c(rep(1, 9), 1.25, 1.5)
plot_ly(data.table(cleanVar),
        x = ~factor(cleanVar),
        type = ""histogram"")




Result:


",,,false,,,
https://stackoverflow.com/questions/54878982,true,"The issue is related to the Jupyter Notebook environment and its interaction with the PowerShell terminal, rather than a specific API problem.",Jupyter Notebook,N/A,"The user encountered an issue where launching Jupyter Notebook from PowerShell resulted in a failure to connect to the kernel. Additionally, there was a discrepancy in importing the 'Plotly' module between PowerShell and Jupyter Notebook. The issue is likely related to the environment setup and configuration rather than a specific API problem.",Jupyter Notebook should launch and connect to the kernel without any issues when executed from the command line or PowerShell.,The issue is triggered when launching Jupyter Notebook from PowerShell and encountering difficulties in connecting to the kernel or importing modules.,"This issue might be challenging to detect and troubleshoot, as it involves the interaction between the Jupyter Notebook environment, PowerShell, and the user's specific system configuration.",Jupyter Notebook kernal is not connecting when lunching from power shell,"I am facing this strange issue, when I am directly launching Jupyter Notebook from CMD it is running properly but when I am launching it from powershell it is not able to connect to the Kernal. 

Also I have pip installed Plotly, when I am importing it in powershell, I am able to import properly, but the same this in jupyter, it is saying no module name Plotly (with proper casing)?

jupyter 4.4.0 and Python 3.6.5, iPython is already up to date

 
I am unable to find out what might be causing this issue.
or something to inspect the kernals.
Can someone help me with this issue?
","according to github issue try downgrading prompt-toolkit to the version 1.0.15

pip3 install 'prompt-toolkit&lt;2.0.0,&gt;=1.0.15' --force-reinstall

Python 3.6.5
jupyter 1.0.0
jupyter-client 5.2.3
jupyter-console 5.2.0
jupyter-core 4.4.0
ipython 6.4.0

You can even try upgrading iPython

pip3 install --upgrade --user ipython
","Try this on powershell python -m notebook
",,false,,,
https://stackoverflow.com/questions/64781996,true,The issue involves the connection of points in a 3D line plot using Plotly. The user encountered unexpected behavior where certain points were not connected correctly between frames. The issue is likely related to the ordering of points and the way traces are created.,Plotly,3D line plot,The user encountered an issue where points in a 3D line plot were not connected correctly between frames. This behavior is likely due to the ordering of points and the way traces are created in Plotly.,"In a 3D line plot, points should be connected in the order specified by the 'aa_num' column, and each frame should have its own trace.",The issue is triggered when there is a problem with the ordering of points or the creation of traces in the 3D line plot.,"This issue might be challenging to detect and troubleshoot, as it requires careful examination of the data, the ordering of points, and the creation of traces in Plotly.",Issue with connecting points for 3d line plot in plotly,"I have a dataframe of the following format:
       x    y    z aa_num frame_num cluster
1   1.86 3.11 8.62      1         1       1
2   1.77 3.32 8.31      2         1       1
3   1.59 3.17 8.00      3         1       1
4   1.67 3.49 7.81      4         1       1
5   2.04 3.59 7.81      5         1       1
6   2.20 3.34 7.57      6         1       1
7   2.09 3.19 7.25      7         1       1
8   2.13 3.30 6.89      8         1       1
9   2.17 3.63 6.70      9         1       1
10  2.22 3.63 6.33     10         1       1
11  2.06 3.83 6.04     11         1       1
12  2.31 3.75 5.76     12         1       1
13  2.15 3.45 5.59     13         1       1
14  2.21 3.28 5.26     14         1       1
15  2.00 3.13 4.98     15         1       1
16  2.13 2.86 4.74     16         1       1
17  1.97 2.78 4.41     17         1       1
18  2.20 2.76 4.10     18         1       1
19  2.43 2.46 4.14     19         1       1
20  2.34 2.23 3.85     20         1       1
21  2.61 2.16 3.59     21         1       1
22  2.42 1.92 3.36     22         1       1
23  2.44 1.95 2.98     23         1       1
24  2.26 1.62 2.94     24         1       1
25  2.19 1.35 3.20     25         1       1
26  1.92 1.11 3.08     26         1       1
27  1.93 0.83 3.33     27         1       1
28  1.83 0.72 3.68     28         1       1
29  1.95 0.47 3.95     29         1       1
30  1.84 0.36 4.29     30         1       1
31  0.56 3.93 7.07      1         2       1
32  0.66 3.84 7.42      2         2       1
33  0.87 3.54 7.49      3         2       1
34  0.84 3.19 7.33      4         2       1
35  0.76 3.32 6.98      5         2       1
36  0.88 3.23 6.63      6         2       1
37  1.10 3.46 6.43      7         2       1
38  1.35 3.49 6.15      8         2       1
39  1.72 3.50 6.23      9         2       1
40  1.88 3.67 5.93     10         2       1
41  2.25 3.72 5.97     11         2       1
42  2.43 3.48 5.74     12         2       1
43  2.23 3.35 5.44     13         2       1
44  2.23 3.38 5.06     14         2       1
45  2.01 3.38 4.76     15         2       1
46  2.02 3.44 4.38     16         2       1
47  1.98 3.10 4.20     17         2       1
48  2.05 3.13 3.83     18         2       1
49  2.28 2.85 3.72     19         2       1
50  2.09 2.56 3.58     20         2       1
51  2.21 2.37 3.27     21         2       1
52  2.06 2.04 3.15     22         2       1
53  1.93 2.01 2.80     23         2       1
54  1.86 1.64 2.83     24         2       1
55  1.95 1.38 3.10     25         2       1
56  1.78 1.04 3.04     26         2       1
57  1.90 0.84 3.34     27         2       1
58  1.83 0.74 3.70     28         2       1
59  1.95 0.48 3.95     29         2       1
60  1.84 0.36 4.29     30         2       1
etc..

I'm trying to create a 3d line plot of this data, where a line consisting of 30 &lt;x,y,z&gt; points will be plotted for each frame_num and the points would be connected in the order of aa_num. The code to do this is as follows:
    fig = plot_ly(output_cl, x = ~x, y = ~y, z = ~z, type = 'scatter3d', mode = 'lines+markers',
                   opacity = 1, line = list(width = 1, color = ~frame_num, colorscale = 'Viridis'),
                  marker = list(size = 2, color = ~frame_num, colorscale = 'Viridis'))

When I plot a single frame, it works fine:

However, a strange issue arises when I try to plot multiple instances.

For some reason, when I try to plot frame 1 and 2, point 1 and 30 connect to each other for frame 2. However, this doesn't happen for frame 1. Any ideas why? Is there someway to specify the ordering of points in 3d in plotly?
","If you want to create two different traces based on column frame_num you need to pass it as a categorial variable by using factor. As an alternative you can use name = ~ frame_num or split = ~ frame_num to create multiple traces.
library(plotly)

output_cl &lt;- data.frame(
           x = c(1.86,1.77,1.59,1.67,2.04,2.2,2.09,
                 2.13,2.17,2.22,2.06,2.31,2.15,2.21,2,2.13,1.97,2.2,
                 2.43,2.34,2.61,2.42,2.44,2.26,2.19,1.92,1.93,1.83,1.95,
                 1.84,0.56,0.66,0.87,0.84,0.76,0.88,1.1,1.35,1.72,1.88,
                 2.25,2.43,2.23,2.23,2.01,2.02,1.98,2.05,2.28,2.09,
                 2.21,2.06,1.93,1.86,1.95,1.78,1.9,1.83,1.95,1.84),
           y = c(3.11,3.32,3.17,3.49,3.59,3.34,3.19,
                 3.3,3.63,3.63,3.83,3.75,3.45,3.28,3.13,2.86,2.78,2.76,
                 2.46,2.23,2.16,1.92,1.95,1.62,1.35,1.11,0.83,0.72,
                 0.47,0.36,3.93,3.84,3.54,3.19,3.32,3.23,3.46,3.49,3.5,
                 3.67,3.72,3.48,3.35,3.38,3.38,3.44,3.1,3.13,2.85,2.56,
                 2.37,2.04,2.01,1.64,1.38,1.04,0.84,0.74,0.48,0.36),
           z = c(8.62,8.31,8,7.81,7.81,7.57,7.25,6.89,
                 6.7,6.33,6.04,5.76,5.59,5.26,4.98,4.74,4.41,4.1,
                 4.14,3.85,3.59,3.36,2.98,2.94,3.2,3.08,3.33,3.68,3.95,
                 4.29,7.07,7.42,7.49,7.33,6.98,6.63,6.43,6.15,6.23,5.93,
                 5.97,5.74,5.44,5.06,4.76,4.38,4.2,3.83,3.72,3.58,
                 3.27,3.15,2.8,2.83,3.1,3.04,3.34,3.7,3.95,4.29),
      aa_num = c(1L,2L,3L,4L,5L,6L,7L,8L,9L,10L,
                 11L,12L,13L,14L,15L,16L,17L,18L,19L,20L,21L,22L,23L,
                 24L,25L,26L,27L,28L,29L,30L,1L,2L,3L,4L,5L,6L,7L,
                 8L,9L,10L,11L,12L,13L,14L,15L,16L,17L,18L,19L,20L,
                 21L,22L,23L,24L,25L,26L,27L,28L,29L,30L),
   frame_num = c(1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,
                 1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,
                 1L,1L,1L,2L,2L,2L,2L,2L,2L,2L,2L,2L,2L,2L,2L,
                 2L,2L,2L,2L,2L,2L,2L,2L,2L,2L,2L,2L,2L,2L,2L,2L,
                 2L,2L),
     cluster = c(1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,
                 1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,
                 1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,
                 1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,1L,
                 1L,1L)
)

fig = plot_ly(output_cl, x = ~x, y = ~y, z = ~z, type = 'scatter3d', mode = 'lines+markers', color = ~factor(frame_num), # or name = ~ frame_num or split = ~ frame_num
              colors =""Set2"", opacity = 1, line = list(width = 1), marker = list(size = 2))
fig


",,,false,,,
https://stackoverflow.com/questions/61710209,true,"The issue is related to the 'fitbounds' property in Plotly, which is not recognized as a valid property for the 'Geo' object in the layout. The user encountered an error when trying to use the 'fitbounds' property to set the default zoom level for a chloropleth map.",Plotly,fitbounds,The user encountered an error when trying to use the 'fitbounds' property in Plotly to set the default zoom level for a chloropleth map. The error message indicates that 'fitbounds' is not a valid property for the 'Geo' object in the layout.,"The 'fitbounds' property can be used to set the default zoom level for a chloropleth map in Plotly, but it needs to be applied correctly and recognized as a valid property.",The issue is triggered when the 'fitbounds' property is used incorrectly or when it is not recognized as a valid property for the 'Geo' object in the layout.,This issue might be challenging to detect for users who are not familiar with the specific requirements and limitations of the 'fitbounds' property in Plotly.,ValueError: Invalid property specified for object of type plotly.graph_objs.layout.Geo: &#39;fitbounds&#39;,"I am trying to make a chloropleth map in Dash Plotly and since the data is bound to Europe I want the default zoom to be focused on there. There should be a bounds fitting feature in Plotly, as described in the tutorial documentation:

https://plotly.com/python/map-configuration/



However, I cannot get it to work, not on my map, but not even on this basic tutorial, I am always getting:

   ValueError: Invalid property specified for object of type plotly.graph_objs.layout.Geo: 'fitbounds'


It seems as if the fitbounds property is not defined for the geos, strange.

Code to replicate the issue:

fig = px.line_geo(lat=[0, 15, 20, 35], lon=[5, 10, 25, 30])
fig.update_geos(fitbounds=""locations"")
fig.update_layout(height=300, margin={""r"": 0, ""t"": 0, ""l"": 0, ""b"": 0})


What could this be caused by?
","For me just trying to understand your problem, I had to install nbformat package. And it works perfectly after installing it. maybe your problem is just an update issue. **please note that I can NOT make any comments yet and that's why I'm posting an answer!

pip(3) install --upgrade nbformat
pip(3) install --upgrade plotly

",,,false,,,
https://stackoverflow.com/questions/56532527,false,"The issue does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is a question related to customizing text in Plotly for R, but it does not indicate any API-related problems.",,,,,,,"Customizing text (text size, text color, text angle) in Plotly for R","I'm working on making a donut chart/open pie chart in Plotly. Because of help from this question, Open Pie Chart/Donut Chart in R using Plotly with count and percentage, I was able to get fairly far with my plot. However, now I need help customizing the text size, angle, and color.

Here's the dataset:

library(dplyr)
testfile &lt;- tibble(personID = 1:10,
                   status = c(""bad"", ""good"", ""bad"", ""bad"", ""bad"", ""bad"", ""bad"", ""bad"", ""bad"", ""good""),
                   department = c(""sales"", ""sales"", ""marketing"", ""sales"", ""marketing"", ""management"", ""management"", ""sales"", ""sales"", ""sales""))


Here's the code to make the plot thus far. It has the count and percentage for each status, and in the center, it has the percentage of ""good"" status individuals.

library(plotly)

plot &lt;- plot_ly(values, labels = ~status, values = ~count, text = ~count, color = I(""white"")) %&gt;%
  add_pie(hole = 0.6) %&gt;%
  layout(title = ""Ratio of Good to Bad"",  showlegend = F, position = ""topcenter"", 
         xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = TRUE),
         yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = TRUE))

plot &lt;- layout(p, annotations=list(text=paste(good$count / sum(values$count) * 100, ""%"", sep=""""), ""showarrow""=F))
plot


This code yields these two plots. Surprisingly, it looks the first way when I click ""zoom"" on R Studio, but it looks the second (very wrong) way when I click export and open the PNG file.

Zoomed plot (mostly correct)


Exported plot (looks very different than how it should...)


This zoomed in plot is exactly what I want except for three issues:


I want the center text (20%) to be larger. I've tried p &lt;- layout(p, annotations=list(text=paste(good$count / sum(values$count) * 100, ""%"", sep=""""), ""showarrow""=F, size = 25)) but that did nothing.
I want both of the labels (2 20% and 8 80%) to be white, not just the 8 80%. I thought color = I(""white"") would do the trick, but the output is the same as when I don't specify the color at all.
I want the labels to be horizontal instead of curving and for them to fit within the bars.


Optional: Why does it look different when it is exported vs zoomed in? I need it to look like the zoomed in version. Also, is there also an easy way to get it to say n = 2 instead of just 2?

Thank you!

EDIT: This code makes the labels horizontal, but they are too small. When I add size = 15 or any number, it always makes the font the same large size but no longer horizontal. This also fixes the issue where the export and zoom are inconsistent. It also fixes the center text size. I just need the labels to both be white, larger in size, and horizontal.

plot &lt;- plot_ly(values, labels = ~status, values = ~count, text = ~count) %&gt;%
  add_pie(hole = 0.6) %&gt;%
  layout(title = ""Ratio of Good to Bad"",  showlegend = F, position = ""topcenter"", 
         xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = TRUE),
         yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = TRUE),
         annotations=list(text=paste(good$count / sum(values$count) * 100, ""%"", sep=""""), ""showarrow""=F, font=list(size = 40)))
plot



","Update, I cracked the code! Here's the code that worked

library(plotly)
library(dplyr)

values &lt;- testfile %&gt;%
  group_by(status) %&gt;%
  summarize(count = n())

t &lt;- list(size = 14, color = ""white"")

good &lt;- values %&gt;% filter(status == 'good')

plot &lt;- plot_ly(values, labels = ~status, values = ~count, text = ~count, textfont = list(color = ""white"", size = 40)) %&gt;%
  add_pie(hole = 0.6) %&gt;%
  layout(title = ""Ratio of Good to Bad"",  showlegend = TRUE, 
         xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = TRUE),
         yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = TRUE),
         annotations=list(text=paste(good$count / sum(values$count) * 100, ""%"", sep=""""), ""showarrow""=F, font=list(size = 180, color = ""black"")))
plot


Here's what the plot looks like now:


",,,false,,,
https://stackoverflow.com/questions/66205856,false,"The issue does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is a question about sizing of ggiraph::girafe() output, but it does not indicate any API-related problems.",,,,,,,Sizing of ggiraph::girafe() output is not consistent with documentation on RStudio viewer after use with flexdashboard,"I have a number of plots using {ggplot2} and {ggiraph} that I have consolidated into a {flexdashboard}
Before attempting to display them with the dashboard, these plots displayed correctly on RStudio's viewer using the sizing option width = 0.7
However, they do not display on the dashboard (just a blank panel), and now produce a blank panel if run directly in RStudio. After some investigation it seems that some setting has changed and that the charts are not output because the size is inconsistent with the window.
If I change the width setting to 10 it displays correctly in the RStudio viewer which seems odd.
I have a small reprex here:
library(ggplot2)
library(ggiraph)

#dummy dataframe
df &lt;- data.frame(
  x = seq.Date(Sys.Date() - 30, Sys.Date() - 1, by = ""days""),
  y = runif(30, 0, 2) 
)

p &lt;- ggplot2::ggplot(df, (aes(x,y)))+
  geom_point_interactive(aes(tooltip = x, data_id = x))


plot &lt;- girafe(ggobj = p, 
                width =0.7)

print(plot)

This produces the following output:

However if I adjust width setting to 10
plot &lt;- girafe(ggobj = p, 
                width =10)

print(plot)

I get the following:

This seems inconsistent with the documentation for {ggiraph}, is there some graphics setting that has been modified by {flexdashboard}? I've tried interactive (js) charts with {plotly} and {echarts4r} on {flexdashboard} output which don't show the same behaviour.
I'm using
RStudio 1.4.1103
R version 4.0.2
System: x86_64-apple-darwin17.0
","I've been experimenting and it seems that I can control the output by using width_svg consistently.
I still don't know why there is an issue but I suspect some underlying graphics setting.
",,,false,,,
https://stackoverflow.com/questions/63712393,false,"The issue does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is a question about a vertical line in a plotly line plot, but it does not indicate any API-related problems.",,,,,,,Plotly Vertical Line Wrong X value,"I am trying to add a vertical line to a plotly line plot in python and it seems to work but plotly sometimes misplaces the vertical line and I do not know why. The x-values are string timestamps of the form '10:45:21.000000' and the y-values are just integers.
Here is my code:
import plotly.graph_objects as go
import plotly.express as px

vert_line = '10:45:49.983727'

fig = px.line(data, x=""time"", y=""y"")
fig.add_shape(
        dict(
            type=""line"",
            x0=vert_line,
            y0=data['y'].min(),
            x1=vert_line,
            y1=data['y'].max(),
            line=dict(
                color=""Red"",
                width=3,
                dash=""dot"",
            )
))
fig.show()


I can post some toy data, but i noticed the behaviour is super inconsistent depending on the data I feed it. Here are some examples where I sliced the data differently. Each plot is based on the above code just slicing the data by data[:100] , data[:200], and data[:300] respectively:



Notice the vertical line changes places and is never at what its actual value is. Why is this occurring? How can I get to plot where it should be?
EDIT: As requested, here's some toy data to get you started but this issue is dependent on the exact slice of data so it won't be reproducible with just this bit of data, the actual complete dataset is larger and I don't know a practical way to share that on stackoverflow.
[{'time': '10:42:21.000000', 'y': 342688},
 {'time': '10:42:22.000000', 'y': 342700},
 {'time': '10:42:23.000000', 'y': 342681},
 {'time': '10:42:24.000000', 'y': 342680},
 {'time': '10:42:25.000000', 'y': 342692},
 {'time': '10:42:26.000000', 'y': 342696},
 {'time': '10:42:27.000000', 'y': 342699},
 {'time': '10:42:28.000000', 'y': 342727},
 {'time': '10:42:29.000000', 'y': 342725},
 {'time': '10:42:30.000000', 'y': 342731},
 {'time': '10:42:31.000000', 'y': 342735},
 {'time': '10:42:32.000000', 'y': 342750},
 {'time': '10:42:33.000000', 'y': 342750},
 {'time': '10:42:34.000000', 'y': 342725},
 {'time': '10:42:35.000000', 'y': 342700},
 {'time': '10:42:36.000000', 'y': 342725},
 {'time': '10:42:37.000000', 'y': 342725},
 {'time': '10:42:38.000000', 'y': 342700},
 {'time': '10:42:39.000000', 'y': 342700}]

","Complete snippet at the end

I've managed to reproduce your issue, and my preliminary conclusion has to be that this is caused by a bug. I'm basing this conclusion on an assumption that  the variable 'vert_line' has a value that falls outside the x-range for your figures. And, as I will show you, the specified shape seems to be put in the middle of the figure if x0 and x1 fall out of the range displayed on the x-axis. Below I have recreated a dataset with a time value that replicates your real world data. And I've set vert_line = '00:00:00.000044'.
This works fine for the first figure where '00:00:00.000044' is included in the x-axis range:

Now see what happens if I change vert_line = '00:00:00.000044' to a value outside the displayed range. Or, as in your case, make another subset of the data with data = data[:40] that also makes the specified vert_line fall out of the range:

For apparently no reason what so ever, the shape is placed right in the middle of the figure. Just as in all your provided figures. I can't possibly fix how these things work. But you can make sure to not produce the shape if vert_line falls out of the range displayed.
Complete code:
import plotly.graph_objects as go
import plotly.express as px
import random
import numpy as np
import pandas as pd

# data
np.random.seed(4)
n = 600
data = pd.DataFrame({'time':[t[11:28] for t in pd.date_range('2020', freq='U', periods=n).format()],
                      'y':np.random.uniform(low=-1, high=1, size=n).tolist()})
data['y']=data['y'].cumsum()

#vert_line = '10:45:49.983727'
#vert_line = random.choice(data['time'].to_list())
#vert_line = '00:00:00.000256'
vert_line = '00:00:00.000044'


data = data[:40]
fig = px.line(data, x=""time"", y=""y"")
fig.add_shape(
        dict(
            type=""line"",
            x0=vert_line,
            y0=data['y'].min(),
            x1=vert_line,
            y1=data['y'].max(),
            line=dict(
                color=""Red"",
                width=3,
                dash=""dot"",
            )
))

fig.update_layout(title=vert_line)
fig.update_xaxes(tickangle=90)

fig.show()

Edit: Test for different values of vert_line and a subset of the original data
The following snippet sets up a dataset with 100 observations, selects a random vert_line value from those observations, but splits the dataset in two before the figure is produced. This way, there will only be a 50% chance that vert_line stays in the range of the figure. Run it a few times, and you'll see that the shape is shown exactly as it's supposed to be as long as vert_line can be found on the x-axis. As soon as it can't, the shape is just placed there in the middle.
import plotly.graph_objects as go
import plotly.express as px
import random
import numpy as np
import pandas as pd

# data
np.random.seed(4)
n = 100
data = pd.DataFrame({'time':[t[11:28] for t in pd.date_range('2020', freq='U', periods=n).format()],
                      'y':np.random.uniform(low=-1, high=1, size=n).tolist()})
data['y']=data['y'].cumsum()

#vert_line = '10:45:49.983727'
vert_line = random.choice(data['time'].to_list())
#vert_line = '00:00:00.000256'
#vert_line = '00:00:00.000044'


data = data[:50]
fig = px.line(data, x=""time"", y=""y"")
fig.add_shape(
        dict(
            type=""line"",
            x0=vert_line,
            y0=data['y'].min(),
            x1=vert_line,
            y1=data['y'].max(),
            line=dict(
                color=""Red"",
                width=3,
                dash=""dot"",
            )
))

fig.update_layout(title=vert_line)
fig.update_xaxes(tickangle=90)

fig.show()

",,,false,,,
https://stackoverflow.com/questions/74081386,false,"The issue does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is a question about displaying Plotly graphs in HTML, but it does not indicate any API-related problems.",,,,,,,Plotly graph display issue when embeded in HTML,"So there is this weird issue with Plotly displaying graphs in my HTML webpage that I'm not sure how to solve.
Basically, I have multiple graphs I wish to display on a webpage.
So what I did was:

come up with a Plotly graph
use fig.write_html to write that graph into a HTML file
embed it into my website using &lt;iframe&gt; and style it.

And it looks something like this
Now, I need to show multiple of these same graphs, so instead of creating many HTML files, I just used one HTML file and placed all my graphs into divs of their own category. To show the div, I toggle the display of the div using display:none and display:flex in my JavaScript.
Here's the issue and I think it's best if I demonstrate it as a gif
As you can see, the graphs in the second div aren't showing properly. So let's say I refresh the website: if I wait for the webpage to load completely and toggle the display on to show the second graphs, their resolution, positioning and size gets all messed up. And if, without waiting for the webpage to load completely, I toggle to show the second graphs, their positioning and resolution becomes normal, but the first graph gets all messed up.
I'm not sure if by disabling the div, I caused the graphs to not show properly, and I don't really know a workaround. I think this is a bad way to embed graphs into my webpage, but I don't exactly have a lot of time to change it, so let me know a quick fix if there is one. Thanks
Edit: the graphs displays very inconsistently. Sometimes it shows properly but other times it gets all messed up, so I'm not very sure what's going on.
","Ok so I think this is more of a workaround but I got a solution.
I first set all the div's containing my graphs to visible. So it will look all messy and stuff initially.
Then I created a JS code using onLoad:
    window.onload = function () {
        mbsTopGraphContainer.style.display = ""none"";
        mbsBottomGraphContainer.style.display = ""none"";
        sglTopGraphContainer.style.display = ""none"";
        sglBottomGraphContainer.style.display = ""none"";
        fulTopGraphContainer.style.display = ""none"";
        fulBottomGraphContainer.style.display = ""none"";
    }

where I disable the respective div's that I wanted to hide initially. So all my graphs will be visible and would be loading together, and after it finished loading, the graphs that we don't want to see yet would be hidden.
",,,false,,,
https://stackoverflow.com/questions/47405628,false,"The issue does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions. It is a question about a 'utf8' codec error in Bokeh, but it does not indicate any API-related problems.",,,,,,,Bokeh &#39;utf8&#39; codec can&#39;t decode byte 0xe9 : unexpected end of data,"Im using Bokeh to plot a pandas Dataframe. Following is the code:

map_options = GMapOptions(lat=19.075984, lng=72.877656, map_type=""roadmap"", zoom=11)
plot = GMapPlot(x_range=DataRange1d(), y_range=DataRange1d(), map_options=map_options)


plot.api_key = ""xxxxx""
source = ColumnDataSource(
    data=dict(
        lat=[float(i) for i in data.lat],
        lon=[float(i) for i in data.lon],
        size=[int(i)/1000 for i in data['count']],
        ID = [i for i in data.merchant_id],
        Merchant = [str(i) for i in data.merchant_name],
        count = [float(i) for i in data['count']]
    )
)
hover = HoverTool(tooltips=[
    (""(x,y)"", ""($lat, $lon)""),
    (""ID"", ""$ID""),
    (""Name"", ""@Merchant""),
    (""count"",""$count"")
])


# hover.renderers.append(circle_glyph)
plot.tools.append(hover)
circle = Circle(x=""lon"", y=""lat"", size='size', fill_color=""blue"", fill_alpha=0.8, line_color=None)
plot.add_glyph(source, circle)

# plot.add_layout(labels)
plot.add_tools(PanTool(), WheelZoomTool(), BoxSelectTool())
output_file(""gmap_plot.html"")
show(plot)


In the Hovertool using the ""Name"" field throws the following error:


  UnicodeDecodeError: 'utf8' codec can't decode byte 0xe9 in position 6:
  unexpected end of data


Also commenting the ""Name"" field still gives me the error but there is an output plot.

Following is the dataframe I'm using:

    lat lon merchant_id count   merchant_name
0   18.539971   73.893963   757 777 Portobello
1   18.565766   73.910980   745 10193   The Wok Box
2   18.815427   76.775143   1058    2354    Burrito Factory
3   18.914633   72.817916   87  1985    Flamboyante
4   18.915794   72.824370   94  1116    Butterfly Pond
5   18.916473   72.826868   145 1010    Leo's Boulangerie
6   18.918923   72.828325   115 517 Brijwasi Sweets
7   18.928063   72.832888   973 613 Pandora's Box
8   18.928562   72.832353   101 64  La Folie Patisserie
9   18.929516   72.831860   961 6673    Burma Burma


From my knowledge, the merchant name has characters that's causing the error, but i've tried encoding the column with 'utf-8', 'ascii', etc. But I get the following error:

data['merchant_name'] = data['merchant_name'].str.encode('utf-8')



  UnicodeDecodeError: 'ascii' codec can't decode byte 0xe9 in position 6: ordinal not in range(128)


Any Idea on how to proceed ?
","The byte 0xe9 is not in pure ascii, because it is 233 (in decadical system) and ascii has only 127 symbols. In UTF-8 it is a special byte, which introduces a charecter taking next two bytes. Thus the string is probably in another encoding. For example in latin1 and latin2 the byte 0xe9 symbolizes the letter é.

And remember, first you must decode the string. You tried encode the type str, (normal string) which does not make sense. Therefore Python tried his default decode('ascii') and you got the UnicodeDecodeError on encode method.

I didn't manage to replicate the error and also I don't see any special characters in the data you provided (especially I don't see the 0xe9 byte). So I can only guess. I would try something like this:

data['merchant_name'] = data['merchant_name'].str.decode('latin1').encode('utf-8')


And last but not least please please please, when you post your code, post the complete code with all imports and everything. I never used Bokeh, and now, when I tried to replicate your error, it was time consuming to reconstruct them. (But anyway -- at the end I managed to import everything, but I didn't get your error.) 
","I solved the problem like this
tsne_df['words'] = list(w2v_model.wv.vocab.keys())[:5000]

tsne_df['words'] = tsne_df['words'].str.decode('latin1').str.encode('utf-8')

plot_tfidf.scatter(x='x', y='y', source=tsne_df)
hover = plot_tfidf.select(dict(type=HoverTool))
hover.tooltips={""word"": ""@words""}
show(plot_tfidf)

",,false,,,
https://stackoverflow.com/questions/55642814,true,The issue involves the usage of the Bokeh checkbox API and the unexpected behavior is related to the active attribute.,Bokeh,CheckboxGroup.active,"The issue arises when attempting to uncheck a Bokeh checkbox using a custom button. The checkboxes are not being created in the checked state, and the button does not clear the checkboxes.",The CheckboxGroup.active attribute is used to specify the index of the selected items.,The issue is triggered when the CheckboxGroup.active attribute is not properly set to uncheck the checkboxes.,This issue might be challenging to detect for users who are not familiar with the specific behavior of the CheckboxGroup API or those who assume that setting the active attribute to an empty list would uncheck the checkboxes.,Bokeh uncheck checkbox,"For now, I am trying to simply uncheck a Bokeh checkbox using a custom button. 

But I'm getting unexpected results: The boxes are not being created in the checked state and the button does not clear the checkboxes.

Is this because I'm misunderstanding the active attribute?

from bokeh.models.widgets import CheckboxGroup, Button
from bokeh.layouts import column
from bokeh.io import curdoc
from bokeh.plotting import show

checkbox_group_1 = CheckboxGroup(labels=[""Group 1 Button""], active=[1])
checkbox_group_2 = CheckboxGroup(labels=[""Group 2 Button A"", ""Group 2 Button B""], active=[1,1])
checkbox_group_3 = CheckboxGroup(labels=[""Group 3 Button A"", ""Group 3 Button B""], active=[1,1])


button = Button(label=""Foo"", button_type=""success"")

def buttonclick():
    checkbox_group_1.active = [0]
    checkbox_group_2.active = [0,0]
    checkbox_group_3.active = [0,0]

button.on_click(buttonclick)


layout=column(checkbox_group_1,checkbox_group_2,checkbox_group_3, button)
curdoc().add_root(layout)


!powershell -command {'bokeh serve --show Buttoninteraction.ipynb'}
#I'm working within Jupyter notebook.


Ideally, I'd like to have boxes get unchecked when one from another group is checked. 
Appreciate any help. 
","The active attribute is a list that specifies the index of the selected items. So to unselect them all simply use checkbox_group.active = []

from bokeh.models.widgets import CheckboxGroup, Button
from bokeh.layouts import column
from bokeh.io import curdoc
from bokeh.plotting import show

checkbox_group_1 = CheckboxGroup(labels = [""Group 1 Button""], active = [0])
checkbox_group_2 = CheckboxGroup(labels = [""Group 2 Button A"", ""Group 2 Button B""], active = [1])
checkbox_group_3 = CheckboxGroup(labels = [""Group 3 Button A"", ""Group 3 Button B""], active = [1])

button = Button(label = ""Foo"", button_type = ""success"")

def buttonclick():
    checkbox_group_1.active = []
    checkbox_group_2.active = []
    checkbox_group_3.active = []

button.on_click(buttonclick)

layout = column(checkbox_group_1, checkbox_group_2, checkbox_group_3, button)
curdoc().add_root(layout)


Example for active value for checkbox_group_2:

value      selected
[0]        first 
[1]        second
[0, 1]     both
[]         None

",,,false,,,
https://stackoverflow.com/questions/41172227,false,The issue is related to the layout arrangement in Bokeh and does not involve any API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,bokeh layout for plot and widget arrangement,"I have a specific design in mind for my bokeh app. I am using bokeh 0.12.3 and a bokeh server to keep everything in sync. Please, have a look at my mockup:



On the left-hand side, there is a static navigation bar, the right part of the view will consist of plots, that are manually added. The amount of plot columns on the right-hand side shall change w.r.t. window size. I am well aware of the bokeh layout documentation laying out plots and widgets, but it's a bit more complicated. This is the layout I currently have:

doc_layout = layout(children=[[column(radio_buttons,
                                      cbx_buttons,
                                      div,
                                      data_table,
                                      plot,
                                      button)]],
                    sizing_mode='scale_width')
curdoc().add_root(doc_layout)


In order to add new plots I use:

doc_layout.children[-1].children.append(plot)
# appends plot to layout children [[column(..), plot]]


But the behavior is very strange, and not at all what I actually want to achieve. New plots are added on top of the column (menu panel) instead.

Here, a short example where you can try out to see what I mean:

from bokeh.io import curdoc
from bokeh.plotting import figure
from bokeh.models.sources import ColumnDataSource
from bokeh.models.widgets import Button, DataTable, TableColumn
from bokeh.layouts import layout, widgetbox, column, row

WIDTH = 200
HEIGHT = 200

def add_plot():
    p = figure(width=WIDTH, height=HEIGHT, tools=[], toolbar_location=None)
    p.line([0, 1, 2, 3, 4, 5], [0, 1, 4, 9, 16, 25])
    doc_layout.children[-1].children.append(p)

src = ColumnDataSource(dict(x=[0, 1, 2, 3, 4, 5], y=[0, 1, 4, 9, 16, 25]))
t1 = DataTable(source=src, width=WIDTH, height=HEIGHT,
               columns=[TableColumn(field='x', title='x'),
                        TableColumn(field='y', title='y')])
b = Button(label='add plot')
b.on_click(add_plot)

doc_layout = layout([[widgetbox(b, t1)]], sizing_mode='scale_width')
curdoc().add_root(doc_layout)


I am not sure what is the best solution to overcome this problem. I've tried several things, from layout() with different sizing modes, gridplot(), column()/row() in different combinations. In my previous version, where the navigation menu was placed on the top of the page instead on the left-hand side, everything seemed to work:

layout(children=[[widgetbox(radio_button, cbx_button),
                  widgetbox(data_table),
                  widgetbox(div),
                  widgetbox(button)],
                  [Spacer()]],
       sizing_mode='scale_width')

","You can change the last line in your callback to:

doc_layout.children[0].children[-1].children.append(p)


And change your layout to:

doc_layout = layout(sizing_mode='scale_width') 
doc_layout.children.append(row(column(widgetbox(b, t1)), column()))


But then then don't propagate exactly as you'd like. I think for that you would need to do some custom css styling.

Assuming yours is a directory format app, one option would be to make a template/index.html file where you can add a style block in the header where you could try to override css to make your plots inline-blocks or something. 

&lt;style&gt;
  .bk-whatever-class {
    ...
  }
&lt;/style&gt;


Use a developer tool on your browser to find the appropriate classes and toy with them. But perhaps not the best solution....

For widgets there is a css_classes attribute, where you could specify a class for that widget to use, but that unfortunately doesn't help with the plot canvases.

mycol = column(css_classes=['myclass'])

",,,false,,,
https://stackoverflow.com/questions/51505436,true,The issue is related to loading BokehJS in JupyterLab and the behavior difference between JupyterLab and Jupyter Notebook.,Bokeh,jupyterlab_bokeh extension,"When trying to load Bokeh in JupyterLab, the ""Loading bokehJS..."" message persists, but plotting with Jupyter Notebook works fine. This indicates a potential issue with JupyterLab or incorrect usage.","Bokeh can be loaded and used in JupyterLab without encountering the constant ""Loading bokehJS..."" message.",The issue is triggered when attempting to load Bokeh in JupyterLab.,This issue might be challenging to detect for users who are not familiar with the specific requirements for loading Bokeh in JupyterLab or those who assume that the behavior should be the same as in Jupyter Notebook.,loading bokehJS in jupyter lab,"I am having a strange behavior with bokeh library. 

So apparently, I am trying to create some beautiful plots with bokeh. When I try to load the bokeh in JupyterLab, I get constant, ""Loading bokehJS..."" message but if I try to plot with jupyter (from bokeh.io import output_notebook, show output_notebook()), I could plot it. It looks like lab has some issues? or am I not using lab properly?

comparative screenshot attached. Dark (JupyterLab), Light(Jupyter Notebook)


","You likely need to install the jupyterlab_bokeh extension: 

https://docs.bokeh.org/en/latest/docs/user_guide/notebook.html#jupyterlab
",,,false,,,
https://stackoverflow.com/questions/37272310,true,The issue involves calculating the PDF and CDF with Bokeh and the error is related to unsupported operand types.,Bokeh,numpy operations,"When trying to calculate the PDF and CDF with Bokeh, a TypeError occurs due to unsupported operand types ('list' and 'int').",The calculations of PDF and CDF using numpy operations should work without encountering the TypeError.,The issue is triggered when attempting to perform numpy operations on incompatible operand types.,This issue might be challenging to detect for users who are not familiar with the specific requirements of the numpy operations involved or those who assume that the calculations should work with any operand types.,Error- Plot PDF and CDF Bokeh : unsupported operand type(s) for /: &#39;list&#39; and &#39;int&#39;,"I am trying to read a csv and calculate the PDF and CDF with Bokeh. I am getting error. The input file is keyword and freq. The distribution of the frequency is to plotted. The input below are few rows from more than 50k rows. 

Input:

#sportsnews,8
#mashupradiomx,1
#arrestobama,2
#alemanha,1
#bizeskiden,1
#musicnews,4
#costumedesign,2
#champain,1
#pacer,1
#brunner,1
#fotoviajera,1
#itsjihadstupid,1
#lesdernierssurvivants,1
#sainsburycentre,1
#alanalwaysinourheart,1
#runinapp,1
#foroporlavida,1
#kidsday,1
#momentofart,2


Code:

# -*- coding: utf-8 -*-
import numpy as np
import scipy.special
import pandas as pd

from bokeh.plotting import figure, show, output_file, vplot

df = pd.read_csv('keyword.csv', header = None)

df.columns = ['keyword','freq']

p5 = figure(title=""Weibull Distribution (λ=1, k=1.25)"", tools=""save"",
            background_fill_color=""#E8DDCB"")

lam, k = 1, 1.25

#measured = lam*(-np.log(np.random.uniform(0, 1, 1000)))**(1/k)
#hist, edges = np.histogram(measured, density=True, bins=50)

x = df['freq']
pdf = (k/lam)*(x/lam)**(k-1) * np.exp(-(x/lam)**k)
cdf = 1 - np.exp(-(x/lam)**k)

p5.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:],
       fill_color=""#036564"", line_color=""#033649"")

p5.line(x, pdf, line_color=""#D95B43"", line_width=8, alpha=0.7, legend=""PDF"")
p5.line(x, cdf, line_color=""white"", line_width=2, alpha=0.7, legend=""CDF"")

p5.legend.location = ""top_left""
p5.xaxis.axis_label = 'x'
p5.yaxis.axis_label = 'Pr(x)'

output_file('histogram.html', title=""histogram.py example"")

show(vplot(p5))


I want to plot both line plots only. 

Error: 

Traceback (most recent call last):
  File ""pdf_bokeh.py"", line 21, in &lt;module&gt;
    pdf = (k/lam)*(x/lam)**(k-1) * np.exp(-(x/lam)**k)
TypeError: unsupported operand type(s) for /: 'list' and 'int'


Edit 1: After changing x=df['freq'] I am getting strange output. 
The full input file Dropbox  The data is discrete in nature but still distribution plots do not look like the below output.

The output: This is not really any where close to what it should be.


","Your problem is the x-axis for the theoretical distribution, you do not want to sample this at x=df['freq'], but at some pretty looking coordinates. I downloaded your dataset and was able to get something sensible with:

x = np.linspace(0, 5, 100) # 100 points between 0 and 5


You could do some fancy statistics to figure out that most of the data is below 5.
",,,false,,,
https://stackoverflow.com/questions/58642600,false,The issue is related to exporting a gmap plot to PNG and does not involve any API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Save gmap plot not including google tiles (the map),"Exporting a gmap plot to png (from the Bokeh SaveTool) does not include the map tiles. Just a grey background with lat and long axes and the plot title.
The bokeh tools are also missing.

Have tried on Brave, Chrome and Safari also tried adding a server side save using export_png which works albeit with a strange height and width (even when they are passed). The server side solution is not great as it does not reflect any client side zooms or pans, just the original plot.

I have simplified the plot to just a map with no overlays, still no joy.

from bokeh.models import (GMapPlot, GMapOptions, BoxSelectTool, SaveTool, Plot)
from bokeh.io import output_notebook, show
from bokeh.plotting import figure, gmap

output_notebook()

map_options = GMapOptions(lat=-33.79822854506091, lng=151.2562823223427, map_type=""roadmap"", zoom=13)


plot = gmap(""myGoogleKey"", map_options, height_policy=""max"", width_policy=""max"")
plot.title.text = ""Sample Plot""
plot.add_tools(BoxSelectTool(), SaveTool())
show(plot)


The expected output is what is shown on the screen, the actual output (to file) shows the lat/lng axes and tickers but the entire map area is grey.

This is after allowing plenty of time for the screen load (the screen is loaded)

There are no JavaScript errors in the browser console.

If I zoom (client side) the grid shown on the output png file reflects my location and zoom level - i.e. it knows what i have done but still no map tiles.
","The save tool only saves the HTML canvas object. Neither the toolbar, which is a separate DOM object off the canvas, or the Google Map itself, which is a separate DOM object underneath the (transparent) canvas, are included in that. This is simply an intrinsic limitation of the SaveTool. It will not be able to save Google Map tiles. 

You might try the other non-Google tile renderer options in Bokeh. Those render raster tiles directly on to the HTML canvas. Otherwise, the only options is the export_png function. 
",,,false,,,
https://stackoverflow.com/questions/54987509,false,The issue is related to the spacing between elements in a gridplot and does not involve any API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Bokeh remove space between elements in gridplot,"I have a Bokeh app (bokeh==1.0.1) where I use gridplot to render a slider widgetbox and several figures. I am using sizing_mode='stretch_both'. How can I eliminate the white space between the widget row and the rest of the figure panels? Here is a screenshot:

 

I create a layout for the widget as:

blank_button = bkm.widgets.RadioButtonGroup()
blank_wb = widgetbox(blank_button, width=50, height=100, sizing_mode='fixed') # placeholder for space
date_slider_wb = widgetbox(date_slider, width=400, height=100, sizing_mode='fixed')
apply_button = bkm.widgets.Button(label=""APPLY"")
apply_wb = widgetbox(apply_button, width=100, height=100, sizing_mode='fixed')

hor_layout_date_slider = (
    row(
      column(blank_wb),
      column(date_slider_wb),
      column(apply_wb),
    )
)


Then I include hor_layout_date_slider in a gridplot as:

grid = gridplot(
  children = [
    hor_layout_date_slider,
    airtemp_fig,
    windspeed_fig,
    winddir_fig,
    interval_fig,
    precip_fig,
    pressure_fig
    ],
    ncols=1,
    sizing_mode='stretch_both',
    merge_tools=False,
)

curdoc().add_root(grid)


I am using the bokeh server and rendering the bokeh document in a single div in my html template as:

  &lt;div class=""placeholderbokehapp rounded"" id=""tbc-id""&gt;

&lt;script src=""http://localhost:5858/stormtracker_bokehapp/autoload.js?bokeh-autoload-element=1000&amp;bokeh-app-path=/stormtracker_bokehapp&amp;bokeh-absolute-url=http://localhost:5858/stormtracker_bokehapp&amp;resources=none"" id=""1000""&gt;&lt;/script&gt;
  &lt;/div&gt;


As an attempted hack solution, I have been able to pass custom css rules to define the height of the div containing hor_layout_date_slider, but there is still a ""place holder"" for this element that persists (which I cannot access with inspect elements).

I have also tried using a simple widgetbox containing only the slider (without defining height and width and using sizing_mode='stretch_both'), instead of the full hor_layout_date_slider as defined above. However, this results in the same white space following the slider element.

Strangely enough, this problem does not occur with sizing_mode='scale_width' (the slider is tight in the layout).

Is there a Bokeh setting I am not aware of to control the spacing in this layout when using sizing_mode='stretch_both'?

UPDATE:

If I add the widget and the grid separately as:

curdoc().add_root(hor_layout_date_slider)
curdoc().add_root(grid)


The widget is then rendered underneath the first figure panel (you can see part of the slider widget showing through in the screenshot below).


","sizing_mode doesn't work well when nesting columns and rows in a grid or tabs. Just take the slider out of the grid and add separately to the root.

from bokeh.plotting import figure, curdoc
from bokeh.layouts import row, gridplot
from bokeh.models.widgets import Slider, RadioButtonGroup, Button

blank_button = RadioButtonGroup()
date_slider = Slider(start = 1, end = 10, value = 5)
apply_button = Button(label = ""APPLY"")

hor_layout_date_slider = row(blank_button, date_slider, apply_button)
airtemp_fig = figure()
windspeed_fig = figure()
grid = gridplot(children = [airtemp_fig, windspeed_fig],
                ncols = 1,
                sizing_mode = 'stretch_both',
                merge_tools = False)

curdoc().add_root(hor_layout_date_slider)
curdoc().add_root(grid)

",,,false,,,
https://stackoverflow.com/questions/57480666,true,The issue involves creating a hexmap using the HexTile feature in Bokeh and the unexpected behavior is related to the coordinate system.,Bokeh,HexTile,"The hexmap plot looks skewed compared to the desired result. The issue is related to the coordinate system used in Bokeh's HexTile feature, which may differ from the Leeds ODI's coordinate system.",The HexTile feature should accurately represent the hexagonal tiles based on the specified coordinate system.,The issue is triggered when attempting to create a hexmap using the HexTile feature with coordinates that do not align with Bokeh's coordinate system.,This issue might be challenging to detect for users who are not familiar with the specific coordinate system requirements of the HexTile feature or those who assume that the coordinate system used by the Leeds ODI would directly translate to Bokeh's HexTile.,"How to skew hexagonal tiles on an x,y graph, using bokeh HexTile","I am trying to create a hexmap of the UK parliamentary constituencies in python using the HexTile feature of the Bokeh library. I am attempting to emulate the Leeds ODI hexmap (https://odileeds.org/projects/hexmaps/constituencies/) and have used the q r coordinate system as supplied in their downloadable .hexjson file.

However, my plot looks skewed.

I am aware that the q r coordinate system that us used in the Bokeh HexTile feature may be different from the one that is used by the Leeds ODI. Hence why I have inverted the r value as before this plotted at a strange angle.

from bokeh.models import ColumnDataSource, Plot, LinearAxis, Grid, HoverTool
from bokeh.models.glyphs import HexTile
from bokeh.io import curdoc, show
import pandas as pd

df = pd.read_csv('/Users/georgefry/Documents/data_science/uk_pol/hex_map/cons_hex_coords.csv')

df['r'] = df['r'] * -1

df['q'] = df['q']

source = ColumnDataSource(df)

hover = HoverTool(tooltips=[('Code', '@code')])

plot = Plot(
    title=None, plot_width=300, plot_height=300,
    min_border=0, toolbar_location=None, tools=[hover])

glyph = HexTile(q=""q"", r=""r"", size=1, fill_color=""#fb9a99"", line_color=""white"")
plot.add_glyph(source, glyph)

xaxis = LinearAxis()
plot.add_layout(xaxis, 'below')

yaxis = LinearAxis()
plot.add_layout(yaxis, 'left')

plot.add_layout(Grid(dimension=1, ticker=xaxis.ticker))
plot.add_layout(Grid(dimension=0, ticker=yaxis.ticker))

curdoc().add_root(plot)

show(plot)


I appreciate that this is as much a geometry problem as a Bokeh-specific problem. I am also aware that the solution would be found by progressively skewing everything below the origin on the y-axis to the left, and everything above to the right. However, I have tried a number of transformations but none of them produced the desired result. 

The desired result is something similar to the Leeds ODI link.


","If you look at this image from the Bokeh docs:



You can see the ""q=0"" axis goes up and to the left. There are unfortunately different conventions, and some systems have a ""q=0"" axis that goes up and to the right. I think to convert, you will need to successively add 1 to the q value for every row in your data i.e. q+=1 for all the hexes in the first row, then q+=2 for all the hexes in the second row, etc... including taking in to account and ""missing"" rows of data (though you don't appear to have any in your particular data set).

Assuming that works, please open an issue on GitHub, perhaps we can provide some sort of adapter for this situation.
",,,false,,,
https://stackoverflow.com/questions/38800189,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Why does matplotlib require setting log scale before plt.scatter() but not plt.plot()?,"I found out in this helpful answer that plt.scatter() and  plt.plot() behave differently when a logrithmic scale is used on the y axis. 

With plot, I can change to log any time before I use plt.show(), but log has to be set up-front, before the scatter method is used.

Is this just a historical and irreversible artifact in matplotlib, or is this in the 'unexpected behavior' category?



import matplotlib.pyplot as plt

X = [0.997, 2.643, 0.354, 0.075, 1.0, 0.03, 2.39, 0.364, 0.221, 0.437]
Y = [15.487507, 2.320735, 0.085742, 0.303032, 1.0, 0.025435, 4.436435,
     0.025435, 0.000503, 2.320735]

plt.figure()

plt.subplot(2,2,1)
plt.scatter(X, Y)
plt.xscale('log')
plt.yscale('log')
plt.title('scatter - scale last')   

plt.subplot(2,2,2)
plt.plot(X, Y)
plt.xscale('log')
plt.yscale('log')
plt.title('plot - scale last')   

plt.subplot(2,2,3)
plt.xscale('log')
plt.yscale('log')
plt.scatter(X, Y)
plt.title('scatter - scale first')   


plt.subplot(2,2,4)
plt.xscale('log')
plt.yscale('log')
plt.plot(X, Y)
plt.title('plot - scale first')   


plt.show()

","This somehow has to do with the the display area (axes limits) calculated by matplotlib. 

This behaviour is fixed by manually editing the axes range by using set_xlim and set_ylim methods.

plt.figure()
plt.scatter(X, Y)
plt.yscale('log')
plt.xscale('log')
axes = plt.gca()
axes.set_xlim([min(X),max(X)])
axes.set_ylim([min(Y),max(Y)])
plt.show()




The exact reason of this behavior is however not yet figured out by me. Suggestions are welcomed.

EDIT

As mentioned in comments section, apparently Matplotlib has identified Autoscaling has fundamental problems as a Release Critical Issue on their official Github repo, which would be fixed in upcoming versions. Thanks.
",,,false,,,
https://stackoverflow.com/questions/13132194,false,The issue does not meet the criteria for deeper analysis as it is related to font requirements for camera-ready submissions rather than an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Type 1 fonts with log graphs,"I'm trying to use Matplotlib graphs as part of a camera-ready
submission, and the publishing house requires the use of Type 1 fonts
only.

I'm finding that the PDF backend happily outputs Type-1 fonts for
simple graphs with linear Y axes, but outputs Type-3 fonts for
logarithmic Y axes.

Using a logarithmic yscale incurs the use of mathtext, which seems to
use Type 3 fonts, presumably because of the default use of exponential
notation.  I can use an ugly hack to get around this - using
pyplot.yticks() to force the axis ticks to not use exponents - but
this would require moving the plot region to accommodate large labels
(like 10 ^ 6) or writing the axes as 10, 100, 1K, etc. so they fit.

I've tested the example below with the
matplotlib master branch as of today, as well as 1.1.1, which produces
the same behavior, so I don't know that this is a bug, probably just
unexpected behavior.

#!/usr/bin/env python
# Simple program to test for type 1 fonts. 
# Generate a line graph w/linear and log Y axes.

from matplotlib import rc, rcParams

rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})
#rc('font',**{'family':'sans-serif','sans-serif':['computer modern sans serif']})

# These lines are needed to get type-1 results:
# http://nerdjusttyped.blogspot.com/2010/07/type-1-fonts-and-matplotlib-figures.html
rcParams['ps.useafm'] = True
rcParams['pdf.use14corefonts'] = True
rcParams['text.usetex'] = False

import matplotlib.pyplot as plt

YSCALES = ['linear', 'log']

def plot(filename, yscale):
    plt.figure(1)
    xvals = range(1, 2)
    yvals = xvals
    plt.plot(xvals, yvals)
    plt.yscale(yscale)
    plt.savefig(filename + '.pdf')

if __name__ == '__main__':
    for yscale in YSCALES:
        plot('linegraph-' + yscale, yscale)


Does anyone know a clean way to get Type 1 fonts with log axes?

Thanks!
","This is the code I use for camera-ready submissions:

from matplotlib import pyplot as plt

def SetPlotRC():
    #If fonttype = 1 doesn't work with LaTeX, try fonttype 42.
    plt.rc('pdf',fonttype = 1)
    plt.rc('ps',fonttype = 1)

def ApplyFont(ax):

    ticks = ax.get_xticklabels() + ax.get_yticklabels()

    text_size = 14.0

    for t in ticks:
        t.set_fontname('Times New Roman')
        t.set_fontsize(text_size)

    txt = ax.get_xlabel()
    txt_obj = ax.set_xlabel(txt)
    txt_obj.set_fontname('Times New Roman')
    txt_obj.set_fontsize(text_size)

    txt = ax.get_ylabel()
    txt_obj = ax.set_ylabel(txt)
    txt_obj.set_fontname('Times New Roman')
    txt_obj.set_fontsize(text_size)

    txt = ax.get_title()
    txt_obj = ax.set_title(txt)
    txt_obj.set_fontname('Times New Roman')
    txt_obj.set_fontsize(text_size)


The fonts won't appear until you run savefig

Example:

import numpy as np

SetPlotRC()

t = np.arange(0, 2*np.pi, 0.01)
y = np.sin(t)

plt.plot(t,y)
plt.xlabel(""Time"")
plt.ylabel(""Signal"")
plt.title(""Sine Wave"")

ApplyFont(plt.gca())
plt.savefig(""sine.pdf"")

","The preferred method to get Type 1 fonts via matplotlib seems to be to use TeX for typesetting. Doing so results in all axis being typeset in the default math font, which is typically undesired but which can be avoided by using TeX-commands.

Long story short, I found this solution:

import matplotlib.pyplot as mp
import numpy as np

mp.rcParams['text.usetex'] = True #Let TeX do the typsetting
mp.rcParams['text.latex.preamble'] = [r'\usepackage{sansmath}', r'\sansmath'] #Force sans-serif math mode (for axes labels)
mp.rcParams['font.family'] = 'sans-serif' # ... for regular text
mp.rcParams['font.sans-serif'] = 'Helvetica, Avant Garde, Computer Modern Sans serif' # Choose a nice font here

fig = mp.figure()
dim = [0.1, 0.1, 0.8, 0.8]

ax = fig.add_axes(dim)
ax.text(0.001, 0.1, 'Sample Text')
ax.set_xlim(10**-4, 10**0)
ax.set_ylim(10**-2, 10**2)
ax.set_xscale(""log"")
ax.set_yscale(""log"")
ax.set_xlabel('$\mu_0$ (mA)')
ax.set_ylabel('R (m)')
t = np.arange(10**-4, 10**0, 10**-4)
y = 10*t

mp.plot(t,y)

mp.savefig('tmp.png', dpi=300)


Then results in this


Inspired by:
https://stackoverflow.com/a/20709149/4189024 and
http://wiki.scipy.org/Cookbook/Matplotlib/UsingTex
","The other answers did not work for me, but the following did:
import matplotlib.pylab as pylab

params = {'pdf.fonttype': 42}
pylab.rcParams.update(params)

",false,,,
https://stackoverflow.com/questions/18572234,false,The issue does not meet the criteria for deeper analysis as it is related to logical operator behavior in pandas rather than an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,matplotlib axes.set_aspect(&#39;equal&#39;) doesn&#39;t behave like expected,"I need a figure in matplotlib where both axes are always the same length. For this I am using the option 'equal'. In most cases it works quite well and I get the expected results  (see figure 1), but when the values of the y-axis are much higher than x, the figure shows an unexpected behaviour (see figure 2). Does anyone know this behavior of matplotlib?

Danke, Jörg

        host = SubplotHost(fig, 111)
        try:
            min_x_val = min(x for x in self.x_values if x is not None)
            max_x_val = max(self.x_values)
        except ValueError:
            return

        max_y_val = list()
        for n, evaluator in enumerate(self.cleaned_evaluators):
            max_y_val.append(max(self.y_values[n]))

        # axis settings
        host.axis['left'].label.set_fontsize('small')
        host.axis['left'].major_ticklabels.set_fontsize('small')
        host.axis['bottom'].label.set_fontsize('small')
        host.axis['bottom'].major_ticklabels.set_fontsize('small')
        host.axis['bottom'].major_ticklabels.set_rotation(0)
        host.set_ylabel(y_label)
        host.set_xlabel(x_label)


        host.set_xlim(0, max_x_val)
        host.set_ylim(0, max_y_val)

        host.minorticks_on()
        host.toggle_axisline(False)
        host.axes.set_aspect('equal')
        host.grid(True, alpha=0.4)

        return fig


Figure 1:



Figure 2:


","equal means that the x and y dimensions are the same length in data coordinates. To obtain square axis you can set manually the aspect ratio:

ax.set_aspect(1./ax.get_data_ratio())

",,,false,,,
https://stackoverflow.com/questions/34660617,false,The issue does not meet the criteria for deeper analysis as it is related to adding a panel button in matplotlib rather than an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Matplotlib Python: How to add panel button,"I am using matplotlib to create a simple interactive plot where the user will be able to place markers on the plot. For that matter everything works fine.

Now I want to add a button that when pressed a certain function will be executed. For that I followed that example. But using the button causes unexpected behavior. With the button included instead of being able to add markers all markers are placed inside the button area and are not displayed at all in the graph. Which doesn't make much sense.

I am looking for a way to add a panel button like those that exist by default in every matplotlib window. Do you have any suggestion? Any other example that I could take a look into? I have seen a lot of examples but I find to it hard to navigate through the documentation to find exactly what I need. Thanks in advance. 

update

The code I use right now looks like this:

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.widgets import Button

dataX = np.array([1,2,3,4,5,6,7,8,9,10])
dataY = np.array([1193,1225,1125,1644,1255,13676,2007,2008,12359,1210])

def on_click(event):
    if event.dblclick:
        plt.plot((event.xdata, event.xdata),(mean-standardDeviation, mean+standardDeviation), 'r-')
        plt.show()

def _yes(event):
    print ""yolo""

global mean, standardDeviation

# mean and standard deviation
mean = np.mean(dataY)
standardDeviation = np.std(dataY)

# plot data
plt.plot(dataX, dataY, linewidth=0.5)

plt.connect('button_press_event', on_click)

# button
axcut = plt.axes([0.9, 0.0, 0.1, 0.075])
bcut = Button(axcut, 'YES', color='red', hovercolor='green')
bcut.on_clicked(_yes)

plt.show()


When the button is not added everything works as expected. With the button I can only place markers inside the button's area. Any idea?
","You need to separate those two.

Let's try with subplot:

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.widgets import Button

dataX = np.array([1,2,3,4,5,6,7,8,9,10])
dataY = np.array([1193,1225,1125,1644,1255,13676,2007,2008,12359,1210])

ax = plt.subplot(111)
def on_click(event):
    if event.dblclick:
       ax.plot((event.xdata, event.xdata), (mean-standardDeviation, mean+standardDeviation), 'r-')
       plt.show()

def _yes(event):
    print(""yolo"")

mean = np.mean(dataY)
standardDeviation = np.std(dataY)

ax.plot(dataX, dataY, linewidth=0.5)
plt.connect('button_press_event', on_click)

axcut = plt.axes([0.9, 0.0, 0.1, 0.075])
bcut = Button(axcut, 'YES', color='red', hovercolor='green')
bcut.on_clicked(_yes)

plt.show()


Now it should work.

But, if you accidentally double click on yes it will draw a line on a graph. So, if you change button action to right-click:

def _yes(event):
    if event.button == 3:
        print(""yolo"")


Now it's fine :)
",,,false,,,
https://stackoverflow.com/questions/69516844,false,The issue does not meet the criteria for deeper analysis as it is related to plotting two pandas time-series on the same axes rather than an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Plotting two pandas time-series on the same axes with matplotlib - unexpected behavior,"I'm working with two timeseries (df1 and df2) and when I try to plot the on the same x-axis, with different y axis I get unexpected behavior.
Below the code and data.
dates1 = ['2021-08-26', '2021-08-27', '2021-08-30', '2021-08-31',
               '2021-09-01', '2021-09-02', '2021-09-03', '2021-09-07',
               '2021-09-08', '2021-09-09', '2021-09-10', '2021-09-13',
               '2021-09-14', '2021-09-15', '2021-09-16', '2021-09-17',
               '2021-09-20', '2021-09-21', '2021-09-22', '2021-09-23',
               '2021-09-24', '2021-09-27', '2021-09-28', '2021-09-29',
               '2021-09-30', '2021-10-01', '2021-10-04', '2021-10-05',
               '2021-10-06', '2021-10-07', '2021-10-08']


dates2 = ['2021-08-29', '2021-09-05', '2021-09-12', '2021-09-19',
               '2021-09-26']

y1 = np.random.randn(len(dates1)).cumsum()
y2 = np.random.randn(len(dates2)).cumsum()

df1 = pd.DataFrame({'date':pd.to_datetime(dates1), 'y1':y1})
df1.set_index('date', inplace=True)

df2 = pd.DataFrame({'date':pd.to_datetime(dates2), 'y2':y2})
df2.set_index('date', inplace=True)

When plotting the two datasets together either I see no plot (first plot) or I see the y data resampled in some way I don't understand (second plot). If I plot the data separately there is no issue (third &amp; fourth plots).
fig, axs = plt.subplots(1,4, figsize=[12,4])

df1.plot(ax=axs[0])
df2.plot(ax=axs[0], secondary_y=True)

df2.plot(ax=axs[1])
df1.plot(ax=axs[1], secondary_y=True)

df1.y1.plot(ax=axs[2])
df2.y2.plot(ax=axs[3])

plt.tight_layout()


","
pandas bug: #43972
The issue is how pandas deals with the xticks for different spans of datetimes.

Currently dates2 is less than one month. As you can see on the plots with pandas.DataFrame.plot, when the span is less than a month, the format is different. If dates2 spans at least a month, the issue doesn't occur. (e.g. dates2 = ['2021-08-29', '2021-09-05', '2021-09-12', '2021-09-19', '2021-09-26', '2021-09-29']).


Using secondary_y=True affects how pandas manages the ticks, because axs[0] plots correctly if secondary_y=True is removed.

I don't know why df1 will work if df2 is first as in axs[1], but df2 won't work when df1 is first.



fig, axs = plt.subplots(1, 4, figsize=[15, 6], sharey=False, sharex=False)
axs = axs.flatten()

df1.plot(ax=axs[0])
print(f'axs[0]: {axs[0].get_xticks()}')
ax4 = axs[0].twiny() 
df2.plot(ax=ax4, color='tab:orange')
print(f'ax4: {ax4.get_xticks()}')

df2.plot(ax=axs[1], color='tab:orange')
print(f'axs[1]: {axs[1].get_xticks()}')
df1.plot(ax=axs[1], secondary_y=True)
print(f'axs[1]: {axs[1].get_xticks()}')

df1.y1.plot(ax=axs[2])
print(f'axs[2]: {axs[2].get_xticks()}')

df2.y2.plot(ax=axs[3])
print(f'axs[3]: {axs[3].get_xticks()}')

plt.tight_layout()

[output]:
axs[0]: [18871. 18878. 18885. 18892. 18901. 18908.]
ax4: [2696 2697 2700]
axs[1]: [2696 2697 2700]  # after plotting df2
axs[1]: [2696 2697 2701 2702]  # after plotting df1
axs[2]: [18871. 18878. 18885. 18892. 18901. 18908.]
axs[3]: [2696 2697 2700]


Note the difference in the printed xticks, which are the locations on the axis for each tick.




Plotting with matplotlib.pyplot.plot treats the dataframe datetime index the same.

fig, axs = plt.subplots(2, 2, figsize=[20, 12], sharey=False, sharex=False)
axs = axs.flatten()

axs[0].plot(df1.index, df1.y1, marker='.', color='tab:blue')
print(f'axs[0]: {axs[0].get_xticks()}')
ax4 = axs[0].twinx()
ax4.plot(df2.index, df2.y2, marker='.', color='tab:orange')
print(f'ax4: {ax4.get_xticks()}')

axs[1].plot(df2.index, df2.y2, marker='.', color='tab:orange')
print(f'axs[1]: {axs[1].get_xticks()}')
ax5 = axs[1].twinx()
ax5.plot(df1.index, df1.y1, marker='.', color='tab:blue')
print(f'ax5: {ax5.get_xticks()}')

axs[2].plot(df1.index, df1.y1, marker='.', color='tab:blue')
print(f'axs[2]: {axs[2].get_xticks()}')
axs[3].plot(df2.index, df2.y2, marker='.', color='tab:orange')
print(f'axs[3]: {axs[3].get_xticks()}')

[output]:
axs[0]: [18871. 18878. 18885. 18892. 18901. 18908.]
ax4: [18871. 18878. 18885. 18892. 18901. 18908.]
axs[1]: [18868. 18871. 18875. 18879. 18883. 18887. 18891. 18895.]
ax5: [18871. 18878. 18885. 18892. 18901. 18908.]
axs[2]: [18871. 18878. 18885. 18892. 18901. 18908.]
axs[3]: [18868. 18871. 18875. 18879. 18883. 18887. 18891. 18895.]


",,,false,,,
https://stackoverflow.com/questions/22721060,false,The issue does not meet the criteria for deeper analysis as it is related to the usage of gridspec in matplotlib rather than an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,matplotlib: Unexpected gridspec behavior,"I try to plot two plots vertically within one figure using gridspec. The upper one is supposed to be twice as high as the lower one (i.e. the ratio is 2:1 with 3 equal vertical parts) and they have to share the x-axis scale. I have the following minimal example, which produces the correct 3-part plot, but it does not span the upper subplot twice as high as the lower one. The first plot is at the top third, the second is in the bottom third, and the middle is emptyWhere is the error?

import matplotlib.gridspec as gridspec
x = y = [1,2,3]
gs = gridspec.GridSpec(3, 1)
ax1 = plt.subplot(gs[0:1, 0])
ax1.plot(x, y)
ax2 = plt.subplot(gs[2, 0], sharex=ax1)
ax2.plot(x,y)
plt.show()

","When using gridspec the indexing acts similarly to numpy arrays. As such you need gs[0:2, 0] to get the output that you want.

import matplotlib.pyplot as plt
from matplotlib import gridspec

x = y = [1,2,3]

gs = gridspec.GridSpec(3, 1)

ax1 = plt.subplot(gs[0:2, 0])
ax1.plot(x, y)

ax2 = plt.subplot(gs[2, 0], sharex=ax1)
ax2.plot(x,y)

plt.show()


Note that you could use plt.tight_layout() to remove the overlap of axis


",,,false,,,
https://stackoverflow.com/questions/42302672,false,The issue does not meet the criteria for deeper analysis as it is related to the interaction between multiprocessing and matplotlib rather than an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Requests.get in multiprocessing pool blocked by a Matplotlib figure?,"See the code example below.  The symptom is that the requests.get(url) within a multiprocessing Pool seems to be somehow blocked by a matplotlib figure().

The ingredients needed to reproduce this rather unexpected behavior are:


Use the multiprocessing Pool to apply a function to a list; a plain request.get(url) after plt.figure() runs fluently.
The function for the Pool map contains requests.get; using other ""simpler"" function such as the identity function (e.g. f in the code sample) runs fluently.
Before starting the Pool, create a matplotlib figure; without this figure, the code runs fluently.


Code example:

# matplotlib.__version__: 1.4.3
# requests.__version__: 2.9.1
# Python version:
#   2.7.12 |Anaconda 2.3.0 (x86_64)| (default, Jul  2 2016, 17:43:17)
#   [GCC 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)]
# uname -a:
#   Darwin myMBP 16.4.0 Darwin Kernel Version 16.4.0:
#   Thu Dec 22 22:53:21 PST 2016;
#   root:xnu-3789.41.3~3/RELEASE_X86_64 x86_64 i386 MacBookPro11,3 Darwin


from matplotlib import pyplot as plt
from multiprocessing import Pool
import requests

urls = ['http://stackoverflow.com']

# Runs as expected:
p = Pool(processes=1)
print 1, p.map(requests.get, urls)

# Runs as expected:
def f(x):
    return x
fig = plt.figure()
p = Pool(processes=1)
print 2, p.map(f, urls)

# Will not run (the p.map takes forever to run):
fig = plt.figure()
p = Pool(processes=1)
print 3, p.map(requests.get, urls)

# REPLACING the previous block with the following
# will again runs as expected:
fig = plt.figure()
print 4, requests.get(urls[0])


Output of the code sample:

1 [&lt;Response [200]&gt;]
2 ['http://stackoverflow.com']
3

","If you are running this in windows, you will need to move all your code below def f() into a:

if __name__ == ""__main__"":


block.
",,,false,,,
https://stackoverflow.com/questions/7170631,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,What can cause delay in my worker thread Queue.get()?,"Note: This is closely related to my other topic here and here, but is an independent question and you needn't read them if you're not interested to..

I have some unexpected delays in processing items from the queue.  It seems to be related to the matplotlib GUI thread, because I can make the delay arbitrarily long by avoiding generating any GUI events, but for example if I create some mouse move events, I can get at the queue.  What is the cause of this delay and how to fix it?

# ~/repo/wim/mpl_q.py
import threading, Queue, time, random, sys

t0 = time.time()
t = lambda : time.time() - t0

def worker():
  while True:
    thing = queue.get()
    sys.stdout.write('({0}) hello {1}!\n'.format(t(), thing))
    queue.task_done()

queue = Queue.Queue()
thread = threading.Thread(target=worker)
thread.daemon = True
thread.start()

def say_hello(thing='world'):
  print '({0}) --&gt; say_hello({1})'.format(t(), thing)
  queue.put(thing)

say_hello('world')
say_hello('cruel world')
say_hello('stack overflow')

import matplotlib.pyplot as plt
fig = plt.figure()

def event_handler(event):
  world = random.choice(['foo', 'bar', 'baz'])
  say_hello(world)

event_handler_ = lambda x: event_handler(x)
cid0 = fig.canvas.mpl_connect('key_press_event', event_handler)
cid1 = fig.canvas.mpl_connect('button_press_event', event_handler_)

plt.show()


Example of typical output , you can see the scripted items happen on time, but the user generated ones can come much later..

wim@wim-acer:~/repo/wim$ python mpl_q.py
(0.000166893005371) --&gt; say_hello(world)
(0.000200986862183) --&gt; say_hello(cruel world)
(0.000216960906982) hello world!
(0.000231027603149) --&gt; say_hello(stack overflow)
(0.000247955322266) hello cruel world!
(0.00425505638123) hello stack overflow!
(7.80911588669) --&gt; say_hello(foo)
(7.84842705727) hello foo!
(9.41998004913) --&gt; say_hello(baz)
(11.4023530483) hello baz!
(14.3315930367) --&gt; say_hello(foo)
(19.4317750931) hello foo!
(20.96124506) --&gt; say_hello(bar)
(23.2277729511) --&gt; say_hello(baz)
(23.2278220654) hello bar!
(29.0094120502) hello baz!


edit: I am using GTKAgg backend, and matplotlib version 1.1.0
",,,,false,,,
https://stackoverflow.com/questions/70954411,false,The issue does not provide enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,ValueError: Found unexpected losses or metrics that do not correspond to any Model output,,,,,false,,,
https://stackoverflow.com/questions/69148495,false,"The issue is related to resolving a TypeError when working with Featuretools library, and it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.",,,,,,,TypeError: import_optional_dependency() got an unexpected keyword argument &#39;errors&#39;,"I am trying to work with Featuretools to develop an automated feature engineering workflow for the customer churn dataset. The end outcome is a function that takes in a dataset and label times for customers and builds a feature matrix that can be used to train a machine learning model.
As part of this exercise I am trying to  execute the below code for plotting a histogram and got ""TypeError: import_optional_dependency() got an unexpected keyword argument 'errors' "". Please help resolve this TypeError.
import matplotlib.pyplot as plt
%matplotlib inline
plt.style.use('fivethirtyeight')
plt.rcParams['figure.figsize'] = (10, 6)

trans.loc[trans['actual_amount_paid'] &lt; 250, 'actual_amount_paid'].dropna().plot.hist(bins = 30)
plt.title('Distribution of Actual Amount Paid')

Below is the full error I received:
    ---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-32-7e19affd5fc1&gt; in &lt;module&gt;
      4 plt.rcParams['figure.figsize'] = (10, 6)
      5 
----&gt; 6 trans.loc[trans['actual_amount_paid'] &lt; 250, 'actual_amount_paid'].dropna().plot.hist(bins = 30)
      7 plt.title('Distribution of Actual Amount Paid')

~\anaconda3\lib\site-packages\pandas\core\ops\common.py in new_method(self, other)
     63                     break
     64                 if isinstance(other, cls):
---&gt; 65                     return NotImplemented
     66 
     67         other = item_from_zerodim(other)

~\anaconda3\lib\site-packages\pandas\core\arraylike.py in __lt__(self, other)
     35     def __ne__(self, other):
     36         return self._cmp_method(other, operator.ne)
---&gt; 37 
     38     @unpack_zerodim_and_defer(""__lt__"")
     39     def __lt__(self, other):

~\anaconda3\lib\site-packages\pandas\core\series.py in _cmp_method(self, other, op)  
   4937         --------
   4938         &gt;&gt;&gt; s = pd.Series(range(3))
-&gt; 4939         &gt;&gt;&gt; s.memory_usage()
   4940         152
   4941 

~\anaconda3\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op)
    248     lvalues = ensure_wrapped_if_datetimelike(left)
    249     rvalues = ensure_wrapped_if_datetimelike(right)
--&gt; 250 
    251     rvalues = lib.item_from_zerodim(rvalues)
    252     if isinstance(rvalues, list):

~\anaconda3\lib\site-packages\pandas\core\ops\array_ops.py in _na_arithmetic_op(left, right, op, is_cmp)
    137 
    138 def _na_arithmetic_op(left, right, op, is_cmp: bool = False):
--&gt; 139     
    140     Return the result of evaluating op on the passed in values.
    141 

~\anaconda3\lib\site-packages\pandas\core\computation\expressions.py in &lt;module&gt;
     17 from pandas._typing import FuncType
     18 
---&gt; 19 from pandas.core.computation.check import NUMEXPR_INSTALLED
     20 from pandas.core.ops import roperator
     21 

~\anaconda3\lib\site-packages\pandas\core\computation\check.py in &lt;module&gt;
      1 from pandas.compat._optional import import_optional_dependency
      2 
----&gt; 3 ne = import_optional_dependency(""numexpr"", errors=""warn"")
      4 NUMEXPR_INSTALLED = ne is not None
      5 if NUMEXPR_INSTALLED:

TypeError: import_optional_dependency() got an unexpected keyword argument 'errors'

","Try to upgrade pandas:
pip install pandas --upgrade

",,,false,,,
https://stackoverflow.com/questions/57381514,false,"The issue is about removing an unexpected edge in an SVG file generated with Matplotlib, and it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.",,,,,,,Make matplotlib export figure svg without stroke,"I am trying to generate an svg file with Python and matplotlib. A simpler version of the code that I use is the following :
import matplotlib.pyplot as plt


plt.figure()
plt.fill([0,1,0.5],[0,0,1],color = ""r"")
plt.fill([1.5,1,0.5],[1,0,1],color = ""b"")
plt.show()
plt.savefig(""soedgesvg.svg"")

So far so good the result is as expected :

But when I open it in Inkscape I get an unexpected ghost edge with no color specified. This can be seen in the following picture :

Is there a way to remove this edge in Python before exporting the svg ?
Edit
This occurs only when a color is specified from my experience.
Inkscape 0.92.3 and matplotlib 3.1.1
","The way too go is to add linewidth=0 when calling plt.fill like so :

plt.fill([0,1,0.5],[0,0,1],color = ""r"", linewidth=0)
plt.fill([1.5,1,0.5],[1,0,1],color = ""b"", linewidth=0)


This answer has been provided by @ImportanceOfBeingErnest in the comments with the following explanation :


  Because the linewidth is defined in points. When you zoom inside matplotlib, the lines always keep their physical size, e.g. 1/72. of an inch. When you zoom in in Inkscape you zoom into the actual figure, up to the point where maybe your screen only shows 1/72. of an inch and hence the line will be as large as the screen.

",,,false,,,
https://stackoverflow.com/questions/42216865,false,"The issue is related to labeling timedelta objects on the x-axis in Matplotlib, and it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.",,,,,,,Python Matplotlib x-axis improperly labels timedelta64 object,"I am trying to generate a plot from a Pandas dataframe in Python with Matplotlib. Here is a summary of the dataframe. 

import pandas as pd
import datetime
import matplotlib.pyplot as plt

# Summarize data frame.
&gt;&gt;&gt; df.shape
(40, 4)

&gt;&gt;&gt; df.dtypes
ID                         object
relative_time     timedelta64[ns]
value                     float64
relative_value            float64
dtype: object

&gt;&gt;&gt; df.head()
    ID     relative_time  value  relative_value
0  001 -1 days +18:08:04    4.5            -1.0
1  001 -1 days +18:18:03    4.5            -1.0
2  001 -1 days +18:28:03    4.5            -1.0
3  001 -1 days +18:38:04    4.5            -1.0
4  001 -1 days +18:48:03    4.5            -1.0

&gt;&gt;&gt; df.tail()
     ID     relative_time  value  relative_value
35  001 -1 days +23:58:03    5.5             0.0
36  001          00:08:03    5.5             0.0
37  001          00:18:03    5.5             0.0
38  001          00:28:02    5.5             0.0
39  001          00:38:04    5.5             0.0


I am trying to plot relative_time on the x-axis and relative_value on the y-axis. However, the code below produces an unexpected result, where I cannot what tell what units the x-axis is in. 

# Plot the desired plot.
plt.plot(test['relative_time'], test['relative_value'], marker='.')




Note, the x-axis in the plot above is not in units of hours (relative to time 0). Such a plot would look like the following. 

plt.plot(test['relative_time'] / np.timedelta64(1, 'h'), test['relative_value'], marker='.')




How can I plot the x-axis so that it displays time in the same format as the relative_time column? For example, if the x-axis were to have tick marks every hour, they would be labeled as, -1 days +18:00:00, -1 days +19:00:00, ...,  00:00:00, and 01:00:00. 
",,,,false,,,
https://stackoverflow.com/questions/28101851,false,"The issue is related to a TypeError when using the 'delim_whitespace' argument in the read_csv() function of pandas, and it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.",,,,,,,ipython pandas TypeError: read_csv() got an unexpected keyword argument &#39;delim-whitespace&#39;&#39;,,,,,false,,,
https://stackoverflow.com/questions/64952236,false,"The issue is about placing an image at a specific point in a data-coordinate system using Matplotlib, and it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.",,,,,,,matplotlib: how to put picture to a specific point of data-coordinate system,"I'm trying to add picture at the plot in specific place in it by a given coordinates in data-coordinate system. However it runs a little bit unpredicted. Here is a code snippet I wrote:
import matplotlib.pyplot as plt
import numpy as np

fig, ax = plt.subplots(figsize=(5,5))

ax.set_xlim(0, 1)
ax.set_ylim(0, 1)
ax.grid('on')

x = np.arange(0, 1, 0.005)
y = np.exp(-x/2.) * np.sin(2*np.pi*x)
ax.plot(x, y)

im_orange = plt.imread('./test100x100_orange.png')
im_blue = plt.imread('./test100x100_blue.png')

x0, y0 = ax.transData.transform((0,0))
print('transData(0,0) = {}'.format(ax.transData.transform((0,0))))

ax.figure.figimage(im_orange, alpha=0.5)
ax.figure.figimage(im_blue, x0, y0, alpha=0.5)

ax.transData.transform((0,0)) returns transData(0,0) = [45. 45.] which is unexpected since doesn't represent actual position of (0,0) on the plot. Here is result image as well:

My base question is how to put picture left bottom corner exactly at (0,0) point in data-coordinates? And if possible please explain such behaviour of matplotlib.
Update. A few experiments on top. I've run a slightly modified script (provided below by Iammuratc but with plt.savefig() instead) in 3 modes:

From python console (copy and paste):

Python script (something like python test.py:
Result is the same as before.

ipython from Jupiter Notebook:
Suboption A: plt.show()


Suboption B: plt.savefig()

Now it's even more confusing..
","It works for me how you did it. You might check the image arrays in case they are shifted.
import numpy as np
import matplotlib.pyplot as plt


im_orange  = np.zeros((128,128,3),'uint8')
im_orange[:,:,0] = 255

im_blue = np.zeros((128,128,3),'uint8')
im_blue[:,:,2] = 255


fig, ax = plt.subplots(figsize=(5,5))

ax.set_xlim(0, 1)
ax.set_ylim(0, 1)
ax.grid('on')

x = np.arange(0, 1, 0.005)
y = np.exp(-x/2.) * np.sin(2*np.pi*x)
ax.plot(x, y)

# im_orange = plt.imread('./test100x100_orange.png')
# im_blue = plt.imread('./test100x100_blue.png')

x0, y0 = ax.transData.transform((0,0))
print('transData(0,0) = {}'.format(ax.transData.transform((0,0))))

ax.figure.figimage(im_orange,x0,y0, alpha=0.5)
ax.figure.figimage(im_blue, x0, y0, alpha=0.5)

plt.show()


",,,false,,,
https://stackoverflow.com/questions/59798684,false,"The issue is about changing axis labels in Matplotlib, and it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.",,,,,,,How to change axis labels in matplotlib?,"I have the following piece of code which creates a simple plot with matplotlib (python 3.6.9, matplotlib 3.1.2, Mac Mojave):

import numpy as np
import matplotlib.pyplot as plt

plt.imshow(np.random.random((50,50)))
plt.show()


The created plot is as expected:



Now, in order to relabel the xtick/ytick labels I am using the following code

import numpy as np
import matplotlib.pyplot as plt

plt.imshow(np.random.random((50,50)));

ticks, labels = plt.xticks()
labels[1] = '22'
plt.xticks(ticks, labels)

plt.show()


where I expect the second label to be replaced by '22', but everything else stays the same. However, I get the following plot instead:




There is some unexpected white area in the left part of the plot
All the other labels have vanished. 


How to do it correctly? 

Just as a reminder: I want to get the exact same result as the original image (first plot), ONLY with one of the lables changed.

This question has been asked before, one example is here. But the answer does not seem to work. Here is the code

import numpy as np
import matplotlib.pyplot as plt

fig, ax = plt.subplots()
plt.imshow(np.random.random((50,50)))

labels = [item.get_text() for item in ax.get_xticklabels()]
labels[1] = 'Test'
ax.set_xticklabels(labels)

plt.show()


which creates an image as follows:



which does not show the white area anymore, but still the other labels are not shown. 
","Create axes using subplots, so that you can have set_xticklabels method, so you can update the labels.

You need to use, canvas.draw() to get the values.

import numpy as np
import matplotlib.pyplot as plt

fig,ax = plt.subplots()
ax.imshow(np.random.random((50,50)));
fig.canvas.draw()
#labels = ['-10','0','22','20','30','40'] or
labels[2]=22
ax.set_xticklabels(labels)

plt.show()


Output:



Hope this is what you need!
",,,false,,,
https://stackoverflow.com/questions/44273021,false,"The issue is related to formatting the x-axis of a stacked horizontal bar graph in Matplotlib, and it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.",,,,,,,Matplotlib: Formatting time on x-axis of stacked horizontal bar graph,"I am trying to graph the amounts of time a user spent on different tasks in a stacked horizontal bar graph using matplotlib. The x-axis is time. Each portion of the bar represents the amount of time spent on the task. However, I am getting an unexpected graph with incorrect formatting. The formatting of the graph requires me to zoom very far on the graph in order to see all of the bars.

The graph does resemble what I need, but at first it looks like this: original graph

And I have to zoom in very far in order to get this: zoomed-in graph

The zoomed-in graph seems to have the correct proportions of the bars except for the first and last data points.

My data is a list of timedelta objects so they may be added together. I am converting them to datetime objects to graph the data.

The code that gives me undesired results is:

import matplotlib.pyplot as plt
from datetime import datetime
from datetime import timedelta
import matplotlib.dates as dt

def sum_times(data, N):
    '''sums the first N datetime elements in a list
       changes from timedelta object to datetime object
    '''
    # initialize
    summ = datetime(1900, 1, 1, 0, 0, 0)
    for i in range(len(data[0:N])):
        summ += data[i]
    return summ

start_date = datetime(1900, 1, 1, 0, 0, 0)
times = [timedelta(0, 737), 
         timedelta(0, 110), 
         timedelta(0, 356), 
         timedelta(0, 171), 
         timedelta(0, 306)]

fig, ax1 = plt.subplots(1,1, sharex=True, sharey=True)

ax1.set_title(""Bug being fixed"")
ax1.set_xlabel('time')
ax1.xaxis_date()

# the graph uses datetime objects
ax1.barh(1, times[0] + start_date)
ax1.barh(1, times[1] + start_date, left=sum_times(times, 1))
ax1.barh(1, times[2] + start_date, left=sum_times(times, 2))
ax1.barh(1, times[3] + start_date, left=sum_times(times, 3))
ax1.barh(1, times[4] + start_date, left=sum_times(times, 4))

ax1.set_xticks(range(1,10))   # arbitrary 

plt.show()


What can I do to change the formatting?

I have tried using ax1.set_xticklabels() with either datetime or timedelta objects, but I get the exception: ValueError: ordinal must be &gt;= 1. 

When I use

ax1.xaxis.set_major_locator(dt.MinuteLocator(interval=60))
ax1.xaxis.set_major_formatter(dt.DateFormatter('%M:%S'))


the formatting is still incorrect.

I am using python 3.6, matplotlib, PyDev IDE, and Windows 8.

If there are any libraries that are better suited to display this sort of data or can supplement matplotlib/pyplot, I would appreciate a solution using one.

Also, I have tried using a loop to automate the calls to ax1.barh(...) but the graph window doesn't display and becomes unresponsive. Since I would like to graph larger data sets, I could use a more elegant solution.
","Building on the suggestion @rvd provided, I have come up with a somewhat better solution using pandas. It's still not ideal in terms of formatting, but I do not need to zoom in ridiculously far in order to see my graph and the data is proportional.
Here is the code that got it working a little better using pandas:
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
from datetime import timedelta
import matplotlib.dates as dt

times = [timedelta(0, 737), 
         timedelta(0, 110), 
         timedelta(0, 356), 
         timedelta(0, 171), 
         timedelta(0, 306)]

start_date = datetime(1900, 1, 1, 0, 0, 0)
times_datetime = [start_date + times[i] for i in range(len(times))]
# pandas requires numerical data on dependent axis
times_num = dt.date2num(times_datetime)
# to make times_num proportionally correct
for i in range(len(times_num)):
    times_num[i] -= dt.date2num(start_date)
    
df = pd.DataFrame([times_num], index=['bugs'])
fig, ax1 = plt.subplots(1,1, sharex=True, sharey=True)
df.plot(kind='barh', ax=ax1, stacked=True)
plt.show()

And this produces: 
The x-axis ticks may not be times, but the data visualization is more along the lines of what I'm looking for.
Thanks!
",,,false,,,
https://stackoverflow.com/questions/28398660,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,"Matplotlib parametric surface plot unexpected results, why?","I am trying to plot an ellipsoid so, I thought I would amend the example code for a sphere from the matplotlib 3D plotting page.

from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt
from matplotlib import cm
import numpy as np

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')

# Ellipsoid
u = np.linspace(-np.pi/2.0,np.pi/2.0,100)
v = np.linspace(-np.pi,np.pi,100)
x = 10 * np.outer(np.cos(u), np.cos(v))
y = 10 * np.outer(np.cos(u), np.sin(v))
z = 10 * np.outer(np.ones(np.size(u)), np.sin(v))


# Sphere
#u = np.linspace(0, 2 * np.pi, 100)
#v = np.linspace(0, np.pi, 100)
#x = 10 * np.outer(np.cos(u), np.sin(v))
#y = 10 * np.outer(np.sin(u), np.sin(v))
#z = 10 * np.outer(np.ones(np.size(u)), np.cos(v))

ax.plot_surface(x, y, z,  rstride=4, cstride=4, cmap = cm.copper)
ax.set_xlabel('x-axis')
ax.set_ylabel('y-axis')
ax.set_zlabel('z-axis')
plt.show()


If you run the code you will see that the plot returns an aesthetically pleasing half inside out boat like surface but sadly not an ellipsoid.

Have included the sphere code (commented out) for comparison.

Is there something obvious here that I'm missing?
",,,,false,,,
https://stackoverflow.com/questions/24641179,false,"The issue does not meet the criteria for deeper analysis as it is a general question about pandas pivoting and plotting workflow, without indicating any specific API-related problems.",,,,,,,Pandas: Pivoting and plotting workflow,,,,,false,,,
https://stackoverflow.com/questions/17066313,false,"The issue does not meet the criteria for deeper analysis as it is a question about unexpected results in pandas plotting two graphs on one scale, without indicating any specific API-related problems.",,,,,,,Pandas plotting two graphs on one scale,"I have a line graph that I am highligting at end with a marker(shown as large red diamond here).

I am using two two pandas plot commands to create it.   Problem is that I get unexpected results.   depending on the length of the data and whether I put the plot for the red diamond first or second I get different results.   There does not seem to be a pattern that I can discern. The Correct / Expected result shown below



sometimes i get:



and most of the time with big data sets I get the following warning:

/Users/xxxxx/.virtualenvs/test2/lib/python2.7/site-packages/matplotlib/axes.py:2542: UserWarning: Attempting to set identical left==right results
in singular transformations; automatically expanding.
left=15727, right=15727
  + 'left=%s, right=%s') % (left, right))

The Warning only shows 1st time it happens.   Obviously pandas does not like support the plotting of 2 different series with different x scales on the same axis? 

Can try code below to generate the graphs, can play around by passing, Series or Dataframes for plot can also reverse the order of the plotting of the red diamond.   Can also change the number of data points.   One error that I could not recreate here is with the red diamond in middle and blue line only going of to left.

Code:

plot_with_series = False
reverse_order = False
import pandas as pd
dates = pd.date_range('20101115', periods=800)
df =  pd.DataFrame(randn(len(dates)), index = dates, columns = ['A'])
ds = pd.Series(randn(len(dates)), index = dates)
clf()
if plot_with_series:
    if reverse_order: ds.plot()
    ds.tail(1).plot(style='rD', markersize=20)
    if not reverse_order: ds.plot()
else:
    if reverse_order: df.plot(legend=False)
    df.A.tail(1).plot(style='rD', markersize=20,legend=False)
    if not reverse_order: df.plot(legend=False)


The errors/warnings happen from both within IPython or from running the as script from command line.  Also constant across 2 latest versions of pandas.  Any ideas or obvious problems?
",,,,false,,,
https://stackoverflow.com/questions/75172467,true,"The issue involves the PyVista API and the unexpected behavior of extruding a concave, complex polygon. Further analysis is required to provide detailed information about the API and the conditions under which the unexpected behavior occurs.",,,,,,,"Extrude a concave, complex polygon in PyVista","I wish to take a concave and complex (containing holes) polygon and extrude it 'vertically' into a polyhedron, purely for visualisation. I begin with a shapely Polygon, like below:
poly = Polygon(
    [(0,0), (10,0), (10,10), (5,8), (0,10), (1,7), (0,5), (1,3)], 
    holes=[
        [(2,2),(4,2),(4,4),(2,4)],
        [(6,6), (7,6), (6.5,6.5), (7,7), (6,7), (6.2,6.5)]])

which I correctly plot (reorientating the exterior coordinates to be clockwise, and the hole coordinates to be counterclockwise) in matplotlib as:

I then seek to render this polygon extruded out-of-the-page (along z), using PyVista. There are a few hurdles; PyVista doesn't directly support concave (nor complex) input to its PolyData type. So we first create an extrusion of simple (hole-free) concave polygons, as per this discussion.
def extrude_simple_polygon(xy, z0, z1):

    # force counter-clockwise ordering, so PyVista interprets polygon correctly
    xy = _reorient_coords(xy, clockwise=False)

    # remove duplication of first &amp; last vertex
    xyz0 = [(x,y,z0) for x,y in xy]
    if (xyz0[0] == xyz0[-1]):
        xyz0.pop()

    # explicitly set edge_source
    base_vert = [len(xyz0)] + list(range(len(xyz0)))
    base_data = pyvista.PolyData(xyz0, base_vert)
    base_mesh = base_data.delaunay_2d(edge_source=base_data)
    vol_mesh  = base_mesh.extrude((0, 0, z1-z0), capping=True)

    # force triangulation, so PyVista allows boolean_difference
    return vol_mesh.triangulate()

Observe this works when extruding the outer polygon and each of its internal polygons in-turn:
extrude_simple_polygon(list(poly.exterior.coords), 0, 5).plot()


extrude_simple_polygon(list(poly.interiors[0].coords), 0, 5).plot()
extrude_simple_polygon(list(poly.interiors[1].coords), 0, 5).plot()



I reasoned that to create an extrusion of the original complex polygon, I could compute the boolean_difference. Alas, the result of
outer_vol = extrude_simple_polygon(list(poly.exterior.coords), 0, 5)
for hole in poly.interiors:
    hole_vol = extrude_simple_polygon(list(hole.coords), 0, 5)
    outer_vol = outer_vol.boolean_difference(hole_vol)

outer_vol.plot()

is erroneous:

The doc advises to inspect the normals via plot_normals, revealing that all extruded volumes have inward-pointing (or else, unexpected) normals:



The extrude doc mentions nothing of the extruded surface normals nor the original object (in this case, a polygon) orientation.
We could be forgiven for expecting our polygons must be clockwise, so we set clockwise=True in the first line of extrude_simple_polygon and try again. Alas, PolyData now  misinterprets our base polygon; calling base_mesh.plot() reveals (what should look like our original blue outer polygon):

with extrusion


Does PyVista always expect counter-clockwise polygons?
Why does extrude create volumes with inward-pointing surface normals?
How can I correct the extruded surface normals?
Otherwise, how can I make PyVista correctly visualise what should be an incredibly simply-extruded concave complex polygon??

","You're very close. What you have to do is use a single call to delaunay_2d() with all three polygons (i.e., the enclosing one and the two holes) as edge source (loop source?). It's also important to have faces (rather than lines) from each polygon; this is what makes it possible to enforce the holeyness of the holes.
Here's a complete example for your input (where I manually flipped the orientation of the holes; you seem to have a _reorient_coords() helper that you should use instead):
import pyvista as pv

# coordinates of enclosing polygon
poly_points = [
    (0, 0), (10, 0), (10, 10), (5, 8), (0, 10), (1, 7), (0, 5), (1, 3),
]
# hole point order hard-coded here; use your _reorient_coords() function
holes = [
    [(2, 2), (4, 2), (4, 4), (2, 4)][::-1],
    [(6, 6), (7, 6), (6.5, 6.5), (7, 7), (6, 7), (6.2, 6.5)][::-1],
]

z0, z1 = 0.0, 5.0

def points_2d_to_poly(points, z):
    """"""Convert a sequence of 2d coordinates to a polydata with a polygon.""""""
    faces = [len(points), *range(len(points))]
    poly = pv.PolyData([p + (z,) for p in points], faces=faces)
    return poly

# bounding polygon
polygon = points_2d_to_poly(poly_points, z0)

# add all holes
for hole_points in holes:
    polygon += points_2d_to_poly(hole_points, z0)

# triangulate poly with all three subpolygons supplying edges
# (relative face orientation is critical here)
polygon_with_holes = polygon.delaunay_2d(edge_source=polygon)

# extrude
holey_solid = polygon_with_holes.extrude((0, 0, z1 - z0), capping=True)
holey_solid.plot()


Here's the top view of the polygon pre-extrusion:
plotter = pv.Plotter()
plotter.add_mesh(polygon_with_holes, show_edges=True, color='cyan')
plotter.view_xy()
plotter.show()


",,,false,,,
https://stackoverflow.com/questions/70915345,true,The issue involves the TensorRT API and the unexpected error related to the 'is_dynamic_op' field. Further analysis is required to provide detailed information about the API and the conditions under which the error occurs.,,,,,,,Why did I get unexpected field names: [&#39;is_dynamic_op&#39;]?,"I am working on a low light video processing project where I am getting some errors in some areas,
For this code.
params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(
    precision_mode='FP16',
    is_dynamic_op = True)

I am getting this error.
&gt; --------------------------------------------------------------------------- ValueError                                Traceback (most recent call
&gt; last) &lt;ipython-input-8-326230ed5373&gt; in &lt;module&gt;()
&gt;       2 params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(
&gt;       3     precision_mode='FP16',
&gt; ----&gt; 4     is_dynamic_op = True)
&gt;       5 
&gt;       6 # Convert the model
&gt; 
&gt; /usr/lib/python3.7/collections/__init__.py in _replace(_self, **kwds)
&gt;     414         result = _self._make(map(kwds.pop, field_names, _self))
&gt;     415         if kwds:
&gt; --&gt; 416             raise ValueError(f'Got unexpected field names: {list(kwds)!r}')
&gt;     417         return result
&gt;     418 
&gt; 
&gt; ValueError: Got unexpected field names: ['is_dynamic_op']

I have used these libraries,
from glob import glob
from PIL import Image
from matplotlib import pyplot as plt
from mirnet.inference import Inferer
from mirnet.utils import download_dataset, plot_result
from tensorflow.python.compiler.tensorrt import trt_convert as trt

import tensorflow as tf
import numpy as np
import time

I have imported all the libraries but am still stuck.
","Firstly, it seems that trt.DEFAULT_TRT_CONVERSION_PARAMS doesn't have the field 'is_dynamic_op'. My guess would be that, some documentation exists for the library, and there you can probably see whether the field is settable or not.
Secondly, it seems you are using TensorFlow and the TensorRT API. (but again, it's a guess...). In the source-code of the library, they use ""is_dynamic_op"" on some ""rewrite_config"". Maybe this helps you reformat your code to work: https://github.com/tensorflow/tensorflow/blob/dd38449b8ac3fd9ffaa98349d39d36ec26e72dfe/tensorflow/python/compiler/tensorrt/trt_convert.py#L1136
",,,false,,,
https://stackoverflow.com/questions/55995209,false,"The issue does not meet the criteria for deeper analysis as it is a question about making a custom class compatible with matplotlib's units, without indicating any specific API-related problems.",,,,,,,How to make matplotlib handle custom class &quot;units&quot;,"I am trying to make my class compatible with matplotlib's units and facing an unexpected behaviour.

Here is a simplified version of my custom class, that is not a subclass of numpy's ndarray :

import numpy as np
import matplotlib
import matplotlib.units as units

class Toto:
    def __init__(self, value_like, unit_like):
        self.value_like = value_like # typically a scalar or array
        self.unit_like = unit_like # a string describing the unit

    def __array__(self, *args, **kwargs):
        return np.array(self.value_like, *args, **kwargs)

# To test if plot as expected, without units handling
arr_x = Toto(np.arange(5), ""meter"")
arr_y = Toto(np.arange(5), ""second"")
plt.plot(arr_x, arr_y)


Notice I added a __array__ method in order to make it ""plottable"" with matplotlib (if not, I get a TypeError: float() argument must be a string or a number, not 'Toto' exception, when numpy tries to cast Toto with array(toto_instance, float)). I suspect my problem actually come from this method but I can't figure out why/how. Anyway, moving on the actual problem :

Now I followed the example in the doc to make a conversion-interface for my Toto class:

class TotoConverter(units.ConversionInterface):

    @staticmethod
    def convert(value, unit, axis):
        'Convert a toto object value to a scalar or array'
        old_toto_unit = axis.get_unit()
        # stupid computation to determine new_unit (simpler for a MWE)
        new_unit = old_toto_unit
        new_toto = Toto(value, new_unit)
        return new_toto.value_like

    @staticmethod
    def axisinfo(unit, axis):
        return units.AxisInfo(label=str(unit))

    @staticmethod
    def default_units(x, axis):
        'Return the default unit for x or None'
        return getattr(x, 'unit_like', None)



In the end, I add the conversion interface of my class to matplotlib's registry of conversion interfaces:

units.registry[Toto] = TotoConverter()


Then the problem :
At this point, I should get the unit on the label when plotting Toto instances, but I get the same result as before defining and registering my unit conversion-interface. Why is that ? 

I suspect the conversion object is never called since my Toto instances are converted into ndarray but I'm not sure

Cheers
","I suspect you mean something like this, where you have a list/array of Totos, and not a Toto of values.

import matplotlib.pyplot as plt
import matplotlib.units as units

class Toto:
    def __init__(self, value_like, unit_like):
        self.value_like = value_like # typically a scalar or array
        self.unit_like = unit_like # a string describing the unit

class TotoConverter(units.ConversionInterface):

    @staticmethod
    def convert(value, unit, axis):
        if isinstance(value, Toto):
            return value.value_like
        else:
            return [toto.value_like for toto in value]

    @staticmethod
    def axisinfo(unit, axis):
        return units.AxisInfo(label=str(unit))

    @staticmethod
    def default_units(x, axis):
        'Return the default unit for x or None'
        if isinstance(x, Toto):
            return getattr(x, 'unit_like', None)
        else:
            return getattr(x[0], 'unit_like', None)


Then register and use it,

units.registry[Toto] = TotoConverter()


arr_x = [Toto(i, ""meter"") for i in range(5)]
arr_y = [Toto(i, ""second"") for i in range(5)]

plt.plot(arr_x, arr_y)            #use lists of Totos
plt.axhline(Toto(2, ""second""))    # use Toto scalars
plt.xlim(Toto(-1, ""meter""), None) # use Toto scalars

plt.show()

",,,false,,,
https://stackoverflow.com/questions/54386130,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,How to set x-axis tick mark labels using matplotlib in python?,"I only want x-labels displayed for the bars in the bar chart using matplotlib in python i.e. 1992, 1993, 1994, 1995 instead of 1990, 1990.5, 1991, 1991.5, etc on the x-axis which is what it does by default

I've tried using the code suggested here: Manipulating x axis tick labels in matplotlib
which suggests using this: ind = range(2,6); plt.xticks(ind,x)

import pandas as pd
import numpy as np

np.random.seed(12346)

df = pd.DataFrame([np.random.normal(32000,200000,3650), 
                   np.random.normal(43000,100000,3650), 
                   np.random.normal(43500,140000,3650), 
                   np.random.normal(48000,70000,3650)], 
                  index=[1992,1993,1994,1995])
Y = 40000

import math

%matplotlib notebook

plt.figure()

std = df.std(axis = 1)
stderror = std/math.sqrt(df.shape[1])
marginoferror = stderror*1.96
print(df.mean(axis=1).iloc[0] - marginoferror.iloc[0])

def color_def(y,dataframe,mofe):
    color = []
    for i in range(0,dataframe.shape[0]):
        if (dataframe.mean(axis=1).iloc[i] - mofe.iloc[i] &gt; y):
            color.append('darkred')
        elif (dataframe.mean(axis=1).iloc[i] + mofe.iloc[i] &lt; y):
            color.append('darkblue')
        else:
            color.append('white')
    return(color)
x = df.index.values
plt.bar(df.index.values,df.mean(axis=1),yerr=marginoferror,align='center', color = color_def(Y,df,marginoferror),alpha=0.5, edgecolor = 'black',ecolor='black', capsize=10)

plt.axhline(y=Y)

ind = range(2, 6)    # the x locations for the groups
plt.xticks( ind, x)


When I use these 2 lines of code  ind = range(2,6); plt.xticks(ind,x), the unexpected result can be seen at this link:
https://www.dropbox.com/s/0ciuix13nhdj5jz/HW3%20v0.1.jpg?dl=0

which is not a nicely formatted bar graph and does not have the x-axis labeled with 1992, 1993, 1994 and 1995.

When I take these 2 lines of code out: 
ind = range(2,6); plt.xticks(ind,x),
I do get a nicely formatted bar chart just with the clunky x-axis labeling
","Not sure how the numbers 2 to 5 would relate to your data. Your data is 1992 ... 1995, which is the index of the dataframe, hence

plt.xticks(df.index.values)


would tick exactly those values.
",,,false,,,
https://stackoverflow.com/questions/46613117,false,The issue does not meet the criteria for deeper analysis as it is related to package installation and configuration rather than an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Why does conda install tk not work in my docker container even though it says its installed?,"I was having issues with tk in my python 3 docker container.

I tried:

conda install tk


but it says it did install it

root@36602e2cd649:/home_simulation_research/overparametrized_experiments/pytorch_experiments# conda install tk
Fetching package metadata ...........
Solving package specifications: .

# All requested packages already installed.
# packages in environment at /opt/conda:
#
tk                        8.6.7                h5979e9b_1


but when I go to python and try to import it it does not work:

&gt;&gt;&gt; import Tkinter
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
ImportError: No module named 'Tkinter'


and other errors:

&gt;&gt;&gt; import tkinter
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""/opt/conda/envs/pytorch-py35/lib/python3.5/tkinter/__init__.py"", line 35, in &lt;module&gt;
    import _tkinter # If this fails your Python may not be configured for Tk
ImportError: libX11.so.6: cannot open shared object file: No such file or directory


when I run a script that needs it:

Traceback (most recent call last):
  File ""bulk_experiment_dispatcher.py"", line 18, in &lt;module&gt;
    from data_file import *
  File ""/home_simulation_research/overparametrized_experiments/pytorch_experiments/data_file.py"", line 16, in &lt;module&gt;
    import matplotlib.pyplot as plt
  File ""/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/matplotlib/pyplot.py"", line 115, in &lt;module&gt;
    _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup()
  File ""/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/matplotlib/backends/__init__.py"", line 32, in pylab_setup
    globals(),locals(),[backend_name],0)
  File ""/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/matplotlib/backends/backend_tkagg.py"", line 6, in &lt;module&gt;
    from six.moves import tkinter as Tk
  File ""/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/six.py"", line 92, in __get__
    result = self._resolve()
  File ""/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/six.py"", line 115, in _resolve
    return _import_module(self.mod)
  File ""/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/six.py"", line 82, in _import_module
    __import__(name)
  File ""/opt/conda/envs/pytorch-py35/lib/python3.5/tkinter/__init__.py"", line 35, in &lt;module&gt;
    import _tkinter # If this fails your Python may not be configured for Tk
ImportError: libX11.so.6: cannot open shared object file: No such file or directory


I tried apt-get install python-tk (from Install tkinter for Python) but it did not work:

root@36602e2cd649:/home_simulation_research/overparametrized_experiments/pytorch_experiments# apt-get install python-tk
Reading package lists... Done
Building dependency tree
Reading state information... Done
E: Unable to locate package python-tk




I tried running ENTERYPOINT as one of the answers suggested but it threw me some more errors:

/path/fake_gui.sh: 8: /home_simulation_research/overparametrized_experiments/docker_files/runtime/fake_gui.sh: source: not found
/path/fake_gui.sh: 12: /home_simulation_research/overparametrized_experiments/docker_files/runtime/fake_gui.sh: function: not found
/path/fake_gui.sh: 13: kill: invalid signal number or name: SIGTERM
/path/fake_gui.sh: 15: /home_simulation_research/overparametrized_experiments/docker_files/runtime/fake_gui.sh: Syntax error: ""}"" unexpected


but not sure what to do...



Helpful questions:

How to install python-tk in my docker image
","Ok so once I put a dummy screen in the image it stopped crashing:

RUN apt-get update
RUN apt-get install -y xvfb
#RUN Xvfb :1 -screen 0 1024x768x16 &amp;&gt; xvfb.log  &amp;


when I ran my docker image.
","You need to use a Docker container that has a virtual framebuffer installed and running.

This blog post explains the ""Why and How"" of putting X11 into a docker container.

You can see how they're doing it in the Selenium Docker container via their entry_point.sh:

#!/bin/bash
#
# IMPORTANT: Change this file only in directory Standalone!

source /opt/bin/functions.sh

export GEOMETRY=""$SCREEN_WIDTH""""x""""$SCREEN_HEIGHT""""x""""$SCREEN_DEPTH""

function shutdown {
  kill -s SIGTERM $NODE_PID
  wait $NODE_PID
}

if [ ! -z ""$SE_OPTS"" ]; then
  echo ""appending selenium options: ${SE_OPTS}""
fi

SERVERNUM=$(get_server_num)

rm -f /tmp/.X*lock

xvfb-run -n $SERVERNUM --server-args=""-screen 0 $GEOMETRY -ac +extension RANDR"" \
  java ${JAVA_OPTS} -jar /opt/selenium/selenium-server-standalone.jar \
  ${SE_OPTS} &amp;
NODE_PID=$!

trap shutdown SIGTERM SIGINT
wait $NODE_PID


Source for the above code is from this repository on GitHub, SeleniumHQ/docker-selenium.
","With python 3, you must import as follows:

import tkinter   # with a small caps 't'

",false,,,
https://stackoverflow.com/questions/43132792,false,The issue does not meet the criteria for deeper analysis as it is related to the expected behavior of a matplotlib polar plot rather than an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,matplotlib unexpected results polar plot,"I am trying to plot simple function r = 3*sin(2*theta) using matplotlib:

import numpy as np
import matplotlib.pyplot as plt
theta = np.arange(0,2*np.pi,0.01)
r = 3.0*np.sin(2.0*theta)
ax = plt.subplot(111, projection='polar')
ax.plot(theta, r)
plt.show()


This is the result I get (it is not correct):



This is what I expect to see (wolfram alpha): 

Am I missing something?
Thanks!
",,,,false,,,
https://stackoverflow.com/questions/38512870,false,The issue does not meet the criteria for deeper analysis as it is related to the usage of AxesGrid in matplotlib rather than an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Can AxesGrid be used to plot two imshows (overlay) with two separate colorbars?,"I am using AxesGrid in matplotlib to create a plot that overlays two imshow plots, with a separate colourbar side by side for each image colourmap. While I can see in this question/answer that using pyplot.colorbar() automatically plots the second colour bar next to the first, this doesn't seem to work with AxesGrid.

    import matplotlib.pyplot as plt
    from mpl_toolkits.axes_grid1 import AxesGrid

    fig = plt.figure(1, facecolor='white',figsize=(10,7.5))

    grid = AxesGrid(fig, 111, 
                    nrows_ncols=(1, 1),
                    axes_pad=(0.45, 0.15),
                    label_mode=""1"",
                    share_all=True,
                    cbar_location=""right"",
                    cbar_mode=""each"",
                    cbar_size=""7%"",
                    cbar_pad=""2%"",
                    )

    im = grid[0].imshow(my_image, my_cmap)
    cbar = grid.cbar_axes[0].colorbar(im)

    im2 = grid[0].imshow(my_image_overlay, my_cmap2, alpha=0.5)
    cbar2 = grid.cbar_axes[0].colorbar(im2)

    plt.show()


However, this just shows the second colourbar. (Presumably overlaying the first one). I tried overriding the padding in cbar2 with:

    cbar2 = grid.cbar_axes[0].colorbar(im2, pad=0.5)


but this results in an error with ""got an unexpected keyword argument 'pad'""

Is there a way to offset the second colourbar?
",,,,false,,,
https://stackoverflow.com/questions/30292291,false,The issue does not meet the criteria for deeper analysis as it is related to the usage of markers and line width in matplotlib rather than an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,matplotlib line with markers and line width - unexpected results,"Seems like a super simple thing, hopefully I'm missing something obvious or there is a bug in matplotlib. I'm using matplotlib 1.4.3 if that helps.

from pylab import *
t = arange(0.0, 2.0, 0.01)
s = sin(2 * pi * t)
plot(t, s, c='m', lw=10)




Everything looks good. Awesome.

from pylab import *
t = arange(0.0, 2.0, 0.01)
s = sin(2 * pi * t)
plot(t, s, c='m', lw=10, marker='o', mfc='m')




Say what?? My line is now blue, even though I have c='m'??

Even more confusing ... don't set the line width...

from pylab import *
t = arange(0.0, 2.0, 0.01)
s = sin(2 * pi * t)
plot(t, s, c='m', marker='o', mfc='m')




Again, works as expected, no problems, line color is magenta c='m'. What am I missing here? Why is the line color blue if I set a line width and have markers?

Thanks,
Bob
",,,,false,,,
https://stackoverflow.com/questions/23406677,false,The issue does not have sufficient information to determine whether it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,matplotlib GridSpec indexing yields unexpected results,,,,,false,,,
https://stackoverflow.com/questions/14034529,false,The issue does not meet the criteria for deeper analysis as it is related to the deployment of matplotlib on Heroku rather than an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,How to deploy matplotlib on heroku - fulfilling numpy requirement,"I'm trying to deploy a web app on Heroku that uses matplotlib. This question is related but doesn't seem to address my specific problem. More precisely, I'm deploying a duplicate app ""staging"" for testing purposes. When I run the command:

git push staging master


to push my app to Heroku I get an unexpected Heroku push rejection:  

           ============================================================================
           BUILDING MATPLOTLIB
                       matplotlib: 1.1.1
                           python: 2.7.2 (default, Oct 31 2011, 16:22:04)  [GCC 4.4.3]
                         platform: linux2

           REQUIRED DEPENDENCIES
                            numpy: no
                                   * You must install numpy 1.4 or later to build
                                   * matplotlib.
           Complete output from command python setup.py egg_info:
           basedirlist is: ['/usr/local', '/usr']

       ============================================================================

       BUILDING MATPLOTLIB

                   matplotlib: 1.1.1

                       python: 2.7.2 (default, Oct 31 2011, 16:22:04)  [GCC 4.4.3]

                     platform: linux2



       REQUIRED DEPENDENCIES

                        numpy: no

                               * You must install numpy 1.4 or later to build

                               * matplotlib.

       ----------------------------------------
       Command python setup.py egg_info failed with error code 1 in /tmp/build_sj82km4g47z3/.heroku/venv/build/matplotlib
       Storing complete log in /app/.pip/pip.log
 !     Heroku push rejected, failed to compile Python app

To git@heroku.com:warm-atoll-3630.git
 ! [remote rejected] master -&gt; master (pre-receive hook declined)
error: failed to push some refs to 'git@heroku.com:warm-atoll-3630.git'


Unexpected because I thought I had resolved this problem. Indeed my production app is working just fine. I resolved it by having a two layered requirements file.

requirements.txt:

numpy==1.6.2
-r ./prod-requirements.txt


prod-requirements.txt:

matplotlib==1.1.1
other requirements... 


Clearly I have forgotten how I actually resolved this issue. I remember that because of the way matplotlib depends on numpy and how Heroku installs requirements via pip that this is tricky.  Here is the issue I'm referring to. What can be done? Thanks in advance.
","I resolved the issue by removing matplotlib from my prod-requirements.txt file (see orginal question). Then deploying, then adding matplotlib to my prod-requirements.txt file then deploying again. I had assumed that's what was achieving by having  a requirements.txt: 

numpy==1.6.2
-r ./prod-requirements.txt


And then putting matplotlib=1.1.1 in the prod-requirements file .
But apparently not. It seems likely that i could have achieved this with just one requirements file.
",,,false,,,
https://stackoverflow.com/questions/69569617,false,The issue does not meet the criteria for deeper analysis as it is related to the unexpected presence of negative values in the x-axis of a matplotlib bar chart rather than an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Unexpected negative values in x-axis matplotlib,"I have the following x and y values:
x = [0.  , 0.02, 0.04, 0.06, 0.08, 0.1 , 0.12, 0.14, 0.16, 0.18, 0.2 ,
       0.22, 0.24, 0.26, 0.28, 0.3 , 0.32, 0.34, 0.36, 0.38, 0.4 , 0.42,
       0.44, 0.46, 0.48, 0.5 , 0.52, 0.54, 0.56, 0.58, 0.6 , 0.62, 0.64,
       0.66, 0.68, 0.7 , 0.72, 0.74, 0.76, 0.78, 0.8 , 0.82, 0.84, 0.86,
       0.88, 0.9 , 0.92, 0.94, 0.96, 0.98]

y = [4179,  628,   41,  142,  117,    6,   11,    2,    1,    0,    6,
          2,   12,    5,    7,    3,    2,    3,    2,    3,   30,   27,
         31,   29,   14,   31,   22,   28,   18,   19,   19,   22,   20,
         19,   21,   23,   25,   24,   20,   29,   23,   25,   31,   25,
         24,   28,   23,   26,   32,   21]

I'm plotting a bar chart using the code
fig, cx = plt.subplots(figsize =(15, 7))
cx.bar(x,y)
plt.show()

Which is giving me the following plot

This plot is unexpected because as shown in the diagram, the values of the x-axis lie between 0 and 1. There are no negative values and no values greater than 1 in the data. I wasn't sure about the reason for the presence of bars beyond the 0-1 region.
I tried out the solutions given in the following two question links:
Why is Python Matplotlib bar-chart's X axis ticks showing strange and wrong negative values? and
Matplotlib yaxis range display using absolute values rather than offset values?
I tried using the following solutions:

cx = plt.gca() cx.ticklabel_format(useOffset=False)
plt.bar(x, y, tick_label=x)
cx.get_xaxis().get_major_formatter().set_useOffset(False)
cx = plt.gca() cx.set_xticklabels(ax.get_xticks())

Solutions #1, #3, and #4 didn't lead to any changes. Solution #2 added ticks and the values were overlapped as shown in the figure below. But the bars didn't change.

Since few of the bars in the middle regions of the graphs have smaller bar widths it doesn't seem like bigger bar width is the issue here.
Any idea to solve this is appreciated. Thanks in advance :)
","The documentation for plt.bar() should clear things up.
The function creates bars centered at x, each with width width (0.8 by default). So your first bar is centered at x = 0 and spans from -0.4 to 0.4. Likewise for the last one. You can change the alignment or width (smaller would make them thinner), but that's about it.
",,,false,,,
https://stackoverflow.com/questions/20655246,false,The issue does not have sufficient information to determine whether it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Intersecting matplotlib graph with unsorted data,,,,,false,,,
https://stackoverflow.com/questions/15538099,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Conversion of unicode minus sign ( from matplotlib ticklabels ),"I'm having a problem with the Text object that matplotlib use to represent the ticklabels.

For testing reason I need to check the value of the ticks labels that are created in a plot. If the label is a string or a positive number, there is no problem: a unicode string is returned, I test it (or convert it to a number, given the circumstances) and everything is fine.

But if the label is a negative number what I get back is a mangled unicode string for a reason I cannot understand.

Let's take this example code:

import pylab as plt
fig, ax = plt.subplots(1)
ax.plot([-1, 0, 1, 2], range(4))
labels = ax.get_xticklabels()


now, if I ask the text content of the second label (the 0) I obtain a normal unicode string:

labels[1].get_text()
# u'0.0'


but the unicode of the first one (the -1) is a strange thing

labels[1].get_text()
# u'\u22121'


This is printed correctly in the terminal, but in this case I need to confront it with a numerical value, and every conversion fail, both with int and float.

I tried to convert it to an UTF-8 string with

text = labels[1].get_text()
text.encode('utf8')
# '\xe2\x88\x921'


but again it is something that is correctly printed and raise an error when converted. I also looked to the unicodedata module, but looks like it can only convert single character, so in this case is useless. I've tried also to normalize the string with unicodedata.normalize and any possible format, but again no success.

I moved to the pipy module unidecode (as suggested in Python and character normalization), again without any success

from unidecode import unidecode
unidecode(text)
# '[?]1'


I have tried also to avoid font issues using the solution in Non-ASCII characters in Matplotlib, but with the same result (I'm not sure if it should even have something to do, being that a problem of visualization...). the question Accented characters in Matplotlib has a similar problem, as it is concerned about the visualization and not the value in itself

I'm starting to feel a little lost...I know that python 2.7 has some unicode ""difficulty"", but normally I can avoid them in a way or the other.

I know that the issue is the minus sign, as I can avoid the problem using a brute replacement of the culprit:

text.replace(u'\u2212', '-')
# u'-1'


But this is more and hack than a solution, and I'm almost certain that it's not stable across different systems, so I would like something closer to a solution.

I'm working with 


python 2.7.3 
matplotlib 1.2.0
pylab 1.7.0
IPython 0.13.1 


on Kubuntu 12.10.

Thank you very much for your help!

EDIT:

Corrected the order of the plot, as I got the x and y inverted, sorry

EDIT2:

a similar info is present at this link:http://www.coniferproductions.com/2012/12/17/unicode-character-dump-in-python/

in the end it shows how in some books the minus sign used is a more estetically pleasant one but not recognized by the python interpreter as a valid character.

EDIT3:

Riddle solved. the character that matplotlib return is the ""MINUS SIGN"", i.e. the correct typografical sign for the minus. The one the keybord create is in fact ""HYPHEN-MINUS"", that is commonly used but not typografically correct. see on wikipedia for an explanation http://en.wikipedia.org/wiki/Hyphen-minus.

So, the simple replace I used is in fact the correct practical thing to do, but ""ethically"" is a bug in python (2.7 and 3.x alike) that do not recognize the correct symbol for the minus sign.

see the bug tracking in http://bugs.python.org/issue6632

EDIT4:

to disable this behavior there is a simple solution on matplotlib, just modify the rcparams, either in the .matplotlibrc or programmatically.

import matplotlib as mpl
mpl.rcParams['axes.unicode_minus']=False

",,,,false,,,
https://stackoverflow.com/questions/11893414,false,"The issue does not meet the criteria for deeper analysis as it is a question about creating square subplots in matplotlib with heatmaps, without indicating any unexpected behavior or failure of an API.",,,,,,,how to make square subplots in matplotlib with heatmaps?,,,,,false,,,
https://stackoverflow.com/questions/15165065,false,"The issue does not meet the criteria for deeper analysis as it is a question about datetime x-labels in matplotlib, without indicating any unexpected behavior or failure of an API.",,,,,,,matplotlib datetime xlabel issue,"I'm seeing some strange behavior in the x-axis auto-labeling for dates in matplotlib. When I issue the command:

from datetime import datetime as dt
plot( [ dt(2013, 1, 1), dt(2013, 5, 17)], [ 1 , 1 ], linestyle='None', marker='.')


I get the very reasonably labeled chart:



But if I increase the end date by 1 day:

plot( [ dt(2013, 1, 1), dt(2013, 5, 18)], [ 1 , 1 ], linestyle='None', marker='.')


I get this:



I've reproduced this at several different calendar date ranges(in 2012), and each time the magic number of days required to trip the bug is around 140 (in this case 136/137). Anyone know what's going on here? Is this a known bug, and if so, is there a workaround?

A couple notes: In the above commands, I'm using IPython in --pylab mode to create the plots, but I first encountered this issue using matplotlib directly, and it is reproducible in script form (i.e. I don't think this is an IPython issue). Also, I've observed this in both matplotlib 1.1.0 and 1.2.X.

UPDATE:

It looks like there is a window where, if you push far enough ahead, the labels start behaving normally again. For the example above, the labels remain garbled from May 18 through May 31, but on June 1, the labels start plotting normally again. So,

(labels are garbled)
plot( [ dt(2013, 1, 1), dt(2013, 5, 31)], [ 1 , 1 ], linestyle='None', marker='.')

(labels are fine)
plot( [ dt(2013, 1, 1), dt(2013, 6, 1)], [ 1 , 1 ], linestyle='None', marker='.')

",,,,false,,,
https://stackoverflow.com/questions/24961674,false,"The issue does not meet the criteria for deeper analysis as it is a question about using IPython Notebook widgets for matplotlib interactivity, without indicating any unexpected behavior or failure of an API.",,,,,,,IPython Notebook widgets for Matplotlib interactivity,"I would like to use the ipython notebook widgets to add some degree of interactivity to inline matplotlib plots. 

In general the plot can be quite heavy and I want to only update a specific element of the plot. I understand that widgets have a throttling feature built-in that helps to don't flood the kernel, but when the plot takes let say 30s I don't want to wait so long just to update a line.

By reading the example notebooks I was able to create a basic example in which I add a cross cursor (driven by 2 sliders) to a mpl axis.

The problem is that the figure is displayed twice. Here is the code (cell 1):

fig, ax = plt.subplots() 
ax.plot([3,1,2,4,0,5,3,2,0,2,4])


... figure displayed ..., cell 2 (edit: thanks Thomas K for the improvement):

vline = ax.axvline(1)
hline = ax.axhline(0.5)

def set_cursor(x, y):
    vline.set_xdata((x, x))
    hline.set_ydata((y, y))
    display(fig)


and finally (cell 3):

interact(set_cursor, x=(1, 9, 0.01), y=(0, 5, 0.01))


shows again the figure with the widgets.

So the question is:


how can I inhibit the first figure display?
is that the right way to do it or is there a better approach?


EDIT

I found an ipython config knob that, according to this notebook, allows inhibiting the figure display 

%config InlineBackend.close_figures = False


While the example notebook works, I can't figure out how to use this option by itself (without the context manager class provided in the linked example) to hide a figure display.

EDIT 2

I found some documentation of the InlineBackend.close_figures configurable.

EDIT 3

Triggered by @shadanan answer, I want to clarify that my purpose is to add a cursor to an existing figure without redrawing the plot from scratch at each cursor movement. Merging the 3 cells in a single  cell:

fig, ax = plt.subplots()
ax.plot([3,1,2,4,0,5,3,2,0,2,4])

vline = ax.axvline(1)
hline = ax.axhline(0.5)

def set_cursor(x, y):
    vline.set_xdata((x, x))
    hline.set_ydata((y, y))
    display(fig)

interact(set_cursor, x=(1, 9, 0.01), y=(0, 5, 0.01))


it ""should"" work but it doesn't. The first time the cell is executed it shows 2 figures. After widget interaction only 1 figure is displayed. This is the ""strange behavior"" that requires a workaround like the one shown in @shadanan answer. Can an ipython dev comment on this? Is it a bug? 
","The solution turns out to be really simple. To avoid showing the first figure we just need to add a close() call before the interact call.

Recalling the example of the question, a cell like this will correctly show a single interactive figure (instead of two):

fig, ax = plt.subplots()
ax.plot([3,1,2,4,0,5,3,2,0,2,4])
plt.close(fig)

vline = ax.axvline(1)
hline = ax.axhline(0.5)

def set_cursor(x, y):
    vline.set_xdata((x, x))
    hline.set_ydata((y, y))
    display(fig)

interact(set_cursor, x=(1, 9, 0.01), y=(0, 5, 0.01))


A cleaner approach is defining the function add_cursor (in a separate cell or script):

def add_cursor(fig, ax):
    plt.close(fig)

    vline = ax.axvline(1, color='k')
    hline = ax.axhline(0.5, color='k')

    def set_cursor(x, y):
        vline.set_xdata((x, x))
        hline.set_ydata((y, y))
        display(fig)

    interact(set_cursor, x=ax.get_xlim(), y=ax.get_ylim())


and then call it whenever we want to add an interactive cursor:

fig, ax = plt.subplots()
ax.plot([3,1,2,4,0,5,3,2,0,2,4])
add_cursor(fig, ax)

","You can do this in a very strait forward way using the new(ish) notebook backend

%matplotlib notebook
import matplotlib.pyplot as plt
from IPython.html.widgets import interactive

fig, ax = plt.subplots()
ax.plot(range(5))


vline = ax.axvline(1, color='k')
hline = ax.axhline(0.5, color='k')

def set_cursor(x, y):
    vline.set_xdata((x, x))
    hline.set_ydata((y, y))
    ax.figure.canvas.draw_idle()


and in a separate cell:

interactive(set_cursor, x=ax.get_xlim(), y=ax.get_ylim())


This will still re-draw the entire figure every time you move the cursor because notebook does not currently support blitting (which is being worked on https://github.com/matplotlib/matplotlib/pull/4290 )
",,false,,,
https://stackoverflow.com/questions/16770049,false,"The issue does not meet the criteria for deeper analysis as it is a question about strange matplotlib zorder behavior with legend and errorbar, without indicating any unexpected behavior or failure of an API.",,,,,,,Strange matplotlib zorder behavior with legend and errorbar,"I encountered a rather strange behavior of legend and the errorbar plot commands. I am using Python xy 2.7.3.1 with matplotlib 1.1.1 
The code below exemplifies the observed behavior:

import pylab as P
import numpy as N

x1=N.linspace(0,6,10)
y1=N.sin(x1)
x2=N.linspace(0,6,5000)
y2=N.sin(x2)
xerr = N.repeat(0.01,10)
yerr = N.repeat(0.01,10)

#error bar caps visible in scatter dots
P.figure()
P.subplot(121)
P.title(""strange error bar caps"")
P.scatter(x1,y1,s=100,c=""k"",zorder=1)
P.errorbar(x1,y1,yerr=yerr,xerr=xerr,color=""0.7"", 
    ecolor=""0.7"",fmt=None, zorder=0)
P.plot(x2,y2,label=""a label"")
P.legend(loc=""center"")

P.subplot(122)
P.title(""strange legend behaviour"")
P.scatter(x1,y1,s=100,c=""k"",zorder=100)
P.errorbar(x1,y1,yerr=yerr,xerr=xerr,color=""0.7"", 
    ecolor=""0.7"",fmt=None, zorder=99)
P.plot(x2,y2,label=""a label"", zorder=101)
P.legend(loc=""center"")
P.show()


which yields this plot:



As you can see, the errorbar caps are overwriting the scatter plot. If I increase zorder enough this does not happen any more, but the plot line overwrites the legend. I have the suspicion that the problem is related to this zorder problem with matplotlib.

Quick, dirty, hacky solutions also appreciated.

Edit (thanks @nordev): the desired outcome is the following: 


errorbars, as well as the ending caps shall be below the scatter plot point.
the line plot shall be above the scatter and the error bars
the legend shall be above all others


Adjusting the zorder according to your answer:


P.legend(zorder=100)  --&gt; self.legend_ = mlegend.Legend(self, handles, labels, **kwargs)
TypeError: __init__() got an unexpected keyword argument 'zorder'
P.errorbar(zorder=0), P.scatter(zorder=1), ... as correctly suggested by you, still yields the same plot, the error bar caps are still above the scatter dots. I corrected the example above accordingly.

","i use
plt.legend(loc='center').set_zorder(100)

",,,false,,,
https://stackoverflow.com/questions/6485000,false,"The issue does not meet the criteria for deeper analysis as it is a question about colorbar setting tick formatter/locator in matplotlib, without indicating any unexpected behavior or failure of an API.",,,,,,,colorbar setting tick formator/locator changes tick labels,"users, 
I want to customize the ticks on a colorbar. However, I found the following strange behavior. I try to change the tick formator to the default formator (I thought this should change nothing at all) but I end up with different labels. Does anybody know what I am doing wrong? Or is this a bug?

I use matplotlib from git (v1.0.1-961-gb516ae0 , git describe).
The following code produces the two plots:

#http://matplotlib.sourceforge.net/examples/pylab_examples/griddata_demo.html
from numpy.random import uniform, seed
from matplotlib.mlab import griddata
import matplotlib.pyplot as plt
import matplotlib.ticker
import numpy as np
# make up data.
seed(0)
npts = 200
x = uniform(-2,2,npts)
y = uniform(-2,2,npts)
z = x*np.exp(-x**2-y**2)
# define grid
xi = np.linspace(-2.1,2.1,100)
yi = np.linspace(-2.1,2.1,200)
# grid the data.
zi = griddata(x,y,z,xi,yi,interp='linear')

##### FIRST PLOT
plt.figure()
CS  = plt.contour(xi,yi,zi,25,cmap=plt.cm.jet)
bar = plt.colorbar() # draw colorbar
# plot data points.
#plt.scatter(x,y,marker='o',c='b',s=5,zorder=10)
plt.xlim(-2,2)
plt.ylim(-2,2)
plt.title('griddata test (%d points)' % npts)
plt.show()

##### SECOND PLOT
plt.figure()
CS  = plt.contour(xi,yi,zi,25,cmap=plt.cm.jet)
bar = plt.colorbar() # draw colorbar
bar.ax.yaxis.set_minor_locator(matplotlib.ticker.AutoLocator())
bar.ax.yaxis.set_major_locator(matplotlib.ticker.AutoLocator())
# plot data points.
#plt.scatter(x,y,marker='o',c='b',s=5,zorder=10)
plt.xlim(-2,2)
plt.ylim(-2,2)
plt.title('griddata test (%d points)' % npts)
plt.show()

",,,,false,,,
https://stackoverflow.com/questions/21189954,false,"The issue does not meet the criteria for deeper analysis as it is a question about pandas plotting time-series, without indicating any unexpected behavior or failure of an API.",,,,,,,Can pandas plot a time-series without trying to convert the index to Periods?,"When plotting a time-series, I observe an unusual behavior, which eventually results in not being able to format the xticks of the plot.
It seems that pandas internally tries to convert the index into a PeriodIndex, but obviously only succeeds if the timestamp values are equally spaced. If they are unevenly spaced (or - strangely - if they are evenly spaced but timezone-aware) the index remains a DatetimeIndex.
The latter case works as expected. I can set DateFormatter and Locators. If however the index is interally converted to a PeriodIndex before plotting, the x-axis of the resulting plott seems to be messed up.

Here is an Example to reproduce the problem.

from pandas import Series, DataFrame
import pandas as pd
from datetime import datetime
import pytz
import matplotlib.pyplot as plt
import matplotlib as mpl
import numpy as np

idx1 = np.array([datetime(2014, 1, 16, 0),
                 datetime(2014, 1, 16, 5),
                 datetime(2014, 1, 16, 10),
                 datetime(2014, 1, 16, 15), 
                 datetime(2014, 1, 16, 20), 
                 datetime(2014, 1, 17, 1)])
idx2 = np.array([datetime(2014, 1, 16, 0),
                 datetime(2014, 1, 16, 5),
                 datetime(2014, 1, 16, 10),
                 datetime(2014, 1, 16, 15),
                 datetime(2014, 1, 16, 20),
                 datetime(2014, 1, 16, 23)])
y = [0, 2, np.nan, 5, 2, 1]
tz = pytz.timezone('Europe/Berlin')

fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(15,4))

# index convertible to period index
s1 = Series(y, index=idx1)
s1.plot(ax=ax1)
print ax1.get_xticks()
print ax1.xaxis.get_major_locator()
print ax1.xaxis.get_major_formatter()
#ax1.xaxis.set_major_formatter(mpl.dates.DateFormatter('%H'))
#ax1.xaxis.set_major_locator(mpl.ticker.MultipleLocator(0.25))

# index not convertible to period index
s2 = Series(y, index=idx2)
s2.plot(ax=ax2)
print ax2.get_xticks()
#ax2.xaxis.set_major_formatter(mpl.dates.DateFormatter('%H'))
#ax2.xaxis.set_major_locator(mpl.ticker.MultipleLocator(0.25))

# index convertible to period index but tz-aware
s3 = Series(y, index=idx1)
s3 = s3.tz_localize(tz)
s3.plot(ax=ax3)
print ax3.get_xticks()
#ax2.xaxis.set_major_formatter(mpl.dates.DateFormatter('%H'))
#ax2.xaxis.set_major_locator(mpl.ticker.MultipleLocator(0.25))

fig.autofmt_xdate()  # just temporarily

plt.tight_layout()
plt.show(block=False)


Is there a way to tell pandas to keep the index in its original format and not to convert it to Periods? Any ideas how to deal with this are greatly appreciated!

I use pandas 0.13 and matplotlib 1.3.1

As a sidenote: 
It would of course be great if the timezones were not converted all to UTC. However I realize this problem may still persist for a while. But if anyone has a hint for a workaround I'd be glad to hear (I tried passing a tz directly to the DateFormatter. That works, but the Locators don't seem to like it much).
","Dealing with the conversion from UTC to local time
import time
import pytz
import matplotlib.dates
…
# Get the time zone.
tz = pytz.timezone(time.tzname[0])
…
ax1.xaxis.set_major_locator(matplotlib.dates.HourLocator(interval=1, tz=tz))
ax1.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H', tz=tz))

",,,false,,,
https://stackoverflow.com/questions/25272701,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Matplotlib pick event order for overlapping artists,"I'm hitting a very strange issue with matplotlib pick events.  I have two artists that are both pickable and are non-overlapping to begin with (""holes"" and ""pegs"").  When I pick one of them, during the event handling I move the other one to where I just clicked (moving a ""peg"" into the ""hole"").  Then, without doing anything else, a pick event from the moved artist (the peg) is generated even though it wasn't there when the first event was generated.  My only explanation for it is that somehow the event manager is still moving through artist layers when the event is processed, and therefore hits the second artist after it is moved under the cursor.

So then my question is - how do pick events (or any events for that matter) iterate through overlapping artists on the canvas, and is there a way to control it?  I think I would get my desired behavior if it moved from the top down always (rather than bottom up or randomly).  I haven't been able to find sufficient enough documentation, and a lengthy search on SO has not revealed this exact issue.  Below is a working example that illustrates the problem, with PathCollections from scatter as pegs and holes:

import matplotlib.pyplot as plt
import sys

class peg_tester():
    def __init__(self):
        self.fig = plt.figure(figsize=(3,1))
        self.ax = self.fig.add_axes([0,0,1,1])
        self.ax.set_xlim([-0.5,2.5])
        self.ax.set_ylim([-0.25,0.25])
        self.ax.text(-0.4, 0.15, 'One click on the hole, and I get 2 events not 1',
                     fontsize=8)

        self.holes = self.ax.scatter([1], [0], color='black', picker=0)
        self.pegs = self.ax.scatter([0], [0], s=100, facecolor='#dd8800',
                                    edgecolor='black', picker=0)

        self.fig.canvas.mpl_connect('pick_event', self.handler)
        plt.show()

    def handler(self, event):
        if event.artist is self.holes:
            # If I get a hole event, then move a peg (to that hole) ...
            # but then I get a peg event also with no extra clicks!
            offs = self.pegs.get_offsets()
            offs[0,:] = [1,0] # Moves left peg to the middle
            self.pegs.set_offsets(offs)
            self.fig.canvas.draw()
            print 'picked a hole, moving left peg to center'
        elif event.artist is self.pegs:
            print 'picked a peg'
        sys.stdout.flush() # Necessary when in ipython qtconsole

if __name__ == ""__main__"":
    pt = peg_tester()


I have tried setting the zorder to make the pegs always above the holes, but that doesn't change how the pick events are generated, and particularly this funny phantom event.

EDIT:
The context is an implementation of peg solitaire, so I want to be able to pick up a peg then click on an empty hole to drop it there.  Currently the same peg is immediately picked up again as soon as it is dropped.
",,,,false,,,
https://stackoverflow.com/questions/43334273,false,The issue does not meet the criteria for deeper analysis as it is related to the behavior of multiple grids in matplotlib rather than an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Matplotlib multiple grids zorder not working with errorbars,"I am currently dealing with some strange behavior of matplotlib when plotting multiple errorbars with different y axes into one subplot. 

When doing so, the grid corresponding to the second errorbar plot always overlaps the first errorbar plot. With the zorder options I was only able to move the other grid below the errorbars. 

I would like both grids to be below the two errorbars. 
Does anyone know a solution to this, or is this a bug in matplotlib? 

I am using Python 2.7.12 with matplotlib 1.5.1. 

Minimal working example:

import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.colors as colors

# numbers of epochs
ttimes_means_list = [251.4, 153.3, 22.0, 202.1, 46.6]
ttimes_stddevs_list = [32.1, 35.1, 12.0, 84.9, 14.7]
# numbers of times
times_means_list = [5231, 3167, 860, 3932, 1244]
times_stddevs_list = [1381, 572, 253, 1445, 215]

labels = ['x1', 'x2', 'x3', 'x4', 'x5']
linewidth=3

xvalues = np.arange(0, len(times_means_list), 1)
xvalues_s = xvalues + 0.1

fig = plt.figure()
ax1 = fig.add_subplot(111)
ax2 = ax1.twinx()
ax1.set_ylabel('Number')
ax1.xaxis.grid(False)
ax1.yaxis.grid(True, color='navy', linewidth=linewidth/2.0)
ax2.xaxis.grid(False)
ax1.set_zorder(0)
ax2.set_zorder(0)
ax2.yaxis.grid(True, color='darkorange', linewidth=linewidth/2.0)
ax2.set_ylabel('Time')
ax1.set_xticks(xvalues)
ax2.set_xticks(xvalues)
ax1.set_xticklabels(labels)
ax2.set_xticklabels(labels)
ax1.set_xlabel('x label')
errplot1 = ax1.errorbar(xvalues, ttimes_means_list, yerr=ttimes_stddevs_list,
        linestyle=""None"", elinewidth=linewidth, color='navy', label='Number',
        capthick=linewidth, zorder=10)
errplot2 = ax2.errorbar(xvalues_s, times_means_list, yerr=times_stddevs_list, 
        linestyle=""None"", elinewidth=linewidth, color='darkorange',
        label='Time', capthick=linewidth, zorder=10)
ax1.set_axisbelow(True)
ax2.set_axisbelow(True)
fig.legend((errplot1, errplot2), ('number', 'time'), 
        loc='upper right', numpoints=1)
plt.xlim(-0.5, len(times_means_list)-0.5)
plt.title('Some plot title')
plt.savefig('mwe_plot.pdf')
plt.clf()


Output plot (the orange grid dots are overlapping the blue bars): 

","Maybe you can draw the 'navy' line twice.

import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.colors as colors

# numbers of epochs
ttimes_means_list = [251.4, 153.3, 22.0, 202.1, 46.6]
ttimes_stddevs_list = [32.1, 35.1, 12.0, 84.9, 14.7]
# numbers of times
times_means_list = [5231, 3167, 860, 3932, 1244]
times_stddevs_list = [1381, 572, 253, 1445, 215]

labels = ['x1', 'x2', 'x3', 'x4', 'x5']
linewidth=3

xvalues = np.arange(0, len(times_means_list), 1)
xvalues_s = xvalues + 0.1

fig = plt.figure()
ax1 = fig.add_subplot(111)
ax2 = ax1.twinx()
ax1.set_ylabel('Number')
ax1.xaxis.grid(False)
g1 = ax1.yaxis.grid(True, color='navy', linewidth=linewidth/2.0)
ax2.xaxis.grid(False)
ax1.set_zorder(0)
ax2.set_zorder(0)
g2 = ax2.yaxis.grid(True, color='darkorange', linewidth=linewidth/2.0)
ax2.set_ylabel('Time')
ax1.set_xticks(xvalues)
ax2.set_xticks(xvalues)
ax1.set_xticklabels(labels)
ax2.set_xticklabels(labels)
ax1.set_xlabel('x label')
ax1.errorbar(xvalues, ttimes_means_list, yerr=ttimes_stddevs_list,
        linestyle=""None"", elinewidth=1, color='navy', label='Number',
        capthick=1, zorder=10,)
errplot2 = ax2.errorbar(xvalues_s, times_means_list, yerr=times_stddevs_list, 
        linestyle=""None"", elinewidth=linewidth, color='darkorange',
        label='Time', capthick=linewidth, zorder=10)
ax1.set_axisbelow(True)
ax2.set_axisbelow(True)

# draw the 'navy' line again
ax3 = ax1.twinx()
ax3.yaxis.grid(False)
errplot1 = ax3.errorbar(xvalues, ttimes_means_list, yerr=ttimes_stddevs_list,
        linestyle=""None"", elinewidth=linewidth, color='navy', label='Number',
        capthick=linewidth, zorder=10)

fig.legend((errplot1, errplot2), ('number', 'time'), 
        loc='upper right', numpoints=1)
plt.xlim(-0.5, len(times_means_list)-0.5)
plt.title('Some plot title')
# plt.savefig('mwe_plot.pdf')
# plt.clf()

plt.show()


And you will get:

",,,false,,,
https://stackoverflow.com/questions/46880493,false,The issue does not meet the criteria for deeper analysis as it is related to the freezing behavior of matplotlib.pyplot.Figure.show() and does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,matplotlib.pyplot.Figure.show freezes instantly,"Following strange problem: This code

import matplotlib.pyplot as plt
fig = plt.figure()
ax = fig.add_subplot(111)
ax.plot([1, 2, 3], [3, 0, 3])
fig.show()


causes the graph window (backend: tkagg) to freeze as soon as it opens, however this code

import matplotlib.pyplot as plt
plt.plot([1, 2, 3], [3, 0, 3])
plt.show()


opens the graph window (also tkagg) as expected. I tried debugging, but attaching Visual Studio to python.exe and hitting pause causes VS to crash and python_d.exe always complains cannot import name 'multiarray'. I did a fresh reinstall of python (purging all files, installing python 3.6.3 x86_64, pip install matplotlib) and the behavior continues. What is causing this behavior? Is there a way to fix it?

More information about my system: I'm running Windows 8.1 x86_64 with Python v3.6.3:2c5fed8 x86_64 and matplotlib 2.1.0 (rev-id b392d46466e98cd6a437e16b52b3ed8de23b0b52).

Solution:

import matplotlib.pyplot as plt
fig = plt.figure()
ax = fig.add_subplot(111)
ax.plot([1, 2, 3], [3, 0, 3])

root = fig.canvas._tkcanvas.winfo_toplevel() # Get tkinter root
fig.show()
root.mainloop() # Enter mainloop

","I don't see quite the same behaviour, but I'm testing on Python 3.5, matplotlib 2.1, and Ubuntu 16.04. When I run your first version, I see the plot window open very briefly, and then close itself.

However, if you look at the documentation, it's not too surprising that the behaviour of the two examples is different. You're calling two different show() methods.

In the first version, you're calling Figure.show():


  If using a GUI backend with pyplot, display the figure window.


In the second version, you're calling pyplot.show():


  Display a figure... In non-interactive mode, display all figures and block until the figures have been closed...


I stepped through the second method, and it's basically equivalent to this:

fig.show()
tkinter.mainloop()


So I'm not sure why it's freezing on you, but it probably wasn't what you wanted in the first place. Create the subplots if you want, but call plt.show() at the end.
",,,false,,,
https://stackoverflow.com/questions/16481224,false,The issue does not contain enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Strange Behavior of Python&#39;s Matplotlib Module - Plotting a Circle,,,,,false,,,
https://stackoverflow.com/questions/33648920,false,The issue does not meet the criteria for deeper analysis as it is related to the zorder behavior of matplotlib legends and does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,matplotlib.legend.set_zorder() doesn&#39;t work in ipython notebook,"here's a quick thing which is quite annoying me. I've followed the indications found in  strange matplotlib zorder behavior with legend and errorbar but it doesn't work. Here's a very brief working example

x = np.linspace(0,10) 
y = (x-5)**2 
plt.plot(x,y,label='test curve',zorder=100)
plt.legend(loc='center right').set_zorder(102)


If you try this you will see that the legend is still underneath the curve, despite the zordering. Does anyone know why?



I'm using matplotlib 1.3.1 on ipython 3.1.0
","Following on from @cel's comment, I agree you need to add an opaque background to the legend. Try adding:

leg=plt.legend(loc='center right')
leg.set_zorder(102)
leg.get_frame().set_facecolor('w')


Its also possible to set legend.facecolor in your matplotlibrc or via plt.rcParams



Alternatively make sure the fill of the legend frame is set to True:

print leg.get_frame().get_fill()


If that prints False, try

leg.get_frame().set_fill(True)

",,,false,,,
https://stackoverflow.com/questions/38107493,false,The issue does not meet the criteria for deeper analysis as it is related to the memory order behavior when converting a numpy array to QImage and does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Memory order behavior issue when converting numpy array to QImage,"I have a simple viewer in PyQt4, and I'm having some strange behavior when converting from a numpy array (8-bit grayscale) to a QImage to display.  It seems to me like something is going haywire when I try to construct a QImage from a transposed array, even though the memory order should have been updated (i.e. it's not just a view with different strides).

Below is a heavily cut-down version of the viewer:

import numpy as np
from PyQt4 import QtGui

class SimpleViewer(QtGui.QMainWindow):

    def __init__(self, data, parent=None):
        super(SimpleViewer, self).__init__(parent=parent)

        hgt, wid = data.shape

        dmin = data.min()
        dmax = data.max()
        bdata = ((data - dmin)/(dmax - dmin)*255).astype(np.uint8)

        img = QtGui.QImage(bdata, wid, hgt, QtGui.QImage.Format_Indexed8)

        self.scene = QtGui.QGraphicsScene(0, 0, wid, hgt)
        self.px = self.scene.addPixmap(QtGui.QPixmap.fromImage(img))

        self.view = QtGui.QGraphicsView(self.scene)
        self.setCentralWidget(self.view)


if __name__ == ""__main__"":

    app = QtGui.QApplication.instance()
    if app is None:
        app = QtGui.QApplication(['python'])

    xx, yy = np.meshgrid(np.arange(-100,100), np.arange(350))
    zz = xx * np.cos(yy/350.*6*np.pi)

    viewer = SimpleViewer(zz)
    viewer.show()
    app.exec_()


Now, as-is this produces something like this, which is fine:



However, I need to view my real images with the first dimension as ""x"" and the second dimension as ""y"" so it needs to be transposed (plus a y-flip so the origin is lower-left, but that's outside the scope here).

If I change hgt, wid = data.shape to wid, hgt = data.shape and do nothing else (which is wrong), I get the following.  It makes sense, because the QImage is just reading the memory.



However, if I also pass in bdata.T.copy() instead of bdata, I'm expecting that the array will be transposed and the memory re-ordered by the copy operation.  But what I get is this:



It's so close but off by just a hair for some reason.  Also, I noticed that if the dimensions just happen to be integer multiples of each other (e.g. 200x100), then it comes out okay.  What is going on?  Have I just missed something really really stupid?

I can't tell if this is a PyQt issue or a numpy issue ... the transposed array plots fine with matplotlib, but matplotlib handles the striding so that may not mean anything.

I get the same behavior in Python 2.7 and Python 3.5.  The PyQt4 version is 4.11.4, using Qt version 4.8.7.  Numpy version is 1.10.1.
","The issue stems from the creation of the QImage.

img = QtGui.QImage(bdata, wid, hgt, QtGui.QImage.Format_Indexed8)


The documentation for the signature of the constructor you are using says


  ... data must be 32-bit aligned, and each scanline of data in the image must also be 32-bit aligned.


If you change the dimensions of your array so that it is 32-bit aligned (for example using xx, yy = np.meshgrid(np.arange(-128,128), np.arange(384))) then your code works correctly.

To correct this issue without needing a multiple of 32 bytes per line, you want to use a slightly different constructor for the QImage:

QImage(data, width, height, bytesPerLine, format)


In your case, this is simply:

img = QtGui.QImage(bdata, wid, hgt, wid, QtGui.QImage.Format_Indexed8)


since each pixel contains 1 byte of information.
",,,false,,,
https://stackoverflow.com/questions/53758472,false,The issue does not meet the criteria for deeper analysis as it is related to the usage of plt.pause() in matplotlib and does not involve an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Why is plt.pause not described in any tutorials if it is so essential? (Or am I doing this wrong?),"I am writing a python script with interspersed plots and computations.
I am confused about the behavior of matplotlib and in particular the necessity of plt.pause. Consider the following snippets:

import matplotlib.pyplot as plt
import time
fig,ax=plt.subplots()
ax.plot([1,2])
fig.show()
time.sleep(5) #This is a substitute for real computations


-&gt; Nothing happens for five seconds

import matplotlib.pyplot as plt
import time
fig,ax=plt.subplots()
ax.plot([1,2])
plt.pause(0.1)
fig.show()
time.sleep(5) #This is a substitute for real computations


-&gt; Window displays the desired plot for five seconds

It seems that plt.pause is required to see anything. Why then does the documentation say ""This function is experimental; its behavior may be changed or extended in a future release."" and why did I not see plt.pause in any tutorials?

Also, why would such an essential function be designed so strangely that the user has to input a small enough time, yet not zero? I get that some people actually want to pause exeuction, but I don't, I just want to see the plots. Is this so unusual? 



By the way, I noticed that I can also do plt.show(), which, for reasons unknown to me, behaves different than plt.gcf().show()[=fig.show] and blocks the execution until the user closes the window. While this does show the plot when I want it, I do not want the execution to be stopped and I want the user to keep seeing the plot during the subsequent computations. Using plt.show(block=False) DOES seem to behave like plt.gcf().show()[=fig.show()], so it is also useless. 

Furthermore, I read somewhere that plt.ion should help, but it doesn't. Adding plt.ion() before fig,ax=plt.subplots() in the snippets above doesn't change anything.

Finally, I heard that different backends might behave differently. I am using python 3.6 (anaconda) on Ubuntu 18 with matplotlib 2.2.2. If I add import matplotlib; matplotlib.use('Qt5Agg') at the beginning of the snippets, not much changes, but instead of showing nothing for five seconds the first snippets shows a garbage window for five seconds (the window shows whatever was shown on the screen at the location where it popped up).
","From the documentation of plt.pause()  


  Pause for interval seconds.
  If there is an active figure, it will be updated and displayed before the pause, and the GUI event loop (if any) will run during the pause.
  This can be used for crude animation. For more complex animation, see matplotlib.animation.


Hence the pause will actually draw the figure.

The key why plt.pause is ""required"" is that it starts the mock-up event-loop such that it has time to run at least once and produce the figure in completeness.  After that your code can continue. While the code is running, no further events are processed. Therefore the figure may appear unresponsive. This means you should call pause repeatedly afterwards to not let the window freeze. In this way you emulate an event-loop while still being able to run other code in between.

plt.pause() is mentionned in this example, which does what is described above.

fig.show() does not run the event-loop. So without a running event loop, and without pause it will only show the figure window; but if you don't give any time for any events to be processed, it will freeze instantly. Here you may experience differences between operating systems and backends. Maybe you only see the window border and nothing painted in between, or you may see the toolbars and a white surface. 

In general, the key of all of this is to understand that python (like other programming languages) processes code linearly. The desire to have an event loop running, meaning a responsive GUI window, and some other code being executed in parallel contradicts this principle. The usual way to circumvent this is to run any other code in a different thread. However, matplotlib cannot know what code that is and how to synchronize it to the main thread. Hence such solution would require the user to implement it. 
",,,false,,,
https://stackoverflow.com/questions/56299971,true,"The issue involves the behavior of the basemap library when setting the central longitude of the plotted map. This unexpected behavior occurs under specific conditions, such as setting lon_0 to a positive number.",basemap,Basemap,"When using basemap and setting lon_0 to a positive number, the map gets flipped, switching the east and west directions. This behavior is unexpected, as lon_0 should only set the central longitude of the plotted map.",The Basemap API is used to create maps with specified projections and other parameters.,The issue is triggered when setting lon_0 to a positive number.,This issue might be challenging to detect for users who are not familiar with the specific behavior of the basemap library or those who assume that setting lon_0 to a positive number would not cause the map to flip.,"When I use basemap in python, longitude is sometimes reversed, flipping the map","In python, I use basemap (https://matplotlib.org/basemap/) for plotting spatial data, and I've used it for several years without any large problems.  I recently had to reinstall python3 (through conda, along with a number of modules) and basemap now has a strange issue: under certain conditions, the map will be displayed with flipped longitudes, switching east and west.  As an example, I use this code: https://matplotlib.org/basemap/users/robin.html.  If I use that code as-is, the map displays fine, but when I set lon_0=180, the map gets flipped, as shown in the image below.

Image of map problem

Setting lon_0 to any positive number results in a flipped map, while 0 or negative numbers result in a correct map.  lon_0 should simply set the central longitude of the plotted map, and should not have this behavior, so I'm unsure what's going on.  Has anyone seen this behavior before, or have suggestions for how to fix it?  I could alter my code to work around it, but I'd rather have things work properly.

I am using python3.7.3.  I've tried updating basemap with the command ""conda install -c anaconda basemap"", but it tells me that basemap is up to date already.

Here is the code.  It is identical to the code linked above, but with lon_0 set to 180.

from mpl_toolkits.basemap import Basemap
import numpy as np
import matplotlib.pyplot as plt
# lon_0 is central longitude of projection.
# resolution = 'c' means use crude resolution coastlines.
m = Basemap(projection='robin',lon_0=180,resolution='c')
m.drawcoastlines()
m.fillcontinents(color='coral',lake_color='aqua')
# draw parallels and meridians.
m.drawparallels(np.arange(-90.,120.,30.))
m.drawmeridians(np.arange(0.,360.,60.))
m.drawmapboundary(fill_color='aqua')
plt.title(""Robinson Projection"")
plt.show()


When I run the code, the only output is this, which seems unrelated:

map_test.py:36: MatplotlibDeprecationWarning:
The dedent function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use inspect.cleandoc instead.
  m = Basemap(projection='robin',lon_0=180,resolution='c')

Any ideas?
","This should solve the problem. Just add this after creating the axes:

# Matplotlib &gt;= 3.1.0 (introduced ""set_inverted"")
ax.xaxis.set_inverted(False)

# Matplotlib &lt; 3.1.0 (this is just the source code for ""set_inverted"")
interval = ax.xaxis.get_view_interval()
ax.set_xlim(sorted(interval), auto=None)


After some trial and error it also seems that selecting a negative central longitude instead of positive longitude works:

m = Basemap('robin', lon_0=-180)

",,,false,,,
https://stackoverflow.com/questions/22591174/pandas-multiple-conditions-while-indexing-data-frame-unexpected-behavior,false,The behavior is due to a misunderstanding of logical operators and conditions in pandas rather than a problem with the API itself.,,,,,,,,,,,,false,,,
https://stackoverflow.com/questions/65693394,true,The issue involves the behavior of the twinx function in matplotlib when used after calling set_position. The twinx plot is generated using the old positions of the host plot instead of the new positions.,matplotlib,twinx,"When calling twinx after setting the position of the host plot, the twinx plot is generated using the old positions of the host plot instead of the new positions. This behavior is unexpected, as the twinx plot should be generated on the new positions of the host plot.",The twinx function is used to create a twin Axes sharing the x-axis with the host plot.,The issue is triggered when calling twinx after setting the position of the host plot.,This issue might be challenging to detect for users who are not familiar with the specific behavior of the twinx function or those who assume that it would work correctly regardless of the position of the host plot.,Why am I getting the ImportError ../lib/libgobject-2.0.so.0: undefined symbol: g_uri_ref based on order of import?,"On one of my experiments, I found this strange behavior.
If I do
import matplotlib.pyplot as plt
import cv2
Then I get ImportError

ImportError: /home/deep/anaconda3/bin/../lib/libgobject-2.0.so.0: undefined symbol: g_uri_ref


But, If I change the order of imports as
import cv2
import matplotlib.pyplot as plt
Everything runs fine. Matplotlib version is 3.2.2 and cv2 version is 4.3.0
I tried to see if I could find some similar problem or explanation, but have not yet found an answer. I'm not sure why this problem occurs and how to fix it.
","You can try install the mentioned package, libgobject-2.0.so.0 from here:   https://pkgs.org/search/?q=libgobject-2.0.so.0
For Ubuntu:
Step 1: Update the package index:
sudo apt-get update

Step 2: Install libglib2.0-0 deb package:
sudo apt-get install libglib2.0-0

","set up a virtual enviroment (best with anaconda) to be save and try:
pip3 install opencv-python==4.5.1.48

and
pip3 install pyqt5

So far it works, but I get other errors. owever, this could be due to my own script. I will update if I have more info.
Good luck
",,false,,,
https://stackoverflow.com/questions/66737752,false,"The issue is related to the usage of matplotlib's imsave and imread functions, where the RGB values change due to the conversion process and the interpretation of float values.",,,,,,,Python: How to save EXACT numpy array data to image using matplotlib.image.imsave(),"I observed some strange behavior when saving and loading data using matplotlibs imsave() and imread() functions. The RGB values I save are different to the ones I get when loading the picture back in again.
import numpy as np
from matplotlib import image

s_pic = np.zeros((1, 1, 3))

s_pic[0,0,0] = 0.123
s_pic[0,0,1] = 0.456
s_pic[0,0,2] = 0.789

image.imsave('pic.png', s_pic)

l_pic = image.imread('pic.png')

print(l_pic[0,0,0])
print(l_pic[0,0,1])
print(l_pic[0,0,2])

The output I get is:
0.12156863
0.45490196
0.7882353

Can somebody explain why the RGB values change in this process? I have checked the matplotlib documentation but couldn't find an answer to this question.
","
Can somebody explain why the RGB values change in this process?

RGB values are integers in the range 0-255. Your float is interpreted as:
&gt;&gt;&gt; .123 * 255
31.365
&gt;&gt;&gt; int(.123 * 255)
31

Thirty-one is being written to that pixel. Then the reverse..
&gt;&gt;&gt;
&gt;&gt;&gt; 31 / 255
0.12156862745098039
&gt;&gt;&gt;


Delving into the source for imsave() the array passed to imsave() is converted to RGBA values using matplotlib.cm.ScalarMappable().to_rgba(bytes=True)
&gt;&gt;&gt; from matplotlib import cm
&gt;&gt;&gt; sm = cm.ScalarMappable()
&gt;&gt;&gt; rgba = sm.to_rgba(s_pic, bytes=True)
&gt;&gt;&gt; rgba
array([[[ 31, 116, 201, 255]]], dtype=uint8)
&gt;&gt;&gt;

",,,false,,,
https://stackoverflow.com/questions/64966611,false,The issue is not related to any API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Why does pandas dataframe return 2 columns when only 1 is selected,"While creating some plots with matplotlib I found a strange behavior of pandas, when I select only 1 column it returns 2.
import pandas as pd
import io

data = io.StringIO(""""""time_0,1,time_1,2,time_2,0,time_3,3
-0.002,-0.1225,-0.002,-0.0904,-0.002,0.0331,-0.002,0.,
0.0,-0.1225,0.,-0.0904,0.,0.0331,0.,0.,
0.002,-0.1224,0.002,-0.0904,0.002,0.0331,0.002,0.,
0.004,-0.1225,0.004,-0.0904,0.004,0.0331,0.004,0.,"""""")

df = pd.read_csv(data)
print(df[""time_0""])

Output:

-0.002   -0.1225
0.000   -0.1225
0.002   -0.1224
0.004   -0.1225
Name: time_0, dtype: float64

It shows values from both column ""time_0"" and ""1"", but only ""time_0"" was selected. Is this a bug or a feature?
","your dataframe returns only one line, but it also prionting the index which is same as the column ""1""
df
Out[3]: 
        time_0      1  time_1      2  time_2      0  time_3   3
-0.002 -0.1225 -0.002 -0.0904 -0.002  0.0331 -0.002     0.0 NaN
 0.000 -0.1225  0.000 -0.0904  0.000  0.0331  0.000     0.0 NaN
 0.002 -0.1224  0.002 -0.0904  0.002  0.0331  0.002     0.0 NaN
 0.004 -0.1225  0.004 -0.0904  0.004  0.0331  0.004     0.0 NaN

it seems like it takes unintentionally the first column as index...
it  takes the last column as a nan value because of the extra , in each line....
try removing the ,:
 import pandas as pd
 import io
 
 data = io.StringIO(""""""time_0,1,time_1,2,time_2,0,time_3,3
 -0.002,-0.1225,-0.002,-0.0904,-0.002,0.0331,-0.002,0.
 0.0,-0.1225,0.,-0.0904,0.,0.0331,0.,0.
 0.002,-0.1224,0.002,-0.0904,0.002,0.0331,0.002,0.
 0.004,-0.1225,0.004,-0.0904,0.004,0.0331,0.004,0."""""")
 
 df = pd.read_csv(data)
 print(df[""time_0""])

this code will print
0   -0.002
1    0.000
2    0.002
3    0.004
Name: time_0, dtype: float64

",,,false,,,
https://stackoverflow.com/questions/23897118,false,The issue does not provide enough information to determine if it involves any API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,pylab.plot &quot;cannot convert float NaN to integer&quot; after calling scipy.stats.multivariate_normal,"While testing a regression algorithm I found this strange behavior: for some covariance matrices, the multivariate_normal function gives correct samples but then an exception is raised (only) the first time pylab.plot() is called:

ValueError: cannot convert float NaN to integer

The following code reproduces the error:
import numpy as np
from scipy.stats import multivariate_normal as mnorm
from matplotlib import pyplot as plt

B = np.array([ 0, 0, 0])

# works fine
v1 = np.array([[1, 0, 0],
              [0, 1, 0],
              [0, 0, 1]])


# OK. non positive semidefinite, well raised exception
v2 = np.array([[ 0.2 , -0.2, -0.3],
              [-0.2,  0.4, -0.9],
              [-0.3, -0.9,  0.7]])

# KO. exception (?)
v3 = np.array([[ 0.2 , -0.02, -0.026],
              [-0.02,  0.014, -0.009],
              [-0.026, -0.009,  0.017]])



w = mnorm(mean=B, cov=v3).rvs()
print w

plt.plot(w)
plt.show()

And if plt.plot(w) is called a second time, then it works. Any ideas?
Versions:

python 2.7.5 Anaconda 1.9.1 (64-bit)
scipy 0.14.0
matplotlib 1.3.1
numpy 1.8.1

",,,,false,,,
https://stackoverflow.com/questions/17189313,false,The issue does not provide enough information to determine if it involves any API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,strange behavior of numpy.asmatrix or matplotlib.pyplot.scatter,,,,,false,,,
https://stackoverflow.com/questions/45536365,false,The issue is not related to any API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Error when using mathtext.fontset = &#39;custom&#39; in stylelib,"I encounter a strange behavior using matplotlib when I try define a custom math font (with usetex=false):

mpl.__version__ = '2.0.2' with python 2.7

I define a stylesheet (i.e. *.mplstyle file in stylelib folder) in which I write

mathtext.fontset = 'custom'
mathtext.rm = 'Avenir Next'
mathtext.it = 'Avenir Next:italic'
mathtext.bf = 'Avenir Next:bold'
mathtext.fallback_to_cm : True


If I try to make a plot with that style I get the error:

Bad key ""mathtext.rm = 'Avenir Next"" on line 49 in
/Users/gp/.matplotlib/stylelib/simple.mplstyle.
You probably need to get an updated matplotlibrc file from
http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template
or from the matplotlib source distribution
 UserWarning: In /Users/gp/.matplotlib/stylelib/simple.mplstyle: Illegal line #48
""mathtext.fontset = 'custom'
""
in file ""/Users/gp/.matplotlib/stylelib/simple.mplstyle""


And also similar errors about mathtext.it and mathtext.bf.

If I instead comment these lines out and just write into the py document that I use to generate the plot (after loading the style with the now commented lines about mathtext) the following lines than everything works flawless (w/o error and with the expected behavior).

mpl.rcParams['mathtext.fontset'] = 'custom'
mpl.rcParams['mathtext.rm'] = 'Avenir Next'
mpl.rcParams['mathtext.it'] = 'Avenir Next:italic'
mpl.rcParams['mathtext.bf'] = 'Avenir Next:bold'


I am puzzled because the lines of my stylesheet are as described in the matplotlib documentary. Can somebody make anything of it?

Georg

edit: typos
","After sitting over it for some days I posted the question just to realize directly afterwards that the syntax in the style file is wrong at several places.
The single quotation marks don't belong there. Also the =must be replaced by colons :.

Then it works!
",,,false,,,
https://stackoverflow.com/questions/65415390,false,The issue does not provide enough information to determine if it involves any API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Geopandas consistent user defined color scheme for subplots,"I am new to geopandas and I am having trouble creating choropleth subplots with consistent bins. I need to create a consistent user defined color scheme across all subplots.
I have followed the examples below:
matplotlib geopandas plot chloropleth with set bins for colorscheme
https://github.com/geopandas/geopandas/issues/1019
While I am able to reproduce both examples, I get very strange behavior with my own data. Below is a toy example that replicates my problem.
import geopandas as gpd
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from mapclassify import Quantiles, UserDefined
import os

# Note you can read directly from the URL
gdf = gpd.read_file('https://opendata.arcgis.com/datasets/8d3a9e6e7bd445e2bdcc26cdf007eac7_4.geojson')
#gdf.plot()
gdf.shape
gdf.columns
gdf['rgn15nm'].head(9)


d = {
'rgn15nm': ['North East', 'North West', 'Yorkshire and The Humber', 'East Midlands', 'West Midlands', 'East of England', 'London', 'South East', 'South West'],
'1980' : pd.Series([0, 1, 0, 0, 0, 0, 0, 0, 0]),
'2000' : pd.Series([1, 1, 1, 0, 0, 0, 0, 0, 0]),
'2020' : pd.Series([1, 1, 10, 3, 1, 0, 0, 0, 1])
}

df = pd.DataFrame(d) 

The data looks like this:

gdf = gdf.merge(df, on='rgn15nm')


# Define bins
gdf['2020'].describe()
bins= UserDefined(gdf['2020'], bins=[0,1,2,3,4,5,6,7,8,9,10]).bins
bins

# create a new column with the discretized values and plot that col
# repeat for each view
fig,(ax1,ax2,ax3) = plt.subplots(1,3,figsize=(15,6))
gdf.assign(cl=UserDefined(gdf['1980'].dropna(), bins).yb).plot(column='cl', ax=ax1, cmap='OrRd', legend = True )
gdf.assign(cl=UserDefined(gdf['2000'].dropna(), bins).yb).plot(column='cl', ax=ax2, cmap='OrRd', legend = True) 
gdf.assign(cl=UserDefined(gdf['2020'].dropna(), list(bins)).yb).plot(column='cl', ax=ax3, cmap='OrRd', legend = True)
for ax in (ax1,ax2,ax3,):
    ax.axis('off')


Clearly, the color scheme is not the same across subplots. What I mean by this is that 'Northwest' (the only region highlighted in the 1980 subplot) had the same value of 1 in all years 1980, 2000 and 2020. Yet, this region shows in different colors across the 3 subplots, despite the value being constant. I want ""Northwest"" to show in the same color (that of the subplot for 2020) across all 3 subplots.
I also tried this:
fig,(ax1,ax2,ax3) = plt.subplots(1,3,figsize=(15,6))
ax1.set_title('1980')
ax2.set_title('2000')
ax3.set_title('2020')
gdf.plot(column='1980', ax=ax1, cmap='OrRd', scheme='userdefined', classification_kwds={'bins':[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]})
gdf.plot(column='2000', ax=ax2, cmap='OrRd', scheme='userdefined', classification_kwds={'bins':[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]})
gdf.plot(column='2020', ax=ax3, cmap='OrRd', scheme='userdefined', classification_kwds={'bins':[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]})
for ax in (ax1,ax2,ax3):
    ax.axis('off')

But got exactly the same figure as immediately above (see below)

Does any one have any insight? I want a consistent color scheme across all 3 subplots.
","So ultimately the solution was using the ""norm"" option. Following this example: Geopandas userdefined color scheme drops colors. See below:
from matplotlib.colors import Normalize
bins= UserDefined(gdf['2020'], bins=[0,1,2,3,4,5,6,7,8,9,10]).bins
bins

fig,(ax1,ax2,ax3) = plt.subplots(1,3,figsize=(15,6))
ax1.set_title('1980')
ax2.set_title('2000')
ax3.set_title('2020')
gdf.plot(column='1980', ax=ax1, cmap='OrRd', scheme='userdefined', classification_kwds={'bins':bins}, norm=Normalize(0, len(bins)))
gdf.plot(column='2000', ax=ax2, cmap='OrRd', scheme='userdefined', classification_kwds={'bins':bins}, norm=Normalize(0, len(bins)))
gdf.plot(column='2020', ax=ax3, cmap='OrRd', scheme='userdefined', classification_kwds={'bins':bins}, norm=Normalize(0, len(bins)))
for ax in (ax1,ax2,ax3):
    ax.axis('off')

The result is what I wanted:
Expected Graph
or as suggested by Paul H:
fig,(ax1,ax2,ax3) = plt.subplots(1,3,figsize=(15,6))
ax1.set_title('1980')
ax2.set_title('2000')
ax3.set_title('2020')
gdf.plot(column='1980', ax=ax1, cmap='OrRd', scheme='userdefined', classification_kwds={'bins':bins}, vmin = 0, vmax = 10)
gdf.plot(column='2000', ax=ax2, cmap='OrRd', scheme='userdefined', classification_kwds={'bins':bins}, vmin = 0, vmax = 10)
gdf.plot(column='2020', ax=ax3, cmap='OrRd', scheme='userdefined', classification_kwds={'bins':bins}, vmin = 0, vmax = 10)
for ax in (ax1,ax2,ax3):
    ax.axis('off')

",,,false,,,
https://stackoverflow.com/questions/66737752,false,The issue is not related to any API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Python: How to save EXACT numpy array data to image using matplotlib.image.imsave(),"I observed some strange behavior when saving and loading data using matplotlibs imsave() and imread() functions. The RGB values I save are different to the ones I get when loading the picture back in again.
import numpy as np
from matplotlib import image

s_pic = np.zeros((1, 1, 3))

s_pic[0,0,0] = 0.123
s_pic[0,0,1] = 0.456
s_pic[0,0,2] = 0.789

image.imsave('pic.png', s_pic)

l_pic = image.imread('pic.png')

print(l_pic[0,0,0])
print(l_pic[0,0,1])
print(l_pic[0,0,2])

The output I get is:
0.12156863
0.45490196
0.7882353

Can somebody explain why the RGB values change in this process? I have checked the matplotlib documentation but couldn't find an answer to this question.
","
Can somebody explain why the RGB values change in this process?

RGB values are integers in the range 0-255. Your float is interpreted as:
&gt;&gt;&gt; .123 * 255
31.365
&gt;&gt;&gt; int(.123 * 255)
31

Thirty-one is being written to that pixel. Then the reverse..
&gt;&gt;&gt;
&gt;&gt;&gt; 31 / 255
0.12156862745098039
&gt;&gt;&gt;


Delving into the source for imsave() the array passed to imsave() is converted to RGBA values using matplotlib.cm.ScalarMappable().to_rgba(bytes=True)
&gt;&gt;&gt; from matplotlib import cm
&gt;&gt;&gt; sm = cm.ScalarMappable()
&gt;&gt;&gt; rgba = sm.to_rgba(s_pic, bytes=True)
&gt;&gt;&gt; rgba
array([[[ 31, 116, 201, 255]]], dtype=uint8)
&gt;&gt;&gt;

",,,false,,,
https://stackoverflow.com/questions/23897118,false,The issue does not provide enough information to determine if it involves any API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,pylab.plot &quot;cannot convert float NaN to integer&quot; after calling scipy.stats.multivariate_normal,"While testing a regression algorithm I found this strange behavior: for some covariance matrices, the multivariate_normal function gives correct samples but then an exception is raised (only) the first time pylab.plot() is called:

ValueError: cannot convert float NaN to integer

The following code reproduces the error:
import numpy as np
from scipy.stats import multivariate_normal as mnorm
from matplotlib import pyplot as plt

B = np.array([ 0, 0, 0])

# works fine
v1 = np.array([[1, 0, 0],
              [0, 1, 0],
              [0, 0, 1]])


# OK. non positive semidefinite, well raised exception
v2 = np.array([[ 0.2 , -0.2, -0.3],
              [-0.2,  0.4, -0.9],
              [-0.3, -0.9,  0.7]])

# KO. exception (?)
v3 = np.array([[ 0.2 , -0.02, -0.026],
              [-0.02,  0.014, -0.009],
              [-0.026, -0.009,  0.017]])



w = mnorm(mean=B, cov=v3).rvs()
print w

plt.plot(w)
plt.show()

And if plt.plot(w) is called a second time, then it works. Any ideas?
Versions:

python 2.7.5 Anaconda 1.9.1 (64-bit)
scipy 0.14.0
matplotlib 1.3.1
numpy 1.8.1

",,,,false,,,
https://stackoverflow.com/questions/28048647,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Python : strange behavior with matplotlib barchart,"I have a strange behavior using matplotlib in an ipython notebook: when I change the attribute ""color"" of the barchart, the result is ugly, I have some bars in red and some others in black. This is happening only when I have a high amount of bars to display (&gt;100).

You can execute the code below to reproduce the problem, playing with the dataPoints parameter to see the effect of the number of bars:

import random
import matplotlib.pyplot as plt

dataPoints = 400
data = random.sample(range(300, 1000), dataPoints)
xCoords = range(dataPoints)

fig = plt.figure(figsize=[13,9])
plt.bar(xCoords,data,color='red')
plt.show()


Here is an example of the result :


",,,,false,,,
https://stackoverflow.com/questions/41837171,false,"The issue does not meet the criteria for deeper analysis as it stems from a misunderstanding of logical operators and conditions in pandas, rather than an API-related problem.",,,,,,,Matplotlib 2.0 subscript outside of baseline when super and subscript are both used,"With matplotlib 2.0 I have been having strange behavior when I use both subscript and superscript on the same character. When they are combined, the subscript goes down entirely below the baseline. This didn't happen with MPL 1.5. Here is a complete example:

import matplotlib as mpl
import matplotlib.pyplot as plt
mpl.rc(""font"", family=""Times New Roman"",weight='normal')
plt.rcParams.update({'mathtext.default':  'regular' })
plt.plot(1,1, label='$A_x^{b}$')
plt.plot(2,2,label='$A_x$')
plt.plot(3,3,label='$A^b$')
plt.plot(4,4,label='$A_x^{*}$')
plt.plot(5,5,label='$A^*$')
plt.legend(fontsize='xx-large')
plt.show()


I've taken this plot and zoomed in on the legend and drawn some horizontal lines to show the relative super and subscript positions.



I found in the mathtext.py file these parameters under the class FontConstantBase:

# Percentage of x-height of additional horiz. space after sub/superscripts
script_space = 0.05

# Percentage of x-height that sub/superscripts drop below the baseline
subdrop = 0.4

# Percentage of x-height that superscripts are raised from the baseline
sup1 = 0.7

# Percentage of x-height that subscripts drop below the baseline
sub1 = 0.3

# Percentage of x-height that subscripts drop below the baseline when a
# superscript is present
sub2 = 0.5

# Percentage of x-height that sub/supercripts are offset relative to the
# nucleus edge for non-slanted nuclei
delta = 0.025

# Additional percentage of last character height above 2/3 of the
# x-height that supercripts are offset relative to the subscript
# for slanted nuclei
delta_slanted = 0.2

# Percentage of x-height that supercripts and subscripts are offset for
# integrals
delta_integral = 0.1


Did sub2 exist in previous versions? Could going from 0.3 to 0.5 really drop it completely below the baseline like I'm seeing? I'd like to have simultaneous superscripts and subscripts that aren't completely outside the baseline and I don't see any other way besides modifying mathtext.py itself. Also, it appears that when including an asterisk in the superscript, it also goes higher than anticipated with mpl 2.0. Is there a way to lower it down just a bit without changing mathtext? Thanks. 
","There seems to be no API to change this but you can monkey-patch the appropriate class instead of editing mathtext.py.
Using the default mathtext font the position of the subscript changes if there is a superscript (not totally under the baseline but you can see the effect):
def test_plot():
    plt.figure()
    plt.plot(1, 1, label=""$A_x^b$"")
    plt.plot(2, 2, label=""$A^b_x$"")
    plt.plot(3, 3, label=""$A_x$"")
    plt.plot(4, 4, label=""$A_x^*$"")
    plt.plot(4, 4, label=""$A^*_x$"")
    plt.plot(5, 5, label=""$A^*$"")
    plt.legend(fontsize=""xx-large"")


# default mathtext font in matplotlib 2.0.0 is 'dejavusans'
# set explicitly for reproducibility
plt.rcParams[""mathtext.fontset""] = ""dejavusans""
test_plot()


Monkey-patching mathtext.DejaVuSansFontConstants you can make the effect disappear:
import matplotlib.mathtext as mathtext
mathtext.DejaVuSansFontConstants.sub2 = 0.3  # default 0.5
test_plot()


(For more recent versions of matplotlib, like 3.4.2, this class appears to have been moved to a _mathtext submodule. You may need to do something like the following:)
# Later versions of matplotlib (e.g., 3.4.2)
from matplotlib.mathtext import _mathtext as mathtext

mathtext.FontConstantsBase.sup1 = 0.5

I can't see any issue with the asterisk.
I don't have Times New Roman installed so I can't test your exact use case but probably you need to patch FontConstantsBase instead of DejaVuSansFontConstants. It worked for me using Liberation Serif.
",,,false,,,
https://stackoverflow.com/questions/43792081,false,The issue does not meet the criteria for deeper analysis as it is related to the behavior of the tkinter mainloop and does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,"Destroying tkinter mainloop (with canvas and buttons), strange behaviour","I have root=Tk.Tk() which consist from labels (Tk.Label), entry forms (Tk.Entry), button (Tk.Button) and embedded matplotlib FigureCanvasTkAgg. This is simple script, which plots quadtratic functions with coefficients (a, b, c) specified by user. But I have some problems and misunderstanding with destroying the mainloop. 
I was expecting, that simple closing of the main window (by clicking ""x"" at the right corner), should also lead to the exit from mainloop. This is the case for my script, if I would comment all the code, related to the embeded canvas. But with embedded FigureCanvasTkAgg, it doesn't happen (so there is a need for interrupting kernel for running script again). As was discussed in other questions, there are 2 methods for exiting mainloop: root.quit() and root.destroy(). So I also tried to use these methods for exiting mainloop:

def close_all():
    root.quit()
    root.destroy()


by new button :

button_quit=Tk.Button(root, text=""Quit"", command=close_all)
button_quit.grid(row=5, column=1)


by overwriting ""x"" button :

root.protocol('WM_DELETE_WINDOW', close_all)


My questions:


Using both methods worked. But why if I use only root.destroy(), root.mainloop() would still execute? Why mainloop is not being destroyed just after closing window? And why this problem causes FigureCanvasTkAgg?
Embedding matplotlib figure was done by the following (if it helps to explain):

fig, ax = plt.subplots()
canvas = FigureCanvasTkAgg(fig, master=root)
plot_widget = canvas.get_tk_widget()
#(plotting with plt.plot(..))
canvas.show()
plot_widget.grid(row=6, column = 0, columnspan=3)

close_all() function worked in that sense, that there was performed exit from mainloop, and script execution stopped. But there is still some strange behavior. There variables such as var_a = Tk.StringVar(), used for receiving data from entry fields in a way:

L_a = Tk.Label(master=root, width=10, height=2, bd =2, text=""a"")
E_a = Tk.Entry(master=root, width=10, bd =2, textvariable=var_a) 


with

def get_value():
    if not check_if_float(var_a.get()) or not check_if_float(var_b.get()) or not check_if_float(var_c.get()):
        showerror(title = ""Error"", message = ""Invalid entry. Enter integer or decimal numbers, please"")
        return None
    a=float(var_a.get())
    b=float(var_b.get())
    c=float(var_c.get())


So the problem and strange behavior is that after executing code once, and closing main window (either by clicking ""x"" at the right top corner, or by clicking ""Quit"" button), in the next execution code receives empty var_a, var_b, var_c. If kernel interrupted, and code runs again, it works correctly (running it in jupyter notebook). I have no idea why is it like that.

","This is because you did not provide the variables with a master, so they default to the first Tk() instance created, even if it's been destroyed. The fix is simply to provide the correct root:

var_a = Tk.StringVar(root)


This usually isn't an issue since there are very few situations where you would want to call Tk() more than once. 
",,,false,,,
https://stackoverflow.com/questions/59656632,true,"The issue involves a change in behavior between Matplotlib 3.1.0rc1 and 3.1.0rc2, which affects the usage of the matplotlib.use() function and the matplotlib.get_backend() function. This change in behavior is API-related and warrants further analysis.",,,,,,,"Using qt5agg backend with Matplotlib 3.1.2, get_backend() changes behavior","I have been using a project which embeds Matplotlib figures in a Qt window and found that it failed when I updated Matplotlib to a version greater than 3.1.0rc1. I have created a minimum working example (testImports.py):
import matplotlib

from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.backends.backend_qt5agg import NavigationToolbar2QT as NavigationToolbar

import matplotlib.pyplot as plt
import numpy as np

f = plt.figure()
x = np.arange(0, 10, 0.001)
ysin = np.sin(x)
plt.plot(x, ysin, '--')
plt.show()

With Matplotlib 3.1.0rc1 or earlier, this runs properly, displaying a graph. With Matplotlib 3.1.0rc2 or newer, I get the following error (note that I am working in a virtual environment and I have changed the root of the paths to test_env):
Traceback (most recent call last):
  File ""testImports.py"", line 14, in &lt;module&gt;
    f = plt.figure()
  File ""test_env/lib/python3.6/site-packages/matplotlib/pyplot.py"", line 534, in figure
    **kwargs)
  File ""test_env/lib/python3.6/site-packages/matplotlib/backend_bases.py"", line 3249, in new_figure_manager
    return cls.new_figure_manager_given_figure(num, fig)
  File ""test_env/lib/python3.6/site-packages/matplotlib/backend_bases.py"", line 3255, in new_figure_manager_given_figure
    canvas = cls.FigureCanvas(figure)
TypeError: 'NoneType' object is not callable

I have found that if I include the following lines at the top of testImports.py, it works properly for all versions of Matplotlib 3+.
import matplotlib
matplotlib.use('qt5agg')

So, it seems that something has changed in the way Matplotlib registers backends.
In my testing I also found that having the following at the top of testImports.py solves the problem (without also calling use('qt5agg'):
import matplotlib
print(matplotlib.get_backend())

That seems very strange to me, since the matplotlib.get_backend() function is simply returning a value from a dictionary (from the source):
def get_backend():
    """"""
    Return the name of the current backend.

    See Also
    --------
    matplotlib.use
    """"""
    return rcParams['backend']

This brings me to my questions:

What changed between Matplotlib 3.1.0rc1 and 3.1.0rc2 that has made it necessary to use the matplotlib.use() function prior to importing specific backend functions?
Why is calling matplotlib.get_backend() drastically changing the behavior of my program, making it unnecessary to call matplotlib.use()?

If it helps I am using Python 3.6.9 and Numpy 1.18.0.
Edit:
I installed Matplotlib 3.2.0rc2 and am still experiencing the same behavior.
","I don't know if what I'm about to describe is the intended behavior of matplotlib or a bug. Perhaps the maintainers can weight in.
In essence, matplotlib.get_backend() is NOT is simply returning a value from a dictionary. In fact, it is triggering a lazy initialization of the ""backend"" via importing pyplot under the hook, and I can imagine that creating some variations in behavior, since merely calling import matplotlib is not sufficient to trigger the initialization (at least in all cases).
When you import matplotlib or any of it's modules, matplotlib.__init__.py is implicitly run.
It appears that rcParams.__getitem__() is intended to do a lazy initialization of the ""backend"" if the key value is set to rcsetup._auto_backend_sentinel.
When an rcParam object is first constructed, there is no 'backend' key in the dict, even if the desired default value (could depend on matplotlibrc?) is rcsetup._auto_backend_sentinel.
These lines of the __setitem__() method can involve a situation where key == backend and val == rcsetup._auto_backend_sentinel, but backend is not yet a valid key in the rcParams(MutableMapping, dict) object. As a consequence, when the 3rd line if 'backend' in self:, which implicitly calls __getitem__ with a key of 'backend' to check for the presence of the key, gets processed, the lazy initialization of the backend doesn't occur, since the line of __getitem__ that I've marked ""THIS MAY THROW"" does in fact throw, and prevent the subsequent lazy initialization.
# Excerpt of rcParams(MutableMapping, dict).__setitem__ from around lines 672
elif key == 'backend':
    if val is rcsetup._auto_backend_sentinel:
        if 'backend' in self:
            return

# Excerpt of rcParams(MutableMapping, dict).__getitem__ from around lines 699
elif key == ""backend"":
    val = dict.__getitem__(self, key) # THIS MAY THROW
    if val is rcsetup._auto_backend_sentinel:
        from matplotlib import pyplot as plt
        plt.switch_backend(rcsetup._auto_backend_sentinel)

However, in __setitem__ the code does succeed in getting rcParams['backend'] set to rcsetup._auto_backend_sentinel (it is normal for x in X calls to ignore KeyErrors). So the rcParams is populated, but the lazy initialization is yet to be done.
Now when you call matplotlib.get_backend() (or other related functions), part of the code path will do rcParams['backend'], which this time will actually trigger the lazy initialization in __getitem__.
",,,false,,,
https://stackoverflow.com/questions/59810707,false,The issue does not meet the criteria for deeper analysis as it is related to the positioning of text in Matplotlib plots and does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,MatPlotLib text position strange behavior,"I have a function to display scatter plots:

def critics_and_users_score_corr_with_total_sales(_df, platform):
    critic_score_not_na = df['critic_score'].notna() &amp; (df['platform'] == platform)
    total_sales_for_critic_score = df[critic_score_not_na]['total_sales']
    critic_score = df[critic_score_not_na]['critic_score']

    user_score_not_na = df['user_score'].notna() &amp; (df['platform'] == platform)
    total_sales_for_user_score = df[user_score_not_na]['total_sales']
    user_score = df[user_score_not_na]['user_score']

    info_bbox_props = dict(boxstyle='round', facecolor='white', alpha=0.2)

    fig = plt.figure(figsize=(16, 7))
    ax1 = fig.add_subplot(121)
    ax2 = fig.add_subplot(122)

    ax1.grid(True)
    ax1.set_xlim(0,25)
    ax1.set_title('{} Critics score &amp; Total sales correlation'.format(platform))
    ax1.set_xlabel('Total sales')
    ax1.set_ylabel('Critics score')
    ax1.scatter(total_sales_for_critic_score, critic_score, s = 10)

    ax1.text(0.345, 0.88, 'Corelation: {:.2f}'.format(total_sales_for_critic_score.corr(critic_score)), 
             transform=ax.transAxes, verticalalignment='top', horizontalalignment='right', bbox=info_bbox_props)

    ax2.grid(True)
    ax2.set_xlim(0,25)
    ax2.set_title('{} Users score &amp; Total sales correlation'.format(platform))
    ax2.set_xlabel('Total sales')
    ax2.set_ylabel('Users score')
    ax2.scatter(total_sales_for_user_score, user_score, s = 10)
    ax2.text(0.892, 0.88, 'Corelation: {:.2f}'.format(total_sales_for_user_score.corr(user_score)), 
             transform=ax.transAxes, verticalalignment='top', horizontalalignment='right', bbox=info_bbox_props)

    plt.show()


I call this function further in code:

critics_and_users_score_corr_with_total_sales(df, top_platforms.index[0])


And here is the result:

As we can see, text fields are placed outside the plots.

But if I run this cell by Shift+Enter the second and subsequent time - text the fields are placed in other location:


If I restart the Kernel and run all cells, the text fields are placed outside the plot again.

What kind of magic is this?
","Problem was in following lines:

ax1.text(0.345, 0.88, 'Corelation: {:.2f}'.format(total_sales_for_critic_score.corr(critic_score)), 
         transform=ax.transAxes, verticalalignment='top', horizontalalignment='right', bbox=info_bbox_props)


My ax has a ax1 name, but I send to parameters transform=ax.transAxes. Obviously, ax was declared in other place.

My bad.
",,,false,,,
https://stackoverflow.com/questions/62011120,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Matplotlib histogram misplaced and missing bars,"I have large data files and thus am using numpy histogram (same as used in matplotlib) to manually generate histograms and update them.  However, at plotting, I feel that the graph is shifted.

This is the code I use to manually create and update histograms in batches.  Note that all histograms share the same bins.

temp = np.histogram(batch, bins=np.linspace(0, 40, 41))
hist += temp[0]


The code above is repeated as I parse the data files.  For example, a small data set would have the following as the final histogram data:

[8190, 666, 278, 145, 113, 83, 52, 48, 45, 44, 45, 29, 28, 45, 29, 15, 16, 10, 17, 7, 15, 6, 10, 7, 3, 5, 7, 4, 2, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 29]

Below is the plotting code.

import matplotlib
matplotlib.use('agg')
import matplotlib.pyplot as plt
import numpy as np
plt.xticks(np.linspace(0, 1, 11))
plt.hist([i/40 for i in range(40)], bins=np.linspace(0, 1, 41), weights=scores, rwidth=0.7)
plt.yscale('log', nonposy='clip')


The resulting figure is quite strange.  It shows no bar at [0.475, 0.5) and I expect the 0.975 bin which is range [0.975, 1.0] to include the last 29 values.  However instead, I see that bar at the [0.950, 0.975) position.  I thought this might have to do with using bins and linspace, but the size of the decoy array and weights are the same.  



I'm never seen this kind of behavior.  I also thought it would be the way the ranges are [ x, x+width), but I haven't had issues with this.

A note on using linspace.  It specifies edges, so 40 bins is specified by 41 edges.

In [2]: np.linspace(0,1,41)                                                     
Out[2]: 
array([0.   , 0.025, 0.05 , 0.075, 0.1  , 0.125, 0.15 , 0.175, 0.2  ,
       0.225, 0.25 , 0.275, 0.3  , 0.325, 0.35 , 0.375, 0.4  , 0.425,
       0.45 , 0.475, 0.5  , 0.525, 0.55 , 0.575, 0.6  , 0.625, 0.65 ,
       0.675, 0.7  , 0.725, 0.75 , 0.775, 0.8  , 0.825, 0.85 , 0.875,
       0.9  , 0.925, 0.95 , 0.975, 1.   ])

In [3]: len(np.linspace(0,1,41))                                                
Out[3]: 41

","It seems you're using plt.hist with the idea to put one value into each bin, so simulating a bar plot. As the x-values fall exactly on the bin bounds, due to rounding they might end up in the neighbor bin. That could be mitigated by moving the x-values half a bin width. The simplest is drawing the bars directly.

The following code creates a bar plot with the given data, with each bar at the center of the region it represents. As a check, the bars are measured again at the end and their height displayed.

from  matplotlib.ticker import MultipleLocator
import matplotlib.pyplot as plt
import numpy as np

scores =[8190,666,278,145,113,83,52,48,45,44,45,29,28,45,29,15,16,10,17,7,15,6,10,7,3,5,7,4,2,3,0,1,0,0,0,0,0,0,0,29]
binbounds = np.linspace(0, 1, 41)
rwidth = 0.7
width = binbounds[1] - binbounds[0]
bars = plt.bar(binbounds[:-1] + width / 2, height=scores, width=width * rwidth, align='center')
plt.gca().xaxis.set_major_locator(MultipleLocator(0.1))
plt.gca().xaxis.set_minor_locator(MultipleLocator(0.05))
plt.yscale('log', nonposy='clip')
for rect in bars:
    x, y = rect.get_xy()
    w = rect.get_width()
    h = rect.get_height()
    plt.text(x + w / 2, h, f'{h}\n', ha='center', va='center')
plt.show()




PS: To see what's happening with the original histogram, just do a test plot without the weights:

plt.hist([i/40 for i in range(40)], bins=np.linspace(0, 1, 41), rwidth=1, ec='k')
plt.plot([i/40 for i in range(40)], [0.5] * 40, 'ro')
plt.xticks(np.linspace(0, 1, 11))


A red dot shows where the x-values are. Some fall into the correct bin, some into the neighbor which suddenly gets 2 values.


To create a histogram with the x-values at the center of each bin:

plt.hist([i/40 + 1/80 for i in range(40)], bins=np.linspace(0, 1, 41), rwidth=1, ec='k')
plt.plot([i/40 + 1/80 for i in range(40)], [0.5] * 40, 'ro')
plt.xticks(np.linspace(0, 1, 11))
plt.yticks([0, 1])



","The problem is due to the rounding error of  np.linspace(0, 1, 11).
bins = []
for abin in np.linspace(0, 1, 41):
    bins.append(abin)

The code above will get
bins = [0.0, 0.025, 0.05, 0.07500000000000001, 0.1, 0.125, 0.15000000000000002, ...] 

,which causes the problem.
However, when you do np.round(np.linspace(0, 1, 41), 4), the problem is fixed.
Example:
plt.hist([i/40 for i in range(40)], bins=np.round(np.linspace(0, 1, 41), 4), rwidth=1, ec='k')
plt.plot([i/40 for i in range(40)], [0.5] * 40, 'ro')
plt.xticks(np.linspace(0, 1, 11))


",,false,,,
https://stackoverflow.com/questions/62893128,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Python Matplotlib: Animating a rotating PatchCollection,"I am trying to make an animation in which a PatchCollection rotates around the origin. The easiest way seems to be through using a FuncAnimation.
As per the answer on matplotlib change a Patch in PatchCollection I am using an extension of the PatchCollection class which allows me to update the positions of the individual patches.
The animation function simply calls one of the class methods and returns the collection which is updated:
fig, ax = plt.subplots(1)

grid = HexagonalGrid()

ax.add_collection(grid)

def animate(frame):
    grid.rotateGrid(0.1)
    return (grid,)
    
anim = anim.FuncAnimation(fig, animate, blit=True)


When using RegularPolygon patches all works fine:
class HexagonalGrid(UpdateablePatchCollection):    
    def __init__(self, latticeParameter = 5):
        self.patches = self._initiatePatches(hexRadius)
        UpdateablePatchCollection.__init__(self, self.patches, match_original=True, animated=True)

    def _initiatePatches(self, hexRadius):
        patches = []
        for :
            #calculates the correct starting position for each patch
            patches.append(self._createHex(x,y,hexRadius))
        
    def _createHex(self, x,y, hexRadius):
        return matplotlib.patches.RegularPolygon(
            (x, y),
            numVertices = 6,
            radius = hexRadius,
            orientation = 0,
            fc = (0.1, 0.1, 0.1, 0.1), # fill colour RGBA (black and transparent)
            ec = 'black' # edge colour
        )

        def rotateGrid(self, angle):
        for patch in self.patches:
            x, y = patch.xy
            xNew = x * math.cos(angle) - y * math.sin(angle)
            yNew = x * math.sin(angle) + y * math.cos(angle)
            patch.xy = (xNew, yNew)
            patch.orientation = patch.orientation + angle

But when trying to do this with Rectangle patches which is the same class except for the following functions:
    def _createRectangle(self, x, y, width, height):
        return matplotlib.patches.Rectangle(
            (x, y),
            width,
            height,
            fc=(0.1, 0.1, 0.1, 0.1),
            ec='black',
            animated=True
        )

    def rotateGrid(self, angle):
    for patch in self.patches:
        x, y = patch.xy
        xNew = x * math.cos(angle) - y * math.sin(angle)
        yNew = x * math.sin(angle) + y * math.cos(angle)
        patch.xy = (xNew, yNew)
        patch.angle = patch.angle + angle

The rectangles are not rotated with the grid
Example
(For clarity: I expected the rectangles to be rotated 45 degrees as well)
I have already tried replacing the rotation by
patch.set_transform(patch.get_transform() + matplotlib.transforms.Affine2D().rotate(angle))  but this had some very strange behavior by moving and enlarging the patches.
Does anyone know a way to make the rectangles rotate?
","After some research into the matplotlib source-code I found out what the problem was. In case anyone else encounters the same or a similar problem please read the solution below and see if it will help you!
In the last part of my post I already mentioned the possible use of the Rectangle.set_transform() function. The problem lies in the subsequent calls of this setter function.
Because I wanted to modify my existing transform I used the getter Rectangle.get_transform() to which I added another transform.
For some reason the getter of the transform of Rectangle (but it might be the case for all Patches) does not return the set value. That is:
t = some_transformation
rect = Rectangle(x,y,width,height)
rect.set_transform(t)
print(rect.get_transform() == t) 

prints False
The correct getter to use in this case would be rect.get_data_transform() after which subsequent transforms can be added.
",,,false,,,
https://stackoverflow.com/questions/41655430,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Strange behavior in matplotlib (multiple) histograms,,,,,false,,,
https://stackoverflow.com/questions/67692855,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Approximating sin using the Taylor series,,,,,false,,,
https://stackoverflow.com/questions/25328818,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,python 2.7: cannot pip on windows &quot;bash: pip: command not found&quot;,"I am trying to install the SciPy stack located at https://scipy.org/stackspec.html [I am only allowed 2 links; trying to use them wisely].  I realize that there are much easier ways to do this, but I think there is a lot to be learned by doing it manually.  I am relatively new to a lot of this stuff, so I apologize if I sound ignorant at any point.
I am running  Windows 7 Enterprise - 64 bit.  Here is what I have done so far:

Installed python-2.7.8.msi (32-bit) from https://www.python.org/download/releases/2.7.8/

Installed numpy-1.8.1-win32-superpack-python2.7 from
http://sourceforge.net/projects/numpy/files/
Test: import numpy as np ---&gt; no errors

Installed scipy library,
scipy-0.14.0-win32-superpack-python2.7.exe from
(SCIPY DOT ORG LINK REMOVED)
Test: import scipy as sp ---&gt; no errors

Installed matplotlib: matplotlib-1.3.1.win32-py2.7.exe from
(MATPLOTLIB DOT ORG LINK REMOVED)

Installed PIP by running script here:
https://raw.githubusercontent.com/pypa/pip/master/contrib/get-pip.py
I just copied-pasted script to a new file in IDLE,
saved as C:\Python27\Scripts\pip_install.py and clicked Run&gt;module. No errors reported.


Does the path on which I saved
pip_install.py matter?




HERE IS WHERE I FAIL
Attempted to install matlibplot dependency dateutil: Opened a
Cygwin Shell, and typed
        cd C:\Python27          ! is it necessary to cd to python directtory?
        pip install python-dateutil

This results in the error:
    bash: pip: command not found

I get the same error attempting from cmd.
Any help  is appreciated; the closest I found was bash: pip: command not found.  But the OSX nature of it is just enough to confise me further.

UPDATE:
I added the pip-path per Paul H's suggestion below.  It made the error go away, but strangely, nothing I pip actually installs. For example, in Cygwin, I type:
cbennett2&gt; pip install python-dateutil
cbennett2&gt;                            

You can see that there is no output or feedback from the shell (which I think there should be).  Then when I go to a new python shell:
&gt;&gt;&gt; from dateutil.parser import parse
Traceback (most recent call last):
  File ""&lt;pyshell#12&gt;"", line 1, in &lt;module&gt;
    from dateutil.parser import parse
ImportError: No module named dateutil.parser
&gt;&gt;&gt;&gt;

This happens with all of the modules that I thought I had pip'd ... pandas, tornado, etc.
","The problem is that your Python version and the library you want to use are not same versionally (Python). Even if you install Python's latest version, your PATH might not change properly and automatically. Thus, you should change it manually.After matching their version, it will work.

Ex: When I tried to install Django3, I got same error. I noticed that my PATH still seems C:\python27\Scripts though I already install Python3.8, so that I manually edited my PATH C:\python38\Scripts and reinstalled pip install Django and everything worked well. 
",,,false,,,
https://stackoverflow.com/questions/60832177,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Matplotlib generated pdf cannot be opened by Acrobat Reader,"I am trying to use serif fonts with latex with matplotlib, unfortunately it does not display in Acrobat Reader, but it is OK on Internet Explorer or Chrome. My minimal code produces an error StandardSymL_Slant_167 not found and varepsilon is not visible, what is missing?
import matplotlib as mpl
import matplotlib.pyplot as plt

mpl.rcParams.update(mpl.rcParamsDefault)
mpl.rcParams['text.usetex'] = True
mpl.rcParams['font.family'] = ['serif']
mpl.rcParams['font.serif'] = ['times']

fig, ax = plt.subplots()
ax.set_xlabel(r'$x$ $\alpha \varepsilon$')
fig.savefig('test.pdf')


The output of my enviroment is:
import matplotlib
print(matplotlib.__version__)
3.2.0

edit
Found this as well strange:
pdffonts test.pdf
name                                 type              encoding         emb sub uni object ID
------------------------------------ ----------------- ---------------- --- --- --- ---------
NimbusRomNo9L-Regu                   Type 1            Custom           yes no  no      21  0
CMMI10                               Type 1            Builtin          yes no  no      13  0
NimbusRomNo9L-ReguItal               Type 1            Custom           yes no  no      25  0
StandardSymL_Slant_167               Type 1            Builtin          yes no  no      17  0

","This is not really a nice solution, but I'm not sure a work-around is possible short of manually editing the resulting pdf in a text editor. It seems that this is an error caused by the Adobe Acrobat parser, because matplotlib outputs double precision numbers, whereas Type 1 fonts only support single precision.
Relevant issue which seems it will be fixed in the upcoming version of matplotlib 3.4.0:
https://github.com/matplotlib/matplotlib/issues/16087
The fix has since been merged, so updating to the latest master, e.g. with pip install git+https://github.com/matplotlib/matplotlib.git@master should fix it.
","As I understand, the problem with Greek fonts.
Interesting, that problems usually with win os...
Try win adapted version, please:
import matplotlib as mpl
import matplotlib.pyplot as plt
mpl.rcParams.update(mpl.rcParamsDefault)

mpl.rcParams['text.usetex'] = True
# mpl.rcParams['font.family'] = ['serif']
# mpl.rcParams['font.serif'] = ['times']
mpl.rcParams['font.family'] = ['times new roman']

fig, ax = plt.subplots()
ax.set_xlabel(r'$x$ $\alpha \varepsilon$')
fig.savefig('test.pdf')

","I had a similar issue, I didn't get any informative warnings from pdf readers, but Chrome could display the pdfs.
For me the solution was by changing a linewidth that was set to zero. More specifically in my case for fill_between:
plt.fill_between(steps, lower_line, top_line,
                                 linewidth=0.01, # CANNOT BE ZERO, GIVES ERRORS IN PDF READERS
                                 linestyle='dashdot',
                                 antialiased=True,
                                 )

",false,,,
https://stackoverflow.com/questions/40309448,true,The issue involves the skimage.PiecewiseAffineTransform API from the scikit-image library. It exhibits unexpected behavior in warping images using control points. Further analysis is required.,,,,,,,Piecewise Affine Transform+warp output looks strange,"I have an image I am trying to warp using skimage.PiecewiseAffineTransform and skimage.warp.  I have a set of control points (true) mapped to a new set of control points (ideal) but the warp is not returning what I expect.

In this example, I have a simple gradient of wavelengths I am trying to 'straighten out' into columns. (You might ask why I am finding contours and interpolating but that is because I am actually applying this code to a more complex use case. I just wanted to reproduce all the code for this simple example which results in the same strange output.)

Any reason why my output image just has the input image warped into a square and inset? I'm using Python 2.7.12 and matplotlib 1.5.1. Here is the code. 

import matplotlib.pyplot as plt
import numpy as np
from skimage import measure, transform

true = np.array([range(i,i+10) for i in range(20)])
ideal = np.array([range(10)]*20)

# Find contours of ideal and true images and create list of control points for warp
true_control_pts = []
ideal_control_pts = []

for lam in ideal[0]:
    try:
        # Get the isowavelength contour in the true and ideal images
        tc = measure.find_contours(true, lam)[0]
        ic = measure.find_contours(ideal, lam)[0]
        nc = np.ones(ic.shape)

        # Use the y coordinates of the ideal contour
        nc[:, 0] = ic[:, 0]

        # Interpolate true contour onto ideal contour y axis so there are the same number of points
        nc[:, 1] = np.interp(ic[:, 0], tc[:, 0], tc[:, 1])

        # Add the control points to the appropriate list
        true_control_pts.append(nc.tolist())
        ideal_control_pts.append(ic.tolist())

    except (IndexError,AttributeError):
        pass

true_control_pts = np.array(true_control_pts)
ideal_control_pts = np.array(ideal_control_pts)

length = len(true_control_pts.flatten())/2
true_control_pts = true_control_pts.reshape(length,2)
ideal_control_pts = ideal_control_pts.reshape(length,2)

# Plot the original image
image = np.array([range(i,i+10) for i in range(20)]).astype(np.int32)
plt.figure()
plt.imshow(image, origin='lower', interpolation='none')
plt.title('Input image')

# Warp the actual image given the transformation between the true and ideal wavelength maps
tform = transform.PiecewiseAffineTransform()
tform.estimate(true_control_pts, ideal_control_pts)
out = transform.warp(image, tform)

# Plot the warped image!
fig, ax = plt.subplots()
ax.imshow(out, origin='lower', interpolation='none')
plt.title('Should be parallel lines')


The output for this looks like:



Any assistance would be greatly appreciated!
",,,,false,,,
https://stackoverflow.com/questions/48434919,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Why are bar chart x-axis ticks showing strange and wrong negative values?,"Why is my X-axis ticks showing Negative values when the Xaxis values range from 43990 - 44003. 

import matplotlib.pyplot as plt
x=[44000, 44001, 44002, 44003, 43990, 43991, 43992, 43993, 43994, 43995, 43996, 43997, 43998, 43999]
y=[8, 5, 3, 1, 1, 3, 4, 10, 4, 11, 4, 10, 17, 19]
plt.bar(x,y)
plt.show()


I am seeing the following output. I was expecting x-axis to range from 43990 - 44003


I have tried this on a couple of machines, all showing similar strange behaviour on recent versions of python and matplotlib (tried a few different versions)


  Python 3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19)
  [GCC 7.2.0] on linux
  
  Python 3.4.3 (default, Nov 17 2016, 01:08:31)


Strangely enough many trivial toy example x and y arrays are giving me expected figures.

For e.g the follwowing snippet shows the expected graph with correct x-axis tick labels

x=[20,30,90,70, 50, 60, 80, 70]
y=[3,2,5,10, 3, 9, 7, 6]
plt.bar(x,y)
plt.show()




What obvious thing am i missing here ?
",,,,false,,,
https://stackoverflow.com/questions/34071637,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,NetworkX: How to draw label nodes/edges with tex symbols?,,,,,false,,,
https://stackoverflow.com/questions/17379351,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Six subplots with the same number of xticklabels in matplotlib,,,,,false,,,
https://stackoverflow.com/questions/55169294,true,The issue involves the conversion of AsciiMath or MathML sources to SVG and/or PNG. The user is looking for a solution in math libraries but has not found any. This indicates a potential API-related problem in the libraries the user has explored.,,,,,,,Convert AsciiMath/MathML to SVG/PNG,"I'm looking for a way to convert my AsciiMath (or MathML) sources to SVG and/or PNG. I've found a nodeJS library for SVG conversion but calling that from Python is not very convenient and the output is not entirely satisfying.

Taking the fact I'd like to render mathematical formulas to svg/png it seems logical to look for a solution in math libraries (NumPy, SciPy, Pandas, Matplotlib, Sympy, etc...) but to no avail. All my google results combining all possible permutations of asciimath+mathml+svg+png lead to nothing which is strange.

Please recommend me either search patterns to find a solution or share your experiences/ideas to get this seemingly simple job done in Python.

All help would be highly appreciated!
","I just created ziamath for exactly this purpose. It comes bundled with the STIX math font, so no setup is required beyond the pip install, but it should also work with other math-enabled fonts. Pure-Python, so it does not need a Latex installation or anything else to work. This first version doesn't quite cover the full MathML specification, but the most useful parts are in there.
To bundle it into an app with something like PyInstaller, you'll need to make sure the STIX font gets included, but that should just be one line in the PyInstaller config.
","I have used this for years without issues. It is written in python.

https://sourceforge.net/projects/svgmath/files/svgmath/0.3.3/
",,false,,,
https://stackoverflow.com/questions/51447184,true,The issue involves the behavior of matplotlib's ax.transData.transform in different IPython cells. The user observes that the values returned by ax.transData.transform are different in the initial cell compared to a later cell. This indicates a potential API-related problem with ax.transData.transform.,,,,,,,Why does matplotlib ax.transData.transform gives different values in different ipython cells? How to fix this?,"I was suffering a really bizarre issue with matplotlib's ax.transData.transform in ipython. Basically, in the cell where fig, ax = plt.subplots() is declared, running ax.transData.transform for either the x or y axis is incorrect. However, if you run ax.transData.transform in a later cell, it returns the correct values. 

To demonstrate, here is code running the transformation in the cell where fig, ax = plt.subplots() is declared:

fig, ax = plt.subplots()
ax.set_aspect('equal')
ax.set_ylim(-2,2)
ax.set_xlim(-5,5)
nsize=[x*100 for x in d]
yradius = (ax.transData.transform([(0,2)]) - ax.transData.transform([(0,1)]))[0,1]
print(""yRadius: {}"".format(yradius))
xradius = (ax.transData.transform([(2,0)]) - ax.transData.transform([(1,0)]))[0,0]
print(""xRadius: {}"".format(xradius))


The print output is 

yRadius: 54.360000000000014
xRadius: 33.48000000000002


In a cell below the above cell, if I run 

yradius = (ax.transData.transform([(0,2)]) - ax.transData.transform([(0,1)]))[0,1]
print(""yRadius: {}"".format(yradius))
xradius = (ax.transData.transform([(2,0)]) - ax.transData.transform([(1,0)]))[0,0]
print(""xRadius: {}"".format(xradius))


The output is 

yRadius: 33.48000000000002
xRadius: 33.48000000000002


Why are the values of the two cells not the same? Although the xRadius of the first cell matches the values of the bottom cell, the yRadius is off. I think the bottom cell's values are correct, because since the ax aspect is set to be equal, the two radii should be the same. Why is the yRadius of the first cell wrong here? After trying out a bunch of different values for xlim and ylim I found the pattern that the minimum of the two radii in the first cell is correct, while the other one is off. This seems to me a very strange error. Is there any way of making it return the correct values in the initial cell?
","Your observation is pretty accurate. What happens is simply that the equal aspect is only applied once the figure is drawn. This is the case for the second cell (because the figure is shown as output of the first). However in the first cell the axes still has its original extent. 

Solution: Draw the figure before trying to obtain any coordinates from it,

fig.canvas.draw()

# Now obtain coordinates:
yradius = (ax.transData.transform([(0,2)]) - ax.transData.transform([(0,1)]))[0,1]
print(""yRadius: {}"".format(yradius))
xradius = (ax.transData.transform([(2,0)]) - ax.transData.transform([(1,0)]))[0,0]
print(""xRadius: {}"".format(xradius))

",,,false,,,
https://stackoverflow.com/questions/50855834,true,The issue involves the failure of matplotlib 2.2.2 to xkcdify plots. The user observes that the xkcd function does not produce the expected xkcd-style graph. This indicates a potential API-related problem with the xkcd function in matplotlib 2.2.2.,,,,,,,Matplotlib 2.2.2 fails to xkcdify plots,"I use matplotlib 2.2.2 with Python 3.5.2

When I try to use matplotlib's xkcd function, I get a normal graph:

import matplotlib
print(matplotlib.get_cachedir())
print(matplotlib.__version__)

import matplotlib.font_manager
x = [f.name for f in matplotlib.font_manager.fontManager.ttflist if f.name.startswith(""Humor"")]
print(set(x))

from matplotlib import pyplot as plt
import numpy as np

plt.xkcd(scale=10, length=100, randomness=20)
plt.plot(np.sin(np.linspace(0, 10)))
plt.title('Whoo Hoo!!!')
plt.show()


Output:


  /home/thatsme/.cache/matplotlib
  2.2.2
  {'Humor Sans'}


So, Humor Sans is installed, I deleted the font cache, just in case, as suggested by other threads, I increased the jitter parameters, but nonetheless no sign of xkcdification:



Strange thing is that I have Eclipse installed as a dual-boot on Ubuntu 16.04 and Windows 10, and the xkcd function fails on both systems. I would have expected that the Python and Eclipse installation significantly differs between those systems, but here we are.
Any ideas, what might be the problem?

Edit: As Hans pointed out this might be a problem specific for matplotlib 2.2.2
Even more bizarre - if I run the same script using with : without any other changes like

with plt.xkcd(scale=10, length=100, randomness=20):
    plt.plot(np.sin(np.linspace(0, 10)))
    plt.title('Whoo Hoo!!!')
plt.show()


the output is the expected xkcd figure:


Removing the with : statement brings back the first figure. The same behaviour again on both Linux and Windows, so seemingly a matplotlib version problem. 

Edit: Now that we know it is a temporary, limited bug, back to the main question - How to get rid of the white edgecolor in xkcd
","This is a bug purely present in matplotlib 2.2. The problem is that the garbage collector is too quick. See this comment and below.

This means that currently you need to use the xkcd style inside a context to make it work. The problem should be fixed in the next release. The code from the question hence works as expected in the current development version.
",,,false,,,
https://stackoverflow.com/questions/14715679,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Strange output from matplotlib mathtext,"I tried to use mathtext to get a specially rendered figure title, but it failed. Instead of my test title it just printed cryptic characters. What am I doing wrong?


Operating System: Fedora release 18 (Spherical Cow)
Python and matplotlib are installed from official repositories via yum


Here's the (full) code:

import sys
print sys.version             # prints:
                              # 2.7.3 (default, Aug  9 2012, 17:23:57)
                              # [GCC 4.7.1 20120720 (Red Hat 4.7.1-5)]
import matplotlib
print matplotlib.__version__  # prints:
                              # 1.2.0

import matplotlib.pyplot as plt
plt.plot([1,5])
plt.title(r""$1.2345$"")
plt.show()


Here's the output image:

",,,,false,,,
https://stackoverflow.com/questions/67734899,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,How to avoid the box around a matplotlib image with jupyter?,"On a jupyterhub notebook (python 3.8.5) and using matplotlib (version 3.3.2) I am trying to create a simple plot. The cell content is as follows:
import matplotlib.pyplot as plt

def plot_something(time_array, dependent_var, label=""label""):
    plt.plot(time_array, dependent_var, label=label)
    plt.xlabel('Time (ms)')
    plt.ylabel(label)
plot_something([1,2,3], [4,5,6])

However, there is a strange scroll box drawn around the created image with a scrollbar at the right (i.e. you cannot see the whole image, you have to scroll!):

which does not happen for other matplotlib plots in the same notebook. The image shows the complete output cell (and you can see the upper part of the plot is missing. You need yo scroll up to see it).
How can I programatically avoid this strange box around the matplotlib plot?
P.S. I am not sure how to reproduce this problem. If I execute the code on top of the notebook it work fine, I get just the plot without that strange scroll box:

I also checked for differences in the actual displayed html code between these two cases. I did not any differences!
","That is because of scrolling. To change that, you can go to Cell &gt; All Outputs &gt; Toggle Scrolling or one of the other options until you get the desired result.
","As an actual better solution which neither requires additional code nor user-interaction in the notebook is to check the metadata of the notebook itself. The metadata of the cell that shows the scroll box looks like
{
   ""cell_type"": ""code"",
   ""execution_count"": null,
   ""metadata"": {
    ""scrolled"": true
   },
   ""outputs"": [],
   ""source"": [
    ""plot_timecourse(time, v_soma)""
   ]
  },

Just remove the scroll part, i.e. change it to
{
   ""cell_type"": ""code"",
   ""execution_count"": null,
   ""metadata"": {}
   ""outputs"": [],
   ""source"": [
    ""plot_timecourse(time, v_soma)""
   ]
  },

",,false,,,
https://stackoverflow.com/questions/57303228,true,The issue involves the effective redraw of multiple matplotlib plots using blit. The user is experiencing artifacts and strange behavior when using the blit function. This indicates a potential API-related problem with the blit function in matplotlib.,,,,,,,How to effectively redraw multiple matplotlib plots with blit,"I'm using matplotlib with pyqt5 to draw data into 3 axes, and than user can make selection in one plot that will be shown in other two plots too. Since I'm working with big data (up to 10 millions of points), drawing selection could be slow, especially when I need to draw to scatterplot. 

I am trying to use matplotlib blit function, but have some issues with result. Here is minimum simple example.

import matplotlib
matplotlib.use('Qt5Agg')
import numpy as np
import sys

from matplotlib.backends.qt_compat import QtCore, QtWidgets
from matplotlib.backends.backend_qt5agg import (FigureCanvas, NavigationToolbar2QT as NavigationToolbar)
from matplotlib.figure import Figure


class ApplicationWindow(QtWidgets.QMainWindow):
    def __init__(self):
        super().__init__()
        self._main = QtWidgets.QWidget()
        self.setCentralWidget(self._main)
        layout = QtWidgets.QVBoxLayout(self._main)

        self.static_canvas = FigureCanvas(Figure(figsize=(10, 10)))
        layout.addWidget(self.static_canvas)
        layout.addWidget(NavigationToolbar(self.static_canvas, self))
        axes = self.static_canvas.figure.subplots(2, 1)
        self.ax1 = axes[0]
        self.ax2 = axes[1]
        self.ax1.cla()
        self.ax2.cla()

        button = QtWidgets.QPushButton('Click me!')
        button.clicked.connect(self.update_canvas_blit)
        layout.addWidget(button)
        # Fixing random state for reproducibility
        np.random.seed(19680801)

        # Create random data
        N = 50000
        x = np.random.rand(N)
        y = np.random.rand(N)

        self.ax1.scatter(x, y)
        self.points = self.ax1.scatter([],[], s=5, color='red')

        x = np.linspace(0, 1000, 100000)
        self.ax2.plot(x, np.sin(x))
        self.lines, = self.ax2.plot([],[], color='red')
        self.static_canvas.draw()

        self.background1 = self.static_canvas.copy_from_bbox(self.ax1.bbox)
        self.background2 = self.static_canvas.copy_from_bbox(self.ax2.bbox)

    def update_canvas_blit(self):
        N = 50
        x = np.random.rand(N)
        y = np.random.rand(N)

        self.static_canvas.restore_region(self.background1)
        self.points.set_offsets(np.c_[x,y])
        self.ax1.draw_artist(self.points)
        self.ax1.figure.canvas.blit(self.ax1.bbox)

        self.static_canvas.restore_region(self.background2)
        x = np.linspace(0, np.random.randint(500,1000), 1000)
        self.lines.set_data(x, np.sin(x))
        self.ax2.draw_artist(self.lines)
        self.ax2.figure.canvas.blit(self.ax2.bbox)

if __name__ == ""__main__"":
    qapp = QtWidgets.QApplication(sys.argv)
    app = ApplicationWindow()
    app.show()
    qapp.exec_()


When clicking button, expected output should be still same background with random points/lines redrawing. In a way it is happening but there are some strange artifacts that looks like somehow axes are drawn to each other. But when I try to save it to .png, it will restore to good state.


","The problem is that the snapshot of the background is taken at a moment in time where the figure has not yet been shown on screen. At that point the figure is 10 by 10 inches large. Later, it is shown inside the QMainWindow and resized to fit into the widget.
Only once that has happened, it makes sense to take the background snapshot. 

One option is to use a timer of 1 second and only then copy the background. This would look as follows.

import numpy as np
import sys

from matplotlib.backends.qt_compat import QtCore, QtWidgets
from matplotlib.backends.backend_qt5agg import (FigureCanvas, NavigationToolbar2QT as NavigationToolbar)
from matplotlib.figure import Figure


class ApplicationWindow(QtWidgets.QMainWindow):
    def __init__(self):
        super().__init__()
        self._main = QtWidgets.QWidget()
        self.setCentralWidget(self._main)
        layout = QtWidgets.QVBoxLayout(self._main)

        self.static_canvas = FigureCanvas(Figure(figsize=(10, 10)))
        layout.addWidget(self.static_canvas)
        layout.addWidget(NavigationToolbar(self.static_canvas, self))
        axes = self.static_canvas.figure.subplots(2, 1)
        self.ax1 = axes[0]
        self.ax2 = axes[1]
        self.ax1.cla()
        self.ax2.cla()

        button = QtWidgets.QPushButton('Click me!')
        button.clicked.connect(self.update_canvas_blit)
        layout.addWidget(button)
        # Fixing random state for reproducibility
        np.random.seed(19680801)

        # Create random data
        N = 50000
        x = np.random.rand(N)
        y = np.random.rand(N)

        self.ax1.scatter(x, y)
        self.points = self.ax1.scatter([],[], s=5, color='red')

        x = np.linspace(0, 1000, 100000)
        self.ax2.plot(x, np.sin(x))
        self.lines, = self.ax2.plot([],[], color='red')
        self.static_canvas.draw()

        self._later()


    def _later(self, evt=None):
        self.timer = self.static_canvas.new_timer(interval=1000)
        self.timer.single_shot = True
        self.timer.add_callback(self.update_background)
        self.timer.start()


    def update_background(self, evt=None):
        self.background1 = self.static_canvas.copy_from_bbox(self.ax1.bbox)
        self.background2 = self.static_canvas.copy_from_bbox(self.ax2.bbox)

    def update_canvas_blit(self):
        N = 50
        x = np.random.rand(N)
        y = np.random.rand(N)

        self.static_canvas.restore_region(self.background1)
        self.points.set_offsets(np.c_[x,y])
        self.ax1.draw_artist(self.points)
        self.ax1.figure.canvas.blit(self.ax1.bbox)

        self.static_canvas.restore_region(self.background2)
        x = np.linspace(0, np.random.randint(500,1000), 1000)
        self.lines.set_data(x, np.sin(x))
        self.ax2.draw_artist(self.lines)
        self.ax2.figure.canvas.blit(self.ax2.bbox)

if __name__ == ""__main__"":
    qapp = QtWidgets.QApplication(sys.argv)
    app = ApplicationWindow()
    app.show()
    qapp.exec_()

",,,false,,,
https://stackoverflow.com/questions/61025167,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Lambda slack file upload is getting triggered multiple times,"My app architecture is slack events -&gt; API Gateway -&gt; Lambda -&gt; does someoperation and returns an .png file which is generated using numpy and matplotlib.

When i deal with just text output in lambda, it works fine, but when i deal with file uploads, it works strange,

It uploads files to slack using[files.upload] method and then after a minute again my lambda gets triggered and ends up in uploading another file.

Is it because slack return HTTP response for file.upload method and somehow my app catches that and it runs agian?

It would be of great help as even in the slack events, events are same without any difference but i am really not sure why my lambda gets invoked again and i verified the request ID's and it is different and even at API getway there are two different request ID's but i have requested only one time...it drives me crazy...
","I found out the way to do this. With the help of this article https://aws.amazon.com/premiumsupport/knowledge-center/custom-headers-api-gateway-lambda/ i added HTTP Header [client Header information] in API Gateway and i pass it to lambda. So, in Lambda i catch the retry events from slack with the help of header which contains X-Slack-Retry-Num for retry events and return it immediately as return 200.

if 'X-Slack-Retry-Num' in output['headers']:
    slk_retry = output['headers']['X-Slack-Retry-Num']
    return 200
else:
    ""Consider this as first event and provide your actual code and logic""

",,,false,,,
https://stackoverflow.com/questions/39681620,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Gantt Chart python machine scheduling,"I'm having some bad time trying to plot a Gantt chart from a data set with python. I have a set of machines that work on different tasks during a time period. I want to make a Gantt chart that shows by the y axis the machines and x axis the time spent on each task.
Each machine should appear just once on the y axis and to make easier to see the tasks I want the same color for each task.
The idea is to check strange things like having the same task being processed by two or more machines together.
Let me show what data set I have with a small example:
machine   equipment   start   finish
  m1         e2       date1    date2
  m2         e2       date3    date4
  m1         e1       date5    date6
  m3         e3       date7    date8
  m3         e4       date9    date10

I tried to use the broken_barh from matplotlib, but I can't figure out a way to add the data for the plot efficiently. Since I have some thing like 100 machines and 400 tasks.
Here is a picture to show how the output should look like.

Current code below:
import datetime as dt

machines = set(list(mydata[""machine""]))
tasks = set(list(mydata[""task""]))

fig, ax = plt.subplots(figsize=(20, 10))

yrange = 5 # y width of gantt bar
ymin = 0
orign = min(list(mydata[""start""])) # time origin

for i in machines:
    
    stdur = [] # list of tuples (start, duration)
    ymin = index*6 # start y of gantt bar
    
    for index, row in mydata.iterrows():
        
        if row[""machine""] == i:
            start = (row[""start""] -  orign).total_seconds()/3600
            duration = (row[""finish""] -  row[""start""]).total_seconds()/3600
        
            stdur.append((start,duration))
        
    ax.broken_barh(stdur,(ymin,yrange))
        
ax.set_xlabel('Time')
ax.set_yticklabels(machines)

plt.show()

","If you are fine passing the entire data to the client and let a JS Gantt do its thing, then the RadiantQ jQuery Gantt Package will be a better option for you. Here is an online demo of something similar:
http://demos.radiantq.com/jQueryGanttDemo/Samples/ServerStatusWithHugeData.htm
This is how it looks:

More on the product here:
http://radiantq.com/products/jquery-gantt-package/jquery-gantt-package-features/
",,,false,,,
https://stackoverflow.com/questions/68140087,false,The issue does not meet the criteria for deeper analysis as it is a specific question about exporting a matplotlib plot as an EMF file and does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Export matplotlib as emf and avoid black bacground fill,"The previous discussion [1] helps us to export a matplotlib plot as an .emf file. However, the strange error is that the output file has nodes filled with black background as shown below.
How is it possible to obtain the .emf exactly as the .svg?
import matplotlib.pyplot as plt
import subprocess, os

# Graph with 4 nodes - its coordinates
x = [0, 5, 5, 0]
y = [0, 0, 5, 5]

fig, ax = plt.subplots()

# Plot the vertices
for i in range(len(x)):
        ax.plot(x[i], y[i], 'ro',
                 markersize = 12,
                 fillstyle = 'none',
                 label = 'A')

# Plot the edges
plt.plot(x,y)

# Legend
handles, labels = plt.gca().get_legend_handles_labels()
by_label = dict(zip(labels, handles))
plt.legend(by_label.values(), by_label.keys())

# File export
inkscape_path = ""C://Program Files//Inkscape//bin//inkscape.exe""
out_file = ""C:/Users/banbar/Desktop/out1.emf""

path, filename = os.path.split(out_file)
filename, extension = os.path.splitext(filename)

svg_filepath = os.path.join(path, filename+'.svg')
emf_filepath = os.path.join(path, filename+'.emf')

fig.savefig(svg_filepath, format='svg')

subprocess.call([inkscape_path, svg_filepath, '--export-filename', emf_filepath])   


","This is only one half of the answer, which is the SVG half:
When you select one of those squares in Inkscape, you will probably notice that it says 'Fill unset' in the bottom left where the fill indicator is.
That would be because matplotlib leaves the fill attribute out entirely. A valid value in SVG would be 'none' or a fill color with opacity = 0.
I've found a link about how to determine the fill color here:
https://matplotlib.org/2.1.1/api/_as_gen/matplotlib.pyplot.plot.html
You should be able to figure out the rest from there, hopefully.
","I had the same issue, simple workaround:

let matplotlib generate a pdf
convert to svg (pdftocairo or pdf2svg)
convert to emf finally using inkscape

Regards Stefan
",,false,,,
https://stackoverflow.com/questions/67878607,false,The issue does not meet the criteria for deeper analysis as it is a specific question about a strange problem with multiple polar plots in matplotlib and does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Strange problem with multiple polar plots in matplotlib,"I've run into a strange issue plotting two ellipses on a single polar plot with matplotlib. Here's my Python code:
import numpy as np
import matplotlib.pyplot as plt

def EllipseRadius(a, b, angle):
    return a * b / np.sqrt((b * np.cos(angle)) ** 2 + (a * np.sin(angle)) ** 2)

ell_a = 9   # Outer ellipse semi-major axis
ell_b = 1   # Outer ellipse semi-minor axis
ell_k = 0.1 # Ratio of inner ellipse to outer ellipse

fig = plt.figure(figsize=(15,15))
ax = fig.add_subplot(projection='polar')

# First ellipse
angles1 = np.linspace(0, 2*np.pi, 1000)
rs1 = EllipseRadius(ell_a, ell_b, angles1)
ax.plot(angles1, rs1)

# Second ellipse
angles2 = np.linspace(0, 2*np.pi, 1000)
rs2 = EllipseRadius(ell_k*ell_a, ell_k*ell_b, angles2)
ax.plot(angles2, rs2)

##for i in range(len(angles1)):
##    print(angles1[i], rs1[i], rs2[i])

plt.show()

If I run this code, here's what I see:

Note the central ""bulge"" in both ellipses. Strangely, if I comment out the larger ellipse (labeled ""first ellipse"" in the code above), here's the output:

That looks a lot more like what I expected. If I comment out the other ellipse instead, I get another great looking ellipse. So, for some reason, if I plot just either ellipse alone, it looks great, but if I plot both, they develop this strange shape.
I am using Python 3.7.3 and matplotlib 3.1.0.
What could be causing this?
Thanks!
Michael
","I have matplotlib version 3.4.1 and this is my output. Try to update matplotlib
pip install --upgrade matplotlib
or
conda update matplotlib


",,,false,,,
https://stackoverflow.com/questions/66054173,false,The issue does not meet the criteria for deeper analysis as it is a specific question about running Octave code without the Octave IDE and does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,How to run Octave code without the Octave IDE (similarly to Python)?,"Context: When I use Python + matplotlib, I can compose the code in any text editor (like Sublime Text), do CTRL+B, and then the text output appears in the ""Build results"" panel of the text editor, and, optionally, graph/plots are rendered in a new GUI window.
Under the hood, the text editor calls python myscript.py when we do ""Build"", and that's it.
It's simple and working flawlessly, easily.

Now I'm trying to do the same with GNU Octave: write a test.m code (such as this one). Then run it from my favorite text editor (and not the Octave IDE), or from command-line. I tried:

octave test.m: the plot is displayed during 100 ms and then disappears! not OK

octave --persist test.m: the plot stays displayed, this is ok ... but this part is not good: it opens an IDE (which I don't want since I want to continue using my usual text editor!), see the background window:



How to have GNU Octave behave like expected: the text output in stdout (either in terminal or in the ""Build Results"" panel of your text editor) and the plot output in a new window? Important: without spawning an IDE window.
I find strange that this behaviour is not the default behaviour. Shouldn't it be?

Edit: solved with:
octave-cli test.m

and
k = plot(...)
waitfor(k)

","to have a similar effect I run the command line interface octave-cli or octave --no-gui in a terminal and vim in a different one.
Not exactly what you are looking for, but matplotlib is a python module while octave is a separate program from your editor.
See example of the two terminals and the graphs, all on separate windows.

",,,false,,,
https://stackoverflow.com/questions/59667803,false,The issue does not meet the criteria for deeper analysis as it is a specific question about Python only using one core and does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Python only uses one core,"i have a python script which handles files with sensor datas from a md4 file and plots them in an image. 
Therefore i am using the libs asammdf and matplotlib - they have a dependency to numpy.

On my windows main computer where i developed the script everything works fine - all threads are used and the speed of the script is fine.

But on other devices where the script should also run to handle more files the script only uses one core with multiple threads while running on Ubuntu 16.04 with own compiled python 3.7.0:



I searched a lot and tried everything what is sugessted - some of them are a bit older for ubuntu 12.. :
https://shahhj.wordpress.com/2013/10/27/numpy-and-blas-no-problemo/
Importing scipy breaks multiprocessing support in Python
Why does multiprocessing use only a single core after I import numpy?

The linux machines are new installed - only python3.7, pip3 and the python libs are installed. I even downloaded the newest ubuntu 19.10 image where python3.7.5 is preinstalled.
What i have done:


tried os.sched_setaffinity
tried os.system(""taskset -p 0xff %d"" % os.getpid())



  pid 20534's current affinity mask: ff
  pid 20534's new affinity mask: ff



installed the ATLAS and set the alternatives but those does not seems
to get taken..


on my windows machine i have:
python 3.7.1
and the output for &gt;&gt;&gt; import numpy; numpy.show_config() 

blas_mkl_info:   NOT AVAILABLE blis_info:   NOT AVAILABLE openblas_info:
    library_dirs = ['C:\\projects\\numpy-wheels\\numpy\\build\\openblas']
    libraries = ['openblas']
    language = f77
    define_macros = [('HAVE_CBLAS', None)] blas_opt_info:
    library_dirs = ['C:\\projects\\numpy-wheels\\numpy\\build\\openblas']
    libraries = ['openblas']
    language = f77
    define_macros = [('HAVE_CBLAS', None)] lapack_mkl_info:   NOT AVAILABLE openblas_lapack_info:
    library_dirs = ['C:\\projects\\numpy-wheels\\numpy\\build\\openblas']
    libraries = ['openblas']
    language = f77
    define_macros = [('HAVE_CBLAS', None)] lapack_opt_info:
    library_dirs = ['C:\\projects\\numpy-wheels\\numpy\\build\\openblas']
    libraries = ['openblas']
    language = f77
    define_macros = [('HAVE_CBLAS', None)]


on my linux machines:
python 3.7.0
and the numpy config:

blas_mkl_info:
  NOT AVAILABLE
blis_info:
  NOT AVAILABLE
openblas_info:
    libraries = ['openblas', 'openblas']
    library_dirs = ['/usr/local/lib']
    language = c
    define_macros = [('HAVE_CBLAS', None)]
blas_opt_info:
    libraries = ['openblas', 'openblas']
    library_dirs = ['/usr/local/lib']
    language = c
    define_macros = [('HAVE_CBLAS', None)]
lapack_mkl_info:
  NOT AVAILABLE
openblas_lapack_info:
    libraries = ['openblas', 'openblas']
    library_dirs = ['/usr/local/lib']
    language = c
    define_macros = [('HAVE_CBLAS', None)]
lapack_opt_info:
    libraries = ['openblas', 'openblas']
    library_dirs = ['/usr/local/lib']
    language = c
    define_macros = [('HAVE_CBLAS', None)]


I do not have any multi threading logic in my code or something similar - all the multi threading logic is handled inside the libs i use. I hope someone can help. I think its very strange i still have this kind of problems so many years later of the questions above i linked.

EDIT: cause question got deleted: i checked in bios that all cores and hyperthreading is activated
","asammdf is completely single threaded. On the windows machine you might be using numpy with the Intel mkl libraries so this might be why the numpy operations are vectorized
",,,false,,,
https://stackoverflow.com/questions/51755124,false,The issue does not meet the criteria for deeper analysis as it is a specific question about why an array made from a PIL draw.text() image does not show properly in Matplotlib and does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Why doesn&#39;t an array made from a PIL draw.text() image show properly in Matplotlib?,"I'd like to understand why, when I convert the PIL image imageRGB to a float array arrayRGB_f and use matplotlib's imshow() without a cmap it looks either black, or strange and unreadable, even though PIL's imageRGB.show() looks fine, and each of the individual r, g, b channels shown with cmap='gray' look okay as well.

I have workarounds, but I just don't understand why this happens.

matplotlib.__version__ returns '2.0.2' and I'm using MacOS with an Anaconda installation.

See this answer for more on the conversion of a ttf rendering to a 1bit.

fyi the output of the print statements are:

float64 (41, 101, 3)
int64 (41, 101, 3)
int64 (41, 101)
int64 (41, 101)




fontname   = 'default' 


imageRGB.show()

 

plt.imshow()



fontname   = 'Arial Unicode.ttf' 


imageRGB.show()



plt.imshow()

 

font   = ImageFont.truetype(fontname, 20)


imageRGB.show()



plt.imshow()



from PIL import Image, ImageDraw, ImageFont
import numpy as np
import matplotlib.pyplot as plt

# fontname   = 'Arial Unicode.ttf' 
fontname   = 'default' 

if fontname == 'default':
    font   = ImageFont.load_default()
else:
    font   = ImageFont.truetype(fontname, 12)

string     = ""Hello "" + fontname[:6]
ww, hh     = 101, 41
threshold  = 80   # https://stackoverflow.com/a/47546095/3904031

imageRGB   = Image.new('RGB', (ww, hh))
draw       = ImageDraw.Draw(imageRGB)
image8bit  = draw.text((10, 12), string, font=font,
                       fill=(255, 255, 255, 255))  # R, G, B alpha

image8bit  = imageRGB.convert(""L"")
image1bit  = image8bit.point(lambda x: 0 if x &lt; threshold else 1, mode='1')  # https://stackoverflow.com/a/47546095/3904031

arrayRGB   = np.array(list(imageRGB.getdata())).reshape(hh, ww, 3)
arrayRGB_f = arrayRGB.astype(float)

array8bit  = np.array(list(image8bit.getdata())).reshape(hh, ww)
array1bit  = np.array(list(image1bit.getdata())).reshape(hh, ww)

for a in (arrayRGB_f, arrayRGB, array8bit, array1bit):
    print a.dtype, a.shape

imageRGB.show()

if True:
    plt.figure()

    a = arrayRGB_f
    plt.subplot(2, 2, 1)
    plt.imshow(a)  # , interpolation='nearest',  cmap='gray',

    for i in range(3):
        plt.subplot(2, 2, 2+i)
        plt.imshow(a[:, :, i], cmap='gray') 

    plt.suptitle('arrayRGB_f, fontname = ' + fontname)
    plt.show()

","I can't find an ideal duplicate so I'll post an answer.

As @ImportanceOfBeingErnest mentions when .imshow() is given an n x m x 3 or n x m x 4 array, it is expecting a normalized array between 0.0 and 1.0.

Best way to do this is:

arrayRGB_f = arrayRGB.astype(float)/255.


though this seems to work as well:

arrayRGB_f = arrayRGB.astype(float)
arrayRGB_f = arrayRGB_f / arrayRGB_f.max()


For longer discussions, see this and this.
",,,false,,,
https://stackoverflow.com/questions/48498766,true,The issue involves the unpacking of Matplotlib hist2d outputs and meets the criteria for deeper analysis as it exhibits unexpected behavior under specific runtime conditions.,,,,,,,Problems with unpacking Matplotlib hist2d outputs,"I'm using Matplotlib's function hist2d() and I want to unpack the output in order to further use it. Here's what I do: I simply load with numpy a 2-column file containing my data and use the following code 

import matplotlib.pyplot as plt
from matplotlib.colors import LogNorm
import numpy as np

traj = np.loadtxt('trajectory.txt')
x = traj[:,0]
y = traj[:,1]
M, xe, ye, img = plt.hist2d(x, y, bins = 80, norm = LogNorm())
plt.imshow(M)
plt.show()


The result I get is the following:



Instead, if I try to directly plot the hist2d results without unpacking them:

import matplotlib.pyplot as plt
from matplotlib.colors import LogNorm
import numpy as np

traj = np.loadtxt('trajectory.txt')
x = traj[:,0]
y = traj[:,1]
plt.hist2d(x, y, bins = 80, norm = LogNorm())
plt.show()


I get the whole plot without the strange blue box. What am I doing wrong?
","You can create a histogram plot directly with plt.hist2d. This calculates the histogram and plots it to the current axes. There is no need to show it yet another time using imshow.

import matplotlib.pyplot as plt
from matplotlib.colors import LogNorm
import numpy as np; np.random.seed(9)

x = np.random.rayleigh(size=9900)
y = np.random.rayleigh(size=9900)

M, xe, ye, img = plt.hist2d(x, y, bins = 80, norm = LogNorm())

plt.show()




Or, you may first calculate the histogram and afterwards plot the result as an image to the current axes. Note that the histogram produced by numpy is transposed, see Matplotlib 2D histogram seems transposed, making it necessary to call imshow(M.T). Also note that in order to obtain the correct axes labeling, you need to set the imshow's extent to the extremal values of the xe and ye edge arrays. 

import matplotlib.pyplot as plt
from matplotlib.colors import LogNorm
import numpy as np; np.random.seed(9)

x = np.random.rayleigh(size=9900)
y = np.random.rayleigh(size=9900)

M, xe, ye = np.histogram2d(x, y, bins = 80)

extent = [xe[0], xe[-1], ye[0], ye[-1]]
plt.imshow(M.T, extent=extent, norm = LogNorm(), origin=""lower"")

plt.show()



",,,false,,,
https://stackoverflow.com/questions/41538059,false,"The issue does not meet the criteria for deeper analysis as it is a specific question about creating a dictionary from values of a function and using it for a graph, and does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.",,,,,,,"Create a dictionary from values of a function, and using that for a graph","what I am trying to do is make a math function that takes input n and outputs a. I input a larger number and this goes through a while loop, subtracts one from that value, prints a, and repeats until a certain value of n. What I want to do is to put this into a dictionary, with n as a key and a as a value, and use that to graph via matplotlib. Looking around a bit there, it doesn't seem like it takes dictionaries, only lists or arrays, so it might be best to make separate lists of keys and values, then input that, and change markers and such. Here is the code I have so far:

def intan(n=3):
    a = 180 -(360/n)
    while n &gt;= 3:
        print(a)
        n -= 1
        intan(n)

intan(4)
    '''Returns strange output of 90.0, 60.0, 90.0,
    instead of just the first two'''


As you can see, there is still a slightly odd error with the code where it cycles through the outputs more than once, but after some tinkering I can't quite figure out why that is. Thank you guys!

Update: The odd error is fixed by StephenRauch's helpful suggestion.
",,,,false,,,
https://stackoverflow.com/questions/41432010,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Strange Error: QObject::~QObject: Timers cannot be stopped from another thread,"This code is running fine as far producing the required output is concerned but is displaying a strange error message:


  QObject::~QObject: Timers cannot be stopped from another thread.


from multiprocessing import Pool,Manager
import matplotlib.pyplot as plt
import numpy as np
import time

def scatter_join(args):
    num = args[2]
    print(num)
    plt.scatter(args[0],args[1],s=1)
    plt.savefig('test_p'+str(num)+'.png')
    if args[3].empty() is False:
        args[4].acquire()
        (ax,fig) = args[3].get()
        ax.scatter(args[0],args[1],s=1)
        args[3].put((ax,fig))
        args[4].release()
    else:
        args[4].acquire()
        fig = plt.figure()
        ax = fig.add_subplot(111)
        ax.scatter(args[0],args[1],s=1)
        args[3].put((ax,fig))
        args[4].release()

    return None



if __name__ == '__main__':
    p = Pool()
    m = Manager()
    q = m.Queue()
    l = m.Lock()
    snap = []
    for looper in range(0,50):
        np.random.seed(int(time.time()))
        snap.append( np.random.normal(0+np.random.randint(-5,5),20+np.random.randint(-5,5),(10000,2)) )

    task = [(snap[x][:,0],snap[x][:,1],x,q,l) for x in range(0,50)]
    t = time.time()
    results = p.map(scatter_join,task,chunksize=18)

    p.close()
    p.join()
    print('Time Elapsed(Parallel): ', abs((time.time()-t)))

    (ax,fig) = q.get()
    fig.savefig('superimposedimg.png')


    t = time.time()
    for looper in range(0,50):
        print(looper)
        np.random.seed(int(time.time()))
        plt.scatter(snap[looper][:,0],snap[looper][:,1],s=1)
        plt.savefig('test_s'+str(looper)+'.png')
        plt.clf()
    print('Time Elapsed(Linear): ',abs(time.time()-t))


I basically want to use multiprocessing to plot plot graphs in a simgle matplotlib object.
","When plotting like that, you need to make sure the backend
is set to the agg backend.  You can do that in a matplotlibrc file or
directly in the plotting script, immediately after importing matplotlib
and before importing pyplot (if you use pyplot at all).

# do this before importing pylab or pyplot
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt


http://matplotlib.org/faq/howto_faq.html#howto-webapp

Also you may plot in isolation. For eg:

fig = plt.figure()
fig, ax = plt.subplots()
 &gt; plot stuff, scatterplot, etc..., set title, lables, etc...
fig.savefig(filename, format='png', dpi=100, facecolor='w',
edgecolor='k') 
plt.close(fig)


NB: Since we close the plot after you don't have to use fig.clf() to clear.
",,,false,,,
https://stackoverflow.com/questions/27489534,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Matplotlib floating point format issue,"I experience strange behaviour loading a FANN2 network from file in Python 2 while using Matplotlib or PyQtGraph simultaneously. I need to plot FANN network's MSE in real time. I will use matplotlib with interactivity and while True loop or Thread to update plot.
Create neural network and store to file:
#!/usr/bin/python2

from fann2 import libfann
import matplotlib.pyplot as plt

PLOT = False

if PLOT:
    plt.show()
    axes = plt.subplot(111)

connection_rate = 1
layers = (10, 5)
activation_f = libfann.SIGMOID_SYMMETRIC_STEPWISE
ann = libfann.neural_net()
ann.create_sparse_array(connection_rate, layers)
ann.randomize_weights(-0.1, 0.1)
ann.save('my_network.ann')

PLOT flag disables plot. Output file, last line:
connections (connected_to_neuron, weight)=(0, -9.04591381549835205078e-02) ...

... means omitted characters. After I change PLOT to True corresponding line looks like:
connections (connected_to_neuron, weight)=(0, -7,55163878202438354492e-02) ...

This leads to errors loading saved network:
from fann2 import libfann
ann = libfann.neural_net()
ann.create_from_file('my_network.ann')


FANN Error 4: Error reading ""connection_rate"" from configuration file ""my_network.ann"".

How to fix this? Should I change a floating point number format in Matplotlib? PyQtGraph gives same results:
#!/usr/bin/python2

from fann2 import libfann
import pyqtgraph as pg

PLOT = False

if PLOT:
pg.plot([1, 2], [3, 4], pen=None, symbol='o')

connection_rate = 1
layers = (10, 5)
activation_f = libfann.SIGMOID_SYMMETRIC_STEPWISE
ann = libfann.neural_net()
ann.create_sparse_array(connection_rate, layers)
ann.randomize_weights(-0.1, 0.1)
ann.save('my_network.ann')

","Add connection_rate in ""my_network.ann"" (and settings like cascade_min_out_epochs that FANN2 complains about):
connection_rate = 0.7000 {or whichever you prefer}

When I updated libfann to FANN2 on loading configuration file I got:

FANN Error 3: Wrong version of configuration file, aborting read of configuration file “myfile.net”. segmentation fault

Fixed it by adding settings FANN2 complained about.
",,,false,,,
https://stackoverflow.com/questions/22591174,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,,,,,,false,,,
https://stackoverflow.com/questions/70252697,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Matplotlib animation.FuncAnimation() animation miss first frame?,,,,,false,,,
https://stackoverflow.com/questions/2066279,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,The memory usage reported by guppy differ from ps command,"I am profiling my twisted server. It uses much more memory than I expected. Its memory usage grows over time.

 ps -o pid,rss,vsz,sz,size,command
  PID   RSS    VSZ    SZ    SZ COMMAND
 7697 70856 102176 25544 88320 twistd -y broadcast.tac


As you can see it costs 102176 KBs, namely, 99.78125 MBs. And I use guppy from a twisted manhole to watch the memory usage profile.

&gt;&gt;&gt; hp.heap()
Partition of a set of 120537 objects. Total size = 10096636 bytes.
 Index  Count   %     Size   % Cumulative  % Kind (class / dict of class)
     0  61145  51  5309736  53   5309736  53 str
     1  27139  23  1031596  10   6341332  63 tuple
     2   2138   2   541328   5   6882660  68 dict (no owner)
     3   7190   6   488920   5   7371580  73 types.CodeType
     4    325   0   436264   4   7807844  77 dict of module
     5   7272   6   407232   4   8215076  81 function
     6    574   0   305776   3   8520852  84 dict of class
     7    605   1   263432   3   8784284  87 type
     8    602   0   237200   2   9021484  89 dict of type
     9    303   0   157560   2   9179044  91 dict of zope.interface.interface.Method
&lt;384 more rows. Type e.g. '_.more' to view.&gt;


Hum... It seems there is something wrong. Guppy shows that the total usage of memory is 10096636 bytes, namely 9859.996 KBs or 9.628 MBs.

That's a huge difference. What's wrong this strange result? What am I doing wrong?

Update:
I wrote a monitor script last night. It records the memory usage and number of on-line users. It is a radio server, so you can see there is radios and total listeners. Here is the figure I generated by matplotlib.


Something is strange. Sometimes the memory usage printed by ps is very low, like this

2010-01-15 00:46:05,139 INFO 4 4 17904 36732 9183 25944
2010-01-15 00:47:03,967 INFO 4 4 17916 36732 9183 25944
2010-01-15 00:48:04,373 INFO 4 4 17916 36732 9183 25944
2010-01-15 00:49:04,379 INFO 4 4 17916 36732 9183 25944
2010-01-15 00:50:02,989 INFO 4 4 3700 5256 1314 2260


What is the reason of the super low value of memory usage? And what's more, even there is no on-line radios, no listeners, the memory usage is still high.
",,,,false,,,
https://stackoverflow.com/questions/58050200,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,How to draw a planar graph with networkx?,"I'm trying to draw a planar portayal of a digraph with the python packages ""matplotlib"" and ""networkx"".
I've tried using the ""networkx.planar_layout"" for the node positions in the plot, but don't like the outcome.
In the following example, ""graph"" is a (planar) directed graph. The keys of the dictionary ""graph"" are the nodes. The value of a key is a list, which contains all neighbors of this node:
import networkx as nx
import matplotlib.pyplot as plt

graph = {'s1': ['v', 't1','w'],
     's2': ['t1','s1'],
     's3': ['v','w'],
     's4': ['x','y'],
     'x': ['v','w'],
     'v': ['t1', 'w'],
     'w': ['y','t1','t2'],
     'y': ['v','t1','t2'],
     't1': [],
     't2': []
     }

def main(G):
    fig = plt.figure()
    fig.show()

    graph = nx.DiGraph()

    for v in G.keys():
        graph.add_node(v)

    for delta in G.items():
        for w in delta[1]:
            graph.add_edge(delta[0],w)

    posit = nx.planar_layout(G)

    nx.draw(graph, posit , with_labels = True)
    fig.canvas.draw()


main(graph)

The image i get: 
What I don't like about it is that the nodes are lined up in a way which results in a ""stack"" of edges. For example, it is not possible to tell from the plot where the edge (s2,t1) is really ending, since the edges are all overlapping in this part of the Image (I don't even think this fits the definition of a planar portrayal of my graph, which is strange since the layout I used is called ""planar_layout"" and the graph is in fact planar).
Is there a better way to plot this?
","I've found a function that could help:
I'm using ""nx.draw_planar"" instead of ""nx.draw"" like this:
def main(G):
    fig = plt.figure()
    fig.show()

    graph = nx.DiGraph()

    for v in G.keys():
        graph.add_node(v)

    for delta in G.items():
        for w in delta[1]:
            graph.add_edge(delta[0],w)

    #posit = nx.shell_layout(G) #ISN'T NEEDED ANYMORE

    nx.draw_planar(graph,with_labels = True, alpha=0.8) #NEW FUNCTION
    fig.canvas.draw()


    main(graph)

I get the following result:

The problem with this solution is that I don't get to save the node positions as in the previous version with ""posit"". I would like to use those later in the program, though. Does anyone know how I can get them without using a layout from networkx?
","The important thing is to ensure that the graph is actually planar.
One way of doing this is by using a PlanarEmbedding rather than a DiGraph - while the PlanarEmbedding is a subclass of DiGraph, it ensures that the graph is planar.
import json
from random import random

import networkx as nx
import matplotlib.pyplot as plt


def draw(n : dict):
    g = nx.PlanarEmbedding()
    g.set_data(n)
    pos = nx.planar_layout(g)  # here are your positions.
    # pos = nx.spring_layout(g, pos=pos, seed=int(2**32 - 1 * random()))
    nx.draw_networkx(g, pos, with_labels=True)
    plt.show()

if __name__ == '__main__':
    j_obj = {}
    with open('planar.json', 'r') as infile:
        nodes = json.load(infile)
        infile.close()
    draw(nodes)

planar.json
{
   ""s1"": [""s2"",""t1"",""w"", ""v""],
   ""s2"": [""t1"",""s1""],
   ""s3"": [""w"",""v""],
   ""s4"": [""x"",""y""],
   ""x"": [""v"",""w"",""s4""],
   ""v"": [""s1"",""s3"",""w"",""x"",""y"",""t1""],
   ""w"": [""t1"",""t2"",""y"",""x"",""v"",""s3"",""s1""],
   ""y"": [""v"",""s4"",""w"",""t2"",""t1""],
   ""t1"": [""s2"",""v"",""y"",""w"",""s1""],
   ""t2"": [""y"",""w""]
}



",,false,,,
https://stackoverflow.com/questions/23455226,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Parametric equation with numpy,,,,,false,,,
https://stackoverflow.com/questions/18982418,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Discontinuous timeseries plot with dates on x-axis,,,,,false,,,
https://stackoverflow.com/questions/4787821,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,bundle_files = 1 fails with py2exe using matplotlib,,,,,false,,,
https://stackoverflow.com/questions/37899364,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,autoscaling not working on drawing arrow,,,,,false,,,
https://stackoverflow.com/questions/31589300,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Matplotlib shows different fonts when saving jpg with respect to png. Why?,,,,,false,,,
https://stackoverflow.com/questions/23405728,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Matplotlib figure window disappears when in interactive mode,"I need to use interactive mode when plotting with matplotlib (it should be a script, not python or ipython console). But setting plt.ion() causes a strange bug (?). When I try to plot my figure (I don't think it really matters, what I do exactly, because in non-interactive mode it works perfectly fine) I don't see it - I get a blank grey window for split-second, which momentarily disappears and the programme exits.
If I explicitly add plt.draw() (and plt.pause(1) to see the result), I see that the figure appears as expected. If I do the same after modifications I want to do to the figure when it is visible, the figure changes. But the window still disappears after the pause is over.

I run it in Spyder with Qt4Agg as a backend under Ubuntu. Tried running the script from terminal as python my_script.py, the result is identical.

What could be the problem? How do I stop the figure from disappearing when in interactive mode?

UPDATE

Working example:

import matplotlib.pyplot as plt
import numpy as np

plt.ion()

x = np.linspace(1, 10)
y = np.sin(x)
plt.plot(x, y)
plt.draw()
plt.pause(1)


If I run this code I see the sine plot for 1 second, then the window disappears.

UPDATE 2

I found a solution here: https://stackoverflow.com/a/10724654/1304161
If I set the run options in Spyder correctly, it works perfectly fine. Although running it in gnome-terminal doesn't work, I don't really need it. Hopefully, there won't be a problem with this when it becomes a part of a GUI app...
","You can make it work by adding these two lines at the end:

plt.ioff()
plt.show()


So this program works fine:

import matplotlib.pyplot as plt
import numpy as np

plt.ion()

x = np.linspace(1, 10)
y = np.sin(x)
plt.plot(x, y)
plt.draw()
plt.ioff()
plt.show()

","To display multiple figures at different times, you can use code.interact(local=locals()), after plt.show() to pause the Python interpreter until a Ctrl-Z is pressed in the Python Shell:
import code
import matplotlib.pyplot as plt
import numpy as np

# Start pyplot's ""interactive mode"" which lets you run plt.show multiple times
plt.ion()

x = np.linspace(1, 10)
y = np.sin(x)

# PLOT #1 - displayed
plt.plot(x, y)
plt.draw()
plt.show()

# Wait for figure to be closed AND Ctrl-Z pressed in Python Shell
code.interact(local=locals())

print(""Some more code can go here..."")

# PLOT #2 - displayed
plt.plot(x, y)
plt.show()

# Wait for figure to be closed AND Ctrl-Z pressed in Python Shell
code.interact(local=locals())

",,false,,,
https://stackoverflow.com/questions/33890596,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,using matplotlib from main and spawned process,,,,,false,,,
https://stackoverflow.com/questions/30699403,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,py2exe exe closes immediately after launch,,,,,false,,,
https://stackoverflow.com/questions/24824192,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Redisplaying plots in Matplotlib in conjunction with PyQt,,,,,false,,,
https://stackoverflow.com/questions/64120358,true,"The issue involves the matplotlib API plot_surface, which exhibits unexpected behavior in the colormap scaling with the z-axis.",matplotlib,plot_surface,"The colormap used in the plot_surface API does not scale with the z-axis, resulting in incorrect color representation of the z-scale. This can be observed when taking a straight line of constant z, where the same color is not seen throughout.",The plot_surface API is typically used to create 3D surface plots with correct colormap scaling.,The issue is triggered when using plot_surface with a colormap that does not scale properly with the z-axis.,This issue might be challenging to detect for users who are not familiar with the specific behavior of the plot_surface API or those who assume that the colormap scaling is handled automatically.,matplotlib plot_surface colormap does not scale with the z-axis,"I try to make simple 3D plot with plot_surface of matplotlib, below is the minimum example:
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import cm
x_test = np.arange(0.001, 0.01, 0.0005)
y_test = np.arange(0.1, 100, 0.05)

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')

Xtest, Ytest = np.meshgrid(x_test, y_test)

Ztest = Xtest**-1 + Ytest

surf = ax.plot_surface(Xtest, Ytest, Ztest,
                       cmap=cm.plasma, alpha=1,
                       antialiased=False)

fig.colorbar(surf, shrink=0.5, aspect=5)
ax.set_ylabel(r'$ Y $', fontsize=16)
ax.set_xlabel(r'$ X $', fontsize=16)
ax.set_zlabel(r'$ Z $', fontsize=16)


The result gives strange colormap, that does not represent the magnitude of the z scale, as you can see from here 3D plot result.
I mean if you take a straight line of constant Z, you don't see the same color.
I've tried to change the ccount and rcount inside plot_surface function or changing the interval of the Xtest or Ytest data, nothing helps.
I've tried some suggestion from here and here. But it seems not related.
Could you help me how to solve this? It seems a simple problem, but I couldn't solve it.
Thanks!
Edit
I add example but using the original equation that I don't write it here (it's complicated), please take a look: Comparison.
While the left figure was done in Matlab (by my advisor),
the right figure by using matplotlib.
You can see clearly the plot on the left really make sense,
the brightest color always on the maximum z-axis. Unfortunately, i don't know matlab. I hope i can do it by using python,
Hopefully this edit makes it more clear of the problem.
Edit 2
I'm sure this is not the best solution. That's why I put it here, not as an answer. As suggested by @swatchai to use the contour3D.
Since surface is set of lines, I can generate the correct result by plotting a lot of contour lines, by using:
surf = ax.contour3D(Xtest, Ytest, Ztest, 500, cmap=cm.plasma,
                 alpha=0.5, antialiased=False)

The colormap is correct as you can see from herealternative1
But the plot is very heavy. When you zoom-in, it doesn't look good, unless you increase again the number of the contour.
Any suggestion are welcome :).
","I guess, the formal answer to plot this kind of surface is by using Axes3D.contour and Axes3D.contourf. Based on documentation
, for example:
surf2 = ax.contourf(Xtest, Ytest, Ztest, 250, cmap=cm.plasma,
                    alpha=0.6, antialiased=False)
surf = ax.contour(Xtest, Ytest, Ztest, 250, cmap=cm.plasma,
                  alpha=0.6, antialiased=False)

The result is here. The colormap shows correct z-scale.
It's not as perfect as smooth surface, as it depends on how much we zoom it or how much we put the contour. I don't know if there's a way to create this by plot_surface. thanks @swatchai.
","I don't know how this can be achieved but maybe some words on why this is happening.
plot_surface generates a mesh where the vertices are defined by x and y and z.
Each patch has 4 corners and gets a color corresponding to its z value. Looking at the plot it
could be the maximal z value of the 4 corners (just a guess).
And if you look closely the colors of the patches actually do get lighter as you move in +y direction.
But what is far more obvious are the color changes in x direction, producing the slopes you mentioned.
But this can not be avoided if each patch has just a single color.
You can see this maybe more clearly if you change the formula to Z = (X**-1 + 10 * Y)

","The behavior of the surface plot is not what you expect. Only contour3D or contourf3D can display such behavior. Here is relevant code that you can try to get the plot that follows:
surf = ax.plot_surface(Xtest, Ytest, Ztest, cmap=cm.plasma, alpha=0.55)
ax.contourf3D(Xtest, Ytest, Ztest, cmap=cm.plasma)

The plot that show both surface and contourf3D:

",false,,,
https://stackoverflow.com/questions/22591174/pandas-multiple-conditions-while-indexing-data-frame-unexpected-behavior,false,The behavior is due to a misunderstanding of logical operators and conditions in pandas rather than a problem with the API itself.,,,,,,,,,,,,false,,,
https://stackoverflow.com/questions/61688891,false,The issue is related to creating a filled volume of a Lorenz Attractor and does not involve an API exhibiting unexpected failures or behaviors.,,,,,,,How best to create a filled volume of Lorenz Attractor in python for volume rendering,"I am trying to create a 3D array to then perform volume rendering on (in other software or volume rendering packages) of strange attractor like Lorenz Attractor. It is easy enough to plot the attractor from data points and provide a value to assign a color and visualize in matplotlib for example. 

However I would like a filled volume array. I have tried interpolation methods like griddata but it doesn't give the desired result. What I am envisioning is something like: 

Which is from the wikipedia page. 

Here is what I have tried but if you open the result in a simple viewer it doesn't look great. I am thinking instead maybe doing a interpolation only between the points that make up the x,y,z array... I am a little lost after playing with this for several hours. What I think I need is to take the points and do some sort of interpolation or filling into an array, here I am calling interp_im. This can then be viewed in volume rendering. Any help is greatly appreciated on this!

import numpy as np
import matplotlib.pyplot as plt
from scipy.integrate import odeint
from scipy.interpolate import griddata
from scipy.interpolate import LinearNDInterpolator
from skimage.external import tifffile

rho = 28.0
sigma = 10.0
beta = 8.0 / 3.0

def f(state, t):
    x, y, z = state  # Unpack the state vector
    return sigma * (y - x), x * (rho - z) - y, x * y - beta * z  # Derivatives

state0 = [1.0, 1.0, 1.0]
t = np.arange(0.0, 40.0, 0.01) #t = np.arange(0.0, 40.0, 0.01)

states = odeint(f, state0, t)

# shift x,y,z positions to int for regular image volume

x = states[:, 0]
y = states[:, 1]
z = states[:, 2]
x_min = x.min()
y_min = y.min()
z_min = z.min()
states_int = states + [abs(x_min),abs(y_min),abs(z_min)] + 1
states_int = states_int * 10
states_int = states_int.astype(int)

# values will be in order of tracing for color
values = []
for i,j in enumerate(states_int):
    values.append(i*10)

values = np.asarray(values)

fig = plt.figure()
ax = fig.gca(projection='3d')
sc = ax.scatter(states_int[:, 0], states_int[:, 1], states_int[:, 2],c=values)
plt.colorbar(sc)
plt.draw()
plt.show()

#print(x.shape, y.shape, z.shape, values.shape)

#Interpolate for volume rendering
x_ = np.linspace(0,999,500)
y_ = np.linspace(0,999,500)
z_ = np.linspace(0,999,500)
xx,yy,zz = np.meshgrid(x_,y_,z_, sparse = True)
#
# X = states_int.tolist()
#
interp_im = griddata(states_int, values, (xx,yy,zz), method='linear')
interp_im = interp_im.astype(np.uint16)

np.save('interp_im.npy', interp_im)

tifffile.imsave('LorenzAttractor.tif', interp_im)


","Your data is in the volume, it is just pixelated. If you blur the volume, for example with a gaussian, you get something much more usable. For example:

from scipy import ndimage

vol = np.zeros((512, 512, 512), dtype=states_int.dtype)
# add data to vol
vol[tuple(np.split(states_int, vol.ndim, axis=1))] = values[:, np.newaxis]
# apply gaussian filter, sigma=5 in this case
vol = ndimage.gaussian_filter(vol, 5)


I would then use something like napari to view the data in 3D:

import napari

with napari.gui_qt():
    napari.view_image(v)




To make the volume smoother you may want to reduce your integration step size.
",,,false,,,
https://stackoverflow.com/questions/42055415,false,The issue does not provide sufficient information or code to determine if it involves an API exhibiting unexpected failures or behaviors.,,,,,,,Undesired colorbar and axis labels/plot titles interaction,,,,,false,,,
https://stackoverflow.com/questions/11898073,false,The issue does not provide sufficient information or code to determine if it involves an API exhibiting unexpected failures or behaviors.,,,,,,,How can I draw a cross which follows my mouse cursor?,,,,,false,,,
https://stackoverflow.com/questions/67408807,false,The issue does not provide sufficient information or code to determine if it involves an API exhibiting unexpected failures or behaviors.,,,,,,,y-axis in scatter plot not monotonic,"I am plotting the data from a .csv file using matplotlib. The data in the file is well behaved - meaning the x labels are equally spaced and monotonic increasing from line 1 to the end.
The y-axis of the plot however, starts at the minimum y-value and increases vertically to the maximum value and THEN jumps back down to a lesser value and DECREASES from there.  Very strange.
Opening the csv file in excel and plotting the same columns results in a normal plot.
import pandas as pd 
import matplotlib.pyplot as plt
weather = pd.read_csv('Weather 210221.csv', names=['Timestamp', 'Wind Speed', 'Wind Direction', 'Outdoor Temp', 'Rain Total', 'Barometer', 'Indoor Temp', 'Outdoor Humidity', 'Indoor Humidity', 'Rain Today', '1 min. Ave Wind Speed', 'Heat Index', 'Dew Point', 'Wind Chill'])
weather.plot.scatter(x='Timestamp', y='Outdoor Temp', title='Temps')
plt.show()

Any ideas what could be happening?  I would attach the data file if I knew how
","found the answer. Apparently python is interpreting my data as strings.  I need to convert to float somehow.  I don't know how to do that yet but I'll figure that out next.
Solution
",,,false,,,
https://stackoverflow.com/questions/65263282,false,"The issue does not involve an API exhibiting unexpected failures or behaviors, but rather a question about displaying a PDF file in Colab.",,,,,,,Display a pdf file using colab,"I have saved some images of my work in .pdf format using matplotlib, I know this is my fault from the beginning and I should save it directly as image but I did not know that I can not display pdf files on colab. To get these results I need another 10 days which is not good choice for me.
Actually I have found this which express my problem precisely but there was not answer.
It just seems strange to me that using matplotlib I can save pdf files but I can not load them using it again.
I just need to display the pdf file in colab cell ,I have tried:
import subprocess
subprocess.Popen(['myfile.pdf'],shell=True)


and this was the result:
&lt;subprocess.Popen at 0x7f4d6a395978&gt;
another methods as in this page do not work for me
","In a Jupyter notebook / Colab you can simply
from pdf2image import convert_from_path

images = convert_from_path(""myfile.pdf"")
images[0]  # first page

The image will be able to render as the cell output. No need for IPython.display
","Ok this works for me, maybe there are a simpler solution but for now this works
from pdf2image import convert_from_path
from IPython.display import display, Image

images = convert_from_path(""myfile.pdf"")
for i, image in enumerate(images):    
    fname = ""image"" + str(i) + "".png""
    image.save(fname, ""PNG"")
Image(fname, width=600, height=300)



",,false,,,
https://stackoverflow.com/questions/62822121,false,"The issue does not involve an API exhibiting unexpected failures or behaviors, but rather a question about contour line errors in plt.contour.",,,,,,,Contour line error with plt.contour in python 3,"I am plotting a contour plot in python 3 with matplotlib, and I am getting a strange result. At first, I was using plt.contourf, and notices there was a strange north-south linear artifact in the data that I knew shouldn't be there (I used simulated data). So I changed plt.contourf to plt.contour, and the problem seems to be that some of the edge contours are deformed for some reason (see picture).

Unfortunately, it is hard for me to past a simple version of my code because this is part of a large GUI based app. Here is what I am doing though.
#grid the x,y,z data so it can be used in the contouring
self.beta_zi = 
#This is matplot griddata, not the scipy.interpolate.griddata
griddata(self.output_df['x'].values,self.output_df['y'].values,
                              self.output_df['Beta'].values,
                              self.cont_grid_x,
                              self.cont_grid_y,
                              interp='linear')

    #call to the contour itself
self.beta_contour=self.beta_cont_ax.contour(self.cont_grid_x,self.cont_grid_y,
                                  self.beta_zi,
                                  levels=np.linspace(start=0,stop=1, num=11, endpoint=True),
                                  cmap=cm.get_cmap(self.user_beta_cmap.get()))        

This seems like a simple problem based on the edges. Has anyone seen this before that can help. I am use a TK backend, which works better with the tkinter based GUI I wrote.
UPDATE: I also tried changing to scipy.interpolate.griddata because matplot's griddata is deprecated, but the problem is the same and persists, so it must be with the actual contour plotting function.
","I found that the problem had to do with how I was interpreting the inputs of contour and grid data.
plt.contour and matplot.griddata takes 
x = x location of sample data
y = y location of sample data
z = height or z value of sample data
xi = locations of x tick marks on grid
zi = locations of y ticks marks on grid

Typically xi and yi are all the locatoins of each grid node, which is what I was supplying, but in this case you only need the unqiue tick marks on each axis.
Thanks to this post I figured it out.
Matplotlib contour from xyz data: griddata invalid index
",,,false,,,
https://stackoverflow.com/questions/62597540,false,"The issue does not involve an API exhibiting unexpected failures or behaviors, but rather a question about disabling the 'zoom to rectangle' functionality in matplotlib.",,,,,,,How to disable &#39;zoom to rectangle&#39; programatically in matplotlib,"I'm trying to modify a pan function for matplotlib such that when pressing ctrl+leftbutton I would be able to pan the axes in the figure.
It works well.
The problem is that if the zoom button is pressed, then trying the above would also 'zoom to rectangle' would happen with strange result.
I want to automatically disable the 'zoom to rectangle' button when pressing the 'control' button.
Any ides how this can be accomplished?
Thanks!
Omri
","If the window comes from matplotlib.pyplot (rather than your own embedding) it will have a tool bar associated with it which you can access via
import matplotlib.pyplot as plt
fig, ax = plt.subplots()
tool_bar = fig.canvas.manager.toolbar

You can then set the mode attribute to '' (empty string)
However I suggest caution when doing this because if you change the mode during a pan or zoom things may not go well.
Another issue is that ctrl does not show up as a normal key, but as a modifier on another mouse or keyboard event (so we can not register a key press event to turn off the zoom).
Instead I suggest you do
if tool_bar.mode != '':
    print(""axes panning does not work with zoom enabled!"")
    return

in your callback.  It leaves it on the user to turn the zoom off, but it will work without having to reach into the (private) internals of the toolbar.
The relevant implementation is at https://github.com/matplotlib/matplotlib/blob/e73d4e056588abc201335d8a491fd9cb37d4c296/lib/matplotlib/backend_bases.py#L2781-L3275
",,,false,,,
https://stackoverflow.com/questions/60405991,false,"The issue does not involve an API exhibiting unexpected failures or behaviors, but rather a question about strange results in a stacked bar chart using matplotlib.",,,,,,,Python matplotlib stacked bar chart -- strange results,"I'm trying to plot four stacked bar charts on the same plot using Python's matplotlib library.

For each observation (obs1, obs2, obs3, obs4), I want to view the quantity of each component (c1, c2, c3, c4, c5, c6) using a stacked bar chart. This is the code I have written:

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

data = np.array([[-904., 97., 59., 5., 252., 138.], [-603., 65., 0., 29., 0., 0.], [-571., -27., 0., -28., 0., 0.], [-80., 40., 0., -9., 0., 0.]])

data2 = pd.DataFrame(data=data)
data2.index = ['obs1', 'obs2', 'obs3', 'obs4']
data2.columns = ['c1', 'c2', 'c3', 'c4', 'c5', 'c6']

ind = np.arange(4)
width = 0.4

p1 = plt.bar(ind, data2['c1'], width)
p2 = plt.bar(ind, data2['c2'], width)
p3 = plt.bar(ind, data2['c3'], width)
p4 = plt.bar(ind, data2['c4'], width)
p5 = plt.bar(ind, data2['c5'], width)
p6 = plt.bar(ind, data2['c6'], width)

plt.legend((p1[0], p2[0], p3[0], p4[0], p5[0], p6[0]), tuple(data2.columns), bbox_to_anchor = (1.05, 1), loc = 'upper left', borderaxespad = 0.)


For clarity, this is the DataFrame (used to produce the plot):

print(data2)
         c1    c2    c3    c4     c5     c6
obs1 -904.0  97.0  59.0   5.0  252.0  138.0
obs2 -603.0  65.0   0.0  29.0    0.0    0.0
obs3 -571.0 -27.0   0.0 -28.0    0.0    0.0
obs4  -80.0  40.0   0.0  -9.0    0.0    0.0


This is the plot:



Note on the plot, the bar for obs1 is at x=0, the bar for obs2 is at x=1, and so on. 

However, there are two problems:


obs1 has a value of 252 for component 5, but the height of component 5 (in purple) is substantially below 252. How can I fix this?
obs3 has a value of -27 for component 2, but this is not shown on the plot at all. How can I solve this?


Thanks.
",,,,false,,,
https://stackoverflow.com/questions/55010236,false,"The issue does not involve an API exhibiting unexpected failures or behaviors, but rather a question about x-ticks and labels missing when using set_major_locator in subplots with different x-axis limits.",,,,,,,`set_major_locator` removes x-ticks (and labels) from previous subplots?,"I ran into this strange problem with using set_major_locator(), when using subplots which have different x-axis limits. A minimal example:

import matplotlib.pyplot as pl
import matplotlib.dates as mdates
from datetime import datetime

h24 = mdates.HourLocator(interval=24)
fmt = mdates.DateFormatter('%d-%m %H:%M')

start1 = datetime(year=2016, month=7, day=7, hour=0)
end1   = datetime(year=2016, month=7, day=9, hour=0)

start2 = datetime(year=2016, month=9, day=30, hour=0)
end2   = datetime(year=2016, month=10, day=2, hour=0)

start3 = datetime(year=2016, month=5, day=8,  hour=0)
end3   = datetime(year=2016, month=5, day=10, hour=0)

pl.figure(figsize=(9,3))

ax=pl.subplot(131)
ax.set_xlim(start1, end1)
ax.xaxis.set_major_locator(h24)
ax.xaxis.set_major_formatter(fmt)

ax=pl.subplot(132)
ax.set_xlim(start2, end2)
ax.xaxis.set_major_locator(h24)
ax.xaxis.set_major_formatter(fmt)

ax=pl.subplot(133)
ax.set_xlim(start3, end3)
ax.xaxis.set_major_locator(h24)
ax.xaxis.set_major_formatter(fmt)

pl.tight_layout()


Which results in:



If I set the x-limit of all sub-plots the same (using in this case ax.set_xlim(start1, end1) for all sub-plots) it works as expected:



Also, leaving the different set_xlim()'s and removing the set_major_locator() and set_major_formatter() lines works (although I get unreadable x-labels in this case..):



Am I making a silly mistake somewhere, or are the missing x-ticks and labels in my first example a bug in Matplotlib?

p.s. Matplotlib 3.0.2, Python 3.7.2
",,,,false,,,
https://stackoverflow.com/questions/53177039,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Scatterplot of pandas DataFrame ends in KeyError: 0,"After I updated pandas (0.23.4) and matplotlib (3.01) I get a strange error trying to do something like the following:

import pandas as pd
import matplotlib.pyplot as plt


clrdict = {1: ""#a6cee3"", 2: ""#1f78b4"", 3: ""#b2df8a"", 4: ""#33a02c""}

df_full = pd.DataFrame({'x':[20,30,30,40],
                        'y':[25,20,30,25],
                        's':[100,200,300,400],
                        'l':[1,2,3,4]})

df_full['c'] = df_full['l'].replace(clrdict)

df_part = df_full[(df_full.x == 30)]

fig = plt.figure()
plt.scatter(x=df_full['x'],
            y=df_full['y'],
            s=df_full['s'],
            c=df_full['c'])
plt.show()

fig = plt.figure()
plt.scatter(x=df_part['x'],
            y=df_part['y'],
            s=df_part['s'],
            c=df_part['c'])
plt.show()


The scatterplot of the original DataFrame (df_full) is shown without problems. But the plot of the partially DataFrame raises the following error:

Traceback (most recent call last):
  File ""G:\data\project\test.py"", line 27, in &lt;module&gt;
    c=df_part['c'])
  File ""C:\Program Files\Python37\lib\site-packages\matplotlib\pyplot.py"", line 2864, in scatter
    is not None else {}), **kwargs)
  File ""C:\Program Files\Python37\lib\site-packages\matplotlib\__init__.py"", line 1805, in inner
    return func(ax, *args, **kwargs)
  File ""C:\Program Files\Python37\lib\site-packages\matplotlib\axes\_axes.py"", line 4195, in scatter
    isinstance(c[0], str))):
  File ""C:\Program Files\Python37\lib\site-packages\pandas\core\series.py"", line 767, in __getitem__
    result = self.index.get_value(self, key)
  File ""C:\Program Files\Python37\lib\site-packages\pandas\core\indexes\base.py"", line 3118, in get_value
    tz=getattr(series.dtype, 'tz', None))
  File ""pandas\_libs\index.pyx"", line 106, in pandas._libs.index.IndexEngine.get_value
  File ""pandas\_libs\index.pyx"", line 114, in pandas._libs.index.IndexEngine.get_value
  File ""pandas\_libs\index.pyx"", line 162, in pandas._libs.index.IndexEngine.get_loc
  File ""pandas\_libs\hashtable_class_helper.pxi"", line 958, in pandas._libs.hashtable.Int64HashTable.get_item
  File ""pandas\_libs\hashtable_class_helper.pxi"", line 964, in pandas._libs.hashtable.Int64HashTable.get_item
KeyError: 0


This is due to the color-option c=df_part['c']. When you leave it out – the problem doesn't occur. This hasn't happend before the updates, so maybe you're not able to reproduce this with lower versions of matplotlib or pandas (I have no idea which one causes it).

In my project the df_part = df_full[(df_full.x == i)] line is used within the update-function of a matplotlib.animation.FuncAnimation. The result is an animation over the values of x (which are timestamps in my project). So I need a way to part the DataFrame.
",,,,false,,,
https://stackoverflow.com/questions/48355655,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,OpenCV error while converting image,"I am trying to import a picture of size (540,960) using matplotlib.
This step is successfully executed. The result is stored in 'image' object (type ndarray). 

# Do relevant imports
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import numpy as np
import cv2

# Read in and grayscale the image
image = mpimg.imread(r'C:\Temp\pic24_bw.jpg')
gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)


But when I try to convert the image into another color space (Gray), using cv2.cvtColor(). I face a error:

error: C:\projects\opencv-python\opencv\modules\imgproc\src\color.cpp:11111:        error: (-215) scn == 3 || scn == 4 in function cv::cvtColor


Please help. Strange thing is this code is running successfully in another citrix environment.
",,,,false,,,
https://stackoverflow.com/questions/22591174/pandas-multiple-conditions-while-indexing-data-frame-unexpected-behavior,false,The issue does not meet the criteria for deeper analysis as it is a misunderstanding of logical operators and conditions in pandas rather than a problem with the API itself.,,,,,,,,,,,,false,,,
https://stackoverflow.com/questions/22591174,false,The issue does not meet the criteria for deeper analysis as it is a misunderstanding of logical operators and conditions in pandas rather than a problem with the API itself.,,,,,,,,,,,,false,,,
https://stackoverflow.com/questions/19556888,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,bounding box problems saving to pdf,,,,,false,,,
https://stackoverflow.com/questions/69741863,true,The issue involves a problem with plotting a tensor using Torch and Matplotlib. Further analysis is required.,,,,,,,Issue plotting a simple tensor with Torch,"Just beginning to use Pyorch, and I am trying to plot a very simple, 1-D array Tensor onto a histogram with Matplotlib.
 torch.manual_seed(8436) 
 a = torch.Tensor(1000) 

 a.normal_(0, 2.) #This will fill our array with a normal distribution
 plt.hist(a);

However, the result is strange..., and just consists of a bunch of vertical, multicolored lines.
The result I am supposed to get, which I do when entering:
plt.hist(a.numpy())

is the normal histogram.
Thanks in advance for any help!
","ok, it seems to me that here is the reason:
cbook._reshape_2D is used to preprocess the data coming into plt.hist . in 3.4.3  it returns a list of arrays with only one element each, which obviously produces the wrong image above.
in 3.2.2 , however, it returns a list with one 1D array, basically a NumPy version of the tensor we provided. and this one is plotted as expected.
I downgraded the package and it worked. Would be interested to hear other solutions.
",,,false,,,
https://stackoverflow.com/questions/62190948,true,The issue involves a problem with triangulation in Matplotlib. Further analysis is required.,,,,,,,Triangulation in Matplotlib with Provided Traingles,"I have data as follow: x, y, triangles

On MATLAB and using the trisurf function, I provide (triangles, x, y) to get the result, very straight forward.

On Matplotlib however, if I use the same data I get:


Triangles number out of bound (if I use existing triangles)
Strange line outside my geometry (red line) if I let tri.triangulation de decide on the triangles. (Delaunay triangulation).


maybe my problem requires different approach, I would be happy if someone can direct me to a better solution.

import matplotlib.pyplot as plt
import matplotlib.tri as tri
import pandas as pd
import numpy as np

dlel = pd.read_fwf('HSH_Calculation.LEL')
dlnd = pd.read_fwf('HSH_Calculation.LND')
dt = pd.read_fwf('HSH_Calculation.HTD')

xy = np.asarray(dlnd.iloc[:, 3:5])

x = xy[:, 0]
y = xy[:, 1]
triangles = np.asarray(dlel.iloc[:, 1:4])
# triang = tri.triangulation(x,y)
triang = tri.Triangulation(x, y)


plt.figure()
plt.gca().set_aspect('equal')
# plt.triplot(x, y, triangles, 'go-', lw=1.0)
plt.triplot(triang, 'go-', lw=1.0)
plt.title('triplot of user-specified triangulation')
plt.xlabel('Longitude (degrees)')
plt.ylabel('Latitude (degrees)')

plt.show()


[Calculation files][1]



[1]: https://drive.google.com/file/d/1HPlSu6HYzVpIgtT7y_maeNESUa5y1WW9/view?usp=sharing, https://drive.google.com/file/d/1YKFxfkU1iIkEfXPs9nZd6f-STkJNqT2Q/view?usp=sharing, https://drive.google.com/file/d/1njxGiYqucUv4YyhY6H0U35lfuN2_zPfw/view?usp=sharing
","Solved!
Finally discovered that this is not the right way to approach the problem.
I had to use patches.Polygon to create separately each triangle.
I later added a color map as per the function output (z).

super happy that it worked!
",,,false,,,
https://stackoverflow.com/questions/60067958,true,The issue involves a problem with Photutils DAOPhot not fitting stars well. Further analysis is required.,,,,,,,Photutils DAOPhot Not Fitting stars well?,"I recently ran across the PhotUtils package and am trying to use it to perform PSF Photometry on some images I have. However, when I try to run the code, I get very strange results. When I plot the image generated by get_residual_image(), the stars are not removed well. Some sample images are shown below. 

The first image has sigma set to 2.05, as it is in one of the sample programs in the PhotUtils documentation: 

However, the stars only appear to be removed in their center.

The second image has sigma set to 5.0. This one is especially strange. Some stars are way over-removed, some are under removed, some black squares are added to the image, etc.


Here is my code:

import photutils
from photutils.psf import DAOPhotPSFPhotometry as DAOP
from photutils.psf import IntegratedGaussianPRF as PRF
from photutils.background import MMMBackground

bkg = MMMBackground()
background = 2.5*bkg(img)
gaussian_prf = PRF(sigma=5.0)
gaussian_prf.sigma.fixed = False
photTester = DAOP(8,background,5,gaussian_prf,31)
photResults = photTester(imgStars)

finalImg = photTester.get_residual_image()


After this, I simply plot the original and final image in MatPlotLib. I use a greyscale colormap.  The reason that the left images appear slightly darker is that they use a different color scaling.

Perhaps I have set one of the parameters incorrectly?

Could someone help me out with this? Thank you!
","Looking at the residual image instantly told me that the background subtraction might be wrong. I could reproduce the result and wondered, if MMMBackground did not do the job correctly.
After taking a closer look at the documentation, Getting startet with Photutils finally gave the essential hint:

image -= np.median(image)  

",,,false,,,
https://stackoverflow.com/questions/54575834,true,The issue involves a problem with plotting with Matplotlib using List - Datetime. Further analysis is required.,,,,,,,Plot with Matplotlib using List - Datetime - Different Behaviour on Format,"Why Matplotlib has this strange behaviour with Date Data Type? 


  Matplotlib allows you to natively plots python datetime instances, and for the most part does a good job picking tick locations and string formats. 
  From the documentation  ""Fixing common date annoyances""


I also read this question that gave me some clues related to Matplotlib Date Format.
I also read the most voted questions about matplotlib and Datetime but I still don't understand the following behaviour. 

#timestamp is a &lt;class 'list'&gt;
timestamp=['2019-02-04', '2019-01-15', '2018-10-08', '2018-07-09',
           '2018-04-09', '2018-02-08', '2017-09-08', '2017-09-08',
           '2017-07-07', '2017-04-07', '2017-01-09', '2016-10-07',
           '2016-07-01', '2016-03-25', '2015-12-27', '2015-09-25',
           '2015-06-26', '2015-03-27', '2014-12-24', '2014-10-06',
           '2014-07-02', '2014-03-28', '2013-12-20', '2013-09-27',
           '2013-06-11', '2013-03-27', '2012-12-27', '2012-09-26',
           '2012-06-13', '2012-03-28', '2011-12-14', '2011-09-28',
           '2011-06-14', '2011-03-30', '2010-12-15', '2010-09-29',
           '2010-06-19', '2010-03-31', '2009-12-29', '2009-09-30',
           '2009-06-17', '2009-04-01', '2008-12-20', '2008-08-25',
           '2008-08-25', '2008-06-19', '2008-03-19', '2008-03-19',
           '2006-04-11', '2005-12-27', '2005-09-28', '2005-07-02',
           '2005-04-20', '2004-12-21', '2004-10-20', '2004-07-21',
           '2003-09-22', '2003-08-20', '2002-12-31']

#time_python is a &lt;class 'datetime.datetime'&gt;
time_python=[datetime.strptime(d, ""%Y-%m-%d"") for d in timestamp]
#time_series is a &lt;class 'pandas.core.indexes.datetimes.DatetimeIndex'&gt;
time_series=pd.to_datetime(timestamp)

array=np.arange(1,len(timestamp)+1) 

time_2_num=mdates.date2num(time_series.to_pydatetime())

#First plot using the List Format as x axes
plt.subplot(411)
plt.bar(timestamp,array)
plt.xticks(rotation='vertical')

#Second plot using the padas Datatime Format as x axes
plt.subplot(412)
plt.bar(time_series,array)
plt.xticks(rotation='vertical')
plt.subplots_adjust(hspace = 1.2)

#Third plot using the DateTime Format as x axes 
plt.subplot(413)
plt.bar(time_python,array)
plt.xticks(rotation='vertical')
plt.subplots_adjust(hspace = 1.2)

#Fourth plot using the Matplot Date Format as x axes 
plt.subplot(414)
plt.bar(time_2_num,array)
plt.xticks(rotation='vertical')
plt.subplots_adjust(hspace = 1.2)

plt.gcf().autofmt_xdate()  

plt.show()


The desired result is obviously the first plot.



I want to understand better why the bars of the II,III,IV plot has this representation, different from the I. The y input is the same for the 4 plots.
",,,,false,,,
https://stackoverflow.com/questions/47957314,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,matplotlib / scipy produces weird results when calculating and plotting multiple data sets (phase portraits of ODEs),,,,,false,,,
https://stackoverflow.com/questions/20494505,false,The issue does not meet the criteria for deeper analysis as it is not related to software development issues involving APIs.,,,,,,,language and toolkit for fast plotting of live data from serial port,,,,,false,,,
https://stackoverflow.com/questions/14345908,false,The issue does not meet the criteria for deeper analysis as it is not related to software development issues involving APIs.,,,,,,,strange looking plots in Matplotlib and django,,,,,false,,,
https://stackoverflow.com/questions/64833558,false,The issue does not meet the criteria for deeper analysis as it is not related to software development issues involving APIs.,,,,,,,Apps not popping up on macOS Big Sur 11.0.1,"It is always risky to upgrade your operation system. It is likely you will encounter some compatibility issue. I took the risk to upgrade my macOS from Catalina to the newest Big Sur. After that, the display in the new OS looks pretty, but all my PyQt5 apps could not be launched in this new OS. The GUI window does not pop up as usual, and there is no error message showing in the terminal. I spent the whole day trying to figure out what makes this problem. I found the solution but in a weird way which I feel confused.
It turns out that the apps comes back to normal after I add the following three lines in the main script.
import matplotlib
import matplotlib.pyplot as plt

matplotlib.use('TkAgg')

It seems to me the new OS has some compatibility issue with Qt5Agg back-end. But the strange thing is that this solution also works for one of the Pyqt5 app, where I don't use matplotlib at all.
The Python version I used is 3.8.4, and the PyQt5 version I have is 5.15.1.
I hope somebody could explain to me what happen under the hood that makes this solution work. Also I hope this temporary solution can help somebody with the same problem.
","A reply to the PyQt mailing list pointed out that setting this env var works:
QT_MAC_WANTS_LAYER=1

Found via Is there any solution regarding to PyQt library doesn't work in Mac OS Big Sur? and https://forums.macrumors.com/threads/pyqt5-and-big-sur.2260773/?post=29243620#post-29243620
","I can confirm that matplotlib.use('TkAgg') followed by matplotlib.use('Qt5Agg') makes things work for me, too. I whittled it down to this as also working:
# from matplotlib.backends import _tkagg
import _tkinter
import matplotlib.pyplot as plt
plt.figure()

So it's something about the compiled _tkinter module. Maybe the inputhook?
","As @Eric said, just add the following on the very start of your code, before the PySide2 import:
import os
os.environ[""QT_MAC_WANTS_LAYER""] = ""1""

Then import PyQt5/PySide2.
",false,,,
https://stackoverflow.com/questions/16905028,false,The issue does not meet the criteria for deeper analysis as it is not related to software development issues involving APIs.,,,,,,,Why is matplotlib plot produced from ipython notebook slightly different from terminal version?,"I have a strange issue. Using IPython Notebook, I created a quite extensive script using pandas and matplotlib to create a number of charts.
When my tinkering was finished, I copied (and cleaned) the code into a standalone python script (so that I can push it into the svn and my paper co-authors can create the charts as well).

For convenience, I import the standalone python script into the notebook again and create a number of charts: 

import create_charts as cc
df = cc.read_csv_files(""./data"")
cc.chart_1(df, 'fig_chart1.pdf')
...


Strange enough, the .pdf file I get using the above method is slightly different from the .pdf file I get when I run my standalone python script from my Windows 7 terminal. The most notable difference is that in a particular chart the legend is located in the upper corner instead of the lower corner. But there are other small diferences as well (bounding box size, font seems slightly different)

What could be the cause of this. And how can I troubleshoot it?
(I already shut down my notebook and restarted it, to reimport my create_charts script and rule out any unsaved changes) 
My terminal reports I am using Python 2.7.2, and pip freeze | grep ipython reports ipython 0.13.1
",,,,false,,,
https://stackoverflow.com/questions/11075436,false,The issue does not meet the criteria for deeper analysis as it is not related to software development issues involving APIs.,,,,,,,"How do I connect discontinous curves in matplotlab, scipy, or etc",,,,,false,,,
https://stackoverflow.com/questions/7450881,false,The issue does not meet the criteria for deeper analysis as it is not related to software development issues involving APIs.,,,,,,,python segmentation fault when closing / quitting,,,,,false,,,
https://stackoverflow.com/questions/48289129,false,The issue does not meet the criteria for deeper analysis as it does not involve an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,Removing space around wedge polar plots in Matplotlib,"I am starting to play around with creating polar plots in Matplotlib that do NOT encompass an entire circle - i.e. a ""wedge"" plot - by setting the thetamin and thetamax properties. This is something I was waiting for for a long time, and I am glad they have it done :)

However, I have noticed that the figure location inside the axes seem to change in a strange manner when using this feature; depending on the wedge angular aperture, it can be difficult to fine tune the figure so it looks nice.

Here's an example:

import numpy as np
import matplotlib.pyplot as plt

# get 4 polar axes in a row
fig, axes = plt.subplots(2, 2, subplot_kw={'projection': 'polar'},
                         figsize=(8, 8))

# set facecolor to better display the boundaries
# (as suggested by ImportanceOfBeingErnest)
fig.set_facecolor('paleturquoise')

for i, theta_max in enumerate([2*np.pi, np.pi, 2*np.pi/3, np.pi/3]):

    # define theta vector with varying end point and some data to plot
    theta = np.linspace(0, theta_max, 181)
    data = (1/6)*np.abs(np.sin(3*theta)/np.sin(theta/2))

    # set 'thetamin' and 'thetamax' according to data
    axes[i//2, i%2].set_thetamin(0)
    axes[i//2, i%2].set_thetamax(theta_max*180/np.pi)

    # actually plot the data, fine tune radius limits and add labels
    axes[i//2, i%2].plot(theta, data)
    axes[i//2, i%2].set_ylim([0, 1])
    axes[i//2, i%2].set_xlabel('Magnitude', fontsize=15)
    axes[i//2, i%2].set_ylabel('Angles', fontsize=15)

fig.set_tight_layout(True)
#fig.savefig('fig.png', facecolor='skyblue')




The labels are in awkward locations and over the tick labels, but can be moved closer or further away from the axes by adding an extra labelpad parameter to set_xlabel, set_ylabel commands, so it's not a big issue.

Unfortunately, I have the impression that the plot is adjusted to fit inside the existing axes dimensions, which in turn lead to a very awkward white space above and below the half circle plot (which of course is the one I need to use).

It sounds like something that should be reasonably easy to get rid of - I mean, the wedge plots are doing it automatically - but I can't seem to figure it out how to do it for the half circle. Can anyone shed a light on this?



EDIT: Apologies, my question was not very clear; I want to create a half circle polar plot, but it seems that using set_thetamin() you end up with large amounts of white space around the image (especially above and below) which I would rather have removed, if possible.

It's the kind of stuff that normally tight_layout() takes care of, but it doesn't seem to be doing the trick here. I tried manually changing the figure window size after plotting, but the white space simply scales with the changes. Below is a minimum working example; I can get the xlabel closer to the image if I want to, but saved image file still contains tons of white space around it.

Does anyone knows how to remove this white space?

import numpy as np
import matplotlib.pyplot as plt

# get a half circle polar plot
fig1, ax1 = plt.subplots(1, 1, subplot_kw={'projection': 'polar'})

# set facecolor to better display the boundaries
# (as suggested by ImportanceOfBeingErnest)
fig1.set_facecolor('skyblue')

theta_min = 0
theta_max = np.pi

theta = np.linspace(theta_min, theta_max, 181)
data = (1/6)*np.abs(np.sin(3*theta)/np.sin(theta/2))

# set 'thetamin' and 'thetamax' according to data
ax1.set_thetamin(0)
ax1.set_thetamax(theta_max*180/np.pi)

# actually plot the data, fine tune radius limits and add labels
ax1.plot(theta, data)
ax1.set_ylim([0, 1])
ax1.set_xlabel('Magnitude', fontsize=15)
ax1.set_ylabel('Angles', fontsize=15)

fig1.set_tight_layout(True)
#fig1.savefig('fig1.png', facecolor='skyblue')






EDIT 2: Added background color to figures to better show the boundaries, as suggested in ImportanteOfBeingErnest's answer.
",,,,false,,,
https://stackoverflow.com/questions/26444318,false,The issue does not meet the criteria for deeper analysis as it stems from a misunderstanding of logical operators and conditions in pandas rather than a problem with the API itself.,,,,,,,How to point pyinstaller to the right versions of MSVC?90.dll?,"I have a python application that I am trying to build as a pyinstaller distributable. A similar script builds successfully on Linux.

I am building it on Windows 7 x64, but want to build 32-bit binary for better compatibility, so I am using 32-bit python-2.7. Among my dependencies are matplotlib and pyside which require MSVC. I install a package called VCForPython27 from Microsoft.

I run into an error when I run my pyinstaller script. I get the following message:


1250 INFO: Adding Microsoft.VC90.CRT to dependent assemblies of final executable
7428 INFO: Searching for assembly x86_Microsoft.VC90.CRT_1fc8b3b9a1e18e3b_9.0.21022.8_none ...
7428 WARNING: Assembly not found
7428 ERROR: Assembly x86_Microsoft.VC90.CRT_1fc8b3b9a1e18e3b_9.0.21022.8_none not found
7475 WARNING: lib not found: MSVCR90.dll dependency of C:\Python27\python.exe
7553 INFO: Searching for assembly x86_Microsoft.VC90.CRT_1fc8b3b9a1e18e3b_9.0.21022.8_none ...
7553 WARNING: Assembly not found
7553 ERROR: Assembly x86_Microsoft.VC90.CRT_1fc8b3b9a1e18e3b_9.0.21022.8_none not found
7662 WARNING: lib not found: MSVCR90.dll dependency of C:\Windows\system32\python27.dll
7662 INFO: Analyzing C:\Python27\lib\site-packages\PyInstaller\loader\_pyi_boots



There are multiple messages like that about both the files MSVCP90.dll and MSVCR90.dll

I can see that I have a folder C:\Windows\winsxs\x86_microsoft.vc90.crt_1fc8b3b9a1e18e3b_9.0.30729.4148_none_5090ab56bcba71c2 that contains versions of both files.

This mismatch occurs both when I install my python packages from Christoph Gohlke's page and with pip (except for matplotlib, which I can't install with pip because of missing dependencies).

Strangely enough pyinstaller makes a binary. Yet, when I try to run it I get a popup saying:


WARNING: file already exists but should not:
C:\Users\Martin\AppData\Local\Temp\_MEI34922\Include\pyconfig.h



Does anyone know how I can do any of the following:


Install the precious x86_Microsoft.VC90.CRT_1fc8b3b9a1e18e3b_9.0.21022.8_none assembly? Where can I take this specific version from?
Tell python to look for the other version (x86_microsoft.vc90.crt_1fc8b3b9a1e18e3b_9.0.30729.4148_none_5090ab56bcba71c2)?
Solve the pyconfig.h unwanted presence issue? Doesn't seem to lead anywhere, but I thought I should try it too.
Find another way to build my code to a binary? It's a complicated code, running external binaries, but if I have to I will try py2exe, not sure that it would be any better though.

",,,,false,,,
https://stackoverflow.com/questions/11972096,true,"The issue involves the behavior of matplotlib when using log scales, where some points are not connected as expected. This could be considered as an unexpected behavior of the API.",,,,,,,matplotlib log scales causes missing points,"I'm having a really strange issue with matplotlib. Plotting some points looks like this:



When I switch to a log scale on the y-axis, some of the points are not connected:



Is this a bug? Am I missing something? Code is below. Comment out the log scale line to see the first graph.

import matplotlib.pyplot as plt

fig = plt.figure()
ax1 = fig.add_subplot(111)

x = [1.0, 2.0, 3.01, 4.01, 5.01, 6.01, 7.04, 8.04, 9.04, 10.05,
     11.05, 12.09, 13.17, 14.18, 15.73, 16.74, 17.74, 18.9, 19.91,
     20.94, 22.05, 23.15, 24.33, 25.48, 26.51, 27.58, 28.86, 29.93,
     30.93, 32.23, 33.25, 34.26, 35.27, 36.29, 37.33, 38.35, 39.36,
     40.37, 41.37]
y = [552427, 464338, 446687, 201960, 227238, 265140, 148903, 134851,
     172234, 120263, 115385, 100671, 164542, 171176, 28, 356, 0, 0,
     195, 313, 9, 0, 132, 0, 249, 242, 81, 217, 159, 140, 203, 215,
     171, 141, 154, 114, 99, 97, 97]

ax1.plot(x, y, c='b', marker='o')

ax1.set_yscale('log')
plt.ylim((-50000, 600000))
plt.show()

","You can try to use ax1.set_yscale('symlog')

",,,false,,,
https://stackoverflow.com/questions/25767469,false,The issue does not have enough information provided to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors under specific runtime conditions.,,,,,,,tkinter and matplotlib: windows not showing until program closes under Linux,,,,,false,,,
https://stackoverflow.com/questions/63028779,true,The issue involves an error when using tight layout with nested Matplotlib Gridspec. This could be considered as an unexpected behavior of the API.,,,,,,,Error using tight layout with nested Matplotlib Gridspec,"I'm having a strange issue with Matplotlib Gridspec. I am making a plot with a nested grid, and I would like a tight/constrained layout to avoid tick label overlap:

My idea was to use tight_layout, which worked fine before I had the nested Gridspec. Now, however I call it, I get an error. Here's a MWE that replicates the problem:
import matplotlib.pyplot as plt
import matplotlib.gridspec as gs
import numpy as np

fig = plt.figure(figsize=(15,10), constrained_layout=True)
grid = gs.GridSpec(8,5, width_ratios=[1,2,1.5,1,1], figure=fig)

a = plt.subplot(grid[0:3,0])
b = plt.subplot(grid[0:4,1])
c = plt.subplot(grid[4:,0:2])
d = plt.subplot(grid[0:2,2:])
e = plt.subplot(grid[2:4,2:])
f = plt.subplot(grid[4:6,2:])
g = plt.subplot(grid[6:,2:])

# create nested grid plot
nested_grid = gs.GridSpecFromSubplotSpec(5,5, subplot_spec=c, wspace=0, hspace=0)
c.get_xaxis().set_ticks([])
c.get_yaxis().set_ticks([])
for k in range(25):
    x, y = np.unravel_index(k, (5, 5))
    gax = fig.add_subplot(nested_grid[x, y])
    gax.set_xticklabels('')
    gax.set_yticklabels('')
    gax.set_xticks([])
    gax.set_yticks([])

grid.tight_layout(fig)

The final line here is what's suggested in the Gridspec docs; previously, I wasn't setting a figure, and I just used plt.tight_layout(), which threw an error and led me to explore the Gridspec-specific tight_layout() method. But I still get the same error:
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-14-1002aa79c5cf&gt; in &lt;module&gt;
     25     gax.set_yticks([])
     26 
---&gt; 27 grid.tight_layout(fig)

~/miniconda3/lib/python3.8/site-packages/matplotlib/gridspec.py in tight_layout(self, figure, renderer, pad, h_pad, w_pad, rect)
    412         """"""
    413 
--&gt; 414         subplotspec_list = tight_layout.get_subplotspec_list(
    415             figure.axes, grid_spec=self)
    416         if None in subplotspec_list:

~/miniconda3/lib/python3.8/site-packages/matplotlib/tight_layout.py in get_subplotspec_list(axes_list, grid_spec)
    247         if hasattr(axes_or_locator, ""get_subplotspec""):
    248             subplotspec = axes_or_locator.get_subplotspec()
--&gt; 249             subplotspec = subplotspec.get_topmost_subplotspec()
    250             gs = subplotspec.get_gridspec()
    251             if grid_spec is not None:

~/miniconda3/lib/python3.8/site-packages/matplotlib/gridspec.py in get_topmost_subplotspec(self)
    611         gridspec = self.get_gridspec()
    612         if hasattr(gridspec, ""get_topmost_subplotspec""):
--&gt; 613             return gridspec.get_topmost_subplotspec()
    614         else:
    615             return self

~/miniconda3/lib/python3.8/site-packages/matplotlib/gridspec.py in get_topmost_subplotspec(self)
    483         Return the topmost `.SubplotSpec` instance associated with the subplot.
    484         """"""
--&gt; 485         return self._subplot_spec.get_topmost_subplotspec()
    486 
    487 

AttributeError: 'AxesSubplot' object has no attribute 'get_topmost_subplotspec'

Note: I have tried using constrained_layout() with the plt.figure() call, which makes no difference (and does not work when I specify a figure in the first Gridspec call.)
EDIT: See answer below for the solution! Here's what it looks like now:

","The problem why you got this error is that the subplot_spec parameter type in gs.GridSpecFromSubplotSpec(5,5, subplot_spec=c) needs to be matplotlib.gridspec.SubplotSpec. But the type of c is matplotlib.axes._subplots.AxesSubplot.
Change c to grid[4:,0:2] could solve the problem.
gs.GridSpecFromSubplotSpec(5, 5, subplot_spec=grid[4:,0:2])

",,,false,,,
https://stackoverflow.com/questions/62853745,true,The issue involves an error in the code that leads to strange interference patterns in a matplotlib plot. This could be considered as an unexpected behavior of the API.,,,,,,,Matplotlib interference figure strange pattern,"I am trying to make an interference figure animation like this one:

The difference is that the above image shows the interference figure over time, so the constructive and destructive interference points remain fixed. On the contrary, I am trying to make an animation where I change the frequency of the two sources, keeping them fixed in the space.
Here is my code:
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation

source = 0.5
sources = [-source, source]
axlim = max(sources)*2 + 1
N = 1000

x = np.linspace(-axlim, axlim, N)
y = np.linspace(-axlim, axlim, N)
X, Y = np.meshgrid(x, y)

fig = plt.figure()

def update(f):
    plt.gca().cla()
    C1 = np.sin(2*np.pi*f*((X - sources[0])**2 + Y**2))
    C2 = np.sin(2*np.pi*f*((X - sources[1])**2 + Y**2))
    Z = C1 + C2

    plt.contour(X, Y, Z)

    plt.plot(sources, [0, 0], 'ro')
    plt.gca().set_aspect('equal')
    plt.axis('off')

ani = FuncAnimation(fig = fig, func = update, frames = 11, interval = 100)

plt.show()


The issue is that strange patterns appear like in the last frames:

those patterns are not physical (they are not consistent with physics' laws), so there must be an error in my code. I cannot find out where, but I think the issue is in the matplotlib contour function: I suspect it introduce a sort of aliasing...
","The issue is in your definition of C1 and C2: you apply the sinusoidal function to the sum of the squared x and y distances, without applying a squared root. You should use:
C1 = np.sin(2*np.pi*f*np.sqrt((X - sources[0])**2 + Y**2))
C2 = np.sin(2*np.pi*f*np.sqrt((X - sources[1])**2 + Y**2))


There is no issue with the contour plot method, however, I suggest you to replace it with contourf or, even better, imshow. The reason is that contour plot lines where your field has the same value, keeping the rest of the plot empty. On the contrary, contourf or imshow fill the empty space with the colormap you choose, so you can display your field in a better way and avoid ambiguous white spaces.
See this code for reference:
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
from matplotlib.animation import FuncAnimation

source = 0.5
sources = [-source, source]
axlim = max(sources)*2 + 1
N = 1000

x = np.linspace(-axlim, axlim, N)
y = np.linspace(-axlim, axlim, N)
X, Y = np.meshgrid(x, y)

norm = plt.Normalize(-2, 2)
cmap = LinearSegmentedColormap.from_list('', ['black', 'white', 'black'])
fig, ax = plt.subplots()

def update(f):
    ax.cla()
    C1 = np.sin(2*np.pi*f*np.sqrt((X - sources[0])**2 + Y**2))
    C2 = np.sin(2*np.pi*f*np.sqrt((X - sources[1])**2 + Y**2))
    Z = C1 + C2

    ax.imshow(Z,
              cmap = cmap,
              norm = norm)
    ax.plot(N/2*(1 + source/axlim), N/2, 'ro')
    ax.plot(N/2*(1 - source/axlim), N/2, 'ro')

    ax.set_title(f'f = {f} Hz')
    ax.set_aspect('equal')
    ax.axis('off')

ani = FuncAnimation(fig = fig, func = update, frames = 11, interval = 100)

plt.show()


Since peaks and valleys of your field are both constructive interference points, while in the destructive points the field is null, I chose a black - white - black colormap, you cannot distinguish peaks from valleys but it is easier to distinguish constructive from destructive interference points.
",,,false,,,
https://stackoverflow.com/questions/53350917,true,The issue involves the behavior of matplotlib artists when removing them from a plot. This could be considered as an unexpected behavior of the API.,,,,,,,matplotlib storing and removing artist,"I have encountered a strange issue with matplotlib artists.

Disclaimer: Unfortunately I only ever used matplotlib in jupyter notebooks and in a tkinter GUI (the latter is where I found this) so I do not know how to write simple code that will replicate the issue. However I do not think sample is code is absolutely needed in this case.

Now the issue:

In the interest of speeding up plotting in a GUI I do not plot everything anew whenever elements of the plot change but rather make use of methods like set_ydata and canvas.draw. Sometimes it is also necessary to remove lines altogether which can be accomplished with artist.remove. Here is the problem: When I have one or several artist(s) stored in a list I can successfully remove them from the plot by iterating over the list and calling remove. If however I store the reference directly (as an attribute of the class that is managing plots), calling remove does not do anything.

As sketch of the code suppose we have

import matplotlib.pyplot as plt
fig = plt.figure()
ax = fig.add_subplot()


the first case is generated by something like

artist_list = list()
for x in range(5):
    line = ax.axhline(x)
    artist_list.append(line)


and can be removed by 

for line in artist_list:
    line.remove()
artist_list = list()


(the last is needed for this to work).

whereas the second would be 

line = ax.axhline(1)
line.remove()


which does not remove the line from the plot (even if del line or line = None are added).

It seems that storing the artist in a list and then assigning that variable to a new empty list is somehow a more complete removal than reassigning the variable that stores the artist directly or even deleting it. Does somebody know what is going here? How could a line be removed if it is simply stored as line rather than in a list?
","As can be seen from the below piece of code, removing a line is pretty easy. Indeed, you just call .remove() on the object in question and redraw the canvas.

import matplotlib.pyplot as plt

fig, ax = plt.subplots()
ax.set(title=""Click to remove line"", xlim=(0,2))

line=ax.axvline(1)

def remove_line(event):
    line.remove()
    fig.canvas.draw()

fig.canvas.mpl_connect(""button_press_event"", remove_line)

plt.show()

",,,false,,,
https://stackoverflow.com/questions/44056833,true,The issue involves the matplotlib.scatter function not accepting a numpy array as the color argument.,Matplotlib,matplotlib.scatter,The issue arises when trying to pass a numpy array as the color argument to the matplotlib.scatter function. This results in a ValueError with the message 'Invalid RGBA argument'.,The matplotlib.scatter function works as expected when the color argument is a valid RGBA color or a sequence of valid RGBA colors.,The issue is triggered when attempting to pass a numpy array as the color argument to the matplotlib.scatter function.,This issue might be challenging to detect during development and testing because the error message does not clearly indicate that the problem lies with the color argument being a numpy array.,matplotlib.scatter color argument not accepting numpy array,"I have written the following python plotting script using matplotlib:

import pynbody as pyn
import numpy as np
import matplotlib.pyplot as plt
import glob

s = pyn.load('./ballsV2.00001')
sl = s.g[np.where((s.g['z'] &lt; 0.005) &amp; (s.g['z']&gt;-0.005))]

sx = s.s['x'][0]
sy = s.s['y'][0]
sz = s.s['z'][0]
r2 = ((s.g['x']-sx)**2+(s.g['y']-sy)**2+(s.g['z']-sz)**2)
Flux = np.array(1./(4*np.pi*r2)*np.exp(-1*7.00114988051*np.sqrt(r2)))

print(type(np.log10(sl['radFlux'])))
print(type(np.log10(Flux)))

plt.figure(figsize = (15,12))
#plt.scatter(sl['x'],sl['y'],c=np.log10(sl['radFlux']),s=75,edgecolors='none', marker = '.',vmin=-6,vmax=1)
plt.scatter(sl['x'],sl['y'],c=np.log10(Flux),s=75,edgecolors='none', marker = '.',vmin=-8,vmax=4)
plt.xlim([-0.5,0.5])
plt.ylim([-0.5,0.5])
plt.xlabel(""x"")
plt.ylabel(""y"")
plt.colorbar(label=""log(Code Flux)"")
plt.savefig('./ballsV2_0.1.pdf')
plt.savefig('./ballsV2_0.1.png')
plt.show()
plt.close()


When I run the script I get the following error:

foo@bar ~/Data/RadTransfer/Scaling_Tests/ballsV2 $ py 
balls.py 
balls.py:15: RuntimeWarning: divide by zero encountered in log10
    print(type(np.log10(sl['radFlux'])))
&lt;class 'numpy.ndarray'&gt;
&lt;class 'numpy.ndarray'&gt;

Traceback (most recent call last):
  File ""/home/grondjj/anaconda3/lib/python3.6/site-packages/matplotlib/colors.py"", line 141, in to_rgba
    rgba = _colors_full_map.cache[c, alpha]
KeyError: (-4.1574455411341349, None)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/grondjj/anaconda3/lib/python3.6/site-packages/matplotlib/colors.py"", line 192, in _to_rgba_no_colorcycle
    c = tuple(map(float, c))
TypeError: 'numpy.float64' object is not iterable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""balls.py"", line 17, in &lt;module&gt;
    plt.scatter(sl['x'],sl['y'],c=np.log10(Flux),s=75,edgecolors='none', marker = '.',vmin=-8,vmax=4)
  File ""/home/grondjj/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py"", line 3435, in scatter
    edgecolors=edgecolors, data=data, **kwargs)
  File ""/home/grondjj/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py"", line 1892, in inner
    return func(ax, *args, **kwargs)
  File ""/home/grondjj/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4028, in scatter
    alpha=alpha
  File ""/home/grondjj/anaconda3/lib/python3.6/site-packages/matplotlib/collections.py"", line 890, in __init__
    Collection.__init__(self, **kwargs)
  File ""/home/grondjj/anaconda3/lib/python3.6/site-packages/matplotlib/collections.py"", line 139, in __init__
    self.set_facecolor(facecolors)
  File ""/home/grondjj/anaconda3/lib/python3.6/site-packages/matplotlib/collections.py"", line 674, in set_facecolor
    self._set_facecolor(c)
  File ""/home/grondjj/anaconda3/lib/python3.6/site-packages/matplotlib/collections.py"", line 659, in _set_facecolor
    self._facecolors = mcolors.to_rgba_array(c, self._alpha)
  File ""/home/grondjj/anaconda3/lib/python3.6/site-packages/matplotlib/colors.py"", line 237, in to_rgba_array
    result[i] = to_rgba(cc, alpha)
  File ""/home/grondjj/anaconda3/lib/python3.6/site-packages/matplotlib/colors.py"", line 143, in to_rgba
    rgba = _to_rgba_no_colorcycle(c, alpha)
  File ""/home/grondjj/anaconda3/lib/python3.6/site-packages/matplotlib/colors.py"", line 194, in _to_rgba_no_colorcycle
    raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c))
ValueError: Invalid RGBA argument: -4.1574455411341349


Ignore the divide by zero stuff,the issue is the scatter plot function isn't taking my array of values to map colour to. What is strange is that the commented out scatter plot command above it runs fine. The only difference is the array of values I am passing it. I made sure to cast them to the same type (they are both &lt;class 'numpy.ndarray'&gt;). Also, the values themselves are more sane ranging between ~4000 and 1E-7 in the Flux array, it is only the np.log10(sl['radFlux'] that has the divide by zero errors and that one works. Any suggestions?
",,,,false,,,
https://stackoverflow.com/questions/43891136,false,The issue is a result of a misunderstanding of logical operators and conditions in pandas rather than a problem with the API itself.,,,,,,,Timeserie datetick problems when using pandas.DataFrame.plot method,"I just discovered something really strange when using plot method of pandas.DataFrame. I am using pandas 0.19.1. Here is my MWE:

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import pandas as pd

t = pd.date_range('1990-01-01', '1990-01-08', freq='1H')
x = pd.DataFrame(np.random.rand(len(t)), index=t)

fig, axe = plt.subplots()
x.plot(ax=axe)
plt.show(axe)

xt = axe.get_xticks()


When I try to format my xticklabels I get strange beahviours, then I insepcted objects to understand and I have found the following:


t[-1] - t[0] = Timedelta('7 days 00:00:00'), confirming the DateTimeIndex is what I expect;
xt = [175320, 175488], xticks are integers but they are not equals to a number of days since epoch (I do not have any idea about what it is);
xt[-1] - xt[0] = 168 there are more like index, there is the same amount that len(x) = 169.


This explains why I cannot succed to format my axe using:

axe.xaxis.set_major_locator(mdates.HourLocator(byhour=(0,6,12,18)))
axe.xaxis.set_major_formatter(mdates.DateFormatter(""%a %H:%M""))


The first raise an error that there is to many ticks to generate
The second show that my first tick is  Fri 00:00 but it should be Mon 00:00 (in fact matplotlib assumes the first tick to be 0481-01-03 00:00, oops this is where my bug is).



It looks like there is some incompatibility between pandas and matplotlib integer to date conversion but I cannot find out how to fix this issue.

If I run instead:

fig, axe = plt.subplots()
axe.plot(x)
axe.xaxis.set_major_formatter(mdates.DateFormatter(""%a %H:%M""))
plt.show(axe)

xt = axe.get_xticks()


Everything works as expected but I miss all cool features from pandas.DataFrame.plot method such as curve labeling, etc. And here xt = [726468.  726475.].

How can I properly format my ticks using pandas.DataFrame.plot method instead of axe.plot and avoiding this issue?

Update

The problem seems to be about origin and scale (units) of underlying numbers for date representation. Anyway I cannot control it, even by forcing it to the correct type:

t = pd.date_range('1990-01-01', '1990-01-08', freq='1H', origin='unix', units='D')


There is a discrepancy between matplotlib and pandas representation. And I could not find any documentation of this problem.
",,,,false,,,
https://stackoverflow.com/questions/44682789,false,The issue is not related to an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Python Bar Chart not Displaying Correctly (Matplotlib),"I have some data I'd like to display in 2 stacked bar charts (side by side).  Using matplotlib.
keys=['BF', 'VL', 'GM', 'VM']
data=[[0.10992407597195027, 0.084754817342900857],
 [0.20119173770112833, 0.24308696457787043],
 [0.49912704691619575, 0.53468456580435009],
 [0.18975713941072578, 0.13747365227487865]]
x = range(2)

f, ax1 = plt.subplots(1, figsize=(10,5))

plt.bar(x,data[0], label=keys[0])
plt.bar(x,data[1], bottom=data[0], label=keys[1])
plt.bar(x,data[2], bottom=data[1], label=keys[2])
plt.bar(x,data[3], bottom=data[2],label=keys[3])

plt.legend(loc='upper left')
plt.show()

The above code displays the following graph:

It seems to me that the red bar (VM) has not been stacked on top of the rest of the bars, leading to the strange look of the graph (despite me specifying the correct bottom attribute.  The data in each bar should sum to 1 exactly.  How can I fix this?
EDIT:
I was able to fix the issue by setting the bottom attribute to the sum of the lower bars, rather than just the lower one explicitly, using the following rather messy code:
plt.bar(x,data[0], width = bar_width, label=keys[0])
plt.bar(x,data[1], width = bar_width, bottom=data[0], label=keys[1])
plt.bar(x,data[2], width = bar_width, bottom=[data[0][i]+data[1][i] for i in x], label=keys[2])
plt.bar(x,data[3], width = bar_width, bottom=[data[0][i]+data[1][i]+data[2][i] for i in x],label=keys[3]

Is there a better way to do this?  It doesn't scale well with more bars.
",,,,false,,,
https://stackoverflow.com/questions/29300510,false,The issue is not related to an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,matplotlib UserWarning When log axis is used in some cases,"Basically I am running some optimisation algorithms that I have created using Numpy and I want to plot the log of the error against the number of iterations. Having done this with linear regression and having had no issues, it is very strange that I seem to get issues when doing the exact same thing with logistic regression. I get the following ""warning"":  


  /usr/lib64/python2.6/site-packages/matplotlib/axis.py:1004:
  UserWarning: Unable to find pixel distance along axis for interval
  padding; assuming no interval padding needed.   warnings.warn(""Unable
  to find pixel distance along axis for interval padding; assuming no
  interval padding needed."")


However, when I don't use a log axis for the y axis, I don't get the error either. All the elements of the array that I am using are also positive, so it shouldn't have anything to do with taking the log of a non-positive number.

Has anyone ever encountered this before? Does anyone know what it may be referring to?

Thanks
","not sure if this issue is still open, but I had a similar problem and updating seaborn fixed the issue for me. For you it might be matplotlib, depending which package you used for creating the graph.
",,,false,,,
https://stackoverflow.com/questions/71410497,false,The issue is not related to an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,How to plot data from a .kml file using matplotlib on python 3.7 and Windows 10&quot;?,"I will first give a little bit of context to my problem.
I have obtained a .kml file of the territorial seas around the world on the site : https://www.marineregions.org/downloads.php, and I would like to display it not on Google Earth but on a matplotlib.pyplot plot (with a cartopy map if possible too). The .kml file looks like this :
&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;
&lt;kml xmlns=""http://www.opengis.net/kml/2.2"" xmlns:gx=""http://www.google.com/kml/ext/2.2"" xmlns:kml=""http://www.opengis.net/kml/2.2"" xmlns:atom=""http://www.w3.org/2005/Atom""&gt;
&lt;NetworkLink&gt;
    &lt;name&gt;Territorial Seas (12NM) v3&lt;/name&gt;
    &lt;description&gt;&lt;![CDATA[Flanders Marine Institute (2019). Maritime Boundaries Geodatabase: Territorial Seas (12NM), version 3. Available online at &lt;a href=""http://www.marineregions.org""&gt;http://www.marineregions.org&lt;/a&gt; https://doi.org/10.14284/387. Consulted on YYYY-MM-DD.]]&gt;&lt;/description&gt;
    &lt;Link&gt;
        &lt;href&gt;http://geo.vliz.be/geoserver/gwc/service/kml/MarineRegions:eez_12nm.png.kml&lt;/href&gt;
    &lt;/Link&gt;
&lt;/NetworkLink&gt;
&lt;/kml&gt;

For that I saws on this other stackoverflow question (Reading KML Files Using Fastkml) that using fastkml to read the file was possible.
So this is the test.py code I am trying to run (it comes from the usage guide https://fastkml.readthedocs.io/en/latest/usage_guide.html#read-a-kml-file-string):
from fastkml import  kml

filename = ""C:\\Users\\dumasal\\Documents\\GOOGLE_EARTH\\MarineRegions-eez_12nm.kml""
with open(filename, 'rt', encoding=""utf-8"") as myfile:
    doc=myfile.read()
    print(doc)
    
    # Create the KML object to store the parsed result
    k = kml.KML()
    
    # Read in the KML string
    k.from_string(doc)
    print('k = ', k)
    
    ### Next we perform some simple sanity checks ###
    
    # Check that the number of features is correct
    # This corresponds to the single ``Document``
    features = list(k.features())
    print(len(features))
    
    # Check that we can access the features as a generator
    # (The two Placemarks of the Document)
    print(features[0].features())
    f2 = list(features[0].features())
    print(len(f2))
    
    # Check specifics of the first Placemark in the Document
    print(f2[0])
    print(f2[0].description)
    print(f2[0].name)
    
    # Check specifics of the second Placemark in the Document
    print(f2[1].name)
    f2[1].name = ""ANOTHER NAME""
    
    # Verify that we can print back out the KML object as a string
    print(k.to_string(prettyprint=True))

When I ran it I got the error: ""ValueError: Unicode strings with encoding declaration are not supported. Please use bytes input or XML fragments without declaration."".
I looked the error up on google and found this git-hub page (https://github.com/cleder/fastkml/issues/57) where they were saying that the ""from_string()"" function only takes bytes so the beginning of my code could be changed to :
from fastkml import  kml

filename = ""C:\\Users\\dumasal\\Documents\\GOOGLE_EARTH\\MarineRegions-eez_12nm.kml""
with open(filename, 'r') as myfile:
    doc=myfile.read().encode('UTF-8')
    print(doc)
    
    # Create the KML object to store the parsed result
    k = kml.KML()
    
    # Read in the KML string
    k.from_string(doc)
    print('k = ', k)

    ### Next we perform some simple sanity checks ###
    
    # Check that the number of features is correct
    # This corresponds to the single ``Document``
    features = list(k.features())
    print(len(features))

And strangely enough the ValueError stopped appearing. However now I get the error :
IndexError: list index out of range

this is because my variables features = [], and I don't know why.
So could you either explain to me why the features variable is empty, or a more direct method to plot a .kml file with python and matplotlib?
Thank you very much !
","One issue is the KML file you have is a super-overlay, which is auto-generated as multiple KML ""files"" referenced as NetworkLinks in sub regions and few KML python packages support recursive NetworkLinks directly. The fastkml module you're using does not implement NetworkLinks so the content is skipped.
The pyKML package can parse the KML file and iterate over the KML layers referenced in the Network Links.
You can do something like this to iterate over the NetworkLinks and the KML content.
import requests
import re
from pykml import parser

count = 0

def walk(elt):
    global count
    for elt in elt.getchildren():
        tag = re.sub(r'^.*\}', '', elt.tag)
        if tag in ['Folder', 'Document']:
            walk(elt)
        elif tag == 'NetworkLink':
            print(tag)
            print(elt.Link.href)
            if count == 10:
                # for debugging stop after 10 links
                raise Exception(""too many links"")
            count += 1
            response = requests.get(elt.Link.href)
            walk(parser.fromstring(response.content))
        elif tag == 'GroundOverlay':
            print(tag)
            # do something with the ground overlay
        else:
            # other tag; e.g. Region, comment, etc
            print(""&gt;&gt;"", tag)

with open(""MarineRegions-eez_12nm.kml"", 'rb') as myfile:
    root = parser.parse(myfile).getroot()
walk(root)

The MarineRegions KML is a super-overlay that recursively sub-divides into smaller regions so trying to plot the GroundOverlay at all levels will be overwrite the larger low-res overlays with smaller hi-res overlays. You need to decide if you only want the hi-res ground overlays or the low-res overlays. For example, if the KML content at a given level doesn't have any NetworkLinks then it's at the lowest level.
Note GeoServer has two different types of super-overlays: raster and vector. The KML you're using is a raster super-overlay. You may want to check if there is a vector overlay available in the case dealing with vectors might be easier than dealing with ground overlay images.
",,,false,,,
https://stackoverflow.com/questions/63495493,true,"The issue involves plotting global contour data that crosses both the meridian and the dateline, resulting in unexpected striping.",CartoPy,plt.contourf,"When plotting global contour data that crosses both the meridian and the dateline, the contour plot shows striping artifacts. Attempting to fix the issue by adjusting the longitudes to positive values results in an IllegalArgumentException with the message 'Invalid number of points in LinearRing found 3 - must be 0 or >= 4'.",The plt.contourf function works as expected when plotting data that does not cross both the meridian and the dateline.,The issue is triggered when plotting global contour data that crosses both the meridian and the dateline.,This issue might be challenging to detect during development and testing because the error message does not provide clear guidance on how to resolve the problem.,Plotting global contour data that crosses both the meridian and the dateline,"So I have two different datasets.  I have one that is a polar orbiting satellite that starts near the north pole goes down towards Africa then goes over the south pole and back up the Atlantic ocean.  I also have a Global composite of a number of Geostationary satellites.  That grid is a full global coverage from -90 to 90 latitude, and 0 to -0.2 (around the dateline) longitudes.
So when I plot my polar orbiting data.  I get a funny striping across the northern hemisphere where the satellite crosses the dateline.  Like this...
polar orbiting data
I did a search and found that if I do this to my longitude values
lons[lons &lt; 0] += 360

that it then removes the strange striping.  I think it actually just moves the stripes to the southern hemisphere (where is crosses the meridian), but since that area is all ""missing"" values it doesn't show on the plot, so I don't care.
polar orbiting data - longitudes all positive
So now there is the problem of the full Global dataset.  When I plot it without converting all the longitudes to positive values, it has quite a few stripes going on.  I believe it is every place there is rain that crosses the dateline.
Global dataset
When I try to apply the ""fix"" that worked for the polar data I get a really nasty very uninformative error.
IllegalArgumentException: Invalid number of points in LinearRing found 3 - must be 0 or &gt;= 4

Process finished with exit code 139 (interrupted by signal 11: SIGSEGV)

There is no traceback or anything, so I'm not even sure if it is matplotlib or cartopy or what that is throwing the error.
I've tried cropping the image by using set_extent() but it still has the stripes.
Any ideas how to fix this, or how to trick matplotlib/cartopy into plotting the data correctly?

Adding code, but not sure how much it will actually be of help.  It is pretty basic.  The issue is more with the fact that the rain data covers the full globe.
normal_proj = ccrs.PlateCarree(central_longitude=0)
pos_lons = lon_data.copy()
pos_lons[pos_lons &lt; 0] += 360
cs = plt.contourf(pos_lons, lat_data, rr_data, clevs, cmap=cmap,
                      transform=normal_proj, norm=norm)

","I think you're running into an annoying, but difficult to track down bug in CartoPy. Basically, in transforming the contours and clipping them to the map extent it generates some Shapely geometries incorrectly. Some things that have worked to get around the problem (not solve it) include slightly adjusting the map boundaries and adjusting the contour levels.
",,,false,,,
https://stackoverflow.com/questions/52344307,true,"The issue involves the behavior of the matplotlib fill_between function when the color parameter is set, leading to unexpected results.",Matplotlib,fill_between,"When the color parameter is set in the fill_between function, the gap in the plot disappears, and the edge line is drawn with rounded borders.",The fill_between function works as expected when the color parameter is not set.,The issue is triggered when the color parameter is set in the fill_between function.,This issue might be challenging to detect because it is not immediately obvious that setting the color parameter would affect the appearance of the plot.,Matplotlib: fill_between drawing rounded edges in SVG when color is set,"I've encountered a strange issue when using matplotlibs fill_between with data that has a tight gap. For example, when I simply want to plot the following data and save it as SVG, it works:

import matplotlib.pyplot as plt

plt.fill_between([0,1e4-1000,1e4,1e4+1000,1e6], [1000,1000,1,1000,1000])
plt.savefig(""test.svg"")




But when I set the color to any value, the gap disappears:

import matplotlib.pyplot as plt

plt.fill_between([0,1e4-1000,1e4,1e4+1000,1e6], [1000,1000,1,1000,1000], color='tab:red')
plt.savefig(""test_colored.svg"")




After zooming in I noticed the edge line is drawn with rounded borders:


How can I change the plot color without this gap disappearing?
I've tried to set different kwargs like capstyle, joinstyle, antialiased, rasterized,... to all possible values without success.
","You are setting the color of the patch. This would include the edgecolor and the facecolor. However, it seems you only want to have the face colored. Hence use facecolor='tab:red'

import matplotlib.pyplot as plt

plt.fill_between([0,1e4-1000,1e4,1e4+1000,1e6], [1000,1000,1,1000,1000], facecolor='tab:red')
plt.savefig(""test_colored.svg"")
plt.show()



",,,false,,,
https://stackoverflow.com/questions/45042722,false,The issue is not related to unexpected failures or unpredictable behaviors of an API.,,,,,,,Cartopy + Matplotlib (contourf) - Map Overriding data,"I'm trying to do a Contour Plot having the Global Map in background. 
Having in mind that my data have LON and LAT values, I decided to use Cartopy with MatplotLib.

The problem is that I can plot my data and the map perfectly when separated, but when I try to integrate the data with the map the Cartopy map override my data plot.

This is my code: 

ax = plt.axes(projection=cartopy.crs.PlateCarree())

v = np.linspace(0, 80, 25, endpoint=True)
cp = plt.contourf(matrixLon, matrixLat, matrixTec, v, transform=cartopy.crs.PlateCarree())
plt.colorbar(cp)

ax.add_feature(cartopy.feature.LAND)
ax.add_feature(cartopy.feature.OCEAN)
ax.add_feature(cartopy.feature.COASTLINE)
ax.add_feature(cartopy.feature.BORDERS, linestyle=':')
ax.set_extent([-85, -30, -60, 15])

plt.title('TEC Map')
plt.show()


Plots:

Plotting only Data

Plotting only the map

It is strange because I think that the logical is the data override the map (and maybe I have to try a transparent color scale) but not the other way around. 

Can someone help me with this issue?
",,,,false,,,
https://stackoverflow.com/questions/43844361,false,The issue is not related to unexpected failures or unpredictable behaviors of an API.,,,,,,,Plot legend goes out of window while zooming in Matplotlib plot window,"I am using Python 2.7 and plotting using matplotlib package. I have a plot with legend at top. When i try to zoom the plot window to see more information in the plot, sometimes the legend moves out of the window. I am not able to figure out why this happens. This does not happen all the time though. I have attached the code. The lists x11,x22...., temp11,...temp25 and humi11,...humi25 are data from database. The plot is displayed correctly. However i am facing issues with strange situation of legend moving out of plot window. I have also attached the portion of the image for  your reference. Kindly provide your insights. 

This is the normal view of the plot.
. 

This is the view of the plot after zooming. See the part of the legend is visible on the corner of window.



Regards

Sriniketh

import matplotlib
import matplotlib.pyplot as plt,mpld3
import matplotlib.dates as mdates
import numpy as np
from matplotlib.backends.backend_tkagg importFigureCanvasTkAgg,NavigationToolbar2TkAgg
from matplotlib.backend_bases import key_press_handler
from matplotlib.figure import Figure
import tkMessageBox   
from drawnow import *
from Tkinter import *
import  Tkinter as tk
from tkinter import ttk
from dateutil.parser import parse
import decimal
plt.subplot(211)
plt.title('Temperatur')
plt.plot((x11), (temp11), 'ro-', label='M1-Node 1')
plt.plot((x12), (temp12), 'go-', label='M1-Node 2')
plt.plot((x13), (temp13), 'bo-', label='M1-Node 3')
plt.plot((x14), (temp14), 'co-', label='M1-Node 4')
plt.plot((x15), (temp15), 'mo-', label='M1-Node 5')
plt.plot((x21), (temp21), 'ro--', label='M2-Node 1')
plt.plot((x22), (temp22), 'go--', label='M2-Node 2')
plt.plot((x23), (temp23), 'bo--', label='M2-Node 3')
plt.plot((x24), (temp24), 'co--', label='M2-Node 4')
plt.plot((x25), (temp25), 'mo--', label='M2-Node 5')

plt.ylabel('Temperatur Grad C')
# plt.legend(loc='upper left')
plt.legend(bbox_to_anchor=(0.985, 0.89),
           bbox_transform=plt.gcf().transFigure)
plt.grid(True)

plt.subplot(212)
plt.title('Relativ Luftfeuchtigkeit')
plt.plot((x11), (humi11), 'ro-', label='M1-Node 1')
plt.plot((x12), (humi12), 'go-', label='M1-Node 2')
plt.plot((x13), (humi13), 'bo-', label='M1-Node 3')
plt.plot((x14), (humi14), 'co-', label='M1-Node 4')
plt.plot((x15), (humi15), 'mo-', label='M1-Node 5')
plt.plot((x21), (humi21), 'rd-', label='M2-Node 1')
plt.plot((x22), (humi22), 'gd-', label='M2-Node 2')
plt.plot((x23), (humi23), 'bd-', label='M2-Node 3')
plt.plot((x24), (humi24), 'cd-', label='M2-Node 4')
plt.plot((x25), (humi25), 'md-', label='M2-Node 5')
plt.ylabel('Relativ Luftfeuchtigkeit')
plt.grid(True)
master = var1.get()
plt.suptitle(""Temperatur und Luftfeuchtigkeit - %s "" % (master))

plt.show()

",,,,false,,,
https://stackoverflow.com/questions/20503889,false,The issue does not provide enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,"OpenCV 1.1, IplImage can not show image correctly",,,,,false,,,
https://stackoverflow.com/questions/14419193,false,The issue does not provide enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,"hg-git can pull from forked repo, but not original repo",,,,,false,,,
https://stackoverflow.com/questions/46077477,false,The issue does not provide enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Python only printing last element of the list,,,,,false,,,
https://stackoverflow.com/questions/41050643,false,The issue does not provide enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Bug in matplotlib scatter plot script,,,,,false,,,
https://stackoverflow.com/questions/25240972,false,The issue does not provide enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,IPython keyboard interrupt CTRL + C inconsistent,"I'm getting inconsistent responses from the Keyboard interrupt Ctrl+C in interactive python (run in xterm) after plotting from matplotlib.

As expected, when executing Ctrl+C inside ipython2 I get the KeyboardInterrupt message.

However, once I plot anything using matplotlib (specifically matplotlib.pyplot) Ctrl+C will exit the interactive python session, as opposed to exiting the running script in the interactive python session (if there is one).

A primitive example.

import numpy as n
import matplotlib.pyplot as m
x = n.linspace(0,4*n.pi,500)
y = x**2*n.sin(x)

m.plot(x,y)
m.show()


Preferrable behavior would be for Ctrl+C to always only interrupt a running script (if any is running), instead of the interactive python session itself.
","I did have the same problem for a long time. Try to run ipython with qt:

ipython --matplotlib=qt

",,,false,,,
https://stackoverflow.com/questions/47143754,false,The issue does not provide enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,Matplotlib path.contains_points returns false for points on some edges but not others,"I'm attempting to use Matplotlib to find all points contained within a polygonal path, but it seems to be missing a few. More specifically, my path is a rectangle, and the points are on an underlying uniform grid. In the following test script it will not consider the points laying on the top line of the polygon as being part of the polygon, but will consider the points on the rest of the edges.

Code:

import matplotlib.path as mpltPath

polygon = [(5,5),(10,5),(10,10),(5,10)]
width =11
height =11

points = [[0,0],[1,0],[2,0],[3,0],[4,0],[5,0],[6,0],[7,0],[8,0],[9,0],[10,0],[11,0], \
          [0,1],[1,1],[2,1],[3,1],[4,1],[5,1],[6,1],[7,1],[8,1],[9,1],[10,1],[11,1],\
          [0,2],[1,2],[2,2],[3,2],[4,2],[5,2],[6,2],[7,2],[8,2],[9,2],[10,2],[11,2],\
          [0,3],[1,3],[2,3],[3,3],[4,3],[5,3],[6,3],[7,3],[8,3],[9,3],[10,3],[11,3],\
          [0,4],[1,4],[2,4],[3,4],[4,4],[5,4],[6,4],[7,4],[8,4],[9,4],[10,4],[11,4],\
          [0,5],[1,5],[2,5],[3,5],[4,5],[5,5],[6,5],[7,5],[8,5],[9,5],[10,5],[11,5],\
          [0,6],[1,6],[2,6],[3,6],[4,6],[5,6],[6,6],[7,6],[8,6],[9,6],[10,6],[11,6],\
          [0,7],[1,7],[2,7],[3,7],[4,7],[5,7],[6,7],[7,7],[8,7],[9,7],[10,7],[11,7],\
          [0,8],[1,8],[2,8],[3,8],[4,8],[5,8],[6,8],[7,8],[8,8],[9,8],[10,8],[11,8],\
          [0,9],[1,9],[2,9],[3,9],[4,9],[5,9],[6,9],[7,9],[8,9],[9,9],[10,9],[11,9],\
          [0,10],[1,10],[2,10],[3,10],[4,10],[5,10],[6,10],[7,10],[8,10],[9,10],[10,10],[11,10],\
          [0,11],[1,11],[2,11],[3,11],[4,11],[5,11],[6,11],[7,11],[8,11],[9,11],[10,11],[11,11]]


path = mpltPath.Path(polygon)
inside = path.contains_points(points)
print(inside)


As is, the code above will return

[False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False  True  True  True  True  True  True False
 False False False False False  True  True  True  True  True  True False
 False False False False False  True  True  True  True  True  True False
 False False False False False  True  True  True  True  True  True False
 False False False False False  True  True  True  True  True  True False
 False False False False False False False False False False False False]


I would expect row 5 of the result to contain True values like the ones following it. If I change the coordinates in the polygon from 5 to 4.9, then I do get the result I expect.

I'm assuming this has something to do with misusing or misunderstanding the function, but I'm not quite sure what or how that might be.

EDIT: It was brought up that contains_points should be returning False for points that fall on the edges of the polygon. In my example, we see this behaviour for the top edge [5,5]-[10,5], but not for the other edges (i.e. [5,5]-[5,10], [5,10]-[10,10], and [10,10]-[10,5]). These three other edges correspond to the first and last columns with True values and the last row containing True values in the example output above. It is this apparent inconsistency that's the problem.
","update: Is now an open issue in matplotlib.



Excluding lines on the border might be the expected behavior for a function like contains_points. However, in this case, the points on the border of a polygon are not treated in a consistent manner:

In the example you give line 5 indicates the exclusion of points on the boarder, but rows 5 10 and line 10 indicate an inclusion of the boarder points.

Drawing the path with polygon[::-1], so inversed orientation, leads to the expected behavior for all borders except for line 10 where again inclusion is applied.

To me there is no logical pattern apparent here. But even if there is one, this behavior certainly is confusing and should be fixed.



Now you can still get the desired behavior by avoiding the points to lay on the boarders of your polygon. You can do so using the radius attribute of the contains_points function: 


  radius allows the path to be made slightly larger or smaller.


So if you provide some small, positive or negative value for the radius attribute like so:

# ...
path = mpltPath.Path(polygon)
inside = path.contains_points(points,radius=0.1)

print(inside)


you get:

[False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False False False False False False False False
 False False False False False  True  True  True  True  True  True False
 False False False False False  True  True  True  True  True  True False
 False False False False False  True  True  True  True  True  True False
 False False False False False  True  True  True  True  True  True False
 False False False False False  True  True  True  True  True  True False
 False False False False False  True  True  True  True  True  True False
 False False False False False False False False False False False False]


Note, whether the radius should be positive or negative depends on the orientation. You find more information about this here. As a rule of thumb: A positive radius expands the path when the path goes counterclockwise and shrinks the path when the path goes clockwise.
",,,false,,,
https://stackoverflow.com/questions/15147287,false,The issue does not provide enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,(numpy) Wrong amplitude(?) of FFT&#39;d array?,"I'm using numpy and matplotlib to analyze data output form my simulations. There is one (apparent) inconsistency that I can't find the roots of. It's the following:

I have a signal that has a given energy a^2~1. When I use rfft to take the FFT and compute the energy in the Fourier space, it comes out to be significantly larger. To void giving the details of my data etc., here is an example with a simple sin wave:

from pylab import *
xx=np.linspace(0.,2*pi,128)
a=np.zeros(128)
for i in range(0,128):
    a[i]=sin(xx[i])
aft=rfft(a)
print mean(abs(aft)**2),mean(a**2) 


In principle both the numbers should be the same (at least in the numerical sense) but this is what I get out of this code:

62.523081632 0.49609375


I tried to go through numpy.fft documentation but could not find anything. A search here gave the following but I was not able to understand the explanations there:

Big FFT amplitude difference between the existing (synthesized) signal and the filtered signal

What am I missing/ misunderstanding? Any help/ pointer in this regard would be greatly appreciated.

Thanks!
","Henry is right on the non-normalization part, but there is a little more to it, because you are using rfft, not fft. The following is consistent with his answer:

&gt;&gt;&gt; x = np.linspace(0, 2 * np.pi, 128)
&gt;&gt;&gt; y = 1 - np.sin(x)
&gt;&gt;&gt; fft = np.fft.fft(y)
&gt;&gt;&gt; np.mean((fft * fft.conj()).real)
191.49999999999991
&gt;&gt;&gt; np.mean(y**2)
1.4960937500000004
&gt;&gt;&gt; fft = fft / np.sqrt(len(fft))
&gt;&gt;&gt; np.mean((fft * fft.conj()).real)
1.4960937499999991


But if you now try the same with rfft, things don't quite work out:

&gt;&gt;&gt; rfft = np.fft.rfft(y)
&gt;&gt;&gt; np.mean((rfft * rfft.conj()).real)
314.58462009358772
&gt;&gt;&gt; rfft /= np.sqrt(len(rfft))
&gt;&gt;&gt; np.mean((rfft * rfft.conj()).real)
4.8397633860551954
65
&gt;&gt;&gt; np.mean((rfft * rfft.conj()).real) / len(rfft)
4.8397633860551954


The following does work properly, though:

&gt;&gt;&gt; (rfft[0] * rfft[0].conj() +
...  2 * np.sum(rfft[1:] * rfft[1:].conj())).real / len(y)
1.4960937873636722


When you use rfft what you are getting is not properly the DFT of your data, but only the positive half of it, since the negative would be symmetric to it. To compute the mean, you need to consider every value other than the DC component twice, which is what the last line of code does.
","In most FFT libraries, the various DFT flavours are not orthogonal. The numpy.fft library applies the necessary normalizations only during the inverse transform.

Consider the Wikipedia description of the DFT; the inverse DFT has the 1/N term that the DFT does not have (in which N is the length of the transform). To make an orthogonal version of the DFT, you need to scale the result of the un-normalised DFT by 1/sqrt(N). In this case, the transform is orthogonal (that is, if we define the orthogonal DFT as F, then the inverse DFT is the conjugate, or hermitian, transpose of F).

In your case, you can get the correct answer by simply scaling aft by 1.0/sqrt(len(a)) (note that N is found from the length of the transform; the real FFT just throws about half the values away, so it's the length of a that is important).

I suspect that the reason for leaving the normalization until the end is that in most situations, it doesn't matter and you therefore save the computational cost of doing the normalization twice. Indeed, the very quick FFTW library doesn't do any normalization in either direction, and leaves it entirely up to the user to deal with.

Edit: Just to be clear, the explanation above is not quite correct. The correct answer will not be arrived at with that simple scaling, as in your case the DC component will be added in twice, although 1.0/sqrt(len(a)) is still the correct scaling to produce the unitary transform.
",,false,,,
https://stackoverflow.com/questions/63797535,false,The issue does not provide enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,"Confusion Matrix ValueError: Found input variables with inconsistent numbers of samples: [3, 360]",,,,,false,,,
https://stackoverflow.com/questions/33158726,false,The issue does not provide enough information to determine if it involves an API exhibiting unexpected failures or unpredictable behaviors.,,,,,,,"Fitting data to multimodal distributions with scipy, matplotlib","I have a dataset that I would like to fit to a known probability distribution. The intention is to use the fitted PDF in a data generator - such that I can sample data from the known (fitted) PDF. Data will be used for simulation purposes. At the moment I am just sampling from a normal distribution, which is inconsistent with the real-data, therefore simulation results are not accurate. 

I first wanted to use the following method : 
Fitting empirical distribution to theoretical ones with Scipy (Python)?

My first thought was to fit it to a weibull distribution, but the data is actually multimodal (picture attached). So I guess I need to combine multiple distributions and then fit the data to the resulting dist, is that right ? Maybe combine a gaussian AND a weibull distirbution ?

How can I use the scipy fit() function with a mixed/multimodal distribution ?

Also I would want to do this in Python (i.e. scipy/numpy/matplotlib), as the data generator is written in Python.

Many thanks !


","I would suggest Kernel Density Estimation (KDE). It gives you a solution as a mixture of PDF.

SciPy has only Gaussian kernel (which lookes fine for your specific histogram), but you can find other kernels in the statsmodels or scikit-learn packages.

For reference, those are the relevant functions:

from sklearn.neighbors import KernelDensity
from scipy.stats import gaussian_kde
from statsmodels.nonparametric.kde import KDEUnivariate
from statsmodels.nonparametric.kernel_density import KDEMultivariate


A great resource for KDE in Python is here.
",,,false,,,
